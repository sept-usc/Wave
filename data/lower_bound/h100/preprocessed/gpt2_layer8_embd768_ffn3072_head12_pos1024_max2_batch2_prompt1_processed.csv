Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,2.944,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,15.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.936,19.232,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.416,23.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,28.8,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,32.416000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,35.232000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.952000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,41.28000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.872,45.15200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,48.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,51.71200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.16,55.872000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,59.13600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,62.52800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.712,66.24000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,5.12,71.36000000000003,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,4.704,76.06400000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,79.52000000000002,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,82.94400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.024,87.96800000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.624,94.59200000000003,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.232,113.82400000000003,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.32,118.14400000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,122.27200000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.32,126.59200000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.544,139.13600000000005,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.944,158.08000000000004,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,161.53600000000003,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.432,167.96800000000002,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,20.0,187.96800000000002,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,191.424,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.552,194.976,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,198.4,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,201.792,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,205.15200000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,37264.0,91424.0,3072.0,0,0.0,94496.0,94496.0,0.0,96.0,0.0,24576.0,24576.0,3.488,208.64000000000001,6144.0,13824.0,35728.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.232,211.872,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.328,215.20000000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),43,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.816,234.01600000000002,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.576,238.592,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,241.95200000000003,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.4,248.35200000000003,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.328,267.68,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.352,272.032,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.256,276.288,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.608,280.896,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.064,292.96000000000004,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",52,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.264,312.22400000000005,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,315.61600000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.496,322.112,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.456,341.56800000000004,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",56,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,344.86400000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",57,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.264,348.12800000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,351.42400000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,354.91200000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,358.14400000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,37280.0,91456.0,3072.0,0,0.0,94528.0,94528.0,0.0,96.0,0.0,24576.0,24576.0,3.424,361.56800000000004,6144.0,13824.0,35744.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.584,365.15200000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",63,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.52,368.672,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),64,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.752,387.42400000000004,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.512,391.93600000000004,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,395.61600000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.464,402.08000000000004,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.104,421.184,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.16,425.34400000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.384,429.72800000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.8,434.5280000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.128,446.65600000000006,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.328,465.98400000000004,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,469.408,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.624,476.03200000000004,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",76,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.808,495.84000000000003,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.168,499.00800000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",78,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.488,502.49600000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,506.04800000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,509.63200000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,512.8320000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,37186.0,91268.0,3072.0,0,0.0,94340.0,94340.0,0.0,96.0,0.0,24576.0,24576.0,3.584,516.416,6144.0,13824.0,35650.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",83,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.424,519.84,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.456,523.296,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),85,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.72,542.0160000000001,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.992,547.008,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.744,550.7520000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.624,557.3760000000001,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.008,576.3840000000001,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.416,580.8000000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.512,585.3120000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,589.4400000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.224,601.6640000000002,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.136,620.8000000000002,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,624.2560000000002,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.432,630.6880000000002,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",97,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.104,649.7920000000003,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,653.3120000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",99,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.52,656.8320000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,660.0640000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",101,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,663.3600000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,666.9120000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,37250.0,91396.0,3072.0,0,0.0,94468.0,94468.0,0.0,96.0,0.0,24576.0,24576.0,3.552,670.4640000000003,6144.0,13824.0,35714.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",104,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.296,673.7600000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.2,676.9600000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),106,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.592,695.5520000000004,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.736,700.2880000000004,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,703.7440000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.4,710.1440000000003,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",110,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.328,729.4720000000003,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.544,734.0160000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,738.1440000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.384,742.5280000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.224,754.7520000000004,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.752,773.5040000000004,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.264,776.7680000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.624,783.3920000000004,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.424,802.8160000000004,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,806.3680000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",120,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.36,809.7280000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",121,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,812.9280000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,816.2560000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,819.7440000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,37208.0,91312.0,3072.0,0,0.0,94384.0,94384.0,0.0,96.0,0.0,24576.0,24576.0,3.52,823.2640000000005,6144.0,13824.0,35672.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",125,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.264,826.5280000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,829.9200000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),127,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.656,848.5760000000005,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.608,853.1840000000004,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,856.6720000000005,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.528,863.2000000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.04,882.2400000000005,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.16,886.4000000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.192,890.5920000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.448,895.0400000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.16,907.2000000000004,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.816,926.0160000000004,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,929.3760000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.528,935.9040000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.552,955.4560000000005,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",140,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.264,958.7200000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",141,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.296,962.0160000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",142,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,965.5680000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,968.9600000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",144,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,972.1600000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",145,37256.0,91408.0,3072.0,0,0.0,94480.0,94480.0,0.0,96.0,0.0,24576.0,24576.0,3.584,975.7440000000006,6144.0,13824.0,35720.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.392,979.1360000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",147,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.488,982.6240000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),148,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.784,1001.4080000000007,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.704,1006.1120000000006,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,1009.6960000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.656,1016.3520000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.232,1035.5840000000005,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,1039.7120000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.512,1044.2240000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.32,1048.5440000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.16,1060.7040000000004,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.88,1079.5840000000005,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,1083.0720000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.816,1089.8880000000006,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.712,1109.6000000000006,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,1112.9600000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",162,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.392,1116.3520000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",163,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,1119.6480000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1123.1360000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",165,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,1126.3360000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,37224.0,91344.0,3072.0,0,0.0,94416.0,94416.0,0.0,96.0,0.0,24576.0,24576.0,3.552,1129.8880000000006,6144.0,13824.0,35688.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",167,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.584,1133.4720000000007,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",168,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.264,1136.7360000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),169,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.72,1155.4560000000006,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.608,1160.0640000000005,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,1163.6160000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.304,1169.9200000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.104,1189.0240000000006,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.384,1193.4080000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.48,1197.8880000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,1202.0160000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,49152.0,1632768.0,0.0,0,14495514624.0,1632768.0,14497147392.0,12768.0,24.0,0.99812382739212,18432.0,6144.0,12.064,1214.0800000000006,1234944.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,576.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.944,1233.0240000000006,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,1236.6400000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,1243.0080000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.552,1262.5600000000004,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,1266.1120000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.616,1269.7280000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,1273.1200000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,1276.5120000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,1279.9360000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,37268.0,91432.0,3072.0,0,0.0,94504.0,94504.0,0.0,96.0,0.0,24576.0,24576.0,3.648,1283.5840000000003,6144.0,13824.0,35732.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.424,1287.0080000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,1290.4000000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),190,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.752,1309.1520000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.608,1313.7600000000002,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,1317.1200000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.496,1323.6160000000002,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,77998976.0,170473088.0,1608448.0,0,0.0,172081536.0,172081536.0,1884696.0,1558034.0,0.5474422914373186,155809792.0,697856.0,59.456,1383.0720000000001,6432896.0,9650688.0,77194752.0,804224.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4869056.0,21808.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1385.8880000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.968,1389.8560000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,1393.2800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,128.0,101376.0,256.0,0,0.0,101632.0,101632.0,0.0,1580.0,0.0,402080.0,402080.0,3.52,1396.8000000000002,0.0,101376.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,1399.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26432.0,5.792,1405.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,826.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,48000.0,0.0,96000.0,0,0.0,96000.0,96000.0,6600.0,41304.0,0.1377755511022044,2569600.0,0.0,8.096,1413.76,0.0,0.0,0.0,48000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26688.0,5.6,1419.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,834.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,28800.0,0.0,57600.0,0,0.0,57600.0,57600.0,6600.0,41904.0,0.13607125185551708,2569600.0,0.0,8.096,1427.456,0.0,0.0,0.0,28800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26240.0,5.632,1433.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,820.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,44800.0,0.0,89600.0,0,0.0,89600.0,89600.0,6600.0,41404.0,0.13748854262144822,2569600.0,0.0,8.16,1441.248,0.0,0.0,0.0,44800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26176.0,5.888,1447.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,818.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,41600.0,0.0,83200.0,0,0.0,83200.0,83200.0,6600.0,41504.0,0.13720272742391484,2569600.0,64.0,8.224,1455.36,0.0,0.0,0.0,41600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,3232.0,416.0,3.744,1459.1039999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,1462.4319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,416.0,0.0,5.6,1468.0319999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,1470.9439999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,416.0,0.0,5.728,1476.6719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,25600.0,0.0,51200.0,0,0.0,51200.0,51200.0,23370.0,6506.0,0.7822332306868389,416224.0,4512.0,8.64,1485.312,0.0,0.0,0.0,25600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13007.0,141.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,8.832,1494.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,408000.0,32832.0,6.048,1500.192,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12750.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,3.776,1503.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,3142.0,0.0,0.0,804128.0,3.68,1507.6480000000001,0.0,0.0,0.0,100514.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,3142.0,0.977282915190514,402080.0,0.0,5.76,1513.4080000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.808,1517.2160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,32929.0,13796.0,0.7047405029427501,1324352.0,986016.0,14.688,1531.9040000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41386.0,30813.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,7807.0,13773.0,0.36177015755329006,1326912.0,1225664.0,11.392,1543.2960000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41466.0,38302.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,9061.0,13752.0,0.39718581510542234,1319744.0,1225664.0,12.576,1555.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41242.0,38302.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,9061.0,13714.0,0.39784851811196487,1322688.0,1119584.0,13.12,1568.9920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41334.0,34987.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,3142.0,0.8247238647774183,804128.0,0.0,4.832,1573.8240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,1577.2160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,7406.0,7325.0,0.5027493041884461,903840.0,713568.0,8.928,1586.1440000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28245.0,22299.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12568.0,0.0,1214272.0,1206208.0,4.64,1590.7840000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37946.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,1561020.0,3327522.0,307648.0,0,0.0,3635170.0,3635170.0,264.0,3352.0,0.07300884955752213,533344.0,377024.0,31.744,1622.5280000000005,412616.0,100514.0,1407196.0,153824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16667.0,11782.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,0.0,512100.0,0.0,0,0.0,512100.0,512100.0,56142.0,6284.0,0.8993368147887099,402144.0,339520.0,97.856,1720.3840000000005,512100.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12567.0,10610.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1580.0,0.0,402080.0,100416.0,3.616,1724.0000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.04,1727.0400000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,904672.0,43776.0,11.84,1738.8800000000003,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28271.0,1368.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,3.936,1742.8160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,1561026.0,3327522.0,307660.0,0,0.0,3635182.0,3635182.0,264.0,3352.0,0.07300884955752213,535392.0,376512.0,32.0,1774.8160000000003,412616.0,100514.0,1407196.0,153830.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16731.0,11766.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,27.072,1801.8880000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1805.344,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,26.56,1831.904,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1835.2,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,1838.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,1843.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,2048.0,110114.0,4096.0,0,0.0,114210.0,114210.0,152.0,791.0,0.16118769883351008,402112.0,64.0,16.192,1859.456,110114.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1862.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.184,1867.84,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,1871.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,1875.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,1106688.0,2011972.0,402432.0,0,0.0,2414404.0,2414404.0,0.0,3142.0,0.0,0.0,402080.0,4.608,1880.3519999999999,0.0,201028.0,905472.0,201216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,628334.0,1005140.0,251528.0,0,0.0,1256668.0,1256668.0,0.0,2370.0,0.0,804160.0,0.0,5.056,1885.408,0.0,0.0,502570.0,125764.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,304.0,791.0,0.2776255707762557,402112.0,64.0,22.4,1907.808,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,1911.168,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1914.56,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.904,1918.464,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,1921.9199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.872,1925.792,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,1928.48,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1931.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,1934.72,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1937.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.904,1941.376,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,32.0,32.0,5.856,1947.232,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.648,1950.8799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1954.1119999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.224,1958.3359999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.12,1963.4559999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,1967.0079999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1970.2719999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,5.024,1975.2959999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.16,1979.4559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1982.6559999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1986.0159999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.776,1989.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.808,1993.5999999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,4.896,1998.4959999999994,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,5.024,2003.5199999999993,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,2007.1679999999992,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2010.4959999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.928,2015.4239999999993,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.752,2022.1759999999992,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.04,2041.2159999999992,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,2046.6559999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,2052.2559999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.512,2056.7679999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.224,2068.9919999999997,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.232,2088.2239999999997,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,2091.7119999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.496,2098.2079999999996,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.232,2117.4399999999996,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",287,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2120.8959999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",288,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.392,2124.2879999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",289,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,2127.8079999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,2131.4239999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,2134.6239999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",292,37237.0,91370.0,3072.0,0,0.0,94442.0,94442.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2138.0799999999995,6144.0,13824.0,35701.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2141.4079999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",294,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2144.8639999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),295,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.592,2163.4559999999997,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.704,2168.16,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,2171.7439999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.592,2178.336,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",299,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,18.848,2197.1839999999997,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.632,2202.816,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,2208.16,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.48,2212.64,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.128,2224.768,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",304,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.168,2243.936,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,2247.424,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",306,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.592,2254.016,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",307,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.04,2273.056,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,2276.448,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",309,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.552,2280.0,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,2283.36,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,2286.6240000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2289.952,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,37245.0,91386.0,3072.0,0,0.0,94458.0,94458.0,0.0,96.0,0.0,24576.0,24576.0,3.52,2293.472,6144.0,13824.0,35709.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",314,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.52,2296.992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",315,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,2300.416,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),316,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.944,2319.36,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",317,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.608,2323.9680000000003,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,2327.456,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,2333.824,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",320,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,18.976,2352.8,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.376,2358.1760000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,2363.7120000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.384,2368.0960000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.032,2380.1280000000006,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",325,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,19.04,2399.1680000000006,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,2402.5920000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,2408.9600000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",328,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.04,2428.0000000000005,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,2431.5520000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.648,2435.2000000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,2438.4960000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,2441.8880000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,2445.184,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,37238.0,91372.0,3072.0,0,0.0,94444.0,94444.0,0.0,96.0,0.0,24576.0,24576.0,3.872,2449.056,6144.0,13824.0,35702.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.392,2452.448,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,2455.8399999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),337,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.72,2474.5599999999995,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.704,2479.2639999999997,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,2482.624,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.624,2489.2479999999996,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",341,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.2,2508.4479999999994,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.28,2513.7279999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.376,2519.104,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.128,2523.232,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.064,2535.296,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.912,2554.2079999999996,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,2557.5679999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,2563.9359999999997,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.168,2583.104,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2586.432,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2589.888,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.264,2593.152,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,2596.704,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,2600.2560000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,37346.0,91588.0,3072.0,0,0.0,94660.0,94660.0,0.0,96.0,0.0,24576.0,24576.0,3.424,2603.6800000000003,6144.0,13824.0,35810.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.232,2606.9120000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,2610.2720000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),358,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.688,2628.9600000000005,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.608,2633.5680000000007,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,2637.1520000000005,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.464,2643.6160000000004,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,18.912,2662.5280000000002,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,2668.0640000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,2673.472,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.384,2677.856,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.128,2689.9840000000004,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.784,2708.7680000000005,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,2712.1920000000005,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.88,2719.0720000000006,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",370,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.68,2738.7520000000004,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",371,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,2741.9840000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",372,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2745.4400000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2748.7680000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",374,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,2752.0960000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.232,2755.3280000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,37263.0,91422.0,3072.0,0,0.0,94494.0,94494.0,0.0,96.0,0.0,24576.0,24576.0,3.424,2758.7520000000004,6144.0,13824.0,35727.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",377,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.392,2762.1440000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2765.6000000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),379,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.944,2784.5440000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.416,2788.9600000000005,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,2792.4160000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,2798.7840000000006,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.072,2817.8560000000007,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,2823.3920000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.376,2828.768000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.672,2833.440000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.256,2845.696000000001,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",388,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.528,2864.2240000000006,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,2867.7440000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",390,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.592,2874.3360000000007,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.552,2893.888000000001,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,2897.248000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",393,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.744,2900.992000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,2904.320000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,2907.936000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,2911.328000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,37295.0,91486.0,3072.0,0,0.0,94558.0,94558.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2914.784000000001,6144.0,13824.0,35759.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.552,2918.336000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",399,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,2921.760000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),400,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.912,2940.672000000001,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",401,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.672,2945.344000000001,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,2949.024000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,2955.3920000000007,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,18.912,2974.3040000000005,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,2979.6480000000006,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.312,2984.9600000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.096,2989.0560000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.224,3001.2800000000007,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.752,3020.0320000000006,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,3023.5200000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",411,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,3029.8880000000004,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.136,3049.0240000000003,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,3052.4480000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",414,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.52,3055.9680000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",415,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,3059.3280000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,3062.5920000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",417,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,3065.9200000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,37228.0,91352.0,3072.0,0,0.0,94424.0,94424.0,0.0,96.0,0.0,24576.0,24576.0,3.648,3069.5680000000007,6144.0,13824.0,35692.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.296,3072.8640000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3076.2880000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),421,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.688,3094.9760000000006,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",422,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.672,3099.6480000000006,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,3102.9760000000006,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,3109.3440000000005,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,3548160.0,7188480.0,18432.0,0,0.0,7206912.0,7206912.0,32544.0,57456.0,0.3616,7308288.0,18432.0,19.232,3128.5760000000005,55296.0,55296.0,3538944.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,576.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,3133.9840000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.728,3139.7120000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,96.0,0.0,6144.0,6144.0,4.064,3143.7760000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,49152.0,1634304.0,0.0,0,14495514624.0,1634304.0,14497148928.0,12768.0,24.0,0.99812382739212,30720.0,6144.0,12.192,3155.9680000000003,1236480.0,299520.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,56623104.0,960.0,192.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,1182720.0,2396160.0,6144.0,0,0.0,2402304.0,2402304.0,10848.0,19152.0,0.3616,2436096.0,6144.0,18.944,3174.9120000000003,18432.0,18432.0,1179648.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,3178.4640000000004,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.368,3184.8320000000003,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 2, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",433,4730880.0,9584640.0,24576.0,0,0.0,9609216.0,9609216.0,43392.0,76608.0,0.3616,9744384.0,24576.0,19.648,3204.4800000000005,73728.0,73728.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,3207.8400000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.424,3211.2640000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,3214.6560000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3218.0160000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.264,3221.2800000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,37237.0,91370.0,3072.0,0,0.0,94442.0,94442.0,0.0,96.0,0.0,24576.0,24576.0,3.776,3225.0560000000005,6144.0,13824.0,35701.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,96.0,0.0,24576.0,24576.0,3.264,3228.3200000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,3231.7120000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),442,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,768.0,0.9984472049689441,9732096.0,98304.0,18.784,3250.4960000000005,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304128.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,13824.0,27648.0,27648.0,0,0.0,55296.0,55296.0,0.0,1296.0,0.0,101376.0,6144.0,4.768,3255.2640000000006,26112.0,1536.0,0.0,13824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,3258.6240000000007,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,15138.0,46714.0,4608.0,0,0.0,51322.0,51322.0,40.0,136.0,0.22727272727272727,18432.0,6272.0,6.56,3265.1840000000007,13080.0,7966.0,12834.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,196.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,77998976.0,170473088.0,1608448.0,0,0.0,172081536.0,172081536.0,1884696.0,1558034.0,0.5474422914373186,155796608.0,694848.0,58.656,3323.8400000000006,6432896.0,9650688.0,77194752.0,804224.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4868644.0,21714.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,3326.5920000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.064,3330.6560000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,3334.1760000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,128.0,101376.0,256.0,0,0.0,101632.0,101632.0,0.0,1580.0,0.0,402080.0,402080.0,3.424,3337.6000000000004,0.0,101376.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,12565.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,3340.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26048.0,5.952,3346.4640000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,814.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,48000.0,0.0,96000.0,0,0.0,96000.0,96000.0,6600.0,41304.0,0.1377755511022044,2569600.0,0.0,8.256,3354.7200000000003,0.0,0.0,0.0,48000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26496.0,5.728,3360.4480000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,828.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,28800.0,0.0,57600.0,0,0.0,57600.0,57600.0,6600.0,41904.0,0.13607125185551708,2569600.0,0.0,8.032,3368.4800000000005,0.0,0.0,0.0,28800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26304.0,5.792,3374.2720000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,822.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,49600.0,0.0,99200.0,0,0.0,99200.0,99200.0,6600.0,41254.0,0.137919505161533,2569600.0,0.0,8.0,3382.2720000000004,0.0,0.0,0.0,49600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,0.0,0.0,0.0,0,0.0,0.0,0.0,1600.0,4742.0,0.2522863450015768,406880.0,26560.0,5.664,3387.9360000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12715.0,830.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,30400.0,0.0,60800.0,0,0.0,60800.0,60800.0,6600.0,41854.0,0.13621166467164733,2569600.0,64.0,7.872,3395.8080000000004,0.0,0.0,0.0,30400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80300.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,3232.0,416.0,3.776,3399.5840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101.0,13.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,3402.688,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,416.0,0.0,5.696,3408.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,3411.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,416.0,0.0,5.568,3416.864,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,25600.0,0.0,51200.0,0,0.0,51200.0,51200.0,26978.0,6510.0,0.8056020066889632,416224.0,4224.0,8.8,3425.664,0.0,0.0,0.0,25600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13007.0,132.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,8.384,3434.0480000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,407968.0,33728.0,5.952,3440.0000000000005,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12749.0,1054.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,3.648,3443.6480000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15707.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,3142.0,0.0,0.0,804128.0,3.616,3447.2640000000006,0.0,0.0,0.0,100514.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,3142.0,0.977282915190514,402080.0,0.0,5.728,3452.9920000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.616,3456.6080000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,32929.0,13803.0,0.7046349396559103,1324480.0,1023040.0,14.592,3471.2000000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41390.0,31970.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,0.0,0.0,0.0,0,0.0,0.0,0.0,9211.0,13779.0,0.40065245759025664,1326272.0,1012544.0,11.808,3483.0080000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41446.0,31642.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,9061.0,13726.0,0.3976390046956598,1324992.0,1225664.0,12.704,3495.712000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41406.0,38302.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,0.0,0.0,0.0,0,0.0,0.0,0.0,9061.0,13732.0,0.3975343307155706,1324096.0,1118656.0,12.896,3508.608000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,41378.0,34958.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,3142.0,0.8247238647774183,804128.0,0.0,4.672,3513.280000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.584,3516.864000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,7406.0,7329.0,0.5026128266033254,900384.0,713664.0,8.96,3525.824000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28137.0,22302.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12568.0,0.0,1214784.0,1206208.0,4.832,3530.656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37962.0,37694.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,1561020.0,3327522.0,307648.0,0,0.0,3635170.0,3635170.0,264.0,3352.0,0.07300884955752213,532192.0,376448.0,31.04,3561.696000000001,412616.0,100514.0,1407196.0,153824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16631.0,11764.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,0.0,512100.0,0.0,0,0.0,512100.0,512100.0,56142.0,6284.0,0.8993368147887099,402112.0,341472.0,97.856,3659.5520000000006,512100.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,10671.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1580.0,0.0,402080.0,100416.0,3.456,3663.0080000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,3138.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.008,3666.0160000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,9426.0,0.0,904672.0,42592.0,11.552,3677.5680000000007,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28271.0,1331.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2370.0,0.0,502624.0,0.0,3.808,3681.3760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15707.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,1561026.0,3327522.0,307660.0,0,0.0,3635182.0,3635182.0,264.0,3352.0,0.07300884955752213,536416.0,375936.0,31.552,3712.928000000001,412616.0,100514.0,1407196.0,153830.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16763.0,11748.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,26.336,3739.2640000000006,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3742.5920000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,788.0,0.07294117647058823,402080.0,32.0,27.136,3769.7280000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12565.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,3773.1520000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,3776.6400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,3781.0560000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,2048.0,110114.0,4096.0,0,0.0,114210.0,114210.0,152.0,791.0,0.16118769883351008,402112.0,64.0,15.904,3796.9600000000005,110114.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,3800.4800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.184,3805.6640000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3808.8960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.352,3813.2480000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,1106688.0,2011972.0,402432.0,0,0.0,2414404.0,2414404.0,0.0,3142.0,0.0,0.0,402080.0,4.704,3817.9520000000007,0.0,201028.0,905472.0,201216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,628334.0,1005140.0,251528.0,0,0.0,1256668.0,1256668.0,0.0,2370.0,0.0,804160.0,0.0,5.088,3823.040000000001,0.0,0.0,502570.0,125764.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25130.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,304.0,791.0,0.2776255707762557,402112.0,64.0,22.432,3845.4720000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,3848.7680000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3852.0960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,4.096,3856.1920000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,3859.4880000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.808,3863.2960000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,3866.3360000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,3869.2160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,3872.8,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,3875.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,96.0,32.0,3.904,3879.456,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,32.0,32.0,6.08,3885.536,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3888.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3892.2239999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.16,3896.3839999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.896,3901.2799999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,3904.7039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
