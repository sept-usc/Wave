Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,8.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,15.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,17.759999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,20.703999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.2,23.903999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.936,27.839999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,31.135999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,34.559999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,37.599999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.84,41.44,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,44.704,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,48.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.584,51.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,5.536,57.376000000000005,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",18,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,4.608,61.984,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",19,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.904,65.888,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,69.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",21,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.528,76.06400000000001,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",22,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.616,83.68,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",23,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.416,96.096,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",24,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.592,102.688,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",25,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,106.144,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",26,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.24,112.384,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",27,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.352,120.736,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",28,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,124.096,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",29,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.392,127.488,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",30,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.488,130.976,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",31,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,134.24,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",32,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.52,137.76000000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,18632.0,45712.0,1536.0,0,0.0,47248.0,47248.0,0.0,48.0,0.0,12288.0,12288.0,3.776,141.53600000000003,3072.0,6912.0,17864.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",34,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.296,144.83200000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",35,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.36,148.19200000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",36,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.888,158.08000000000004,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",37,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.776,161.85600000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",38,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.528,168.38400000000004,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",39,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.68,176.06400000000005,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",40,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.0,188.06400000000005,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",41,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,7.52,195.58400000000006,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",42,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.808,199.39200000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",43,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.528,205.92000000000004,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",44,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,7.936,213.85600000000005,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",45,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,217.21600000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",46,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.52,220.73600000000008,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",47,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,224.12800000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,227.39200000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",49,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,230.72000000000008,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",50,18640.0,45728.0,1536.0,0,0.0,47264.0,47264.0,0.0,48.0,0.0,12288.0,12288.0,3.616,234.3360000000001,3072.0,6912.0,17872.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.552,237.8880000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",52,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.488,241.3760000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",53,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,10.272,251.64800000000008,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.744,255.39200000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",55,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.304,261.6960000000001,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",56,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.968,269.6640000000001,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",57,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.352,282.0160000000001,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.72,288.7360000000001,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,292.1280000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",60,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.4,298.5280000000001,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",61,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.672,307.2000000000001,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,310.6240000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",63,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.2,313.82400000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",64,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,317.1840000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",65,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,320.51200000000006,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",66,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,323.80800000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,18593.0,45634.0,1536.0,0,0.0,47170.0,47170.0,0.0,48.0,0.0,12288.0,12288.0,3.488,327.29600000000005,3072.0,6912.0,17825.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",68,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.328,330.624,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",69,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.392,334.016,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",70,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.888,343.904,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",71,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.808,347.712,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",72,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.432,354.144,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",73,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.68,361.824,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",74,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.064,373.88800000000003,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",75,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.752,380.64000000000004,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",76,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,384.12800000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",77,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.336,390.46400000000006,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",78,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.032,398.49600000000004,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,401.88800000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",80,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.2,405.088,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,408.44800000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,411.93600000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,415.232,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",84,18625.0,45698.0,1536.0,0,0.0,47234.0,47234.0,0.0,48.0,0.0,12288.0,12288.0,3.488,418.72,3072.0,6912.0,17857.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.456,422.17600000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",86,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.648,425.82400000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",87,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.664,435.48800000000006,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,439.0400000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",89,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.752,445.7920000000001,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",90,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.712,453.5040000000001,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",91,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.064,465.5680000000001,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.816,472.38400000000007,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,475.9680000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",94,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.4,482.36800000000005,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",95,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.032,490.40000000000003,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",96,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,493.85600000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",97,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.296,497.15200000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,500.51200000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,503.87200000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,507.20000000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,18604.0,45656.0,1536.0,0,0.0,47192.0,47192.0,0.0,48.0,0.0,12288.0,12288.0,3.648,510.84800000000007,3072.0,6912.0,17836.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",102,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.392,514.2400000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",103,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,517.6640000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",104,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,10.144,527.8080000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",105,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,531.3600000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",106,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.464,537.8240000000002,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",107,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.488,545.3120000000002,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",108,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.032,557.3440000000003,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",109,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,7.264,564.6080000000003,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",110,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,568.3200000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",111,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.304,574.6240000000003,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",112,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.16,582.7840000000002,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",113,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,586.1120000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",114,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,589.3440000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",115,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,592.8000000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,596.0960000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",117,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,599.5520000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",118,18628.0,45704.0,1536.0,0,0.0,47240.0,47240.0,0.0,48.0,0.0,12288.0,12288.0,3.52,603.0720000000002,3072.0,6912.0,17860.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.264,606.3360000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",120,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,609.5680000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",121,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.696,619.2640000000002,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,622.8160000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",123,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.528,629.3440000000003,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",124,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.488,636.8320000000003,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",125,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.032,648.8640000000004,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,7.36,656.2240000000004,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.648,659.8720000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",128,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.4,666.2720000000004,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",129,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.096,674.3680000000004,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",130,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,677.6640000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",131,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.2,680.8640000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",132,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.52,684.3840000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,687.8720000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",134,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.584,691.4560000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,18612.0,45672.0,1536.0,0,0.0,47208.0,47208.0,0.0,48.0,0.0,12288.0,12288.0,3.456,694.9120000000005,3072.0,6912.0,17844.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,698.1440000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",137,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.552,701.6960000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",138,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,10.048,711.7440000000005,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",139,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,715.2960000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",140,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.208,721.5040000000005,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",141,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.68,729.1840000000004,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",142,24576.0,816384.0,0.0,0,7247757312.0,816384.0,7248573696.0,6384.0,12.0,0.99812382739212,9216.0,3072.0,12.128,741.3120000000005,617472.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",143,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.848,748.1600000000004,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.36,751.5200000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.24,757.7600000000004,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",146,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.064,765.8240000000004,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",147,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,769.1200000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",148,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,772.3520000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",149,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.584,775.9360000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,779.3600000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",151,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,782.8160000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",152,18634.0,45716.0,1536.0,0,0.0,47252.0,47252.0,0.0,48.0,0.0,12288.0,12288.0,3.36,786.1760000000004,3072.0,6912.0,17866.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.456,789.6320000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",154,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.296,792.9280000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",155,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.632,802.5600000000004,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,806.0800000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.656,812.7360000000003,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",158,39401600.0,84382175.0,1608448.0,0,0.0,85990623.0,85990623.0,1608277.0,1382113.0,0.5378151344807868,155223808.0,286400.0,54.88,867.6160000000003,2362079.0,4825344.0,38597376.0,804224.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4850744.0,8950.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",159,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,870.3680000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",160,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,3.904,874.2720000000003,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",161,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,877.9840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",162,128.0,50824.0,256.0,0,0.0,51080.0,51080.0,0.0,790.0,0.0,201056.0,201056.0,3.616,881.6000000000003,0.0,50824.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",163,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,884.6400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",164,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,5.76,890.4000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",165,24000.0,0.0,48000.0,0,0.0,48000.0,48000.0,3300.0,20652.0,0.1377755511022044,1284800.0,0.0,7.84,898.2400000000002,0.0,0.0,0.0,24000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12864.0,5.632,903.8720000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,402.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",167,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3300.0,20952.0,0.13607125185551708,1284800.0,0.0,7.584,911.4560000000001,0.0,0.0,0.0,14400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",168,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12800.0,5.408,916.8640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,400.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",169,22400.0,0.0,44800.0,0,0.0,44800.0,44800.0,3300.0,20702.0,0.13748854262144822,1284800.0,0.0,7.68,924.5440000000001,0.0,0.0,0.0,22400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",170,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12864.0,5.728,930.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,402.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",171,19200.0,0.0,38400.0,0,0.0,38400.0,38400.0,3300.0,20802.0,0.13691809808314662,1284800.0,32.0,8.16,938.432,0.0,0.0,0.0,19200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",172,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6.0,0.0,1632.0,224.0,3.808,942.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",173,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,945.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",174,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,224.0,0.0,5.376,950.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,953.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",176,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,224.0,0.0,5.44,959.1360000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",177,12801.0,0.0,25602.0,0,0.0,25602.0,25602.0,11685.0,3253.0,0.7822332306868389,207360.0,2240.0,8.288,967.4240000000001,0.0,0.0,0.0,12801.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6480.0,70.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",178,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.384,975.8080000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,4713.0,0.0,204224.0,15808.0,5.728,981.5360000000001,0.0,0.0,0.0,100514.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6382.0,494.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",180,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,3.36,984.8960000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",181,50257.0,0.0,100514.0,0,0.0,100514.0,100514.0,0.0,1571.0,0.0,0.0,402080.0,3.584,988.48,0.0,0.0,0.0,50257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",182,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,1571.0,0.988510958833983,201056.0,0.0,5.696,994.176,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",183,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,997.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",184,0.0,0.0,0.0,0,0.0,0.0,0.0,16006.0,6798.0,0.7018944044904403,655872.0,505696.0,12.704,1010.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20496.0,15803.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",185,0.0,0.0,0.0,0,0.0,0.0,0.0,4774.0,6788.0,0.4129043418093755,652032.0,613376.0,11.36,1021.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20376.0,19168.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",186,0.0,0.0,0.0,0,0.0,0.0,0.0,5851.0,6748.0,0.4644019366616398,647168.0,613376.0,12.032,1033.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20224.0,19168.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",187,0.0,0.0,0.0,0,0.0,0.0,0.0,5851.0,6751.0,0.4642913823202666,647424.0,550016.0,12.288,1046.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20232.0,17188.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",188,780510.0,1663761.0,153824.0,0,0.0,1817585.0,1817585.0,132.0,1676.0,0.07300884955752213,244832.0,201056.0,31.232,1077.312,206308.0,50257.0,703598.0,76912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7651.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",189,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,480.0,3.072,1080.3839999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",190,25.0,134065.0,50.0,0,0.0,134115.0,134115.0,7017.0,3255.0,0.6831191588785047,218016.0,202720.0,5.376,1085.7599999999998,134065.0,0.0,0.0,25.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6813.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,790.0,0.0,201056.0,50208.0,3.52,1089.2799999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",192,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,1092.1919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,56610.0,0.0,113220.0,0,0.0,113220.0,113220.0,0.0,4713.0,0.0,452352.0,20736.0,11.456,1103.6479999999997,0.0,0.0,0.0,56610.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14136.0,648.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",194,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,3.424,1107.0719999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",195,780513.0,1663761.0,153830.0,0,0.0,1817591.0,1817591.0,132.0,1676.0,0.07300884955752213,257472.0,201056.0,31.968,1139.0399999999997,206308.0,50257.0,703598.0,76915.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8046.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",196,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,16.128,1155.1679999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1158.5279999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",198,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,16.48,1175.0079999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,1178.4319999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,1181.8559999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",201,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,1186.4639999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",202,1024.0,54833.0,2048.0,0,0.0,56881.0,56881.0,62.0,395.0,0.13566739606126915,201056.0,32.0,15.744,1202.2079999999994,54833.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1205.5999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",204,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1208.9919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.32,1213.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",206,554752.0,1008290.0,201728.0,0,0.0,1210018.0,1210018.0,0.0,1571.0,0.0,0.0,201056.0,4.128,1217.4399999999994,0.0,100514.0,453888.0,100864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",207,314295.0,502570.0,126020.0,0,0.0,628590.0,628590.0,0.0,1185.0,0.0,402112.0,0.0,4.928,1222.3679999999995,0.0,0.0,251285.0,63010.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",208,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,124.0,395.0,0.23892100192678228,201056.0,32.0,22.688,1245.0559999999996,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.2,1248.2559999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,1251.6799999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,1255.1039999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,1258.3359999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,3.936,1262.2719999999995,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,1265.1199999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",215,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,1267.9039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,1271.2639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1274.0799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,1277.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,1280.6399999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1283.9999999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.936,1287.9359999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.768,1292.7039999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1296.1599999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1299.519999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,5.024,1304.543999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,1307.423999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.84,1311.263999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1314.591999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1318.0479999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.328,1321.3759999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",231,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,4.8,1326.1759999999988,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",232,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,4.576,1330.7519999999988,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,1334.1439999999989,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1337.4719999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",235,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.248,1342.719999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",236,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.56,1349.2799999999988,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.456,1356.7359999999987,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",238,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.672,1361.4079999999988,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,1366.1119999999987,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",240,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.128,1378.2399999999986,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",241,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.912,1385.1519999999987,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",242,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1388.7039999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",243,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.112,1394.8159999999987,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",244,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.16,1402.9759999999987,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",245,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,1406.2399999999986,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",246,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.328,1409.5679999999986,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",247,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.488,1413.0559999999987,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,1416.5119999999986,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",249,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1419.7439999999986,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",250,18627.0,45702.0,1536.0,0,0.0,47238.0,47238.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1423.1679999999985,3072.0,6912.0,17859.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",251,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.328,1426.4959999999985,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",252,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.584,1430.0799999999986,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",253,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.792,1439.8719999999985,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",254,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,1443.4559999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",255,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.56,1450.0159999999985,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",256,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.68,1457.6959999999985,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",257,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,3.968,1461.6639999999986,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",258,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.576,1466.2399999999986,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",259,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.128,1478.3679999999986,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",260,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.72,1485.0879999999986,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",261,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,1488.5759999999987,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",262,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.368,1494.9439999999986,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",263,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.512,1503.4559999999985,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",264,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.616,1507.0719999999985,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",265,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1510.3039999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1513.6639999999984,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,1516.9919999999984,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",268,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1520.2239999999983,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,18622.0,45692.0,1536.0,0,0.0,47228.0,47228.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1523.6479999999983,3072.0,6912.0,17854.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1527.0079999999982,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.552,1530.5599999999981,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,10.016,1540.5759999999982,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",273,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,1543.9039999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",274,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.432,1550.3359999999982,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",275,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.552,1557.887999999998,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.416,1562.303999999998,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.32,1566.623999999998,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",278,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.096,1578.719999999998,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",279,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.784,1585.503999999998,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,1588.9919999999981,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",281,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.272,1595.263999999998,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",282,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.128,1603.391999999998,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,1606.719999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",284,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1610.143999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",285,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1613.375999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1616.767999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",287,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.616,1620.383999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",288,18609.0,45666.0,1536.0,0,0.0,47202.0,47202.0,0.0,48.0,0.0,12288.0,12288.0,3.616,1623.999999999998,3072.0,6912.0,17841.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.328,1627.327999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",290,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.52,1630.847999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",291,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.952,1640.799999999998,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1644.2559999999978,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",293,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.72,1650.9759999999978,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",294,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.488,1658.463999999998,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.672,1663.135999999998,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",296,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.128,1667.2639999999978,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",297,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.936,1679.1999999999978,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",298,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.72,1685.9199999999978,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1689.4719999999977,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",300,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.336,1695.8079999999977,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",301,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,7.968,1703.7759999999978,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",302,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.552,1707.3279999999977,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",303,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.552,1710.8799999999976,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",304,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,1714.2079999999976,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1717.5039999999976,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",306,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1720.8639999999975,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,18660.0,45768.0,1536.0,0,0.0,47304.0,47304.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1724.2879999999975,3072.0,6912.0,17892.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",308,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1727.5199999999975,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",309,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1730.8159999999975,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",310,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.984,1740.7999999999975,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.68,1744.4799999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",312,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.496,1750.9759999999976,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",313,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.328,1758.3039999999976,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",314,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.512,1762.8159999999975,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",315,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.416,1767.2319999999975,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",316,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,11.936,1779.1679999999974,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",317,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.88,1786.0479999999975,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,1789.6319999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.656,1796.2879999999975,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",320,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.0,1804.2879999999975,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",321,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1807.7119999999975,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",322,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.52,1811.2319999999975,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",323,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1814.6559999999974,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1818.0799999999974,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",325,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1821.3119999999974,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",326,18639.0,45726.0,1536.0,0,0.0,47262.0,47262.0,0.0,48.0,0.0,12288.0,12288.0,3.616,1824.9279999999974,3072.0,6912.0,17871.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",327,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1828.3519999999974,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",328,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1831.7759999999973,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",329,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,10.016,1841.7919999999974,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,1845.3119999999974,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",331,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.368,1851.6799999999973,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",332,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.52,1859.1999999999973,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.128,1863.3279999999972,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",334,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.768,1868.0959999999973,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",335,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.192,1880.2879999999973,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",336,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.816,1887.1039999999973,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",337,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1890.5599999999972,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",338,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.368,1896.9279999999972,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",339,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.064,1904.9919999999972,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",340,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1908.2239999999972,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",341,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1911.4559999999972,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",342,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1914.815999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",343,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1918.2079999999971,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",344,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,1921.5039999999972,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,18654.0,45756.0,1536.0,0,0.0,47292.0,47292.0,0.0,48.0,0.0,12288.0,12288.0,3.552,1925.055999999997,3072.0,6912.0,17886.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",346,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1928.415999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",347,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1931.839999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",348,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.856,1941.695999999997,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",349,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,1945.215999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",350,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.528,1951.743999999997,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",351,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.648,1959.3919999999969,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.48,1963.871999999997,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.0,1967.871999999997,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",354,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.096,1979.967999999997,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",355,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.72,1986.687999999997,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",356,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,1990.111999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",357,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.72,1996.831999999997,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",358,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,8.544,2005.375999999997,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",359,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.712,2009.087999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",360,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.2,2012.287999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,2015.743999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",362,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,2019.1999999999969,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.712,2022.9119999999969,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,18619.0,45686.0,1536.0,0,0.0,47222.0,47222.0,0.0,48.0,0.0,12288.0,12288.0,3.552,2026.4639999999968,3072.0,6912.0,17851.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",365,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.264,2029.7279999999967,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",366,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2033.1519999999966,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",367,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.92,2043.0719999999967,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2046.5599999999968,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.304,2052.863999999997,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",370,1847808.0,3580416.0,152064.0,0,0.0,3732480.0,3732480.0,4464.0,110736.0,0.03875,7308288.0,9216.0,7.872,2060.7359999999967,36864.0,0.0,1771776.0,76032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228384.0,288.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",371,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.544,2065.2799999999966,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",372,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.192,2069.4719999999966,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",373,24576.0,817152.0,0.0,0,7247757312.0,817152.0,7248574464.0,6384.0,12.0,0.99812382739212,15360.0,3072.0,12.096,2081.5679999999966,618240.0,149760.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,28311552.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",374,615936.0,1193472.0,50688.0,0,0.0,1244160.0,1244160.0,1488.0,36912.0,0.03875,2436096.0,3072.0,6.912,2088.4799999999964,12288.0,0.0,590592.0,25344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76128.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",375,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,2092.1919999999964,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",376,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.336,2098.527999999996,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",377,2463744.0,4773888.0,202752.0,0,0.0,4976640.0,4976640.0,5952.0,147648.0,0.03875,9744384.0,12288.0,7.968,2106.495999999996,49152.0,0.0,2362368.0,101376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.552,2110.047999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",379,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.488,2113.535999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",380,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,2116.799999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,2120.159999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,2123.551999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,18631.0,45710.0,1536.0,0,0.0,47246.0,47246.0,0.0,48.0,0.0,12288.0,12288.0,3.584,2127.135999999996,3072.0,6912.0,17863.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",384,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,48.0,0.0,12288.0,12288.0,3.328,2130.463999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",385,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2133.887999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 0, 0, 9, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",386,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,3120.0,147552.0,0.020707231602421154,10030080.0,3072.0,9.824,2143.711999999996,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313440.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2147.135999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",388,7569.0,23357.0,2304.0,0,0.0,25661.0,25661.0,20.0,68.0,0.22727272727272727,9216.0,3136.0,6.464,2153.599999999996,6540.0,3983.0,6417.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,98.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",389,39401600.0,84382175.0,1608448.0,0,0.0,85990623.0,85990623.0,1608277.0,1382113.0,0.5378151344807868,155328256.0,286848.0,55.04,2208.639999999996,2362079.0,4825344.0,38597376.0,804224.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4854008.0,8964.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2211.4879999999957,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.448,2215.9359999999956,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2219.3599999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,50824.0,256.0,0,0.0,51080.0,51080.0,0.0,790.0,0.0,201056.0,201056.0,3.296,2222.6559999999954,0.0,50824.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,6283.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,2225.663999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",395,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12928.0,5.472,2231.1359999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,404.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",396,24000.0,0.0,48000.0,0,0.0,48000.0,48000.0,3300.0,20652.0,0.1377755511022044,1284800.0,0.0,8.352,2239.4879999999953,0.0,0.0,0.0,24000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",397,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,13120.0,5.568,2245.0559999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,410.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",398,14400.0,0.0,28800.0,0,0.0,28800.0,28800.0,3300.0,20952.0,0.13607125185551708,1284800.0,0.0,7.968,2253.0239999999953,0.0,0.0,0.0,14400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",399,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12864.0,5.728,2258.7519999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,402.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",400,25600.0,0.0,51200.0,0,0.0,51200.0,51200.0,3300.0,20602.0,0.13806376035478202,1284800.0,0.0,8.16,2266.9119999999953,0.0,0.0,0.0,25600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",401,0.0,0.0,0.0,0,0.0,0.0,0.0,800.0,2371.0,0.2522863450015768,202656.0,12992.0,5.504,2272.415999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6333.0,406.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",402,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,3300.0,20902.0,0.13635236757292785,1284800.0,32.0,7.968,2280.383999999995,0.0,0.0,0.0,16000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40150.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6.0,0.0,1632.0,224.0,3.744,2284.127999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51.0,7.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,2287.263999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",405,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,224.0,0.0,5.536,2292.799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",406,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,2296.127999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",407,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,224.0,0.0,5.504,2301.631999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",408,12801.0,0.0,25602.0,0,0.0,25602.0,25602.0,10865.0,3255.0,0.7694759206798867,207360.0,2112.0,8.0,2309.631999999995,0.0,0.0,0.0,12801.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6480.0,66.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.544,2318.175999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,100514.0,0.0,201028.0,0,0.0,201028.0,201028.0,0.0,4713.0,0.0,204224.0,16928.0,5.696,2323.871999999995,0.0,0.0,0.0,100514.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6382.0,529.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",411,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,3.36,2327.231999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7854.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",412,50257.0,0.0,100514.0,0,0.0,100514.0,100514.0,0.0,1571.0,0.0,0.0,402080.0,3.584,2330.815999999995,0.0,0.0,0.0,50257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,12565.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",413,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,1571.0,0.988510958833983,201056.0,0.0,5.6,2336.4159999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.552,2339.967999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",415,0.0,0.0,0.0,0,0.0,0.0,0.0,17083.0,6787.0,0.715668202764977,651264.0,504864.0,13.248,2353.215999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20352.0,15777.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",416,0.0,0.0,0.0,0,0.0,0.0,0.0,4774.0,6793.0,0.41272585804443673,651904.0,613376.0,11.616,2364.831999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20372.0,19168.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,5851.0,6748.0,0.4644019366616398,647296.0,613376.0,12.032,2376.863999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20228.0,19168.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,5851.0,6739.0,0.4647339158061954,647168.0,549152.0,12.192,2389.055999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20224.0,17161.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",419,780510.0,1663761.0,153824.0,0,0.0,1817585.0,1817585.0,132.0,1676.0,0.07300884955752213,257120.0,201056.0,30.688,2419.743999999995,206308.0,50257.0,703598.0,76912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8035.0,6283.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",420,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,480.0,2.88,2422.6239999999952,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,15.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",421,25.0,134065.0,50.0,0,0.0,134115.0,134115.0,7017.0,3255.0,0.6831191588785047,219424.0,202720.0,5.472,2428.0959999999955,134065.0,0.0,0.0,25.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6857.0,6335.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,790.0,0.0,201056.0,50208.0,3.52,2431.6159999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1569.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,2434.4959999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,56610.0,0.0,113220.0,0,0.0,113220.0,113220.0,0.0,4713.0,0.0,452352.0,20672.0,11.392,2445.8879999999954,0.0,0.0,0.0,56610.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14136.0,646.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",425,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1185.0,0.0,251328.0,0.0,3.36,2449.2479999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7854.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",426,780513.0,1663761.0,153830.0,0,0.0,1817591.0,1817591.0,132.0,1676.0,0.07300884955752213,257472.0,201056.0,31.488,2480.7359999999953,206308.0,50257.0,703598.0,76915.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8046.0,6283.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",427,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,15.872,2496.607999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2500.031999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",429,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,395.0,0.13566739606126915,201056.0,32.0,16.224,2516.2559999999953,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2519.6159999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",431,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,2522.8799999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",432,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,2527.4239999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",433,1024.0,54833.0,2048.0,0,0.0,56881.0,56881.0,62.0,395.0,0.13566739606126915,201056.0,32.0,16.224,2543.6479999999956,54833.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2547.0399999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2550.3039999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,2554.8799999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",437,554752.0,1008290.0,201728.0,0,0.0,1210018.0,1210018.0,0.0,1571.0,0.0,0.0,201056.0,4.128,2559.0079999999957,0.0,100514.0,453888.0,100864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,6283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",438,314295.0,502570.0,126020.0,0,0.0,628590.0,628590.0,0.0,1185.0,0.0,402112.0,0.0,4.96,2563.9679999999958,0.0,0.0,251285.0,63010.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12566.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",439,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,124.0,395.0,0.23892100192678228,201056.0,32.0,23.104,2587.0719999999956,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6283.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",440,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.16,2591.2319999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",441,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.968,2595.1999999999953,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",442,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,2598.6559999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",443,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,2602.6239999999952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.832,2607.455999999995,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",445,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2610.2399999999952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",446,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,2612.9279999999953,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,2616.415999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2619.231999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,2622.911999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",450,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,2626.431999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.84,2630.271999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",452,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,2634.239999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",453,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.632,2639.871999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",454,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,2643.583999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
