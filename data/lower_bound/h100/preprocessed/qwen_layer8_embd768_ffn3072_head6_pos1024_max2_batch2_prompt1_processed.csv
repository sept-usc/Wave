Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,9.312,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,13.919999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.832,18.752,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,22.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,24.735999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,27.551999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,30.719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.648,34.367999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,37.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,41.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.192,45.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.04,48.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,52.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.392,55.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,4.928,60.448,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,63.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.344,69.312,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,72.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.424,76.16000000000001,0.0,256.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,4.864,81.02400000000002,0.0,0.0,0.0,320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,2048.0,4608.0,0.0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,4.32,85.34400000000002,0.0,512.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.296,88.64000000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,1792.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,16.0,0.0,1024.0,1024.0,4.096,92.73600000000003,0.0,512.0,1792.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.36,96.09600000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.488,99.58400000000003,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.664,105.24800000000003,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,108.48000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,111.93600000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,116.38400000000004,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.288,120.67200000000004,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.224,128.89600000000004,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.776,136.67200000000005,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.68,144.35200000000006,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,148.73600000000005,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.224,152.96000000000004,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,158.27200000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.704,162.97600000000006,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,166.59200000000007,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,171.07200000000006,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.672,175.74400000000006,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.44,181.18400000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.096,185.28000000000006,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,188.67200000000005,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.616,204.28800000000007,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),47,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,215.68000000000006,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",48,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.216,220.89600000000007,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",49,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,224.28800000000007,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",50,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,227.61600000000007,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",51,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.952,233.56800000000007,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",52,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,236.83200000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,240.0960000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.352,244.4480000000001,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",55,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.48,248.92800000000008,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36000.0,8.992,257.9200000000001,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1125.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",57,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.808,261.72800000000007,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35232.0,9.408,271.1360000000001,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1101.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",59,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.616,274.75200000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6752.0,19.744,294.4960000000001,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,211.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,297.8880000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,301.21600000000007,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",63,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,6.112,307.3280000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,310.5920000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",65,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,313.8880000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.512,318.4000000000001,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.704,323.1040000000001,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.288,331.3920000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.776,339.1680000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.968,347.13600000000014,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,351.61600000000016,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.192,355.80800000000016,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",73,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,361.15200000000016,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,365.66400000000016,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,369.2160000000002,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.256,373.4720000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.16,377.63200000000023,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",78,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,382.9760000000002,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,387.4880000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,391.13600000000025,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",81,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.296,406.43200000000024,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),82,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.552,417.98400000000026,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",83,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,422.7840000000003,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,426.40000000000026,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.168,429.56800000000027,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",86,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.76,435.32800000000026,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",87,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,438.62400000000025,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",88,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,441.88800000000026,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.224,446.11200000000025,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,450.65600000000023,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34816.0,9.152,459.8080000000002,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1088.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",92,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.648,463.45600000000024,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35520.0,9.44,472.89600000000024,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1110.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",94,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,476.25600000000026,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",95,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,7040.0,19.552,495.8080000000003,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,220.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,499.23200000000026,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,502.62400000000025,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,6.016,508.64000000000027,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,512.0000000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,515.2960000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.288,519.5840000000003,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.448,524.0320000000003,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.68,531.7120000000002,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.064,539.7760000000002,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.776,547.5520000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,552.0320000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.736,556.7680000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",108,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,562.0800000000002,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.064,566.1440000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",110,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.776,569.9200000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,574.432,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.192,578.624,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",113,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,583.9680000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.704,588.672,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,592.224,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",116,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.36,607.5840000000001,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),117,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,618.912,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",118,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,623.8720000000001,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,627.3600000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,630.6880000000001,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,636.224,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,639.5840000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.776,643.36,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.352,647.712,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,652.096,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34240.0,9.376,661.472,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1070.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.968,665.4399999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35456.0,9.184,674.6239999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1108.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.264,677.8879999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6656.0,19.648,697.536,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,208.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.776,701.3119999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,704.7359999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.44,710.1759999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,713.6959999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,717.0559999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.192,721.2479999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.32,725.568,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.48,734.048,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.648,741.696,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.968,749.664,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.16,753.824,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.384,758.208,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,763.52,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.256,767.776,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,771.3599999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.704,776.0639999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.544,780.6079999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.6,786.2079999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,790.5279999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.744,794.2719999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.456,809.728,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),152,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,821.1519999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,825.9519999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,829.4719999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",155,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.296,832.7679999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",156,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.728,838.4959999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",157,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,841.6959999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,845.088,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,849.472,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.224,853.696,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34976.0,9.344,863.0400000000001,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1093.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.808,866.8480000000001,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",163,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34592.0,9.504,876.3520000000001,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1081.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.584,879.936,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",165,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6432.0,19.744,899.6800000000001,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,201.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,903.1680000000001,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",167,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,906.5280000000001,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",168,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.408,911.9360000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",169,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,915.2640000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,918.8160000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.736,923.5520000000001,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.352,927.9040000000001,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.808,935.7120000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.52,943.2320000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",175,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.904,951.1360000000001,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.224,955.3600000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.352,959.7120000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.632,965.344,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.768,970.1120000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,973.44,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.192,977.6320000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.544,982.176,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",183,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,987.488,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,991.7760000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,995.2,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",186,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.36,1010.5600000000001,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),187,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.552,1022.1120000000001,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",188,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,1026.88,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",189,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,1030.24,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",190,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,1033.696,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",191,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.92,1039.616,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",192,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1042.848,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",193,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1046.144,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",194,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,1050.592,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.832,1055.4240000000002,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35168.0,9.44,1064.8640000000003,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1099.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.968,1068.8320000000003,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,33568.0,9.312,1078.1440000000002,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1049.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",199,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.328,1081.4720000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",200,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6240.0,19.36,1100.832,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,195.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",201,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,1104.256,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",202,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.296,1107.5520000000001,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",203,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,1113.44,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",204,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1116.736,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",205,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,1120.192,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.416,1124.608,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.416,1129.024,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.616,1136.6399999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",209,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.584,1144.224,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",210,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.616,1151.84,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,1156.3519999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.384,1160.7359999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,1166.0159999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.448,1170.464,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,1174.1119999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.256,1178.368,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.416,1182.7839999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",218,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.44,1188.224,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,1192.7359999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",220,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,1196.1599999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",221,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.52,1211.6799999999998,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),222,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,1223.0079999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.216,1228.2239999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,1231.6159999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,1234.9759999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,6.112,1241.0879999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1244.4799999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1247.8079999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.32,1252.1279999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.608,1256.7359999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",231,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35904.0,9.056,1265.7919999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1122.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",232,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.712,1269.5039999999997,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",233,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,33952.0,9.76,1279.2639999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1061.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",234,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,1282.6879999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",235,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6400.0,19.232,1301.9199999999996,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,200.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",236,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,1305.4079999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.296,1308.7039999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",238,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.664,1314.3679999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",239,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,1317.8239999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",240,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1321.2159999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,1325.6639999999998,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,1330.2079999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",243,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.776,1337.984,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",244,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.616,1345.6,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",245,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.584,1353.184,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.448,1357.632,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.352,1361.9840000000002,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",248,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,1367.296,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,1371.584,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,1375.136,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,1379.648,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.256,1383.904,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,1389.28,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",254,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.736,1394.016,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,1397.472,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",256,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.296,1412.768,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),257,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,1424.192,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",258,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.928,1429.1200000000001,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",259,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.776,1432.8960000000002,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.2,1436.0960000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",261,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.632,1441.7280000000003,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",262,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,1445.0560000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.712,1448.7680000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",264,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.416,1453.1840000000002,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,1457.5680000000002,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36576.0,9.344,1466.9120000000003,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1143.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.776,1470.6880000000003,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",268,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,33600.0,9.152,1479.8400000000004,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1050.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,1483.2320000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",270,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6656.0,19.648,1502.8800000000003,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,208.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",271,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,1506.3360000000002,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",272,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.232,1509.5680000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",273,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.408,1514.976,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",274,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,1518.336,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",275,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,1521.888,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,1526.272,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,1530.656,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.16,1538.816,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",279,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.456,1546.272,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",280,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.712,1553.984,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,1558.272,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.512,1562.7839999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.568,1568.3519999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,1572.9599999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,1576.4159999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.704,1581.1199999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.608,1585.7279999999996,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,1591.0719999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,1595.3919999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,1598.9119999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",291,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.488,1614.3999999999996,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),292,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.456,1625.8559999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",293,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.992,1630.8479999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,1634.3359999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",295,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,1637.6639999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",296,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.568,1643.2319999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",297,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1646.4959999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1649.8879999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,1654.3359999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",300,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,1658.7199999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",301,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35424.0,9.12,1667.8399999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1107.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.872,1671.7119999999995,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",303,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35584.0,9.312,1681.0239999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1112.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",304,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.328,1684.3519999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6784.0,19.2,1703.5519999999995,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,212.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.808,1707.3599999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,1710.7839999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",308,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.568,1716.3519999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",309,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1719.5199999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1722.9119999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,1727.3599999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,1731.7439999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",313,235804672.0,515366912.0,4861952.0,0,0.0,520228864.0,520228864.0,5697600.0,4710016.0,0.5474452554744526,469446272.0,1779904.0,160.096,1891.8399999999995,19447808.0,29171712.0,233373696.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14670196.0,55622.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,1894.7519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",315,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.544,1899.2959999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,1902.4319999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,128.0,304128.0,256.0,0,0.0,304384.0,304384.0,0.0,4784.0,0.0,1215488.0,1215488.0,3.936,1906.3679999999995,0.0,304128.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.264,1909.6319999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,82304.0,6.176,1915.8079999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2572.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,143040.0,0.0,286080.0,0,0.0,286080.0,286080.0,19668.0,359094.0,0.05192706765726234,19700288.0,0.0,14.208,1930.0159999999994,0.0,0.0,0.0,143040.0,0,0,0,0,0,0,0,0.0,0.0,0.0,615634.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,83840.0,5.888,1935.9039999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2620.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,85824.0,0.0,171648.0,0,0.0,171648.0,171648.0,19668.0,360882.0,0.051683090264091444,19700288.0,0.0,14.336,1950.2399999999993,0.0,0.0,0.0,85824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,615634.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,81984.0,6.112,1956.3519999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2562.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",324,162112.0,0.0,324224.0,0,0.0,324224.0,324224.0,19668.0,358498.0,0.052008906141747274,19700288.0,0.0,13.952,1970.3039999999994,0.0,0.0,0.0,162112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,615634.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,82560.0,6.016,1976.3199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2580.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",326,95360.0,0.0,190720.0,0,0.0,190720.0,190720.0,19668.0,360584.0,0.051723593827251405,19700288.0,64.0,14.816,1991.1359999999995,0.0,0.0,0.0,95360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,615634.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,30.0,0.0,9568.0,1216.0,4.416,1995.5519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.424,1998.9759999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,29.0,0.9566517189835575,1216.0,0.0,6.016,2004.9919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,2007.8719999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,29.0,0.9566517189835575,1216.0,0.0,5.568,2013.4399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",332,76288.0,0.0,152576.0,0,0.0,152576.0,152576.0,92086.0,19200.0,0.82747155976493,1246656.0,5216.0,9.152,2022.5919999999996,0.0,0.0,0.0,76288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38958.0,163.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,9.024,2031.6159999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,1223936.0,104800.0,6.208,2037.8239999999996,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38248.0,3275.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,6.016,2043.8399999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,47480.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",336,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,9496.0,0.0,0.0,2430976.0,4.448,2048.2879999999996,0.0,0.0,0.0,303872.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,9496.0,0.9343582370181939,1215488.0,0.0,6.24,2054.5279999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.392,2057.919999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,82149.0,41832.0,0.6625934619014204,4210176.0,3067264.0,16.128,2074.0479999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131568.0,95852.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,23421.0,43469.0,0.3501420242188668,4204800.0,2682208.0,12.928,2086.975999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131400.0,83819.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,21777.0,43566.0,0.3332721179009228,4224128.0,3704832.0,14.464,2101.439999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,132004.0,115776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",342,0.0,0.0,0.0,0,0.0,0.0,0.0,21777.0,43524.0,0.33348647034501766,4196096.0,3382304.0,13.408,2114.847999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131128.0,105697.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",343,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,9496.0,0.6088962108731466,2430976.0,0.0,5.248,2120.095999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,2123.583999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,19309.0,23889.0,0.44698828649474515,2912768.0,2144544.0,10.368,2133.951999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,91024.0,67017.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,37984.0,0.0,3666976.0,3646464.0,6.176,2140.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,114593.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",347,4712348.0,10038336.0,916280.0,0,0.0,10954616.0,10954616.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,86.944,2227.0719999999988,1226048.0,303872.0,4254208.0,458140.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",348,0.0,1526058.0,0.0,0,0.0,1526058.0,1526058.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,287.328,2514.3999999999987,1526058.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4784.0,0.0,1215488.0,303296.0,3.872,2518.2719999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.264,2521.5359999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",351,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,2734848.0,142656.0,11.904,2533.4399999999987,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85464.0,4458.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,5.44,2538.8799999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",353,4712352.0,10038336.0,916288.0,0,0.0,10954624.0,10954624.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,86.688,2625.567999999999,1226048.0,303872.0,4254208.0,458144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",354,58880.0,0.0,117760.0,0,0.0,117760.0,117760.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,9.6,2635.1679999999988,0.0,0.0,0.0,58880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2638.6559999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",356,58880.0,0.0,117760.0,0,0.0,117760.0,117760.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,9.568,2648.223999999999,0.0,0.0,0.0,58880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2651.487999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,2655.007999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,2659.615999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",360,59468.0,492838.0,118936.0,0,0.0,611774.0,611774.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,9.504,2669.119999999999,492838.0,0.0,0.0,59468.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,2672.799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",362,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,4.928,2677.7279999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.0,2681.7279999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.8,2686.527999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",365,2973696.0,5473792.0,1081344.0,0,0.0,6555136.0,6555136.0,0.0,9496.0,0.0,0.0,1215488.0,7.04,2693.567999999999,0.0,607744.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",366,1899168.0,3038720.0,759616.0,0,0.0,3798336.0,3798336.0,0.0,7176.0,0.0,2430976.0,0.0,6.112,2699.679999999999,0.0,0.0,1519360.0,379808.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",367,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,6726.0,2456.0,0.7325201481158788,1216128.0,1344.0,12.896,2712.575999999999,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38004.0,42.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.832,2717.407999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2720.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2722.8799999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,2726.335999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2729.8239999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.064,2733.8879999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.832,2738.7199999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2742.0479999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2745.4719999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",377,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,4.896,2750.3679999999986,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.224,2754.5919999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2757.9199999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2761.183999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.296,2764.4799999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.904,2768.3839999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",383,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,6336.0,6144.0,5.824,2774.2079999999987,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2777.6319999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.896,2782.527999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.84,2786.367999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",387,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.488,2789.855999999999,0.0,256.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,4.032,2793.887999999999,0.0,0.0,0.0,320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,2048.0,4608.0,0.0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,3.968,2797.855999999999,0.0,512.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.52,2801.375999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,1800.0,4112.0,0.0,0,0.0,4112.0,4112.0,0.0,16.0,0.0,1024.0,1024.0,4.384,2805.759999999999,0.0,512.0,1800.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.2,2808.9599999999987,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,2812.3839999999987,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",394,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,6.208,2818.5919999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",395,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.584,2822.1759999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2825.5039999999985,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.16,2829.6639999999984,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.416,2834.0799999999986,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",399,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.584,2841.6639999999984,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",400,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.872,2849.5359999999982,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.872,2857.407999999998,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.416,2861.8239999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",403,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.288,2866.1119999999983,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.6,2871.711999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,2876.0319999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,2879.4879999999985,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,2883.8399999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.096,2887.9359999999983,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",409,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.6,2893.5359999999982,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,2897.8239999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",411,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,2901.3759999999984,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.096,2905.4719999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.128,2909.5999999999985,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",414,23072.0,2203302.0,0.0,0,24159191040.0,2203302.0,24161394342.0,12510.0,24.0,0.9980852082336046,30720.0,6144.0,15.744,2925.3439999999987,1860065.0,297093.0,23072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),415,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,2936.6719999999987,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",416,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,2941.567999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,2944.991999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,2948.351999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",419,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,2954.239999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",420,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2957.503999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2960.831999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,2965.087999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",423,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,2969.6319999999987,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",424,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36608.0,9.536,2979.1679999999988,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",425,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.744,2982.911999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34720.0,9.536,2992.447999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1085.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",427,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.552,2995.999999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6784.0,19.808,3015.807999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,212.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",429,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3019.231999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",430,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,3022.623999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",431,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.792,3028.415999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",432,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3031.647999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3034.9439999999986,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",434,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.608,3039.5519999999988,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.576,3044.127999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",436,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.416,3052.543999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",437,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.744,3060.287999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.904,3068.191999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",439,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3072.543999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.096,3076.639999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.536,3082.175999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.576,3086.751999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",443,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,3090.399999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3095.039999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.16,3099.199999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",446,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,3104.479999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,3108.9919999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,3112.3199999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.288,3116.6079999999993,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.8,3121.4079999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",451,23840.0,2205306.0,0.0,0,24159191040.0,2205306.0,24161396346.0,12501.0,24.0,0.9980838323353294,30720.0,6144.0,15.68,3137.0879999999993,1860473.0,297153.0,23840.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),452,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,3148.383999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",453,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,3153.215999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,3156.703999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,3160.127999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",456,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.376,3165.503999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",457,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3168.767999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",458,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3172.191999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,3176.575999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.256,3180.831999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",461,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35424.0,9.248,3190.079999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1107.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.808,3193.887999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34816.0,9.504,3203.391999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1088.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.456,3206.847999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6912.0,19.008,3225.855999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,216.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3229.279999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.552,3232.831999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.6,3238.431999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3241.7279999999987,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3245.087999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,3249.5359999999987,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.256,3253.7919999999986,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.68,3261.4719999999984,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.0,3269.4719999999984,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.872,3277.3439999999982,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3281.695999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.096,3285.791999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.472,3291.2639999999983,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,3295.7439999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,3299.0719999999983,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,3303.3919999999985,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.512,3307.9039999999986,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",483,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,3313.279999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.064,3317.3439999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",485,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.264,3320.607999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",486,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.768,3325.375999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.64,3330.0159999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",488,24032.0,2205810.0,0.0,0,24159191040.0,2205810.0,24161396850.0,12501.0,24.0,0.9980838323353294,30720.0,6144.0,15.36,3345.375999999999,1860575.0,297171.0,24032.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),489,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.552,3356.927999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",490,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.736,3361.663999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,3365.279999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.488,3368.7679999999987,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.44,3374.2079999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3377.5359999999987,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3380.895999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.192,3385.087999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.32,3389.407999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35168.0,9.344,3398.751999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1099.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.84,3402.591999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36704.0,9.472,3412.0639999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1147.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.2,3415.263999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6624.0,19.456,3434.7199999999993,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,207.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,3438.399999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.264,3441.6639999999993,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,3447.1999999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3450.591999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,3454.1439999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.352,3458.495999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.288,3462.783999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.968,3470.751999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.424,3478.175999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.456,3485.631999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.16,3489.791999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.576,3494.367999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.536,3499.903999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.16,3504.063999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,3507.423999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3512.063999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.512,3516.575999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,3521.887999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,3526.175999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,3529.631999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.672,3534.303999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.384,3538.687999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,24064.0,2205894.0,0.0,0,24159191040.0,2205894.0,24161396934.0,12498.0,24.0,0.9980833732630571,30720.0,6144.0,15.392,3554.079999999999,1860592.0,297174.0,24064.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),526,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,3565.375999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,3570.335999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3573.7279999999987,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.296,3577.0239999999985,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,3582.9119999999984,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,3586.2719999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,3589.7599999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.416,3594.1759999999986,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.704,3598.8799999999987,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36032.0,8.96,3607.839999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1126.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.744,3611.583999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35232.0,9.408,3620.991999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1101.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.584,3624.5759999999987,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6400.0,19.552,3644.127999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,200.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3647.5519999999988,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,3650.9759999999987,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.984,3656.9599999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,3660.4479999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3663.7119999999986,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,3667.9679999999985,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.608,3672.5759999999987,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.744,3680.319999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.648,3687.967999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.808,3695.775999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3700.127999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.224,3704.351999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,3709.759999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,3714.143999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,3717.8239999999987,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,3722.3039999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.192,3726.4959999999987,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,3731.775999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,3736.383999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3739.775999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.16,3743.935999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.448,3748.3839999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,24032.0,2205810.0,0.0,0,24159191040.0,2205810.0,24161396850.0,12498.0,24.0,0.9980833732630571,30720.0,6144.0,15.744,3764.127999999999,1860575.0,297171.0,24032.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),563,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.456,3775.583999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,3780.543999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3783.935999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",566,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.264,3787.199999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",567,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.728,3792.927999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",568,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3796.127999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",569,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3799.4559999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,3803.839999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.576,3808.415999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36576.0,8.96,3817.375999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1143.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.68,3821.0559999999987,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35328.0,9.28,3830.335999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1104.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",575,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.52,3833.855999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",576,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6560.0,19.232,3853.087999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,205.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",577,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,3856.639999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",578,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.296,3859.935999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",579,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.728,3865.663999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",580,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3868.895999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3872.127999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.32,3876.447999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,3880.991999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.68,3888.6719999999987,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.712,3896.3839999999987,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",586,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.192,3904.5759999999987,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.448,3909.0239999999985,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.032,3913.0559999999987,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,3918.3679999999986,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3923.0079999999984,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,3926.6559999999986,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.224,3930.8799999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.384,3935.2639999999988,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",594,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,3940.6719999999987,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,3945.1519999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",596,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,3948.4799999999987,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.288,3952.7679999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",598,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.832,3957.5999999999985,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",599,24000.0,2205726.0,0.0,0,24159191040.0,2205726.0,24161396766.0,12498.0,24.0,0.9980833732630571,30720.0,6144.0,15.52,3973.1199999999985,1860558.0,297168.0,24000.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),600,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.52,3984.6399999999985,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",601,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.704,3989.3439999999987,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3992.7679999999987,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.584,3996.3519999999985,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",604,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.504,4001.8559999999984,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",605,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4005.055999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,4008.543999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.8,4013.3439999999982,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.224,4017.5679999999984,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,33792.0,8.896,4026.4639999999986,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1056.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",610,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.808,4030.2719999999986,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35040.0,9.248,4039.5199999999986,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1095.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",612,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,4042.8799999999987,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",613,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,7072.0,19.616,4062.4959999999987,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,221.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,4065.951999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,4069.3439999999987,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",616,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.44,4074.7839999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",617,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4078.047999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",618,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4081.4399999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",619,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.416,4085.855999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.352,4090.2079999999987,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.68,4097.887999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",622,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.776,4105.663999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.936,4113.5999999999985,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.224,4117.823999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.256,4122.079999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",626,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.504,4127.583999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,4132.191999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,4135.807999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,4140.127999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.48,4144.607999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,4149.887999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,4154.175999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",633,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,4157.663999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",634,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.608,4162.271999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.64,4166.911999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",636,24000.0,2205726.0,0.0,0,24159191040.0,2205726.0,24161396766.0,12498.0,24.0,0.9980833732630571,30720.0,6144.0,15.52,4182.431999999999,1860558.0,297168.0,24000.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),637,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,4193.791999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",638,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.992,4198.783999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",639,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,4202.271999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,4205.599999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",641,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.504,4211.103999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",642,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4214.463999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,4217.887999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.192,4222.079999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.288,4226.367999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35328.0,9.056,4235.423999999998,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1104.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",647,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.872,4239.2959999999985,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",648,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34784.0,9.152,4248.4479999999985,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1087.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",649,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,4251.8719999999985,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",650,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6464.0,19.232,4271.103999999998,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,202.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.744,4274.847999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.2,4278.047999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.408,4283.455999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,4286.751999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4290.079999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.608,4294.687999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.256,4298.9439999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",658,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,8.384,4307.3279999999995,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.584,4314.911999999999,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",660,1191936.0,2605056.0,24576.0,0,0.0,2629632.0,2629632.0,28800.0,24192.0,0.5434782608695652,2952192.0,6144.0,7.712,4322.624,98304.0,147456.0,1179648.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92256.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,4326.911999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.48,4331.391999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,4336.671999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,4341.055999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",665,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,4344.479999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,4349.0239999999985,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.544,4353.567999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.44,4359.007999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.128,4363.135999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",670,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,4366.623999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",671,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.576,4371.199999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",672,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.16,4375.359999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",673,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.328,4390.687999999998,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),674,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.456,4402.143999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",675,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,4407.039999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",676,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,4410.495999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",677,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,4413.855999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",678,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.792,4419.647999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",679,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4422.911999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4426.175999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.16,4430.335999999998,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.64,4434.975999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35584.0,8.96,4443.935999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1112.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.904,4447.839999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",685,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35392.0,9.088,4456.927999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1106.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",686,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,4460.287999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",687,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6752.0,19.712,4479.999999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,211.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,4483.423999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",689,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,4486.783999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",690,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.952,4492.735999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",691,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4496.095999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4499.359999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",693,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.608,4503.967999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,4508.351999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",695,235804672.0,515366912.0,4861952.0,0,0.0,520228864.0,520228864.0,5697600.0,4710016.0,0.5474452554744526,469296640.0,1785472.0,159.456,4667.807999999999,19447808.0,29171712.0,233373696.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14665520.0,55796.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4670.527999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",697,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.904,4674.432,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4677.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",699,128.0,304128.0,256.0,0,0.0,304384.0,304384.0,0.0,4784.0,0.0,1215488.0,1215488.0,3.84,4681.6,0.0,304128.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,37984.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.136,4684.736000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,81792.0,6.048,4690.784000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2556.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",702,143040.0,0.0,286080.0,0,0.0,286080.0,286080.0,19668.0,359094.0,0.05192706765726234,19852864.0,0.0,14.08,4704.8640000000005,0.0,0.0,0.0,143040.0,0,0,0,0,0,0,0,0.0,0.0,0.0,620402.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,82880.0,6.016,4710.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2590.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",704,85824.0,0.0,171648.0,0,0.0,171648.0,171648.0,19668.0,360882.0,0.051683090264091444,19852864.0,0.0,14.08,4724.96,0.0,0.0,0.0,85824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,620402.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,81920.0,6.016,4730.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2560.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",706,128736.0,0.0,257472.0,0,0.0,257472.0,257472.0,19668.0,359541.0,0.05186585761413891,19852864.0,0.0,13.952,4744.928,0.0,0.0,0.0,128736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,620402.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,4768.0,14264.0,0.2505254308532997,1219712.0,81728.0,5.952,4750.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38116.0,2554.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",708,100128.0,0.0,200256.0,0,0.0,200256.0,200256.0,19668.0,360435.0,0.05174386942486642,19852864.0,64.0,14.432,4765.312,0.0,0.0,0.0,100128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,620402.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,30.0,0.0,9568.0,1216.0,4.384,4769.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,299.0,38.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,4772.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,29.0,0.9566517189835575,1216.0,0.0,5.888,4778.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,4781.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",713,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,29.0,0.9566517189835575,1216.0,0.0,5.92,4787.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",714,76288.0,0.0,152576.0,0,0.0,152576.0,152576.0,67527.0,19200.0,0.7786156560240756,1246720.0,5344.0,9.088,4796.736,0.0,0.0,0.0,76288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38960.0,167.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,8.32,4805.056,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,1223936.0,103968.0,6.272,4811.3279999999995,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38248.0,3249.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,5.76,4817.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,47480.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",718,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,9496.0,0.0,0.0,2430976.0,4.448,4821.536,0.0,0.0,0.0,303872.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,9496.0,0.9343582370181939,1215488.0,0.0,6.08,4827.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,4831.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,85197.0,41695.0,0.6714134854837185,4121984.0,3010656.0,14.944,4845.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128812.0,94083.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,20613.0,43635.0,0.3208348898020172,4227072.0,3704832.0,12.512,4858.496,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,132096.0,115776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,21777.0,43548.0,0.33336394948335246,4209664.0,3704832.0,13.952,4872.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131552.0,115776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,21777.0,43491.0,0.3336550836550837,4200832.0,3393504.0,14.176,4886.624000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,131276.0,106047.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,9496.0,0.6088962108731466,2430976.0,0.0,5.312,4891.936000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.36,4895.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,19309.0,23933.0,0.4465334628370566,2932608.0,2145056.0,10.4,4905.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,91644.0,67033.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,37984.0,0.0,3666688.0,3646464.0,6.464,4912.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,114584.0,113952.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",729,4712348.0,10038336.0,916280.0,0,0.0,10954616.0,10954616.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,85.632,4997.7919999999995,1226048.0,303872.0,4254208.0,458140.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113952.0,37984.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",730,0.0,1526058.0,0.0,0,0.0,1526058.0,1526058.0,167436.0,18992.0,0.8981268908103933,1215488.0,1215488.0,285.184,5282.976,1526058.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,37984.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",731,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4784.0,0.0,1215488.0,303296.0,3.936,5286.911999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,9478.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.232,5290.143999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",733,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,28488.0,0.0,2734848.0,140352.0,11.52,5301.664,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85464.0,4386.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,7176.0,0.0,1519360.0,0.0,5.984,5307.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,47480.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",735,4712353.0,10038336.0,916290.0,0,0.0,10954626.0,10954626.0,264.0,9568.0,0.026851098454027666,3646464.0,1215488.0,86.816,5394.464,1226048.0,303872.0,4254208.0,458145.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113952.0,37984.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",736,58880.0,0.0,117760.0,0,0.0,117760.0,117760.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,9.12,5403.584,0.0,0.0,0.0,58880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,5406.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",738,58880.0,0.0,117760.0,0,0.0,117760.0,117760.0,3064.0,2415.0,0.5592261361562328,1215648.0,1248.0,9.856,5416.672,0.0,0.0,0.0,58880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37989.0,39.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,5420.031999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,5423.391999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.864,5428.2559999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",742,59468.0,492838.0,118936.0,0,0.0,611774.0,611774.0,3686.0,2416.0,0.6040642412323828,1215680.0,1280.0,9.6,5437.855999999999,492838.0,0.0,0.0,59468.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37990.0,40.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5441.151999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",744,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.184,5446.335999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,5449.567999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,5453.951999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",747,2973696.0,5473792.0,1081344.0,0,0.0,6555136.0,6555136.0,0.0,9496.0,0.0,0.0,1215488.0,7.04,5460.991999999999,0.0,607744.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,37984.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",748,1899169.0,3038720.0,759618.0,0,0.0,3798338.0,3798338.0,0.0,7176.0,0.0,2430976.0,0.0,5.76,5466.7519999999995,0.0,0.0,1519360.0,379809.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",749,49664.0,0.0,99328.0,0,0.0,99328.0,99328.0,6726.0,2456.0,0.7325201481158788,1216128.0,1344.0,12.832,5479.584,0.0,0.0,0.0,49664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,38004.0,42.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",750,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.904,5483.488,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,5486.304,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,5489.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,5492.544000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,5495.776000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",755,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,5499.808000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.992,5504.800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5508.064000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
