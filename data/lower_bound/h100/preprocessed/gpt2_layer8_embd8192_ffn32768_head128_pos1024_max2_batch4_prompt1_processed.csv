Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,11.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,14.975999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.68,18.656,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.672,23.328,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.408,28.736,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,32.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,34.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,40.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.968,44.8,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,48.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,51.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.16,55.42400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,58.592000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,61.824000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.392,65.21600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,3072.0,0.0,34816.0,131072.0,5.728,70.944,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1088.0,4096.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,3072.0,0.0,34816.0,131072.0,5.632,76.57600000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1088.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,80.00000000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,83.39200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.928,88.32000000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.632,109.95200000000001,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824270592.0,393216.0,277.92,387.872,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25758456.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,392.512,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.512,397.024,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.672,401.696,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,32.672,434.36800000000005,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",31,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,153856.0,3.104,437.47200000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4808.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",32,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3435882.0,0.7578472928074934,281309632.0,2127936.0,149.664,587.136,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8790926.0,66498.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",33,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.672,591.808,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.84,595.648,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.792,617.44,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091404672.0,524288.0,361.44,978.8800000000001,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34106396.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,982.5600000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.712,986.272,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,989.792,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.648,993.44,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,997.056,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,729388.0,1819224.0,65536.0,0,0.0,1884760.0,1884760.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,1000.672,131072.0,294912.0,696620.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,1004.352,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,1008.0319999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",45,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158464.0,3.072,1011.1039999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4952.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",46,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14128253.0,0.7528333082782966,1158130592.0,17031424.0,498.432,1509.536,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36191581.0,532232.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",47,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.48,1514.016,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.488,1517.5040000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",49,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.688,1540.1920000000002,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824239360.0,393216.0,278.08,1818.2720000000002,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25757480.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.512,1822.784,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.704,1827.488,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,1832.1280000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.472,1861.6000000000001,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,154752.0,3.072,1864.672,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4836.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",56,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3554624.0,0.7515577682649168,280808352.0,2126912.0,150.432,2015.104,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8775261.0,66466.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",57,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,5.024,2020.128,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.392,2023.52,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",59,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.824,2045.344,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091551488.0,524288.0,357.792,2403.136,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34110984.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,2406.656,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",62,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,2410.24,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,2413.7599999999998,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.904,2417.6639999999998,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",65,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,2421.1519999999996,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,729300.0,1819048.0,65536.0,0,0.0,1884584.0,1884584.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,2424.7679999999996,131072.0,294912.0,696532.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,2428.2559999999994,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,2431.9679999999994,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",69,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156800.0,3.2,2435.167999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4900.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",70,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14586888.0,0.7468409633244766,1157293856.0,17030816.0,489.216,2924.383999999999,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36165433.0,532213.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.576,2928.959999999999,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,2932.4159999999993,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.376,2953.7919999999995,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824349824.0,393216.0,276.704,3230.4959999999996,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25760932.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.48,3234.9759999999997,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.48,3239.4559999999997,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,3244.0959999999995,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",78,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.92,3274.0159999999996,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",79,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158336.0,3.136,3277.1519999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4948.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",80,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3431257.0,0.7580944004140922,281286496.0,2127328.0,150.176,3427.3279999999995,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8790203.0,66479.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",81,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.512,3431.8399999999997,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.392,3435.2319999999995,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",83,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.208,3457.4399999999996,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091800704.0,524288.0,360.512,3817.9519999999998,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34118772.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.744,3821.696,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",86,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.712,3825.408,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.808,3829.216,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",88,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,3832.928,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",89,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,3836.384,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,729116.0,1818680.0,65536.0,0,0.0,1884216.0,1884216.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,3840.032,131072.0,294912.0,696348.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",91,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,3843.4880000000003,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,3847.168,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",93,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157056.0,3.072,3850.2400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4908.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",94,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14316211.0,0.750365931889719,1155735968.0,17029920.0,490.88,4341.12,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36116749.0,532185.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",95,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.608,4345.728,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.648,4349.376,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.312,4370.688,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824174080.0,393216.0,277.76,4648.448,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25755440.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.512,4652.96,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.544,4657.504,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,4662.144,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",102,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.792,4691.936000000001,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",103,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,159616.0,3.104,4695.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4988.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",104,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3537208.0,0.752473717711511,280768608.0,2127712.0,148.512,4843.552000000001,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8774019.0,66491.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",105,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.896,4848.448,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.328,4851.776000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",107,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.472,4873.2480000000005,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091555200.0,524288.0,356.192,5229.4400000000005,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34111100.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",109,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,5232.992,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",110,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,5236.512000000001,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",111,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,5240.064,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,5243.776000000001,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",113,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,5247.296000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",114,729788.0,1820024.0,65536.0,0,0.0,1885560.0,1885560.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,5250.912000000001,131072.0,294912.0,697020.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",115,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,5254.368000000001,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",116,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,5258.080000000002,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",117,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157696.0,3.04,5261.120000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4928.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",118,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,13796025.0,0.7572344777588313,1156420128.0,17030400.0,488.16,5749.280000000002,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36138129.0,532200.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",119,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.64,5753.920000000002,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,5757.440000000002,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.336,5779.776000000003,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",122,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824120064.0,393216.0,275.904,6055.680000000002,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25753752.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.544,6060.224000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.576,6064.800000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,6069.440000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",126,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.504,6098.944000000002,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",127,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157952.0,3.104,6102.0480000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4936.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",128,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3300298.0,0.7651588713330556,281293408.0,2127968.0,150.944,6252.992000000003,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8790419.0,66499.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",129,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.64,6257.632000000003,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.68,6261.3120000000035,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",131,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.408,6282.720000000004,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",132,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091901568.0,524288.0,366.016,6648.7360000000035,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34121924.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,6652.320000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",134,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,6655.872000000003,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",135,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,6659.488000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",136,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.744,6663.232000000003,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,6666.880000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,729456.0,1819360.0,65536.0,0,0.0,1884896.0,1884896.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,6670.528000000003,131072.0,294912.0,696688.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",139,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.424,6673.952000000003,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,6677.664000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",141,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157184.0,3.04,6680.704000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4912.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",142,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14476817.0,0.7482703912385235,1153081984.0,17030624.0,468.864,7149.568000000003,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36033812.0,532207.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",143,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.448,7154.016000000003,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,7157.472000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.248,7178.720000000003,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824046080.0,393216.0,275.52,7454.240000000003,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25751440.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.544,7458.784000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.576,7463.360000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,7468.000000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",150,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,32.16,7500.1600000000035,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",151,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156288.0,3.104,7503.264000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4884.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",152,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3588779.0,0.7497679336412584,281290656.0,2127616.0,149.12,7652.384000000004,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8790333.0,66488.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",153,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.576,7656.960000000004,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,7660.480000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",155,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.888,7682.368000000004,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",156,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091641600.0,524288.0,361.056,8043.424000000004,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34113800.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",157,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,8046.944000000004,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",158,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,8050.4640000000045,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",159,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.808,8054.2720000000045,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.712,8057.984000000005,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,8061.600000000005,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,728988.0,1818424.0,65536.0,0,0.0,1883960.0,1883960.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,8065.248000000005,131072.0,294912.0,696220.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",163,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,8068.704000000005,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.616,8072.320000000005,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,155008.0,3.072,8075.392000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4844.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",166,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14192486.0,0.7519882809388656,1156937760.0,17030272.0,492.512,8567.904000000006,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36154305.0,532196.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",167,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.832,8572.736000000006,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.392,8576.128000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",169,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.048,8598.176000000007,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824284928.0,393216.0,276.032,8874.208000000006,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25758904.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.48,8878.688000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,8883.328000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.896,8888.224000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",174,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.504,8917.728000000006,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,153728.0,3.072,8920.800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4804.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",176,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3428777.0,0.7582269699031879,280915744.0,2127040.0,149.024,9069.824000000006,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8778617.0,66470.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",177,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.576,9074.400000000005,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.872,9078.272000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.72,9100.992000000004,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091699200.0,524288.0,358.368,9459.360000000004,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34115600.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",181,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,4.096,9463.456000000004,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",182,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,9467.072000000004,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,9470.624000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.776,9474.400000000003,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,9477.920000000004,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,729456.0,1819360.0,65536.0,0,0.0,1884896.0,1884896.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,9481.504000000004,131072.0,294912.0,696688.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,9484.992000000004,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.648,9488.640000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",189,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158464.0,3.072,9491.712000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4952.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",190,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,15636036.0,0.7334854964695603,1154923776.0,17031392.0,481.696,9973.408000000003,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36091368.0,532231.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.608,9978.016000000003,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,9981.536000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.92,10003.456000000004,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824176000.0,393216.0,278.848,10282.304000000004,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25755500.0,12288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.8,10287.104000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.48,10291.584000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,10296.224000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",198,1048576.0,34832384.0,0.0,0,309237645312.0,34832384.0,309272477696.0,272384.0,512.0,0.99812382739212,393216.0,131072.0,29.44,10325.664000000002,26345472.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,12288.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157824.0,3.104,10328.768000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4932.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",200,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3417179.0,0.7588475620285751,281021632.0,2127424.0,148.576,10477.344000000001,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8781926.0,66482.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",201,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.768,10482.112000000001,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,10485.568000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",203,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.592,10508.160000000002,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091660800.0,524288.0,357.664,10865.824000000002,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34114400.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",205,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,10869.376000000002,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",206,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,10872.960000000003,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",207,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,10876.544000000004,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.744,10880.288000000004,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",209,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,10883.776000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,729320.0,1819088.0,65536.0,0,0.0,1884624.0,1884624.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,10887.424000000003,131072.0,294912.0,696552.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,10890.944000000003,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",212,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,10894.624000000003,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156800.0,3.008,10897.632000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4900.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",214,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,15287512.0,0.7378688454653909,1154482208.0,17030944.0,475.008,11372.640000000003,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36077569.0,532217.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",215,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.448,11377.088000000003,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,11380.544000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",217,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.496,11403.040000000003,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,74637.0,0.0,0.0,1996768.0,3.968,11407.008000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,62399.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",219,3303168144.0,6603104256.0,6451488.0,0,0.0,6609555744.0,6609555744.0,66030288.0,14250604.0,0.8224907117374829,1705061376.0,14059968.0,860.96,12267.968000000004,0.0,3219456.0,3299942400.0,3225744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53283168.0,439374.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,12270.656000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",221,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.448,12275.104000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,12278.464000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",223,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.712,12282.176000000005,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.136,12285.312000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54080.0,5.792,12291.104000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1690.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",226,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.032,12299.136000000004,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53952.0,5.888,12305.024000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1686.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",228,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,0.0,8.064,12313.088000000005,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54272.0,6.016,12319.104000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1696.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",230,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,0.0,8.032,12327.136000000004,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,5.952,12333.088000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",232,76800.0,0.0,153600.0,0,0.0,153600.0,153600.0,13200.0,83208.0,0.13691809808314662,5134848.0,128.0,7.968,12341.056000000004,0.0,0.0,0.0,76800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.776,12344.832000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,12347.744000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.696,12353.440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.36,12356.800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.696,12362.496000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",238,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,53464.0,13012.0,0.804260184126602,831584.0,9056.0,8.896,12371.392000000005,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,283.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.544,12379.936000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,66528.0,6.144,12386.080000000005,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2079.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.384,12390.464000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",242,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.288,12394.752000000006,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",243,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,12400.992000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,12404.480000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28257.0,0.6997513600816049,2732096.0,2010400.0,15.232,12419.712000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85378.0,62825.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28384.0,0.3336150631544349,2720064.0,2451264.0,11.424,12431.136000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85002.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28197.0,0.3519122919922773,2721600.0,1555168.0,12.8,12443.936000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85050.0,48599.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28222.0,0.35171019686215055,2721984.0,1789760.0,12.992,12456.928000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85062.0,55930.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.928,12461.856000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.872,12465.728000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15293.0,0.49236539865896567,1866528.0,1340736.0,9.76,12475.488000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58329.0,41898.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2430080.0,2412352.0,5.28,12480.768000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75940.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",253,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1060768.0,753408.0,32.512,12513.280000000006,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33149.0,23544.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",254,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804288.0,617568.0,98.464,12611.744000000006,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25134.0,19299.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.648,12615.392000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,12618.624000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,91136.0,11.552,12630.176000000005,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2848.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.416,12634.592000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",259,3122060.0,6655044.0,615336.0,0,0.0,7270380.0,7270380.0,528.0,6704.0,0.07300884955752213,1082688.0,753472.0,31.904,12666.496000000005,825232.0,201028.0,2814392.0,307668.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33834.0,23546.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",260,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.376,12675.872000000005,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,12679.168000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",262,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.472,12688.640000000005,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,12692.000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,12695.424000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,12699.872000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",266,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.256,12716.128000000006,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,12719.520000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",268,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.056,12724.576000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,12727.936000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,12732.480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",271,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.952,12738.432000000006,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",272,1256420.0,2010280.0,502560.0,0,0.0,2512840.0,2512840.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,12743.840000000006,0.0,0.0,1005140.0,251280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",273,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.592,12766.432000000006,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,12769.760000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,12773.312000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.68,12776.992000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,12780.256000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.544,12784.800000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,12787.584000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",280,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,12790.336000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",281,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,12793.856000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",282,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,12796.672000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.904,12800.576000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",284,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.912,12807.488000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",285,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.552,12811.040000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,12814.624000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.416,12819.040000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.896,12823.936000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,12827.360000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,12830.784000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",291,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.768,12835.552000000009,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",292,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.32,12839.872000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.136,12843.008000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,12846.36800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",295,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.2,12849.56800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.68,12853.24800000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",297,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,3072.0,0.0,100352.0,131072.0,6.048,12859.296000000011,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3136.0,4096.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",298,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,3072.0,0.0,34816.0,131072.0,5.6,12864.896000000012,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1088.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.552,12868.448000000011,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",300,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,12871.808000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",301,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.12,12876.928000000013,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",302,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.6,12898.528000000013,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",303,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824375040.0,393216.0,276.384,13174.912000000013,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25761720.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",304,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.176,13181.088000000012,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",305,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.432,13187.520000000013,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.704,13192.224000000013,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",307,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.856,13222.080000000013,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,155264.0,3.04,13225.120000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4852.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",309,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3609727.0,0.7486744008860141,281625344.0,2127712.0,149.568,13374.688000000013,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8800792.0,66491.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",310,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.768,13379.456000000013,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.488,13382.944000000012,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",312,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.984,13404.928000000013,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",313,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091611136.0,524288.0,356.8,13761.728000000012,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34112848.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",314,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,13765.280000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",315,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,13768.864000000012,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",316,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,13772.448000000013,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",317,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.776,13776.224000000013,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,13779.776000000013,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",319,729246.0,1818940.0,65536.0,0,0.0,1884476.0,1884476.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,13783.456000000013,131072.0,294912.0,696478.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",320,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,13787.008000000013,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",321,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,13790.688000000013,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157568.0,3.04,13793.728000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4924.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",323,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14273798.0,0.750921284951653,1157985120.0,17030496.0,504.032,14297.760000000013,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36187035.0,532203.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",324,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.544,14302.304000000013,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",325,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.264,14305.568000000012,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",326,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.24,14327.808000000012,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",327,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824589056.0,393216.0,275.2,14603.008000000013,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25768408.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.016,14609.024000000012,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",329,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.144,14615.168000000012,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.576,14619.744000000012,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",331,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.92,14649.664000000012,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156800.0,3.232,14652.896000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4900.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",333,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3220630.0,0.76952127195936,281089728.0,2127424.0,149.504,14802.400000000012,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8784054.0,66482.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",334,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.544,14806.944000000012,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",335,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,14810.368000000013,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",336,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.76,14832.128000000013,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091655808.0,524288.0,357.184,15189.312000000013,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34114244.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",338,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,15192.864000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",339,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,15196.480000000012,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",340,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,15199.936000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,15203.616000000013,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",342,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.456,15207.072000000013,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,728976.0,1818400.0,65536.0,0,0.0,1883936.0,1883936.0,0.0,2048.0,0.0,524288.0,524288.0,3.712,15210.784000000012,131072.0,294912.0,696208.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,15214.432000000012,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",345,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.936,15218.368000000011,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157568.0,3.008,15221.376000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4924.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",347,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14008667.0,0.7544116105604501,1158639328.0,17029696.0,530.752,15752.128000000012,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36207479.0,532178.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",348,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.544,15756.672000000011,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",349,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.392,15760.064000000011,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",350,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.632,15781.69600000001,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",351,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824139392.0,393216.0,276.192,16057.88800000001,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25754356.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.336,16064.22400000001,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.112,16070.336000000008,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",354,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.576,16074.912000000008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",355,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.408,16104.320000000007,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157952.0,3.04,16107.360000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4936.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",357,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3088936.0,0.7768425858765666,281163136.0,2127872.0,149.44,16256.800000000008,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8786348.0,66496.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",358,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.48,16261.280000000008,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",359,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.808,16265.088000000009,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",360,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.016,16287.104000000008,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",361,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1092092416.0,524288.0,355.296,16642.40000000001,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34127888.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",362,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,16645.92000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",363,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,16649.53600000001,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,16653.12000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,16656.80000000001,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",366,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,16660.416000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",367,729439.0,1819326.0,65536.0,0,0.0,1884862.0,1884862.0,0.0,2048.0,0.0,524288.0,524288.0,3.616,16664.032000000014,131072.0,294912.0,696671.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,16667.616000000013,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.744,16671.36000000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156032.0,3.008,16674.368000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4876.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",371,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,15144322.0,0.7396849519202622,1158784288.0,17031104.0,497.088,17171.456000000013,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36212009.0,532222.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",372,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.576,17176.032000000014,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",373,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.392,17179.424000000014,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",374,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.248,17200.672000000013,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",375,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824022912.0,393216.0,275.968,17476.640000000014,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25750716.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.304,17482.944000000014,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.08,17489.024000000016,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.608,17493.632000000016,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",379,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.6,17523.232000000015,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158080.0,3.04,17526.272000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4940.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",381,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3433786.0,0.7579592593401899,281113344.0,2127456.0,148.448,17674.720000000016,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8784792.0,66483.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",382,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.448,17679.168000000016,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",383,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.584,17682.752000000015,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",384,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.016,17704.768000000015,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",385,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091676544.0,524288.0,356.416,18061.184000000016,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34114892.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,18064.704000000016,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",387,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.424,18068.128000000015,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,18071.616000000016,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.616,18075.232000000018,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",390,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,18078.784000000018,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",391,729553.0,1819554.0,65536.0,0,0.0,1885090.0,1885090.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,18082.368000000017,131072.0,294912.0,696785.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",392,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,18086.048000000017,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.84,18089.888000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,155392.0,3.04,18092.928000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4856.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",395,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14114314.0,0.7530169358297538,1159236224.0,17030912.0,526.496,18619.424000000017,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36226132.0,532216.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",396,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.416,18623.84000000002,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",397,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,18627.264000000017,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",398,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.432,18649.696000000018,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",399,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824089728.0,393216.0,275.488,18925.18400000002,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25752804.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.144,18931.32800000002,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.08,18937.40800000002,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.672,18942.08000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",403,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.568,18971.64800000002,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,155904.0,3.04,18974.68800000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4872.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",405,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3466453.0,0.7562179677916424,280942208.0,2127232.0,149.6,19124.28800000002,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8779444.0,66476.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",406,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.672,19128.960000000017,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",407,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,19132.384000000016,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",408,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.824,19154.208000000017,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1092114304.0,524288.0,357.568,19511.776000000016,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34128572.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",410,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,19515.328000000016,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",411,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,19518.848000000016,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,19522.368000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",413,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.84,19526.208000000017,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",414,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,19529.728000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,729217.0,1818882.0,65536.0,0,0.0,1884418.0,1884418.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,19533.408000000018,131072.0,294912.0,696449.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",416,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.648,19537.05600000002,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",417,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.744,19540.800000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158336.0,3.04,19543.84000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4948.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",419,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,13896687.0,0.7558955400494118,1160272768.0,17030112.0,515.712,20059.552000000018,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36258524.0,532191.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",420,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.448,20064.00000000002,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",421,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,20067.456000000017,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",422,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.664,20089.120000000017,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",423,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824262656.0,393216.0,277.12,20366.240000000016,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25758208.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.144,20372.384000000016,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",425,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.4,20378.784000000018,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.64,20383.424000000017,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",427,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.792,20413.21600000002,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",428,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,159488.0,3.04,20416.25600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4984.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",429,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3325415.0,0.7637937700337374,281189280.0,2127168.0,148.48,20564.73600000002,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8787165.0,66474.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",430,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.448,20569.18400000002,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.552,20572.73600000002,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.856,20594.59200000002,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",433,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091681536.0,524288.0,358.304,20952.89600000002,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34115048.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,20956.480000000018,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.744,20960.224000000017,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,20963.776000000016,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.776,20967.552000000018,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,20971.104000000018,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,729261.0,1818970.0,65536.0,0,0.0,1884506.0,1884506.0,0.0,2048.0,0.0,524288.0,524288.0,3.712,20974.816000000017,131072.0,294912.0,696493.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.68,20978.496000000017,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.776,20982.27200000002,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",442,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,156928.0,3.04,20985.31200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4904.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",443,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,13894585.0,0.755923451021912,1159801152.0,17029280.0,530.976,21516.28800000002,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36243786.0,532165.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",444,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.8,21521.088000000018,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.584,21524.672000000017,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",446,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.528,21547.200000000015,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",447,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,824041216.0,393216.0,276.064,21823.264000000014,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25751288.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.144,21829.408000000014,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.08,21835.488000000016,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.672,21840.160000000014,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",451,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,30.336,21870.496000000014,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",452,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158208.0,3.264,21873.760000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4944.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",453,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3334037.0,0.7633262892806385,281165376.0,2127264.0,147.488,22021.248000000014,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8786418.0,66477.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",454,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.48,22025.728000000014,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,22029.248000000014,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",456,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,23.072,22052.320000000014,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",457,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091880320.0,524288.0,357.76,22410.080000000013,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34121260.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",458,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,22413.66400000001,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",459,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,22417.152000000013,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",460,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,22420.704000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",461,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.648,22424.352000000014,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",462,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.488,22427.840000000015,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,729233.0,1818914.0,65536.0,0,0.0,1884450.0,1884450.0,0.0,2048.0,0.0,524288.0,524288.0,3.872,22431.712000000014,131072.0,294912.0,696465.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",464,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,22435.232000000015,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.84,22439.072000000015,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",466,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,157568.0,3.072,22442.144000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4924.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",467,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,14674549.0,0.7457064617237473,1156058816.0,17031168.0,483.008,22925.152000000016,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36126838.0,532224.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",468,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.544,22929.696000000018,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",469,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,22933.152000000016,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",470,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.696,22954.848000000016,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",471,808550400.0,1629880320.0,6488064.0,0,0.0,1636368384.0,1636368384.0,7093248.0,6690816.0,0.5145977267662135,823793024.0,393216.0,275.584,23230.432000000015,6684672.0,12582912.0,805306368.0,3244032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25743532.0,12288.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",472,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.4,23236.832000000017,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,0.0,4096.0,0.0,262144.0,262144.0,6.272,23243.104000000018,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,2048.0,0.0,131072.0,131072.0,4.896,23248.00000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",475,1048576.0,34865152.0,0.0,0,309237645312.0,34865152.0,309272510464.0,272384.0,512.0,0.99812382739212,655360.0,131072.0,29.248,23277.248000000018,26378240.0,6389760.0,1048576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1207959552.0,20480.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,158208.0,3.04,23280.28800000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4944.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",477,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3406553.0,0.7594170362575097,280690912.0,2127264.0,148.512,23428.800000000017,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8771591.0,66477.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",478,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.8,23433.600000000017,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",479,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.712,23437.312000000016,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",480,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,22.72,23460.032000000017,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",481,1078067200.0,2173173760.0,8650752.0,0,0.0,2181824512.0,2181824512.0,9457664.0,8921088.0,0.5145977267662135,1091729280.0,524288.0,354.816,23814.848000000016,8912896.0,16777216.0,1073741824.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34116540.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",482,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,23818.368000000017,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",483,0.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,23821.952000000016,0.0,262144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",484,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.552,23825.504000000015,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",485,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,3072.0,0.0,1048576.0,524288.0,3.68,23829.184000000016,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",486,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,524288.0,524288.0,3.52,23832.704000000016,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,729331.0,1819110.0,65536.0,0,0.0,1884646.0,1884646.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,23836.288000000015,131072.0,294912.0,696563.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",488,131072.0,262144.0,0.0,0,0.0,262144.0,262144.0,0.0,2048.0,0.0,524288.0,524288.0,3.584,23839.872000000014,0.0,0.0,131072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,16384.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",489,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,3072.0,0.0,1048576.0,524288.0,3.744,23843.616000000013,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32768.0,16384.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8192.0,0.0,0.0,160256.0,3.104,23846.720000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,5008.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",491,2155880448.0,4307550208.0,8404992.0,0,0.0,4315955200.0,4315955200.0,43032576.0,13959052.0,0.7550683760077884,1161205632.0,17030784.0,539.232,24385.952000000012,0.0,4194304.0,2151677952.0,4202496.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36287676.0,532212.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",492,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,10240.0,0.0,163840.0,0.0,4.896,24390.848000000013,32768.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,24394.30400000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",494,178244.0,568564.0,8192.0,0,0.0,576756.0,576756.0,80.0,2824.0,0.027548209366391185,393216.0,131328.0,21.952,24416.256000000012,174640.0,45628.0,174148.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,4104.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,74637.0,0.0,0.0,2009024.0,3.968,24420.224000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,62782.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",496,3303168144.0,6603104256.0,6451488.0,0,0.0,6609555744.0,6609555744.0,66030288.0,14323878.0,0.8217406923245274,1707171456.0,14058720.0,855.328,25275.552000000014,0.0,3219456.0,3299942400.0,3225744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53349108.0,439335.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,25278.336000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.936,25282.272000000015,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",499,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,25285.728000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",500,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.584,25289.312000000013,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,25292.256000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54208.0,5.888,25298.14400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1694.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",503,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.288,25306.43200000001,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,5.984,25312.416000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",505,97600.0,0.0,195200.0,0,0.0,195200.0,195200.0,13200.0,82558.0,0.1378474905490925,5134848.0,0.0,8.096,25320.512000000013,0.0,0.0,0.0,97600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54976.0,5.984,25326.496000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1718.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",507,67200.0,0.0,134400.0,0,0.0,134400.0,134400.0,13200.0,83508.0,0.13649336145923813,5134848.0,0.0,7.968,25334.464000000014,0.0,0.0,0.0,67200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54848.0,5.952,25340.416000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1714.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",509,86400.0,0.0,172800.0,0,0.0,172800.0,172800.0,13200.0,82908.0,0.13734548632788113,5134848.0,128.0,7.936,25348.352000000017,0.0,0.0,0.0,86400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.744,25352.096000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",511,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,25355.328000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.6,25360.928000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,25364.000000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.696,25369.696000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",515,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,39647.0,13020.0,0.7527863747697799,831584.0,8288.0,8.832,25378.528000000013,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,259.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.448,25386.976000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,68608.0,6.016,25392.992000000013,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.416,25397.408000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",519,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,3.936,25401.344000000016,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,25407.584000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",521,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,25411.040000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28320.0,0.6992832492699761,2722240.0,1998624.0,15.072,25426.112000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85070.0,62457.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28288.0,0.33436867617299637,2736192.0,2451264.0,11.456,25437.568000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85506.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28203.0,0.3518637679827182,2736192.0,2250688.0,13.216,25450.784000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85506.0,70334.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28189.0,0.35197701149425287,2717120.0,2247264.0,13.088,25463.872000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84910.0,70227.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.96,25468.832000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.52,25472.352000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15166.0,0.4944498149938331,1866400.0,1341120.0,9.568,25481.920000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58325.0,41910.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",529,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429440.0,2412352.0,5.216,25487.136000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75920.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",530,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1052064.0,753024.0,31.424,25518.560000000012,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32877.0,23532.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",531,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804320.0,618624.0,97.408,25615.96800000001,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25135.0,19332.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.872,25619.84000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.296,25623.13600000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,93472.0,11.84,25634.97600000001,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2921.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",535,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.48,25639.45600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",536,3122059.0,6655044.0,615334.0,0,0.0,7270378.0,7270378.0,528.0,6704.0,0.07300884955752213,1082816.0,753344.0,32.032,25671.48800000001,825232.0,201028.0,2814392.0,307667.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33838.0,23542.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",537,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.344,25680.83200000001,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,25684.16000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",539,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.408,25693.56800000001,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,25696.99200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",541,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,25700.38400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,25704.86400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",543,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.096,25720.96000000001,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,25724.51200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",545,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.12,25729.63200000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,25732.86400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",547,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,25737.248000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",548,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.176,25743.424000000006,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",549,1256419.0,2010280.0,502558.0,0,0.0,2512838.0,2512838.0,0.0,4737.0,0.0,1608256.0,0.0,5.536,25748.960000000006,0.0,0.0,1005140.0,251279.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",550,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.112,25771.072000000007,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",551,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,25774.496000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",552,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,25777.888000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.0,25781.888000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,25785.120000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",555,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.904,25789.024000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,25791.872000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",557,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,25794.752000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",558,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,25798.11200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",559,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,25800.800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.128,25804.928000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",561,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.232,25812.160000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,25815.520000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",563,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,25818.976000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",564,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.096,25823.072000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",565,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.928,25828.000000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",566,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,25831.232000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
