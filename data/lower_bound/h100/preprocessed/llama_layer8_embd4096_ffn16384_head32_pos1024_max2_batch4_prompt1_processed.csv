Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,8.352,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,11.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,15.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.744,19.136,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.704,23.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.928,28.768,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,32.416000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,35.29600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,38.016000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,41.056000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.936,44.992000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,48.096000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,51.48800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.256,55.74400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,58.976000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,62.49600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.552,66.04800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,5.632,71.68000000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,75.10400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,80.38400000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,83.93600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.424,87.36000000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,91.36000000000004,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.544,95.90400000000004,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.392,99.29600000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.448,103.74400000000003,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.296,107.04000000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.744,110.78400000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.512,119.29600000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.68,122.97600000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,126.27200000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,130.84800000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.384,135.23200000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75804160.0,95648.0,36.352,171.58400000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368880.0,2989.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793024.0,96160.0,36.256,207.84000000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368532.0,3005.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75796480.0,97920.0,36.512,244.35200000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368640.0,3060.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,249.05600000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.544,253.60000000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.632,259.232,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.64,263.872,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,267.36,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.736,272.096,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.416,276.512,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.4,282.912,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,287.52,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,290.94399999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,15.776,306.71999999999997,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75781120.0,94752.0,40.672,347.39199999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368160.0,2961.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,350.7199999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,354.0479999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.352,362.39999999999986,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,365.69599999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,369.21599999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,373.82399999999984,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,378.33599999999984,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298109312.0,371712.0,136.192,514.5279999999998,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9315916.0,11616.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.776,518.3039999999997,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297884544.0,370240.0,138.432,656.7359999999998,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9308892.0,11570.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,660.3199999999997,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303112064.0,97504.0,126.816,787.1359999999997,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9472252.0,3047.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,790.5919999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,793.8239999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.288,802.1119999999997,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,805.3759999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,808.7999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.768,813.5679999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.576,818.1439999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75795200.0,95680.0,37.792,855.9359999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368600.0,2990.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75798912.0,96416.0,35.616,891.5519999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368716.0,3013.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75790464.0,98144.0,37.216,928.7679999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368452.0,3067.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.672,933.4399999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.576,938.0159999999998,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.888,943.9039999999999,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.64,948.5439999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,951.9999999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.544,956.5439999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.64,961.1839999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.568,966.7519999999998,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,971.5199999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,974.9439999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,16.192,991.1359999999999,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793408.0,96864.0,36.256,1027.3919999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368544.0,3027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,1030.8479999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.488,1034.3359999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.416,1042.7519999999997,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1045.9839999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1049.1839999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.32,1053.5039999999997,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,1058.0159999999996,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297643904.0,376960.0,137.472,1195.4879999999996,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9301372.0,11780.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.712,1199.1999999999996,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297898752.0,378688.0,134.016,1333.2159999999997,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309336.0,11834.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,1336.7359999999996,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303110016.0,101984.0,127.04,1463.7759999999996,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9472188.0,3187.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,1467.1679999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,1470.5919999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.224,1478.8159999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1481.9839999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1485.2479999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,1489.8239999999994,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,1494.3359999999993,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807872.0,92640.0,36.64,1530.9759999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368996.0,2895.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807744.0,97792.0,36.0,1566.9759999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368992.0,3056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75794944.0,94688.0,35.936,1602.9119999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368592.0,2959.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.48,1607.3919999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.48,1611.8719999999994,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.24,1618.1119999999994,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,1622.8159999999993,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.68,1626.4959999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,1631.0719999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.48,1635.5519999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.568,1641.1199999999994,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,1645.6319999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,1649.0239999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,16.0,1665.0239999999994,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75804672.0,97280.0,34.848,1699.8719999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368896.0,3040.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1703.3919999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,1706.6559999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.352,1715.0079999999994,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1718.2719999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1721.6319999999992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,1726.2079999999992,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.64,1730.8479999999993,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298062592.0,372672.0,138.56,1869.4079999999992,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9314456.0,11646.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.84,1873.2479999999991,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297610624.0,368160.0,136.48,2009.7279999999992,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9300332.0,11505.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,2013.2159999999992,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303243008.0,99520.0,123.264,2136.479999999999,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9476344.0,3110.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,2139.967999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.296,2143.2639999999988,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.064,2151.3279999999986,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,2154.7519999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,2158.2079999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.512,2162.719999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.608,2167.327999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75806336.0,96128.0,36.864,2204.191999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368948.0,3004.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75806464.0,94976.0,37.184,2241.3759999999993,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368952.0,2968.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75799296.0,99680.0,36.512,2277.8879999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368728.0,3115.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,2282.4639999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.576,2287.0399999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.728,2292.7679999999996,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,2297.3439999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,2300.6719999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.416,2305.0879999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.448,2309.5359999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.984,2315.5199999999995,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,2320.0319999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.36,2323.392,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,15.84,2339.232,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75811072.0,97856.0,35.712,2374.944,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369096.0,3058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,2378.464,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,2381.8559999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.416,2390.272,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,2393.6,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2396.832,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.512,2401.344,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,2406.0480000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297654528.0,378688.0,134.464,2540.512,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9301704.0,11834.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.744,2544.2560000000003,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297794304.0,375584.0,138.72,2682.976,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9306072.0,11737.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.616,2686.592,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303156480.0,94912.0,126.912,2813.504,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473640.0,2966.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,2816.96,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,2820.384,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.48,2828.864,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2832.064,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2835.2639999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.512,2839.776,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.48,2844.256,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75787392.0,98240.0,36.8,2881.056,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368356.0,3070.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793664.0,96608.0,36.288,2917.344,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368552.0,3019.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75784448.0,100992.0,34.688,2952.032,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368264.0,3156.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.48,2956.512,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.416,2960.9280000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.176,2967.1040000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,2971.6160000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.36,2974.9760000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.672,2979.6480000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.608,2984.2560000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.728,2989.984000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,2994.560000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,2997.888000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,15.968,3013.8560000000007,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807232.0,98912.0,35.776,3049.6320000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368976.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,3053.0560000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,3056.3840000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.096,3064.4800000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,3067.9680000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3071.3920000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.64,3076.032,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.544,3080.576,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297363840.0,374944.0,134.304,3214.88,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9292620.0,11717.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.744,3218.6240000000003,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297095680.0,378816.0,133.312,3351.936,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9284240.0,11838.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,3355.456,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303181952.0,98528.0,121.088,3476.5440000000003,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474436.0,3079.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,3480.0000000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.36,3483.3600000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.128,3491.4880000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3494.7200000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3498.0160000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.448,3502.4640000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,3506.9760000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793152.0,96064.0,37.824,3544.8000000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368536.0,3002.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75801088.0,97280.0,35.36,3580.1600000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368784.0,3040.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75792000.0,95840.0,37.408,3617.5680000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368500.0,2995.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,3622.272000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.672,3626.944000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.632,3632.576000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,3637.280000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,3640.768000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.672,3645.440000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.544,3649.984000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.08,3656.0640000000008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.48,3660.544000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.264,3663.808000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,15.968,3679.7760000000007,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75818624.0,95680.0,35.648,3715.424000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369332.0,2990.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.616,3719.040000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,3722.368000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.32,3730.688000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3733.888000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3737.0880000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,3741.696000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.768,3746.464000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298078080.0,377184.0,138.24,3884.7040000000006,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9314940.0,11787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.904,3888.6080000000006,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297335936.0,381024.0,131.648,4020.2560000000008,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9291748.0,11907.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.68,4023.9360000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303142528.0,95232.0,130.528,4154.464000000001,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473204.0,2976.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,4157.952000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,4161.408000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.544,4169.952000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4173.120000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4176.384000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.512,4180.896000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.608,4185.504000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75790592.0,98496.0,35.616,4221.120000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368456.0,3078.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75800320.0,96672.0,35.36,4256.4800000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368760.0,3021.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75794432.0,97024.0,35.84,4292.320000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368576.0,3032.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.8,4297.120000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.384,4301.504000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.696,4307.200000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.544,4311.744000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,4315.168000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,4319.936000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.416,4324.352000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.24,4330.592000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,4335.168000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.36,4338.528,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,16.384,4354.912,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75818880.0,95840.0,36.384,4391.296,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369340.0,2995.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,4394.816000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,4398.240000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.16,4406.400000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,4409.856000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4413.152000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.544,4417.696000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,4422.400000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298102528.0,369856.0,133.696,4556.0960000000005,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9315704.0,11558.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.84,4559.936000000001,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297940480.0,377824.0,139.648,4699.584000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9310640.0,11807.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,4703.104000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303165952.0,96256.0,128.864,4831.968000000001,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473936.0,3008.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,4835.456000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,4838.848000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.288,4847.136,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,4850.432000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,4853.856000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,4858.432000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,4862.944,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75803136.0,97568.0,36.448,4899.392000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368848.0,3049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75795200.0,96736.0,36.576,4935.968000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368600.0,3023.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75791104.0,96320.0,40.064,4976.032000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368472.0,3010.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,4980.800000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.576,4985.376000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.696,4991.072000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.64,4995.712000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.584,4999.296000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.576,5003.872000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.512,5008.384000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.984,5014.368000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.896,5019.264000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,5022.752000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,16.0,5038.752000000001,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75799552.0,96960.0,34.976,5073.728000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368736.0,3030.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,5077.120000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,5080.512000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.352,5088.8640000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,5092.192000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,5095.520000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.48,5100.000000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,5104.704000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297988096.0,372832.0,137.248,5241.952,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9312128.0,11651.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.616,5245.568,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298709120.0,372640.0,136.32,5381.888,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9334660.0,11645.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.424,5385.312,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303241344.0,98336.0,121.248,5506.5599999999995,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9476292.0,3073.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,5510.08,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,5513.536,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.288,5521.824,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,5525.023999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,5528.223999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,5532.831999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.736,5537.567999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,533504000.0,1148928000.0,18432000.0,0,0.0,1167360000.0,1167360000.0,6928000.0,6208000.0,0.5274056029232643,579051904.0,740672.0,235.616,5773.183999999999,34816000.0,65536000.0,524288000.0,9216000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18095372.0,23146.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5775.967999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.544,5780.511999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5783.807999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.712,5787.5199999999995,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.168,5790.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35072.0,5.792,5796.48,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.592,5803.071999999999,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34688.0,5.92,5808.991999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1084.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,53248.0,0.0,106496.0,0,0.0,106496.0,106496.0,8448.0,34696.0,0.19580938253291302,2109440.0,0.0,6.656,5815.647999999999,0.0,0.0,0.0,53248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34240.0,5.824,5821.471999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1070.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,8448.0,34568.0,0.19639204017109912,2109440.0,0.0,6.752,5828.223999999999,0.0,0.0,0.0,57344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,5.76,5833.9839999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,8448.0,34824.0,0.19523017193566278,2109440.0,128.0,6.368,5840.352,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.68,5844.032,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,5847.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.568,5852.64,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,5855.712,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.568,5861.280000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,21320.0,8432.0,0.7165904813121807,527232.0,6944.0,8.448,5869.728000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,217.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.512,5878.240000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42720.0,6.528,5884.768000000001,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1335.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.52,5888.288000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.584,5891.872000000001,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.792,5897.664000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,5901.184000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17713.0,0.7018063668961801,1704960.0,1261888.0,15.264,5916.448000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53280.0,39434.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,15108.0,17556.0,0.46252755326965467,1685888.0,1119040.0,11.968,5928.416000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52684.0,34970.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17599.0,0.3802950808127047,1701888.0,1213888.0,13.28,5941.696000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53184.0,37934.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,9396.0,17606.0,0.34797422413154583,1695616.0,1560576.0,13.088,5954.7840000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52988.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.736,5959.520000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.552,5963.072000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9406.0,0.5284976690560931,1169920.0,858336.0,9.12,5972.192000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36560.0,26823.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549632.0,1536000.0,4.8,5976.992000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48426.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512128.0,512000.0,23.072,6000.064000000001,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16004.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,64.064,6064.1280000000015,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.584,6067.712000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,6070.912000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,59328.0,11.936,6082.848000000001,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1854.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.648,6086.496000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.944,6109.440000000001,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.16,6141.600000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6144.960000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.064,6177.024000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,6180.448000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,6183.808000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,6188.256000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.936,6200.192000000001,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6203.552000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.928,6208.4800000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,6211.968000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,6216.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,6221.568,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.088,6226.656,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.576,6243.232,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,6246.624,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,6250.1759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.648,6253.824,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,6257.183999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.384,6261.567999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,6264.447999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,6267.1359999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,6270.495999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,6273.343999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,4.064,6277.407999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.584,6284.991999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,6288.383999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,6291.807999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.128,6295.935999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.8,6300.735999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6304.095999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,6307.647999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.056,6312.703999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.16,6316.863999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.2,6320.063999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.136,6323.199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.36,6326.559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,4.16,6330.7199999999975,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,66560.0,65536.0,7.84,6338.559999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2080.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.424,6341.983999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.992,6346.975999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,6350.495999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.424,6353.919999999998,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,6357.919999999998,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.352,6362.271999999998,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,6365.5999999999985,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.416,6370.015999999999,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.2,6373.2159999999985,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.36,6376.575999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.64,6385.2159999999985,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,6388.479999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,6391.775999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,6396.351999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.544,6400.895999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75785856.0,99584.0,34.304,6435.199999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368308.0,3112.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75803392.0,95200.0,35.648,6470.847999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368856.0,2975.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75810432.0,96960.0,35.392,6506.239999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369076.0,3030.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,6510.847999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.416,6515.263999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.016,6521.279999999999,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.864,6526.143999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.616,6529.759999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,6534.463999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.544,6539.007999999998,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.112,6545.119999999998,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,6549.727999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,6553.151999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.608,6557.759999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.832,6562.591999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,261920.0,23543220.0,0.0,0,257698037760.0,23543220.0,257721580980.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,15.936,6578.527999999998,19849097.0,3170283.0,261920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75780224.0,94496.0,37.984,6616.511999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368132.0,2953.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,6619.935999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,6623.263999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.416,6631.679999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,6634.976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,6638.1759999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,6642.7519999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.576,6647.3279999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297846528.0,373120.0,138.336,6785.664,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9307704.0,11660.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,6789.312,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297474688.0,377312.0,132.832,6922.144,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9296084.0,11791.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,6925.696,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303179904.0,97920.0,137.056,7062.7519999999995,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474372.0,3060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,7066.048,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.264,7069.312,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.512,7077.824,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,7081.152,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,7084.416,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.416,7088.832,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,7093.344,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75805440.0,92832.0,37.152,7130.496,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368920.0,2901.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807488.0,95904.0,34.752,7165.2480000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368984.0,2997.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75791104.0,95840.0,35.776,7201.024,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368472.0,2995.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.672,7205.696,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.48,7210.1759999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.6,7215.776,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,7220.384,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,7223.84,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.544,7228.384,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.48,7232.864,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.472,7238.335999999999,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,7242.847999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,7246.3679999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.64,7251.008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.832,7255.84,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,262080.0,23543640.0,0.0,0,257698037760.0,23543640.0,257721581400.0,133126.0,256.0,0.9980807005443013,327680.0,65536.0,15.872,7271.712,19849182.0,3170298.0,262080.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75784192.0,96832.0,37.152,7308.8640000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368256.0,3026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.648,7312.512000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,7315.904,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.288,7324.192,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,7327.552,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,7330.848,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.672,7335.5199999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.544,7340.063999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298021888.0,369184.0,139.936,7479.999999999999,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9313184.0,11537.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.808,7483.807999999999,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297912448.0,373728.0,138.08,7621.887999999999,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309764.0,11679.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,7625.407999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303149568.0,98528.0,121.984,7747.392,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473424.0,3079.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,7750.848,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,7754.048,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.608,7762.656,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,7766.08,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,7769.312,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,7773.92,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.768,7778.688,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75818496.0,95136.0,35.488,7814.176,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369328.0,2973.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75785472.0,95072.0,37.632,7851.808,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368296.0,2971.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75811072.0,97152.0,37.472,7889.28,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369096.0,3036.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.544,7893.824,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.64,7898.464,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.504,7903.968,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,7908.48,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.648,7912.128,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.48,7916.607999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.384,7920.991999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.472,7926.463999999999,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,7931.167999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.584,7934.751999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.64,7939.391999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.544,7943.935999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,16.032,7959.967999999999,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75801984.0,100704.0,34.752,7994.719999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368812.0,3147.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,7998.143999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,8001.375999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.768,8010.143999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,8013.407999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,8016.575999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.768,8021.343999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.544,8025.887999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297973888.0,377088.0,136.896,8162.783999999999,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9311684.0,11784.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,8166.431999999999,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297809792.0,369664.0,141.184,8307.615999999998,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9306556.0,11552.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,8311.103999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303167616.0,97824.0,120.32,8431.423999999997,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473988.0,3057.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,8434.847999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,8438.175999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.352,8446.527999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,8450.079999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,8453.503999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.672,8458.176,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.384,8462.56,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75786496.0,94816.0,35.904,8498.464,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368328.0,2963.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75797504.0,98528.0,35.712,8534.176,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368672.0,3079.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75812864.0,93216.0,37.28,8571.456,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369152.0,2913.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.448,8575.904,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.448,8580.352,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.664,8586.016000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,8590.784000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.36,8594.144000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.48,8598.624000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.352,8602.976000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.664,8608.640000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.8,8613.440000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,8616.960000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.64,8621.600000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.768,8626.368000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,16.096,8642.464000000002,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75786624.0,97056.0,35.936,8678.400000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368332.0,3033.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,8681.856000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.232,8685.088000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.448,8693.536000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,8696.896000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,8700.128000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.448,8704.576000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,8709.280000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297929728.0,371808.0,135.328,8844.608000000002,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9310304.0,11619.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,8848.256000000001,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298053504.0,374336.0,137.184,8985.44,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9314172.0,11698.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,8988.960000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303155840.0,97376.0,131.264,9120.224,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473620.0,3043.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,9123.68,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.328,9127.008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.608,9135.616,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,9138.912,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,9142.272,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.768,9147.04,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,9151.744,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75812096.0,98656.0,35.84,9187.584,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369128.0,3083.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75809536.0,98016.0,36.384,9223.968,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369048.0,3063.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75800832.0,98208.0,36.032,9260.0,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368776.0,3069.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.544,9264.544,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.48,9269.024,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.984,9275.008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.512,9279.52,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,9282.976,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,9287.744,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.448,9292.192000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.016,9298.208,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.448,9302.656,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,9306.080000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.576,9310.656,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.8,9315.456,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,16.0,9331.456,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75804544.0,96544.0,36.576,9368.032,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368892.0,3017.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,9371.423999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,9374.848,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.512,9383.36,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,9386.656,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,9389.856000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.832,9394.688000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.64,9399.328000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297938688.0,372384.0,134.816,9534.144000000002,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9310584.0,11637.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.808,9537.952000000003,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297529344.0,375488.0,136.0,9673.952000000003,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9297792.0,11734.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.424,9677.376000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303196544.0,99872.0,120.992,9798.368000000004,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474892.0,3121.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,9801.664000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,9805.120000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.32,9813.440000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,9816.992000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,9820.224000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.736,9824.960000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.48,9829.440000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75832960.0,96768.0,34.4,9863.840000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369780.0,3024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75789312.0,98144.0,34.848,9898.688000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368416.0,3067.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75811200.0,94464.0,36.384,9935.072000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369100.0,2952.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.672,9939.744000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.544,9944.288000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.984,9950.272000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,9954.976000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,9958.272000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.736,9963.008000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.352,9967.360000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.176,9973.536000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,9978.240000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,9981.696000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.832,9986.528000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.8,9991.328000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,15.904,10007.232000000005,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75801216.0,95392.0,37.568,10044.800000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368788.0,2981.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,10048.224000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.392,10051.616000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.32,10059.936000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,10063.488000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,10066.720000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,10071.296000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.48,10075.776000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298351872.0,375232.0,135.424,10211.200000000004,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9323496.0,11726.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.904,10215.104000000005,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,296934144.0,379072.0,133.504,10348.608000000006,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9279192.0,11846.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.456,10352.064000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303277824.0,97184.0,120.864,10472.928000000005,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9477432.0,3037.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.68,10476.608000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.456,10480.064000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.576,10488.640000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,10491.936000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,10495.360000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,10499.968000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.704,10504.672000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75821696.0,95840.0,34.944,10539.616000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369428.0,2995.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75801984.0,97408.0,35.168,10574.784000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368812.0,3044.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807104.0,99712.0,35.072,10609.856000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368972.0,3116.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,10614.464000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.576,10619.040000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.6,10624.640000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,10629.344000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,10632.768000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.608,10637.376000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.512,10641.888000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.408,10647.296000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.64,10651.936000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,10655.360000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.64,10660.000000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.864,10664.864000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,16.128,10680.992000000006,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75806080.0,97888.0,35.648,10716.640000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368940.0,3059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,10720.128000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.2,10723.328000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.576,10731.904000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,10735.392000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,10738.752000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.512,10743.264000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.448,10747.712000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297585152.0,375104.0,140.8,10888.512000000004,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9299536.0,11722.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.776,10892.288000000004,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297353216.0,373408.0,134.464,11026.752000000004,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9292288.0,11669.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.424,11030.176000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303159168.0,98208.0,126.464,11156.640000000005,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473724.0,3069.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,11160.032000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.424,11163.456000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.544,11172.000000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,11175.360000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,11178.592000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.608,11183.200000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.512,11187.712000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75795328.0,97952.0,35.584,11223.296000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368604.0,3061.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75783040.0,98464.0,34.688,11257.984000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368220.0,3077.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75797504.0,97568.0,35.2,11293.184000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368672.0,3049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.64,11297.824000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.576,11302.400000000007,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.632,11308.032000000007,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.736,11312.768000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,11316.192000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.704,11320.896000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,4.448,11325.344000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.76,11331.104000000008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,4.768,11335.872000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.584,11339.45600000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.704,11344.160000000009,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,4.64,11348.800000000008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,15.84,11364.640000000009,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75807104.0,94912.0,35.456,11400.096000000009,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368972.0,2966.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,11403.488000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.296,11406.784000000009,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.48,11415.264000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,11418.624000000009,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,11421.98400000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.576,11426.560000000009,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.672,11431.232000000009,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297922304.0,374080.0,134.048,11565.28000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9310072.0,11690.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,3.872,11569.15200000001,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297806720.0,376768.0,138.08,11707.232000000009,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9306460.0,11774.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.456,11710.68800000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303166720.0,96128.0,124.128,11834.81600000001,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473960.0,3004.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.552,11838.36800000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,3.296,11841.66400000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,8.32,11849.98400000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,11853.40800000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,11856.608000000011,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,4.544,11861.152000000011,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,4.672,11865.824000000011,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,533504000.0,1148928000.0,18432000.0,0,0.0,1167360000.0,1167360000.0,6928000.0,6208000.0,0.5274056029232643,579263104.0,728288.0,237.024,12102.84800000001,34816000.0,65536000.0,524288000.0,9216000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18101972.0,22759.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,12105.63200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.904,12109.536000000011,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,12112.70400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.424,12116.128000000012,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,12119.104000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34112.0,5.76,12124.864000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1066.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.368,12131.232000000013,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34880.0,5.952,12137.184000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1090.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,53248.0,0.0,106496.0,0,0.0,106496.0,106496.0,8448.0,34696.0,0.19580938253291302,2109440.0,0.0,6.368,12143.552000000012,0.0,0.0,0.0,53248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34176.0,5.632,12149.184000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1068.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,8448.0,34760.0,0.1955193482688391,2109440.0,0.0,6.496,12155.680000000011,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34304.0,5.92,12161.600000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1072.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,8448.0,34824.0,0.19523017193566278,2109440.0,128.0,6.816,12168.416000000012,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.808,12172.224000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,12175.360000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.6,12180.960000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,12183.808000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.824,12189.632000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,31119.0,8428.0,0.786886489493514,527232.0,7040.0,8.64,12198.272000000014,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,220.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.224,12206.496000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,41600.0,6.336,12212.832000000013,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1300.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.584,12216.416000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.616,12220.032000000014,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.664,12225.696000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.36,12229.056000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17670.0,0.7023147680177904,1710080.0,1287200.0,15.36,12244.416000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53440.0,40225.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17693.0,0.3491631414382932,1702144.0,1560576.0,11.552,12255.968000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53192.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17623.0,0.37997396474685996,1696000.0,1214368.0,13.216,12269.184000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53000.0,37949.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,9396.0,17595.0,0.34811603867955987,1698304.0,1560576.0,12.992,12282.176000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53072.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.96,12287.136000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,12290.560000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9424.0,0.5280212350378124,1175552.0,853376.0,9.184,12299.744000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36736.0,26668.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548992.0,1536000.0,4.768,12304.512000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48406.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.816,12327.328000000016,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.904,12391.232000000016,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.52,12394.752000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.264,12398.016000000016,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,58208.0,11.84,12409.856000000016,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1819.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.584,12413.440000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994567.0,4245120.0,405134.0,0,0.0,4650254.0,4650254.0,528.0,5248.0,0.09141274238227147,514688.0,512000.0,22.912,12436.352000000017,533120.0,128000.0,1792000.0,202567.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16084.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.128,12468.480000000018,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,12471.808000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.744,12503.552000000018,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,12507.040000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,12510.624000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,12515.008000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.584,12526.592000000019,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,12529.79200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.056,12534.84800000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,12538.01600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.736,12542.75200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,12547.872000000021,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799815.0,1280000.0,319630.0,0,0.0,1599630.0,1599630.0,0.0,3000.0,0.0,1024000.0,0.0,5.184,12553.05600000002,0.0,0.0,640000.0,159815.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.736,12569.792000000021,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,12573.05600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,12576.32000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.84,12580.16000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,12583.32800000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.096,12587.424000000019,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,12590.368000000019,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,12593.40800000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,12596.64000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,12599.29600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.968,12603.264000000021,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.2,12610.464000000022,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,12613.728000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,12617.05600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.288,12621.344000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,12625.952000000021,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,12629.12000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
