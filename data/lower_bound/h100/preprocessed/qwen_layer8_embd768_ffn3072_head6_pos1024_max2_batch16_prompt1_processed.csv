Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.624,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,32.0,3.776,9.216,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,128.0,4.352,13.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,4.96,18.528,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,21.823999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.848,24.671999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,27.487999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.2,30.687999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.776,34.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,37.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,41.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,128.0,32.0,4.192,45.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.168,48.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.552,52.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,3.36,55.488,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,1152.0,0.0,3840.0,49152.0,9.792,65.28,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,120.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.84,69.12,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.472,74.592,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,3.456,78.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,3.552,81.60000000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,4.448,86.048,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,16384.0,36864.0,0.0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,4.192,90.24000000000001,0.0,4096.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,93.72800000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,14336.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,32.0,0.0,8192.0,8192.0,4.352,98.08000000000001,0.0,4096.0,14336.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,101.44000000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,104.86400000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.84,112.70400000000002,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.296,116.00000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,119.26400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.384,123.64800000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,128.25600000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),33,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.76,142.01600000000002,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",34,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.152,147.168,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),35,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,160.448,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",36,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,165.472,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),37,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,178.72,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",38,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.96,183.68,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,188.256,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,192.768,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,198.368,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,203.168,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,206.624,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,211.296,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,215.744,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,221.632,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,226.112,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.872,229.98399999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.936,245.92,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),50,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,256.96,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",51,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,260.928,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",52,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,264.448,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,267.936,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",54,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,64.0,7.84,275.77599999999995,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",55,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,278.97599999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,282.27199999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,286.94399999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",58,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,291.48799999999994,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,59,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883232.0,1099776.0,15.712,307.19999999999993,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433851.0,34368.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,60,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.952,313.15199999999993,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.84,316.9919999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,62,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880800.0,1100256.0,15.968,332.9599999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433775.0,34383.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,63,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.664,338.6239999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,342.0479999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,65,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3061632.0,13.024,355.0719999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95676.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,66,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.408,376.4799999999999,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",67,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,379.9679999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.584,383.5519999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",69,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.52,391.0719999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",70,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,394.2719999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,397.6319999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.416,402.0479999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,406.7199999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),74,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.6,420.31999999999994,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,425.40799999999996,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),76,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,438.65599999999995,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.928,443.58399999999995,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),78,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,456.89599999999996,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.992,461.888,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,466.464,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.672,471.136,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",82,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.208,477.34400000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,482.0160000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,485.44000000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",85,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,490.04800000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,494.5280000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",87,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.048,500.5760000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,505.1840000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,508.6400000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",90,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.904,524.5440000000001,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),91,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,535.6160000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,539.5840000000001,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,543.0400000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,546.368,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.648,554.0160000000001,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.424,557.44,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.104,560.5440000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,565.152,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,569.664,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,100,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881504.0,1102656.0,16.032,585.696,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433797.0,34458.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,101,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.728,591.424,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,595.168,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,103,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882656.0,1103488.0,15.744,610.912,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433833.0,34484.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,104,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.048,616.96,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,620.4480000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,106,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3060128.0,13.088,633.5360000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95629.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,107,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.12,654.6560000000001,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,657.984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",109,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.2,661.1840000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",110,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.968,669.152,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",111,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,672.3520000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.072,675.4240000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,679.936,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,684.544,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),115,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,697.792,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",116,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,702.816,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),117,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.216,716.032,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",118,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.216,721.248,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),119,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,734.4960000000001,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.992,739.488,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,744.2560000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,748.7040000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",123,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,754.6880000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,759.2,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,762.624,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,767.168,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.64,771.808,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",128,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,777.28,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,781.9839999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,785.5039999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",131,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.712,801.2159999999999,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),132,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,812.2879999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,816.1919999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,819.6159999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,822.9119999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.648,830.56,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,833.824,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.2,837.024,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,841.536,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,846.2399999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,141,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881344.0,1106944.0,15.872,862.1119999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433792.0,34592.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,142,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.824,867.9359999999998,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",143,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.648,871.5839999999998,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,144,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882016.0,1104736.0,15.776,887.3599999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433813.0,34523.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,145,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,893.2799999999997,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",146,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,896.8959999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,147,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3068608.0,13.024,909.9199999999997,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95894.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,148,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.472,931.3919999999997,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,934.6559999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,938.1759999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.84,946.0159999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,949.2479999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.104,952.3519999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,956.8959999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,961.4399999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),156,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,974.7519999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",157,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,979.7759999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),158,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.184,992.9599999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",159,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,998.0479999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),160,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,1011.3279999999996,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",161,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,1016.3519999999996,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,1021.0559999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1025.5359999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",164,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,1031.1679999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,1035.6479999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",166,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1039.1359999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.448,1043.5839999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1048.0639999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",169,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.76,1053.8239999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,1058.368,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1061.8239999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",172,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.968,1077.792,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),173,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,1088.9279999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",174,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,1092.8319999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1096.2879999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1099.5519999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",177,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.712,1107.2639999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",178,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.456,1110.7199999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.424,1114.1439999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,1118.6879999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,1123.2319999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,182,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883584.0,1103904.0,15.904,1139.1359999999997,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433862.0,34497.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,183,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,1144.8959999999997,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.904,1148.7999999999997,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,185,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882368.0,1104192.0,15.808,1164.6079999999997,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433824.0,34506.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,186,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.888,1170.4959999999996,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",187,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.584,1174.0799999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,188,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3070656.0,13.056,1187.1359999999997,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95958.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,189,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,20.896,1208.0319999999997,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",190,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,1211.3279999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,1214.6239999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",192,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,1222.0799999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",193,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.136,1225.2159999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,1228.5119999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,1233.0559999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,1237.504,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),197,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,1250.752,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",198,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,1255.7759999999998,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),199,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.216,1268.9919999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",200,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,1274.0159999999996,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),201,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,1287.2959999999996,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",202,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.28,1292.5759999999996,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1297.1839999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,1301.5359999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,1307.0079999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.384,1311.3919999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1314.8479999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1319.4559999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,1323.7759999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",210,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,1329.7279999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1334.4639999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",212,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,1337.8879999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",213,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.808,1353.6959999999995,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),214,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,1364.7679999999993,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",215,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,1368.6719999999993,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.776,1372.4479999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",217,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1375.7119999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",218,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.872,1383.5839999999994,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",219,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,1386.8479999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.136,1389.9839999999992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",221,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,1394.5599999999993,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,1399.0719999999992,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,223,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880512.0,1104192.0,15.712,1414.7839999999992,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433766.0,34506.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,224,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,1420.5439999999992,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,1424.2239999999993,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,226,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880672.0,1104224.0,15.744,1439.9679999999992,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433771.0,34507.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,227,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,1445.8879999999992,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,1449.3759999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,229,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3052608.0,12.896,1462.2719999999993,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95394.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,230,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.056,1483.3279999999993,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",231,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1486.6879999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",232,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1489.951999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",233,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,1497.407999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",234,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.616,1501.023999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.2,1504.223999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,1508.831999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,1513.311999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),238,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,1526.623999999999,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",239,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,1531.679999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),240,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,1544.9919999999988,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",241,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,1550.0479999999989,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),242,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.376,1563.4239999999988,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",243,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.312,1568.7359999999987,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1573.4719999999988,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.256,1577.727999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.08,1583.8079999999989,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.384,1588.1919999999989,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,1591.8079999999989,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1596.4159999999988,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.704,1601.1199999999988,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",251,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,1607.0719999999988,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1611.8079999999989,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",253,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1615.1679999999988,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",254,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.648,1630.8159999999987,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),255,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.976,1641.7919999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",256,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,1645.7919999999988,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",257,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1649.2479999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,1652.6079999999986,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",259,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.128,1660.7359999999985,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",260,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.136,1663.8719999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.168,1667.0399999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",262,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,1671.5839999999985,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,1676.0319999999986,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,264,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880544.0,1099360.0,15.712,1691.7439999999986,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433767.0,34355.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,265,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,1697.6639999999986,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,1701.4079999999985,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,267,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881184.0,1102848.0,15.904,1717.3119999999985,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433787.0,34464.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,268,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,1723.2319999999986,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,1726.5919999999985,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,270,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3049920.0,13.024,1739.6159999999984,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95310.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,271,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.216,1760.8319999999983,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",272,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1764.3199999999983,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,1767.6799999999982,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",274,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,64.0,7.936,1775.6159999999982,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",275,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.488,1779.1039999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.104,1782.2079999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,1786.7839999999983,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,1791.2959999999982,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),279,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,1804.5439999999983,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",280,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,1809.6319999999982,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),281,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,1822.9119999999982,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",282,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,1827.9679999999983,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),283,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,1841.2799999999982,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",284,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,1846.3359999999982,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,1850.8799999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",286,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,1855.2639999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.856,1861.1199999999983,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,1865.7599999999984,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1869.0879999999984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,1873.8879999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.608,1878.4959999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",292,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.792,1884.2879999999982,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,1888.9599999999982,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1892.2879999999982,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",295,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.584,1907.8719999999983,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),296,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,1919.0079999999982,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",297,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,1923.0079999999982,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1926.3679999999981,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.584,1929.9519999999982,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.264,1937.215999999998,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.072,1940.287999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.2,1943.487999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.48,1947.967999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,1952.575999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,305,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881664.0,1105024.0,15.808,1968.383999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433802.0,34532.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,306,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.824,1974.207999999998,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",307,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.84,1978.047999999998,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,308,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13879584.0,1100768.0,15.968,1994.015999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433737.0,34399.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,309,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.984,1999.999999999998,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",310,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,2003.519999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,311,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3065920.0,12.928,2016.447999999998,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95810.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,312,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.28,2037.727999999998,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",313,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,2041.087999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",314,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,2044.511999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",315,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.16,2052.6719999999978,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",316,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.36,2056.031999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.04,2059.071999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,2063.775999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.384,2068.159999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),320,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.472,2081.6319999999982,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",321,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,2086.6879999999983,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),322,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.376,2100.0639999999985,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",323,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,2105.0879999999984,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),324,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.344,2118.4319999999984,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",325,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.928,2123.3599999999983,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,2127.9359999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",327,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,2132.4159999999983,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,2138.0159999999983,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,2142.6879999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,2146.0479999999984,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",331,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.832,2150.8799999999983,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,2155.327999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.408,2160.735999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,2165.279999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",335,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,2168.543999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",336,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.712,2184.255999999998,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),337,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,2195.359999999998,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,2199.263999999998,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,2202.879999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",340,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,2206.111999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",341,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.488,2213.5999999999976,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",342,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,2216.7999999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.136,2219.9359999999974,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,2224.4799999999973,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,2229.0879999999975,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,346,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13879680.0,1101696.0,15.68,2244.7679999999973,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433740.0,34428.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,347,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.08,2250.8479999999972,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",348,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.84,2254.6879999999974,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,349,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880672.0,1105248.0,15.776,2270.463999999997,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433771.0,34539.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,350,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.632,2276.0959999999973,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",351,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,2279.583999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,352,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3054336.0,12.992,2292.5759999999973,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95448.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,353,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.504,2314.079999999997,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",354,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,2317.663999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,2321.151999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",356,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.52,2328.671999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",357,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.072,2331.743999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.168,2334.911999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,2339.6159999999973,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",360,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,2344.255999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,361,3738993024.0,7477682176.0,303872.0,0,0.0,7477986048.0,7477986048.0,9317950.0,75968.0,0.9919130654536265,482280064.0,9723904.0,349.952,2694.207999999997,0.0,0.0,3738841088.0,151936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15071252.0,303872.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,3.04,2697.247999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,256.0,512.0,4.512,2701.759999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2704.895999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,2430976.0,0.0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,9723904.0,9723904.0,8.352,2713.247999999997,0.0,2430976.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,303872.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,3.04,2716.287999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,232576.0,11.104,2727.3919999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7268.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",368,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,52800.0,330432.0,0.1377755511022044,20536128.0,96.0,10.016,2737.4079999999967,0.0,0.0,0.0,384000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,641754.0,3.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,229952.0,10.688,2748.095999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7186.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",370,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,52800.0,335232.0,0.13607125185551708,20572384.0,32.0,9.888,2757.9839999999967,0.0,0.0,0.0,230400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,642887.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,232576.0,10.816,2768.7999999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7268.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",372,435200.0,0.0,870400.0,0,0.0,870400.0,870400.0,52800.0,328832.0,0.13835317793057186,20522656.0,160.0,9.792,2778.5919999999965,0.0,0.0,0.0,435200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,641333.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,228672.0,10.624,2789.2159999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7146.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",374,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,52800.0,334432.0,0.13635236757292785,20570112.0,512.0,9.76,2798.9759999999965,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,642816.0,16.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75.0,0.0,25664.0,3200.0,5.632,2804.6079999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,802.0,100.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,2807.4879999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3200.0,0.0,6.048,2813.5359999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,2816.6399999999962,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3200.0,0.0,6.144,2822.783999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",380,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,736688.0,102912.0,0.8774273463554073,9806080.0,29920.0,20.8,2843.583999999996,0.0,0.0,0.0,204800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,306440.0,935.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,8.736,2852.319999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",382,4861952.0,0.0,9723904.0,0,0.0,9723904.0,9723904.0,0.0,227904.0,0.0,9789440.0,751136.0,11.648,2863.967999999996,0.0,0.0,0.0,4861952.0,0,0,0,0,0,0,0,0.0,0.0,0.0,305920.0,23473.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,101248.0,8.832,2872.799999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,379840.0,3164.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",384,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,75968.0,0.0,0.0,19447808.0,12.704,2885.5039999999963,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,607744.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",385,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,75968.0,0.6401939981812671,9723904.0,0.0,11.424,2896.9279999999962,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,2900.415999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,633825.0,335532.0,0.6538612709249534,33263360.0,24016768.0,46.176,2946.591999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1039480.0,750524.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,154065.0,365454.0,0.2965531578248341,33713536.0,29635584.0,35.904,2982.495999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1053548.0,926112.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,155061.0,360756.0,0.30061242650009595,33730048.0,29635584.0,37.344,3019.839999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1054064.0,926112.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,155061.0,359194.0,0.3015255077733809,33760640.0,29635584.0,37.088,3056.9279999999962,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1055020.0,926112.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,75968.0,0.16290550070521861,19447808.0,0.0,10.4,3067.3279999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,607744.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.552,3070.8799999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,155263.0,256061.0,0.3774712878412152,26475648.0,17037504.0,26.88,3097.7599999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,827364.0,532422.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,303872.0,0.0,29336000.0,29171712.0,22.496,3120.2559999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,916750.0,911616.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",395,37698784.0,80306688.0,7330240.0,0,0.0,87636928.0,87636928.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,88.064,3208.3199999999965,9808384.0,2430976.0,34033664.0,3665120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,911616.0,303872.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",396,0.0,12208464.0,0.0,0,0.0,12208464.0,12208464.0,1339488.0,151936.0,0.8981268908103933,9723904.0,9723904.0,285.984,3494.3039999999964,12208464.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,303872.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,37984.0,0.0,9723904.0,2430976.0,6.976,3501.2799999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,75968.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",398,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,3.232,3504.5119999999965,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,4861952.0,0.0,9723904.0,0,0.0,9723904.0,9723904.0,0.0,227904.0,0.0,21878784.0,1249856.0,19.808,3524.3199999999965,0.0,0.0,0.0,4861952.0,0,0,0,0,0,0,0,0.0,0.0,0.0,683712.0,39058.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,109056.0,9.44,3533.7599999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,379840.0,3408.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",401,37698816.0,80306688.0,7330304.0,0,0.0,87636992.0,87636992.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,87.392,3621.1519999999964,9808384.0,2430976.0,34033664.0,3665152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,911616.0,303872.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",402,456704.0,0.0,913408.0,0,0.0,913408.0,913408.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,11.744,3632.8959999999965,0.0,0.0,0.0,456704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3636.2559999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",404,456704.0,0.0,913408.0,0,0.0,913408.0,913408.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,11.712,3647.9679999999967,0.0,0.0,0.0,456704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",405,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,3651.4559999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.648,3655.1039999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",407,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.832,3659.9359999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",408,471808.0,3871024.0,943616.0,0,0.0,4814640.0,4814640.0,19888.0,19328.0,0.5071399428804569,9725568.0,10176.0,11.52,3671.4559999999965,3871024.0,0.0,0.0,471808.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303924.0,318.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.744,3675.1999999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",410,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.728,3680.9279999999967,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,3684.575999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,3689.087999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",413,5677056.0,14053376.0,2162688.0,0,0.0,16216064.0,16216064.0,0.0,75968.0,0.0,0.0,9723904.0,11.808,3700.895999999997,0.0,4861952.0,4595712.0,1081344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,303872.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",414,15192832.0,24309760.0,6075904.0,0,0.0,30385664.0,30385664.0,0.0,56976.0,0.0,19447808.0,306176.0,12.192,3713.087999999997,0.0,0.0,12154880.0,3037952.0,0,0,0,0,0,0,0,0.0,0.0,0.0,607744.0,9568.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",415,321024.0,0.0,642048.0,0,0.0,642048.0,642048.0,34608.0,19648.0,0.637864936596874,9729024.0,11136.0,15.424,3728.511999999997,0.0,0.0,0.0,321024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304032.0,348.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,256.0,512.0,3.904,3732.415999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,3735.135999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3737.9519999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,3741.3119999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3744.5119999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",421,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,4.224,3748.7359999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",422,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,5.28,3754.015999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3757.247999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,3760.671999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",425,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,288.0,128.0,4.832,3765.5039999999967,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",426,0.0,0.0,0.0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,256.0,64.0,4.128,3769.631999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,3.136,3772.767999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",428,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,3.36,3776.127999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",429,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,0.0,3.424,3779.551999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,256.0,128.0,3.968,3783.519999999997,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",431,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,1152.0,0.0,43776.0,49152.0,16.8,3800.319999999997,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1368.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,3.456,3803.775999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",433,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,5.184,3808.9599999999973,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",434,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,3.456,3812.4159999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",435,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,3.36,3815.7759999999976,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",436,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,4.064,3819.8399999999974,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,16384.0,36864.0,0.0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,4.576,3824.4159999999974,0.0,4096.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.68,3828.0959999999973,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,14400.0,32896.0,0.0,0,0.0,32896.0,32896.0,0.0,32.0,0.0,8192.0,8192.0,4.128,3832.2239999999974,0.0,4096.0,14400.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",440,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,3835.5199999999973,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",441,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,3838.8479999999972,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",442,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.096,3846.9439999999972,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",443,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.136,3850.079999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.072,3853.1519999999973,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,3857.599999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,3862.047999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),447,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.696,3875.743999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",448,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.152,3880.895999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),449,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,3894.207999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",450,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,3899.231999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),451,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.408,3912.6399999999967,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",452,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,3917.727999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,3922.303999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.96,3927.263999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.536,3932.799999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,3937.503999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,3941.0559999999973,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,3945.5679999999975,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,3950.0799999999977,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,3955.551999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,3960.223999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3963.647999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",463,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.704,3968.351999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.736,3973.087999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",465,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.128,3989.215999999998,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),466,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.976,4000.191999999998,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",467,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.032,4004.2239999999983,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,4007.5839999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,4011.1359999999986,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.936,4019.0719999999988,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.168,4022.239999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.104,4025.3439999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.8,4030.143999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.352,4034.4959999999987,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,475,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882048.0,1104864.0,15.84,4050.335999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433814.0,34527.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,476,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.048,4056.3839999999987,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,4.256,4060.6399999999985,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,478,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882240.0,1100416.0,15.68,4076.3199999999983,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433820.0,34388.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,479,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.016,4082.3359999999984,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",480,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,4085.7599999999984,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,481,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3055360.0,13.344,4099.103999999998,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95480.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,482,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,20.896,4119.999999999998,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",483,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,4123.4879999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,4126.975999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",485,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.064,4135.039999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",486,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,4138.303999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",487,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.104,4141.407999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,4145.951999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.8,4150.7519999999995,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),490,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.376,4164.128,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",491,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,4169.183999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),492,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.152,4182.335999999999,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",493,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,4187.391999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),494,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,4200.703999999999,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",495,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,4205.791999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,4210.591999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,4214.943999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",498,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.856,4220.799999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,4225.4079999999985,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",500,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,4228.895999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,4233.471999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,4237.919999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",503,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,4243.423999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,4247.967999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",505,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,4251.295999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,4255.871999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",507,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,4260.543999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",508,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.032,4276.575999999999,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),509,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,4287.679999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",510,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,4291.679999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,4295.008,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,4298.336,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",513,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.968,4306.304,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",514,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,4309.568,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.072,4312.64,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,4317.280000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,4321.952,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,518,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882272.0,1102816.0,15.712,4337.664000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433821.0,34463.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,519,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.048,4343.712,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.616,4347.328,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,521,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881376.0,1102176.0,15.616,4362.944,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433793.0,34443.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,522,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.6,4368.544000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",523,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.552,4372.0960000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,524,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3067072.0,13.024,4385.120000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95846.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,525,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.632,4406.752,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",526,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4410.272000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",527,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,4413.536000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",528,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.36,4420.896000000001,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",529,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.392,4424.2880000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.136,4427.424000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,4431.936000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.864,4436.8,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),533,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.216,4450.0160000000005,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",534,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.12,4455.136,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),535,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.344,4468.4800000000005,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",536,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.184,4473.664000000001,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),537,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.344,4487.008000000001,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",538,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.96,4491.968000000001,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,4496.64,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.576,4501.216,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,4507.168000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,4511.84,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",543,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4515.360000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,4520.032,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,4524.416,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",546,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.856,4530.272,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",547,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,4535.008,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",548,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,4538.464,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,4543.1359999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,4547.679999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",551,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.968,4563.647999999999,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),552,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.232,4574.879999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",553,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,4578.719999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,4582.016,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,4585.44,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.616,4593.056,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,4596.288,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,4599.5199999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.736,4604.255999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,4608.896,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,561,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882688.0,1106912.0,15.712,4624.608,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433834.0,34591.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,562,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.728,4630.336,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",563,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.776,4634.112,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,564,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880384.0,1100928.0,15.904,4650.0160000000005,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433762.0,34404.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,565,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.792,4655.808000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",566,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.584,4659.392000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,567,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3066880.0,13.184,4672.576000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95840.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,568,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.248,4693.8240000000005,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,4697.216,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,4700.768,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",571,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,4708.224,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",572,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.136,4711.360000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",573,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.2,4714.56,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,4719.104,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,4723.712,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),576,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,4736.96,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",577,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,4741.984,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),578,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.184,4755.168000000001,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",579,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.12,4760.2880000000005,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),580,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,4773.536,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",581,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.312,4778.848,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,4783.488,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.768,4788.256,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,4793.856000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,4798.432000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.648,4802.080000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,4806.656000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,4811.136,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",589,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,4817.120000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,4821.856000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",591,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,4825.4400000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.64,4830.080000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,4834.656000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",594,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.808,4850.464000000001,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),595,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,4861.472000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",596,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,4865.4400000000005,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4868.960000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,4872.384000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",599,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.808,4880.192000000001,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",600,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.104,4883.296000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.168,4886.464000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,4891.040000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,4895.52,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,604,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882816.0,1097408.0,15.84,4911.360000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433838.0,34294.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,605,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.728,4917.088000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.776,4920.8640000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,607,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882400.0,1100928.0,15.936,4936.8,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433825.0,34404.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,608,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.984,4942.784000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,4946.272000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,610,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3069984.0,12.928,4959.200000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95937.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,611,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.312,4980.512000000001,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,4984.128000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,4987.488,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.776,4995.264,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,4998.592000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.04,5001.6320000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,5006.240000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.352,5010.592000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),619,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.408,5024.000000000001,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",620,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,5029.088000000001,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),621,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,5042.336,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",622,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,5047.360000000001,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),623,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,5060.64,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",624,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.96,5065.6,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,5070.240000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,5074.656000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",627,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,5080.160000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,5084.8640000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",629,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,5088.416,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,5093.0560000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,5097.536,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.376,5102.912,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,5107.52,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",634,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,5110.944,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",635,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.768,5115.712,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",636,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,5120.384,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",637,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.16,5136.544,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),638,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.976,5147.5199999999995,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,5151.487999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,5154.879999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,5158.208,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,64.0,7.744,5165.951999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.104,5169.056,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.168,5172.223999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,5176.831999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,5181.503999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,647,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882432.0,1103968.0,15.968,5197.471999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433826.0,34499.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,648,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,5203.327999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.648,5206.975999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,650,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881120.0,1104064.0,15.584,5222.559999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433785.0,34502.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,651,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,5228.415999999998,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",652,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,5231.775999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,653,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3070304.0,13.12,5244.895999999998,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95947.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,654,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.536,5266.431999999998,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,5270.047999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",656,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,5273.503999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",657,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.84,5281.343999999998,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",658,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,5284.543999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",659,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,5287.807999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,5292.383999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.768,5297.151999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),662,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.376,5310.527999999998,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",663,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.024,5315.551999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),664,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.248,5328.799999999998,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.056,5333.855999999998,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),666,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.28,5347.135999999998,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.992,5352.127999999998,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",668,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,5356.863999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,5361.247999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",670,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.176,5367.423999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,5372.159999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,5375.455999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,5380.031999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,5384.383999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",675,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,5390.015999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,5394.623999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",677,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.712,5398.335999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",678,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.512,5402.847999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",679,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.736,5407.583999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",680,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.872,5423.455999999998,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),681,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,5434.463999999998,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",682,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.872,5438.335999999998,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,5441.759999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,5444.991999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.872,5452.863999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,5456.127999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.392,5459.519999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,5464.127999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.736,5468.863999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,690,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882976.0,1098912.0,15.776,5484.6399999999985,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433843.0,34341.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,691,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.792,5490.431999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.776,5494.207999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,693,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882880.0,1101920.0,15.712,5509.919999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433840.0,34435.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,694,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.888,5515.807999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",695,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,5519.231999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,696,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3056352.0,13.024,5532.255999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95511.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,697,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.536,5553.7919999999995,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,5557.248,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,5560.672,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",700,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.488,5568.16,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",701,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,5571.392,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.424,5574.816,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",703,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,5579.424,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",704,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,5583.936,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),705,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.216,5597.152,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",706,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.184,5602.336,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),707,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.44,5615.776,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.088,5620.864,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),709,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.312,5634.1759999999995,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",710,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.12,5639.295999999999,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,5643.775999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",712,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,5648.127999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",713,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.016,5654.143999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.384,5658.527999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",715,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,5662.015999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,5666.783999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.576,5671.359999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",718,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,5677.311999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",719,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,5682.047999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",720,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,5685.471999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",721,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.608,5690.079999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.48,5694.559999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",723,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.096,5710.655999999998,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),724,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,5721.759999999998,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",725,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,5725.727999999998,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,5729.343999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,5732.735999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",728,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.552,5740.287999999998,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",729,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,5743.519999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",730,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,5746.751999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",731,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,5751.327999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,5755.871999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,733,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881440.0,1099648.0,15.808,5771.679999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433795.0,34364.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,734,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,5777.535999999997,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",735,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,4.064,5781.599999999998,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,736,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882208.0,1104064.0,15.584,5797.1839999999975,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433819.0,34502.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,737,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.888,5803.071999999997,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",738,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,5806.463999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,739,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3059200.0,12.928,5819.391999999997,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95600.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,740,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.664,5841.055999999997,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",741,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,5844.511999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,5848.063999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",743,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,5855.519999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",744,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,5858.751999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",745,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,5862.015999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",746,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,5866.463999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,5871.007999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),748,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.664,5884.671999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.408,5890.079999999997,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),750,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.376,5903.455999999997,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",751,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,4.992,5908.447999999998,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),752,37748736.0,76087296.0,0.0,0,0.0,76087296.0,76087296.0,149184.0,4608.0,0.9700374531835206,2949120.0,589824.0,13.184,5921.631999999998,0.0,589824.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,18432.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",753,24576.0,172032.0,49152.0,0,0.0,221184.0,221184.0,0.0,6144.0,0.0,592896.0,49152.0,5.12,5926.751999999998,159744.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18528.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,5931.423999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,5935.807999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.824,5941.631999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,5946.239999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",758,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,5949.823999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",759,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,5954.431999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",760,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,5958.911999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",761,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.208,5965.119999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",762,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,5969.695999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,5973.215999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",764,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.704,5977.919999999996,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",765,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.8,5982.719999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",766,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.384,5999.103999999997,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),767,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.168,6010.271999999996,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",768,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,6014.175999999997,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,6017.631999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",770,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,6020.927999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",771,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.392,6028.319999999997,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",772,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.136,6031.455999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",773,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,6034.751999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",774,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,6039.263999999997,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",775,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,6043.871999999998,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,776,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883328.0,1105920.0,15.712,6059.583999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433854.0,34560.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,777,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.632,6065.215999999998,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",778,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,6068.895999999998,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,779,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880928.0,1104640.0,15.872,6084.767999999998,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433779.0,34520.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,780,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.176,6090.943999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",781,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,6094.399999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,782,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3063808.0,13.12,6107.519999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95744.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,783,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.184,6128.703999999999,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",784,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,6132.2559999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",785,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,6135.583999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",786,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.064,6143.647999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",787,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.104,6146.7519999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",788,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.328,6150.08,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",789,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,6154.592,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",790,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,6159.103999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,791,3738993024.0,7477682176.0,303872.0,0,0.0,7477986048.0,7477986048.0,9317950.0,75968.0,0.9919130654536265,482009248.0,9723904.0,351.36,6510.463999999999,0.0,0.0,3738841088.0,151936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15062789.0,303872.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",792,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.688,6513.151999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",793,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,384.0,640.0,4.48,6517.631999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",794,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,6520.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",795,0.0,2430976.0,0.0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,9723904.0,9723904.0,8.384,6529.311999999999,0.0,2430976.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,303872.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",796,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,3.072,6532.383999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",797,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,233408.0,11.04,6543.423999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7294.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",798,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,52800.0,330432.0,0.1377755511022044,20529568.0,160.0,9.632,6553.055999999999,0.0,0.0,0.0,384000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,641549.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,231552.0,10.464,6563.519999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7236.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",800,230400.0,0.0,460800.0,0,0.0,460800.0,460800.0,52800.0,335232.0,0.13607125185551708,20550080.0,160.0,9.888,6573.4079999999985,0.0,0.0,0.0,230400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,642190.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",801,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,230208.0,10.496,6583.903999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7194.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",802,321600.0,0.0,643200.0,0,0.0,643200.0,643200.0,52800.0,332382.0,0.13707805660700656,20536736.0,192.0,9.984,6593.887999999999,0.0,0.0,0.0,321600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,641773.0,6.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",803,0.0,0.0,0.0,0,0.0,0.0,0.0,12800.0,88768.0,0.1260239445494644,9732352.0,229312.0,10.656,6604.543999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304136.0,7166.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",804,337600.0,0.0,675200.0,0,0.0,675200.0,675200.0,52800.0,331882.0,0.13725622722144526,20535424.0,512.0,9.76,6614.303999999999,0.0,0.0,0.0,337600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,641732.0,16.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",805,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75.0,0.0,25664.0,3200.0,5.632,6619.935999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,802.0,100.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",806,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,6622.815999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",807,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3200.0,0.0,6.272,6629.087999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",808,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,6632.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",809,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3200.0,0.0,6.08,6638.207999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",810,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,593885.0,102910.0,0.8523095027949397,9806080.0,34080.0,19.584,6657.791999999999,0.0,0.0,0.0,204800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,306440.0,1065.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",811,0.0,0.0,0.0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,8.64,6666.431999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",812,4861952.0,0.0,9723904.0,0,0.0,9723904.0,9723904.0,0.0,227904.0,0.0,9788992.0,744832.0,11.616,6678.047999999999,0.0,0.0,0.0,4861952.0,0,0,0,0,0,0,0,0.0,0.0,0.0,305906.0,23276.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",813,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,119040.0,9.088,6687.135999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,379840.0,3720.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",814,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,75968.0,0.0,0.0,19447808.0,12.672,6699.807999999998,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,607744.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",815,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,75968.0,0.6401939981812671,9723904.0,0.0,10.912,6710.719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",816,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.616,6714.335999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",817,0.0,0.0,0.0,0,0.0,0.0,0.0,681969.0,332579.0,0.6721899801685085,32957696.0,24199488.0,46.56,6760.895999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1029928.0,756234.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",818,0.0,0.0,0.0,0,0.0,0.0,0.0,158277.0,363869.0,0.303127860789894,33696384.0,19014848.0,36.48,6797.375999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1053012.0,594214.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",819,0.0,0.0,0.0,0,0.0,0.0,0.0,155061.0,354349.0,0.3043933177597613,33722624.0,29635584.0,37.504,6834.879999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1053832.0,926112.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",820,0.0,0.0,0.0,0,0.0,0.0,0.0,155061.0,363439.0,0.2990568948891032,33827456.0,29635584.0,37.696,6872.575999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1057108.0,926112.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",821,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,75968.0,0.16290550070521861,19447808.0,0.0,10.624,6883.199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,607744.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",822,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,6886.687999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",823,0.0,0.0,0.0,0,0.0,0.0,0.0,155263.0,268391.0,0.3664853866598687,26631168.0,17025888.0,27.168,6913.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,832224.0,532059.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",824,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,303872.0,0.0,29327712.0,29171712.0,23.136,6936.991999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,916491.0,911616.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",825,37698784.0,80306688.0,7330240.0,0,0.0,87636928.0,87636928.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,87.52,7024.511999999999,9808384.0,2430976.0,34033664.0,3665120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,911616.0,303872.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",826,0.0,12208464.0,0.0,0,0.0,12208464.0,12208464.0,1339488.0,151936.0,0.8981268908103933,9723904.0,9723904.0,287.232,7311.743999999999,12208464.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,303872.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",827,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,37984.0,0.0,9723904.0,2430976.0,6.656,7318.399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,75968.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",828,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,3.232,7321.631999999999,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",829,4861952.0,0.0,9723904.0,0,0.0,9723904.0,9723904.0,0.0,227904.0,0.0,21878784.0,1204896.0,20.032,7341.663999999999,0.0,0.0,0.0,4861952.0,0,0,0,0,0,0,0,0.0,0.0,0.0,683712.0,37653.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",830,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,56976.0,0.0,12154880.0,105344.0,9.12,7350.783999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,379840.0,3292.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",831,37698819.0,80306688.0,7330310.0,0,0.0,87636998.0,87636998.0,2112.0,76544.0,0.026851098454027666,29171712.0,9723904.0,87.904,7438.687999999998,9808384.0,2430976.0,34033664.0,3665155.0,0,0,0,0,0,0,0,0.0,0.0,0.0,911616.0,303872.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",832,456704.0,0.0,913408.0,0,0.0,913408.0,913408.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,11.808,7450.495999999998,0.0,0.0,0.0,456704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,7453.823999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",834,456704.0,0.0,913408.0,0,0.0,913408.0,913408.0,23525.0,19300.0,0.5493286631640397,9725120.0,9536.0,11.872,7465.695999999999,0.0,0.0,0.0,456704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303910.0,298.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",835,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,7468.959999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,7472.255999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",837,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.8,7477.056,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",838,471808.0,3871024.0,943616.0,0,0.0,4814640.0,4814640.0,19888.0,19328.0,0.5071399428804569,9725568.0,10176.0,11.776,7488.831999999999,3871024.0,0.0,0.0,471808.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303924.0,318.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",839,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.456,7492.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",840,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,4.992,7497.28,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",841,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,7500.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",842,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.768,7505.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",843,5677056.0,14053376.0,2162688.0,0,0.0,16216064.0,16216064.0,0.0,75968.0,0.0,0.0,9723904.0,11.936,7517.472,0.0,4861952.0,4595712.0,1081344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,303872.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",844,15192835.0,24309760.0,6075910.0,0,0.0,30385670.0,30385670.0,0.0,56976.0,0.0,19447808.0,388096.0,12.032,7529.504,0.0,0.0,12154880.0,3037955.0,0,0,0,0,0,0,0,0.0,0.0,0.0,607744.0,12128.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",845,321024.0,0.0,642048.0,0,0.0,642048.0,642048.0,34608.0,19648.0,0.637864936596874,9729024.0,11136.0,15.904,7545.408,0.0,0.0,0.0,321024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,304032.0,348.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",846,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,384.0,640.0,4.32,7549.728,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",847,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,7552.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",848,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,7555.200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",849,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,7558.656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,7562.304000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",851,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,4.128,7566.432000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",852,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,4.96,7571.392000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",853,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,7574.592000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
