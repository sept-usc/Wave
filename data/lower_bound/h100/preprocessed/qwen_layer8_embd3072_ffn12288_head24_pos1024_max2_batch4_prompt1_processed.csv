Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.744,9.184,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.448,13.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.056,18.688,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,22.112,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,24.799999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,27.711999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,30.943999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.936,34.879999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,38.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,41.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.128,45.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,49.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,52.672000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,56.160000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,13056.0,49152.0,5.664,61.824000000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,408.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,65.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,70.62400000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,74.17600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.424,77.60000000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.384,81.98400000000002,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.384,86.36800000000002,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.392,89.76000000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.32,94.08000000000001,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.456,97.53600000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,100.92800000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.552,108.48000000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,111.48800000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,114.72000000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,119.32800000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.384,123.71200000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260480.0,61152.0,25.568,149.28000000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383140.0,1911.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44267008.0,60448.0,25.6,174.88000000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383344.0,1889.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44259200.0,61984.0,25.472,200.35200000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383100.0,1937.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,205.02400000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,209.50400000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,215.39200000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.864,220.25600000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,223.71200000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,228.352,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.544,232.89600000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.92,238.816,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,243.424,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,246.68800000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.872,262.56,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44247808.0,72576.0,26.08,288.64,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382744.0,2268.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,292.06399999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,295.35999999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.712,303.07199999999995,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,306.33599999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,309.43999999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,314.0799999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,318.78399999999993,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169115008.0,283072.0,84.512,403.29599999999994,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5284844.0,8846.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.648,406.94399999999996,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168905600.0,282016.0,81.024,487.96799999999996,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5278300.0,8813.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,491.39199999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176970752.0,74496.0,84.8,576.1919999999999,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530336.0,2328.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,579.584,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,582.848,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.84,590.688,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,594.048,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,597.312,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,602.016,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,606.6239999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44263168.0,63232.0,25.728,632.3519999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383224.0,1976.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44265856.0,60672.0,25.504,657.8559999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383308.0,1896.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44267008.0,60512.0,25.888,683.7439999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383344.0,1891.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,688.3199999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,692.7679999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,698.656,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,703.232,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,706.784,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.928,711.712,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,716.128,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,722.0160000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,726.5920000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,729.8880000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.776,745.6640000000001,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44249472.0,74080.0,25.696,771.3600000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382796.0,2315.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,774.7200000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,778.2400000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.424,785.6640000000001,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,788.6720000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,791.8400000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,796.4160000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,800.8960000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168682880.0,285856.0,80.96,881.8560000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5271340.0,8933.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,885.6640000000002,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169157504.0,280032.0,81.6,967.2640000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5286172.0,8751.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,970.7840000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176980736.0,74016.0,85.472,1056.2560000000003,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530648.0,2313.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1059.5840000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1062.8480000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.392,1070.2400000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,1073.2800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1076.6080000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.736,1081.3440000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,1085.7920000000004,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44257152.0,60672.0,24.992,1110.7840000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383036.0,1896.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44258816.0,60480.0,25.984,1136.7680000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383088.0,1890.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44264832.0,61248.0,25.28,1162.0480000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383276.0,1914.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1166.7840000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1171.2640000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.08,1177.3440000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1181.9520000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1185.4080000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1190.016,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.576,1194.592,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.144,1200.736,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,1205.4080000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,1208.8000000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,16.224,1225.0240000000001,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44245120.0,76000.0,24.96,1249.9840000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382660.0,2375.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1253.4720000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.616,1257.0880000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.776,1264.8640000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,1267.9680000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1271.2000000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,1275.7760000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,1280.4480000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169065600.0,282624.0,82.912,1363.3600000000004,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5283300.0,8832.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,1367.1680000000003,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169197056.0,283072.0,82.816,1449.9840000000004,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5287408.0,8846.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,1453.3760000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176998400.0,72864.0,87.456,1540.8320000000003,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531200.0,2277.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1544.2880000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,1547.7120000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.968,1555.6800000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1558.8800000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1562.1440000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,1566.5920000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,1571.0720000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44261376.0,58912.0,26.368,1597.4400000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383168.0,1841.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44264192.0,60384.0,26.56,1624.0000000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383256.0,1887.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44255104.0,59008.0,26.08,1650.0800000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382972.0,1844.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,1654.5600000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,1659.0720000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,1664.672,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,1669.248,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1672.768,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,1677.472,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,1681.792,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.728,1687.52,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,1692.16,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,1695.7440000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.776,1711.5200000000002,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44248320.0,74400.0,24.832,1736.3520000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382760.0,2325.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,1739.6480000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1742.9120000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.296,1750.2080000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1753.2800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1756.4800000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,1761.1200000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,1765.7280000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169109376.0,277536.0,81.312,1847.0400000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5284668.0,8673.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,1850.8480000000002,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169208832.0,282208.0,81.184,1932.0320000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5287776.0,8819.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,1935.4560000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177003264.0,73216.0,86.432,2021.8880000000001,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531352.0,2288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,2025.4080000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2028.736,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.392,2036.1280000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2039.2640000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,2042.4,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,2047.0720000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,2051.552,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44256128.0,60640.0,26.112,2077.664,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383004.0,1895.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260352.0,59488.0,26.048,2103.712,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383136.0,1859.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260352.0,60896.0,25.664,2129.376,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383136.0,1903.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,2134.0480000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,2138.4,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,2144.288,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,2148.8,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2152.288,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,2156.896,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,2161.248,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,2167.136,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,2171.68,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,2175.136,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.872,2191.008,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44251904.0,71232.0,26.688,2217.696,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382872.0,2226.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,2221.0879999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2224.3839999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.744,2232.1279999999997,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,2235.296,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,2238.3999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,2243.008,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,2247.52,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169483264.0,278464.0,83.744,2331.264,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5296352.0,8702.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,2335.0080000000003,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168836224.0,280768.0,81.44,2416.4480000000003,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5276132.0,8774.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,2419.9680000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176976000.0,70336.0,87.168,2507.1360000000004,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530500.0,2198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,2510.5920000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,2514.0160000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.584,2521.6000000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2524.8640000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.072,2527.9360000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.48,2532.4160000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.736,2537.1520000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44253184.0,60416.0,26.624,2563.7760000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382912.0,1888.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44261120.0,60704.0,25.984,2589.76,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383160.0,1897.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44257280.0,61056.0,26.304,2616.0640000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383040.0,1908.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,2620.7360000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.544,2625.28,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,2630.7520000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,2635.4560000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,2638.9760000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.832,2643.8080000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.576,2648.3840000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,2654.0160000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,2658.5280000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2662.0160000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.904,2677.9200000000005,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44243200.0,73664.0,25.248,2703.1680000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382600.0,2302.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,2706.5600000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,2710.0480000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.328,2717.376,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,2720.384,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,2723.52,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,2728.16,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,2732.736,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169101312.0,280640.0,81.984,2814.72,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5284416.0,8770.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,2818.3999999999996,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169064832.0,279104.0,84.032,2902.432,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5283276.0,8722.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,2905.8559999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176988544.0,75680.0,86.592,2992.448,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530892.0,2365.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,2995.872,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,2999.2639999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.232,3006.4959999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3009.5679999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3012.7999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,3017.504,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,3022.08,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44256000.0,59136.0,26.176,3048.256,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383000.0,1848.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260224.0,61248.0,26.016,3074.272,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383132.0,1914.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44264448.0,59744.0,26.112,3100.384,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383264.0,1867.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,3105.12,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,3109.44,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.408,3114.848,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,3119.648,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,3123.136,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,3127.872,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,3132.2239999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.44,3137.6639999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.448,3142.1119999999996,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,3145.4399999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,16.16,3161.5999999999995,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44241792.0,73536.0,24.768,3186.3679999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382556.0,2298.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,3189.9519999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,3193.2159999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.424,3200.6399999999994,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3203.9679999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.04,3207.0079999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,3211.7119999999995,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,3216.2879999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169208320.0,278176.0,83.584,3299.8719999999994,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5287760.0,8693.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,3303.6799999999994,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168964992.0,279744.0,81.536,3385.2159999999994,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5280156.0,8742.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,3388.6719999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177026816.0,74688.0,85.216,3473.8879999999995,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5532088.0,2334.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3477.3119999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,3480.7679999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.712,3488.4799999999996,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3491.6799999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3494.783999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,3499.423999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,3503.999999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44253184.0,61216.0,25.12,3529.119999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382912.0,1913.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44258688.0,62976.0,25.728,3554.847999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383084.0,1968.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44257152.0,59712.0,25.664,3580.5119999999993,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383036.0,1866.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,3585.247999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.608,3589.8559999999993,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,3595.3279999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,3599.9679999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,3603.2319999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,3607.9039999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,3612.3519999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.568,3617.9199999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,3622.6559999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,3626.1119999999996,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,16.128,3642.24,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44243968.0,74432.0,25.088,3667.328,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382624.0,2326.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,3670.912,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,3674.3039999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.36,3681.6639999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3684.7999999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3688.0319999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,3692.64,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,3697.248,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169273088.0,277280.0,83.584,3780.832,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5289784.0,8665.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,3784.576,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169030656.0,278400.0,83.744,3868.32,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5282208.0,8700.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,3871.744,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176972160.0,72256.0,84.576,3956.32,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530380.0,2258.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,3959.8720000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.584,3963.456,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.584,3971.04,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3974.112,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.744,3977.856,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,3982.3680000000004,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,3986.9120000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,1901023232.0,4093763584.0,68067328.0,0,0.0,4161830912.0,4161830912.0,24993472.0,22182656.0,0.5297906602254429,2057837440.0,3490624.0,771.264,4758.176,126410752.0,233373696.0,1866989568.0,34033664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64307420.0,109082.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4761.024,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.416,4765.4400000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4768.8640000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.544,4773.408,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4776.2880000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172672.0,6.368,4782.656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5396.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38121728.0,0.0,14.816,4797.472000000001,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191304.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173184.0,6.4,4803.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5412.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,247936.0,0.0,495872.0,0,0.0,495872.0,495872.0,39336.0,719380.0,0.05184548632162759,38143072.0,32.0,14.624,4818.496,0.0,0.0,0.0,247936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191971.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170624.0,6.176,4824.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5332.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,209792.0,0.0,419584.0,0,0.0,419584.0,419584.0,39336.0,720572.0,0.05176416092474352,38174336.0,0.0,15.232,4839.904,0.0,0.0,0.0,209792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192948.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172032.0,6.144,4846.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5376.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38109120.0,128.0,14.816,4860.8640000000005,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190910.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.992,4865.856000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,4868.896000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.24,4875.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,4878.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.176,4884.224000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,188764.0,38400.0,0.8309591308481977,2488288.0,11200.0,9.856,4894.080000000001,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,350.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.576,4902.656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,196736.0,6.336,4908.992000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6148.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.664,4914.656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.536,4920.192000000001,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.976,4927.168000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,4930.624000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,173202.0,84066.0,0.6732356919632445,8750336.0,6018848.0,17.472,4948.0960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,273448.0,188089.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91803.0,0.30254131054131056,8864128.0,7409664.0,14.496,4962.592000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277004.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91350.0,0.30839465794494414,8848000.0,5724576.0,14.784,4977.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276500.0,178893.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,90609.0,0.30268048853692886,8862336.0,7409664.0,14.4,4991.776,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276948.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.144,4997.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,5001.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51336.0,0.429308313137826,6179328.0,4031296.0,12.192,5013.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193104.0,125978.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7334080.0,7292928.0,8.256,5021.856000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229190.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.296,5109.152000000001,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,284.64,5393.792000000001,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607392.0,4.192,5397.984000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18981.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,5401.216000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,291104.0,11.808,5413.024000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9097.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.6,5418.624000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424708.0,20076672.0,1832584.0,0,0.0,21909256.0,21909256.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.072,5505.696000000002,2452096.0,607744.0,8508416.0,916292.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.408,5515.104000000002,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,5518.464000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.76,5528.224000000002,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5531.488000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,5534.976000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.768,5539.744000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.6,5549.344000000003,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,5552.448000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.056,5557.504000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,5560.8960000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,5565.536000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.264,5572.800000000003,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798340.0,6077440.0,1519240.0,0,0.0,7596680.0,7596680.0,0.0,14280.0,0.0,4861952.0,0.0,6.784,5579.584000000003,0.0,0.0,3038720.0,759620.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2624.0,13.216,5592.800000000003,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,82.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.448,5597.248000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5599.904000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,5602.656000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,5606.336000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,5609.792000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,5613.824000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.832,5618.6560000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,5622.0800000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,5625.568000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.448,5630.016000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.128,5634.144000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.392,5637.536000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.68,5641.216000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.36,5644.576000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.936,5648.512000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,49920.0,49152.0,7.712,5656.224000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1560.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,5659.488000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.088,5664.576000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.808,5668.384000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.552,5671.936000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.096,5676.032000000004,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.288,5680.320000000003,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.424,5683.744000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.416,5688.1600000000035,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.296,5691.456000000004,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,5694.976000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.808,5702.784000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,5706.048000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,5709.472000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,5714.048000000004,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,5718.592000000004,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260480.0,59136.0,25.376,5743.968000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383140.0,1848.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44259200.0,63520.0,25.408,5769.376000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383100.0,1985.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44267776.0,58848.0,25.792,5795.168000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383368.0,1839.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,5799.968000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,5804.320000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.536,5809.856000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,5814.432000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,5817.696000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,5822.336000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,5826.720000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.664,5832.3840000000055,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,5837.024000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,5840.512000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.704,5845.216000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.8,5850.016000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,195872.0,17655924.0,0.0,0,193273528320.0,17655924.0,193291184244.0,99870.0,192.0,0.9980811896624093,245760.0,49152.0,16.096,5866.1120000000055,14886521.0,2377659.0,195872.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44252160.0,75552.0,24.8,5890.912000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382880.0,2361.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,5894.336000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,5897.632000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,8.128,5905.760000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,5909.056000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,5912.256000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,5916.896000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,5921.568000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169214720.0,281696.0,83.648,6005.216000000006,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5287960.0,8803.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.584,6008.800000000006,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169019392.0,278272.0,80.96,6089.760000000006,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5281856.0,8696.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.712,6093.472000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176989440.0,72928.0,84.32,6177.792000000006,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530920.0,2279.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,6181.120000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,6184.544000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.776,6192.320000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,6195.680000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,6198.848000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,6203.392000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,6208.0000000000055,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44267648.0,59328.0,25.376,6233.376000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383364.0,1854.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44263040.0,60832.0,26.88,6260.256000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383220.0,1901.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44267008.0,59904.0,25.12,6285.376000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383344.0,1872.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,6289.9200000000055,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,6294.240000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.824,6300.064000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,6304.736000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,6308.288000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.832,6313.120000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,6317.440000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.856,6323.296000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,6328.064000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,6331.616000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,6336.1600000000035,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.608,6340.768000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,196224.0,17656848.0,0.0,0,193273528320.0,17656848.0,193291185168.0,99861.0,192.0,0.9980810170609576,245760.0,49152.0,16.064,6356.832000000004,14886708.0,2377692.0,196224.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44247936.0,68064.0,25.312,6382.144000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382748.0,2127.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,6385.472000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,6388.736000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,8.032,6396.768000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,6400.000000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,6403.136000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,6407.584000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,6412.288000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168672896.0,276544.0,81.28,6493.568000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5271028.0,8642.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.872,6497.440000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169272064.0,275232.0,81.76,6579.200000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5289752.0,8601.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,6582.656000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176997248.0,74176.0,88.384,6671.040000000005,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531164.0,2318.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,6674.496000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.616,6678.1120000000055,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.936,6686.048000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,6689.3440000000055,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,6692.672000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,6697.184000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,6701.7280000000055,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44255232.0,59776.0,25.824,6727.552000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382976.0,1868.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44265728.0,57984.0,25.632,6753.184000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383304.0,1812.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44259456.0,61376.0,25.12,6778.304000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383108.0,1918.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,6783.104000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,6787.520000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,6793.024000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,6797.632000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,6801.088000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,6805.696000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.288,6809.984000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,6815.6160000000045,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,6820.288000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,6823.904000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,6828.480000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,6833.152000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,15.936,6849.088000000003,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44244352.0,74208.0,24.8,6873.888000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382636.0,2319.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,6877.376000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,6880.704000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.712,6888.416000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,6891.680000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,6895.072000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,6899.584000000004,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,6904.224000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169248384.0,277600.0,81.76,6985.984000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5289012.0,8675.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.712,6989.696000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169252352.0,281248.0,82.304,7072.0000000000055,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5289136.0,8789.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,7075.488000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176988032.0,73664.0,85.344,7160.832000000006,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530876.0,2302.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,7164.352000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,7167.680000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.552,7175.232000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,7178.432000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,7181.568000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,7186.240000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,7190.912000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44259584.0,58976.0,25.696,7216.608000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383112.0,1843.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44257792.0,61216.0,25.504,7242.1120000000055,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383056.0,1913.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44265856.0,58784.0,26.336,7268.448000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383308.0,1837.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,7272.992000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,7277.440000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.824,7283.264000000006,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,7287.872000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,7291.328000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,7296.064000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.256,7300.320000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,7306.272000000006,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,7311.040000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,7314.4960000000065,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,7319.040000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.704,7323.744000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,15.936,7339.680000000006,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44243456.0,74112.0,25.12,7364.800000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382608.0,2316.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,7368.256000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,7371.712000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.744,7379.456000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,7382.688000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,7385.824000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.544,7390.368000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,7395.072000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169307520.0,280928.0,82.496,7477.568000000006,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5290860.0,8779.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,7481.312000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169339776.0,276768.0,81.088,7562.400000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5291868.0,8649.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,7565.856000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177017600.0,73952.0,84.96,7650.816000000005,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531800.0,2311.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,7654.272000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,7657.664000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.68,7665.3440000000055,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,7668.7680000000055,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,7672.1920000000055,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.416,7676.608000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,7681.184000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260736.0,59488.0,25.472,7706.656000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383148.0,1859.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44265088.0,60800.0,25.28,7731.936000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383284.0,1900.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44263424.0,61472.0,25.472,7757.408000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383232.0,1921.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,7762.016000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,7766.496000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.856,7772.352000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,7777.088000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,7780.480000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,7785.024000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.192,7789.216000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.92,7795.136000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,7799.936000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,7803.264000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,7807.840000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.64,7812.480000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,15.904,7828.3840000000055,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44242688.0,70624.0,25.632,7854.016000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382584.0,2207.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,7857.408000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,7860.832000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.744,7868.576000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,7872.064000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,7875.264000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,7879.712000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.736,7884.448000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169509120.0,278944.0,81.568,7966.016000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5297160.0,8717.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,7969.824000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169362560.0,276800.0,84.128,8053.952000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5292580.0,8650.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.648,8057.600000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176989312.0,74208.0,85.12,8142.720000000005,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530916.0,2319.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,8146.016000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,8149.280000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.424,8156.704000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,8159.904000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,8163.040000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,8167.616000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,8172.160000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44254976.0,59008.0,26.496,8198.656000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382968.0,1844.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44263168.0,60544.0,25.792,8224.448000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383224.0,1892.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260992.0,58048.0,25.376,8249.824000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383156.0,1814.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,8254.592000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,8259.104000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,8264.608000000006,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,8269.280000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,8272.800000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,8277.344000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.576,8281.920000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.568,8287.488000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,8291.968000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.68,8295.648000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,8300.192000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.608,8304.800000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,16.096,8320.896000000004,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44245248.0,75168.0,25.344,8346.240000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382664.0,2349.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,8349.632000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,8353.088000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.904,8360.992000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,8364.192000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,8367.424000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,8372.032000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,8376.704000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169017088.0,279680.0,82.848,8459.552000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5281784.0,8740.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.872,8463.424000000005,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169048064.0,283840.0,80.864,8544.288000000004,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5282752.0,8870.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.712,8548.000000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176996864.0,72736.0,85.824,8633.824000000004,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531152.0,2273.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,8637.248000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,8640.544000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.808,8648.352000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,8651.808000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,8654.976000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,8659.648000000007,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,8664.192000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44260992.0,59840.0,25.152,8689.344000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383156.0,1870.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44259456.0,61632.0,25.28,8714.624000000007,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383108.0,1926.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44266112.0,60704.0,26.496,8741.120000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383316.0,1897.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,8745.888000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,8750.304000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.696,8756.000000000005,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.832,8760.832000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,8764.128000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,8768.704000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.224,8772.928000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,8778.432000000006,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,8783.040000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,8786.400000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.64,8791.040000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,8795.584000000006,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,16.288,8811.872000000007,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44243840.0,75968.0,25.408,8837.280000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382620.0,2374.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,8840.736000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.616,8844.352000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.68,8852.032000000007,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,8855.328000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,8858.624000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,8863.328000000007,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.672,8868.000000000007,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168412160.0,280736.0,79.808,8947.808000000008,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5262880.0,8773.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,8951.488000000008,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169841280.0,277536.0,81.344,9032.832000000008,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5307540.0,8673.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,9036.352000000008,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177008000.0,72128.0,83.52,9119.872000000008,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5531500.0,2254.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,9123.232000000009,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.584,9126.81600000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.584,9134.40000000001,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,9137.79200000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,9140.92800000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,9145.536000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.8,9150.33600000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44261120.0,58528.0,24.512,9174.84800000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383160.0,1829.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44255104.0,59744.0,24.896,9199.744000000012,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382972.0,1867.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,450048.0,0.5289389067524116,44263296.0,61152.0,25.088,9224.832000000011,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1383228.0,1911.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,9229.536000000011,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,9234.01600000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.536,9239.55200000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,9244.35200000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,9247.87200000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,9252.51200000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,9256.86400000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,9262.33600000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,9267.10400000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,9270.528000000011,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,9275.10400000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.768,9279.87200000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,196288.0,17657016.0,0.0,0,193273528320.0,17657016.0,193291185336.0,99858.0,192.0,0.9980809595202399,245760.0,49152.0,16.032,9295.90400000001,14886742.0,2377698.0,196288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44242688.0,74144.0,25.472,9321.37600000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1382584.0,2317.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,9324.73600000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,9328.28800000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.456,9335.74400000001,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,9339.20000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,9342.33600000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.736,9347.072000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,9351.680000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,168847104.0,279936.0,79.968,9431.648000000012,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5276472.0,8748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.776,9435.424000000012,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,169552256.0,274464.0,83.584,9519.008000000013,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5298508.0,8577.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,9522.496000000012,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176981376.0,75648.0,84.704,9607.200000000012,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5530668.0,2364.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,9610.752000000011,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,9614.01600000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,7.68,9621.69600000001,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,9625.02400000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,9628.41600000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,9632.92800000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,9637.56800000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,1901023232.0,4093763584.0,68067328.0,0,0.0,4161830912.0,4161830912.0,24993472.0,22182656.0,0.5297906602254429,2057958912.0,3522464.0,760.672,10398.24000000001,126410752.0,233373696.0,1866989568.0,34033664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64311216.0,110077.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,10400.92800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.0,10404.92800000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,10408.16000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.544,10412.70400000001,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,10415.680000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174208.0,6.464,10422.144000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5444.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38120160.0,32.0,14.624,10436.768000000011,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191255.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173824.0,6.336,10443.10400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5432.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,247936.0,0.0,495872.0,0,0.0,495872.0,495872.0,39336.0,719380.0,0.05184548632162759,38143648.0,64.0,14.752,10457.85600000001,0.0,0.0,0.0,247936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191989.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171072.0,6.176,10464.03200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5346.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,252704.0,0.0,505408.0,0,0.0,505408.0,505408.0,39336.0,719231.0,0.051855669967188135,38138336.0,0.0,14.528,10478.56000000001,0.0,0.0,0.0,252704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191823.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172096.0,6.24,10484.80000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5378.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,233632.0,0.0,467264.0,0,0.0,467264.0,467264.0,39336.0,719827.0,0.05181495936972692,38170688.0,128.0,15.04,10499.840000000011,0.0,0.0,0.0,233632.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192834.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.96,10504.80000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.816,10507.61600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.048,10513.664000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.264,10516.92800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.08,10523.00800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,153217.0,38398.0,0.7996085901416904,2488288.0,10528.0,9.664,10532.672000000011,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,329.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.352,10541.024000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,197760.0,6.464,10547.488000000012,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6180.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.376,10552.864000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,10558.432000000012,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.912,10565.344000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,10568.864000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,171798.0,86482.0,0.6651618398637138,8797696.0,6037632.0,17.184,10586.048000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,274928.0,188676.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91119.0,0.30412170366806424,8884224.0,7409664.0,14.848,10600.896000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277632.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91230.0,0.30867509320723835,8861312.0,5713312.0,14.368,10615.264000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276916.0,178541.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,91033.0,0.3016960333837055,8880768.0,7409664.0,14.624,10629.888000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277524.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,5.888,10635.776000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,10639.264000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51481.0,0.4286174097381769,6230656.0,4020608.0,12.96,10652.224000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194708.0,125644.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7331904.0,7292928.0,8.384,10660.608000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229122.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.744,10748.352000000012,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,284.672,11033.024000000012,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.192,11037.216000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.136,11040.352000000012,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,282048.0,11.904,11052.256000000012,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8814.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.472,11057.728000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424709.0,20076672.0,1832586.0,0,0.0,21909258.0,21909258.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.816,11144.544000000013,2452096.0,607744.0,8508416.0,916293.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.28,11153.824000000013,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,11156.992000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.632,11166.624000000013,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,11169.984000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,11173.472000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,11178.112000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.6,11187.712000000012,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,11191.008000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.44,11196.448000000013,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,11199.648000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,11204.160000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.232,11211.392000000014,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798341.0,6077440.0,1519242.0,0,0.0,7596682.0,7596682.0,0.0,14280.0,0.0,4861952.0,1536.0,6.816,11218.208000000015,0.0,0.0,3038720.0,759621.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,48.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,13.12,11231.328000000016,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,11235.200000000015,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,11238.048000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,11240.928000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,11244.256000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,11247.680000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,11251.712000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,11256.736000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,11260.064000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
