Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,11.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.68,18.688,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.16,22.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.248,28.096,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,31.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,34.304,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,36.992000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.456,40.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.064,44.51200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,48.06400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,51.39200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.096,55.488000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,58.84800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,62.112000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,65.60000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,5.92,71.52000000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,5.344,76.86400000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,80.19200000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,83.64800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.024,88.67200000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.088,101.76000000000002,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210066304.0,196608.0,100.8,202.56,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6564572.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,5.056,207.616,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.448,212.06400000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,216.64000000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,17.6,234.24,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",31,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,89216.0,3.168,237.40800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2788.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",32,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,838791.0,0.7623125974258189,72145024.0,1330144.0,74.816,312.22400000000005,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2254532.0,41567.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",33,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.256,316.48,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.872,320.35200000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.056,333.408,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277155968.0,262144.0,109.76,443.168,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8661124.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,446.72,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.616,450.336,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,453.92,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,457.408,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.296,460.704,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,371916.0,924056.0,32768.0,0,0.0,956824.0,956824.0,0.0,1024.0,0.0,262144.0,262144.0,3.68,464.384,65536.0,147456.0,355532.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,467.776,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,471.264,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",45,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,88192.0,3.04,474.30400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2756.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",46,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3756748.0,0.7410884195837123,284053792.0,2128512.0,179.008,653.312,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8876681.0,66516.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",47,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.416,657.7280000000001,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,661.1840000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",49,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.992,674.176,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210099712.0,196608.0,100.416,774.5920000000001,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565616.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,779.104,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,783.6800000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.544,788.224,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.128,804.3520000000001,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86656.0,3.072,807.4240000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2708.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",56,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,845947.0,0.7607699166573109,72263968.0,1330592.0,75.648,883.0720000000001,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2258249.0,41581.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",57,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.16,887.2320000000001,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,890.7520000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",59,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.056,903.8080000000001,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277397504.0,262144.0,108.992,1012.8000000000001,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8668672.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,1016.1600000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",62,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,1019.488,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,1022.912,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.648,1026.56,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",65,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,1029.888,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,372064.0,924352.0,32768.0,0,0.0,957120.0,957120.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,1033.4399999999998,65536.0,147456.0,355680.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.264,1036.7039999999997,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,1040.1919999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",69,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86144.0,3.2,1043.3919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2692.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",70,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3562629.0,0.7511375136013705,285145024.0,2128992.0,178.592,1221.984,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8910782.0,66531.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.256,1226.24,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.616,1229.856,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.896,1242.752,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210103424.0,196608.0,101.504,1344.2559999999999,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565732.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.672,1348.9279999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,1353.504,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,1358.08,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",78,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.288,1374.368,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",79,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87424.0,3.04,1377.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2732.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",80,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,784288.0,0.774270793998729,72222944.0,1330432.0,74.784,1452.192,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2256967.0,41576.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",81,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.128,1456.32,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,1459.648,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",83,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.96,1472.608,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277200768.0,262144.0,108.704,1581.312,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662524.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,1584.8,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",86,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,1588.2559999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,1591.648,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",88,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.776,1595.424,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",89,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,1598.752,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,372488.0,925200.0,32768.0,0,0.0,957968.0,957968.0,0.0,1024.0,0.0,262144.0,262144.0,3.776,1602.528,65536.0,147456.0,356104.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",91,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,1605.888,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.424,1609.312,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",93,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,85376.0,3.072,1612.3839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2668.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",94,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3569734.0,0.7507649015643495,284478848.0,2128672.0,183.264,1795.6479999999997,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8889964.0,66521.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.096,1799.7439999999997,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,1803.0719999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.472,1816.5439999999996,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210080000.0,196608.0,100.8,1917.3439999999996,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565000.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,1921.8559999999995,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,1926.3679999999995,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.608,1930.9759999999994,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",102,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.288,1947.2639999999994,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",103,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,85760.0,3.072,1950.3359999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2680.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",104,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,830662.0,0.7640726440693948,72328480.0,1330272.0,74.304,2024.6399999999994,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2260265.0,41571.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",105,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.192,2028.8319999999994,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,2032.1279999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",107,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.344,2045.4719999999995,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277165568.0,262144.0,108.48,2153.9519999999993,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8661424.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",109,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,2157.2799999999993,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",110,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,2160.671999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",111,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.616,2164.287999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,2167.775999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",113,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.264,2171.039999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",114,372824.0,925872.0,32768.0,0,0.0,958640.0,958640.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,2174.623999999999,65536.0,147456.0,356440.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",115,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,2178.0159999999987,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",116,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,2181.5359999999987,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",117,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87552.0,3.072,2184.607999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2736.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",118,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3774572.0,0.7401791734847252,284308128.0,2128320.0,178.976,2363.583999999999,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8884629.0,66510.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",119,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.16,2367.743999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,2371.2639999999988,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.864,2384.127999999999,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",122,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210081792.0,196608.0,100.032,2484.159999999999,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565056.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.48,2488.639999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.352,2492.991999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.384,2497.375999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",126,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.128,2513.503999999999,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",127,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86400.0,3.072,2516.575999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2700.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",128,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,828978.0,0.7644382712436,72144704.0,1330624.0,74.624,2591.199999999999,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2254522.0,41582.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.224,2595.423999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.36,2598.783999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",131,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.704,2611.4879999999994,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",132,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277182208.0,262144.0,109.28,2720.7679999999996,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8661944.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,2724.2559999999994,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",134,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,2727.7759999999994,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",135,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,2731.1359999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",136,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,2734.7199999999993,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,2738.0799999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,372700.0,925624.0,32768.0,0,0.0,958392.0,958392.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,2741.5999999999995,65536.0,147456.0,356316.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",139,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,2744.9919999999993,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.616,2748.6079999999993,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",141,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87424.0,3.168,2751.7759999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2732.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",142,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3602765.0,0.749037478887437,283997376.0,2128704.0,178.464,2930.2399999999993,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8874918.0,66522.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",143,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.16,2934.399999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.552,2937.9519999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.96,2950.9119999999994,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210122496.0,196608.0,100.32,3051.2319999999995,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6566328.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.544,3055.7759999999994,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.768,3060.5439999999994,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,3065.1199999999994,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",150,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.0,3081.1199999999994,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",151,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,82816.0,3.04,3084.1599999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2588.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",152,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,840922.0,0.761852545582139,72464032.0,1330752.0,75.392,3159.551999999999,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2264501.0,41586.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",153,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.448,3163.999999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,3167.455999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",155,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.12,3180.575999999999,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",156,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277193856.0,262144.0,109.792,3290.367999999999,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662308.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",157,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,3293.727999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",158,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,3297.0879999999993,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",159,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,3300.5439999999994,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,3304.0319999999992,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,3307.455999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,372300.0,924824.0,32768.0,0,0.0,957592.0,957592.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,3311.039999999999,65536.0,147456.0,355916.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",163,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.232,3314.271999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,3317.855999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86016.0,3.328,3321.183999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2688.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",166,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3525356.0,0.753098320677836,284247200.0,2128544.0,177.888,3499.0719999999988,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8882725.0,66517.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",167,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.064,3503.1359999999986,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,3506.6559999999986,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",169,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.736,3519.3919999999985,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210080384.0,196608.0,100.736,3620.1279999999983,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565012.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.416,3624.5439999999985,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.384,3628.9279999999985,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.576,3633.5039999999985,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",174,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,16.16,3649.6639999999984,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,85888.0,3.04,3652.7039999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2684.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",176,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,821297.0,0.7661104043801561,72238240.0,1330624.0,77.024,3729.7279999999982,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2257445.0,41582.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",177,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.352,3734.079999999998,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.68,3737.759999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.864,3750.623999999998,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277190144.0,262144.0,109.408,3860.031999999998,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",181,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,3863.5199999999977,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",182,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,3866.8479999999977,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.616,3870.4639999999977,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.648,3874.111999999998,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,3877.6959999999976,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,372588.0,925400.0,32768.0,0,0.0,958168.0,958168.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,3881.247999999998,65536.0,147456.0,356204.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,3884.6719999999978,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,3888.1599999999976,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",189,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86400.0,3.072,3891.2319999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2700.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",190,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3653104.0,0.7464201345427446,284240160.0,2128224.0,179.456,4070.687999999998,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8882505.0,66507.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.192,4074.879999999998,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.392,4078.2719999999977,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.928,4091.1999999999975,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210084864.0,196608.0,100.704,4191.903999999998,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565152.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.448,4196.351999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.384,4200.735999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.64,4205.375999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",198,524288.0,17416192.0,0.0,0,154618822656.0,17416192.0,154636238848.0,136192.0,256.0,0.99812382739212,196608.0,65536.0,15.968,4221.343999999998,13172736.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,6144.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,88192.0,3.008,4224.351999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2756.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",200,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,853762.0,0.759092286603208,72276544.0,1330304.0,76.96,4301.311999999998,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2258642.0,41572.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",201,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.32,4305.631999999998,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.648,4309.279999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",203,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.216,4322.495999999998,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277185024.0,262144.0,109.568,4432.0639999999985,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662032.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",205,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,4435.583999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",206,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,4439.071999999999,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",207,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,4442.623999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,4446.175999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",209,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,4449.5999999999985,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,372948.0,926120.0,32768.0,0,0.0,958888.0,958888.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,4453.087999999999,65536.0,147456.0,356564.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,4456.415999999999,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",212,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.488,4459.9039999999995,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86784.0,3.072,4462.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2712.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",214,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3649731.0,0.7465949396486992,284081024.0,2128704.0,174.4,4637.375999999999,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8877532.0,66522.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",215,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.192,4641.567999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,4645.088,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",217,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.928,4658.016,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,837884816.0,1804441664.0,28948256.0,0,0.0,1833389920.0,1833389920.0,10880956.0,9750436.0,0.5273980543823703,909538816.0,1414112.0,348.16,5006.1759999999995,54679616.0,102940672.0,823410688.0,14474128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28423088.0,44191.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5008.959999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",220,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.904,5012.864,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5016.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",222,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.84,5019.968,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,5023.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55232.0,5.984,5028.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1726.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",225,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.544,5037.536,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55488.0,5.952,5043.488,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1734.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",227,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,0.0,8.256,5051.744000000001,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54144.0,5.856,5057.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1692.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",229,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.48,5066.08,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54336.0,5.856,5071.936,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1698.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",231,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,128.0,8.16,5080.096,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.904,5084.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,5087.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.472,5092.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,5095.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.92,5101.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",237,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,63304.0,13012.0,0.8294984013837203,831584.0,7936.0,9.216,5110.592000000001,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,248.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.864,5119.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,71712.0,6.24,5125.696,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2241.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.096,5129.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",241,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.064,5133.856,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,5140.096,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",243,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,5143.679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28316.0,0.6993129519703518,2732480.0,2022944.0,15.232,5158.911999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85390.0,63217.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,19826.0,28295.0,0.41200307558030796,2733888.0,1794720.0,12.224,5171.1359999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85434.0,56085.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28201.0,0.35187994116565546,2732096.0,1900480.0,13.152,5184.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85378.0,59390.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,13907.0,28225.0,0.33008164815342256,2724160.0,2451264.0,12.8,5197.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85130.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.088,5202.1759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,5205.567999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15170.0,0.49438389494383894,1864224.0,1336672.0,9.472,5215.039999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58257.0,41771.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429088.0,2412352.0,5.088,5220.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75909.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",252,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1062400.0,753536.0,31.744,5251.8719999999985,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33200.0,23548.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",253,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804352.0,618592.0,97.856,5349.727999999998,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25136.0,19331.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.744,5353.471999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.04,5356.511999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,94816.0,11.744,5368.255999999998,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2963.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.936,5372.191999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",258,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1059136.0,753280.0,31.712,5403.903999999998,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33098.0,23540.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",259,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.568,5413.471999999998,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,5417.055999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",261,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.696,5426.751999999998,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,5430.1439999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,5433.5679999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,5438.175999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",265,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.744,5453.919999999997,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5457.215999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,5462.463999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,5465.887999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,5470.367999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",270,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.952,5476.319999999997,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.376,5481.695999999997,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",272,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.72,5504.415999999997,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,5507.647999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5510.975999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.84,5514.815999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,5518.239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.032,5522.271999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5524.959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,5527.775999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",280,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.552,5531.327999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",281,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,5534.207999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.776,5537.983999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",283,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.328,5545.311999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",284,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,5548.671999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,5552.063999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,5556.095999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.632,5561.727999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5565.023999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,5568.383999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.216,5573.599999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",291,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.936,5577.535999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.168,5580.703999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.584,5584.287999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.296,5587.583999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.488,5591.071999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",296,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,66560.0,65536.0,6.592,5597.663999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2080.0,2048.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",297,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,5.408,5603.071999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,5606.399999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.328,5609.727999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",300,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.024,5614.751999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",301,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.184,5627.935999999999,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",302,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210103168.0,196608.0,99.968,5727.903999999999,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565724.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",303,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.632,5733.535999999998,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",304,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.888,5739.423999999998,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,5743.935999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",306,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.288,5760.223999999997,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,88576.0,3.072,5763.295999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2768.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",308,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,837177.0,0.7626614064427348,71912416.0,1329920.0,73.824,5837.119999999997,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2247263.0,41560.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",309,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.032,5841.151999999997,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",310,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.264,5844.415999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",311,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.056,5857.471999999997,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",312,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277162240.0,262144.0,108.96,5966.431999999997,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8661320.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.36,5969.791999999997,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",314,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,5973.311999999997,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",315,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,5976.639999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.648,5980.287999999998,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,5983.935999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",318,372323.0,924870.0,32768.0,0,0.0,957638.0,957638.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,5987.455999999998,65536.0,147456.0,355939.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,5990.911999999998,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",320,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,5994.463999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87808.0,3.04,5997.503999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2744.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",322,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3603127.0,0.7490185914037822,284404000.0,2128448.0,174.944,6172.4479999999985,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8887625.0,66514.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",323,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.192,6176.6399999999985,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.616,6180.2559999999985,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.8,6193.055999999999,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",326,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210072704.0,196608.0,100.864,6293.919999999998,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6564772.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",327,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.696,6299.615999999998,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.664,6305.279999999998,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.608,6309.887999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",330,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.448,6326.335999999998,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,85504.0,3.232,6329.567999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2672.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",332,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,845188.0,0.7609332447804525,72043232.0,1330016.0,75.2,6404.767999999998,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2251351.0,41563.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",333,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.512,6409.279999999998,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",334,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,6412.575999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",335,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.472,6426.047999999998,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",336,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277399040.0,262144.0,108.352,6534.399999999998,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8668720.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",337,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,6538.047999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",338,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.648,6541.695999999998,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",339,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,6545.119999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",340,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,6548.6399999999985,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,6551.967999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,372473.0,925170.0,32768.0,0,0.0,957938.0,957938.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,6555.487999999999,65536.0,147456.0,356089.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",343,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,6558.9439999999995,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",344,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,6562.495999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87552.0,3.008,6565.503999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2736.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",346,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3586494.0,0.7498874090468034,284152576.0,2128640.0,176.704,6742.207999999999,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8879768.0,66520.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",347,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.256,6746.463999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,6749.759999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.28,6763.039999999999,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210083072.0,196608.0,100.032,6863.071999999999,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565096.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.984,6869.056,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.696,6874.7519999999995,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.544,6879.295999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",354,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.16,6895.455999999999,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87040.0,3.072,6898.527999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2720.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",356,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,848053.0,0.760317096490928,71990976.0,1330240.0,75.648,6974.1759999999995,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2249718.0,41570.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",357,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.352,6978.527999999999,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.52,6982.048,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.832,6994.88,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",360,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277235712.0,262144.0,111.104,7105.984,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8663616.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.68,7109.664000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",362,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,7113.216,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,7116.704000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",364,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,7120.224000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,7123.5520000000015,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,372590.0,925404.0,32768.0,0,0.0,958172.0,958172.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,7127.104000000001,65536.0,147456.0,356206.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",367,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,7130.560000000001,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",368,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,7134.144000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,89088.0,3.072,7137.216000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2784.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",370,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3527510.0,0.7529847273218214,283984064.0,2128704.0,174.944,7312.160000000002,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8874502.0,66522.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",371,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.416,7316.576000000002,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,7320.064000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.864,7332.928000000002,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210083200.0,196608.0,100.448,7433.376000000002,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565100.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.728,7439.104000000002,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.696,7444.800000000002,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,7449.312000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.16,7465.472000000002,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,87936.0,3.04,7468.5120000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2748.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",380,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,857381.0,0.7583179072246056,71930752.0,1329824.0,73.536,7542.048000000002,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2247836.0,41557.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",381,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.608,7546.656000000002,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,7550.112000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.088,7563.200000000002,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",384,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277163520.0,262144.0,109.28,7672.480000000001,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8661360.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,7676.000000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",386,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,7679.488000000002,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,7682.976000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.456,7686.4320000000025,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",389,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,7689.760000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,372580.0,925384.0,32768.0,0,0.0,958152.0,958152.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,7693.344000000003,65536.0,147456.0,356196.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",391,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,7696.832000000003,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,7700.384000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,85760.0,3.04,7703.424000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2680.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",394,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3516492.0,0.7535661335675296,284427744.0,2128416.0,177.28,7880.704000000002,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8888367.0,66513.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",395,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.352,7885.056000000002,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.328,7888.384000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",397,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.024,7901.408000000003,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",398,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210070784.0,196608.0,100.288,8001.696000000003,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6564712.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.792,8007.488000000003,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.856,8013.344000000003,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.448,8017.792000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",402,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.096,8033.888000000003,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,88576.0,3.04,8036.928000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2768.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",404,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,848156.0,0.7602949638417198,71930240.0,1329760.0,73.312,8110.2400000000025,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2247820.0,41555.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",405,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.352,8114.592000000002,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.712,8118.304000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",407,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.832,8131.136000000003,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",408,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277235072.0,262144.0,109.248,8240.384000000004,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8663596.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,8243.936000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",410,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,8247.456000000004,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",411,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.296,8250.752000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",412,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,8254.336000000005,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.296,8257.632000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,372573.0,925370.0,32768.0,0,0.0,958138.0,958138.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,8261.024000000005,65536.0,147456.0,356189.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",415,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,8264.448000000006,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,8268.032000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86912.0,3.2,8271.232000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2716.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",418,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3545685.0,0.7520276131222756,284316000.0,2128864.0,175.968,8447.200000000008,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8884875.0,66527.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",419,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.352,8451.552000000009,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.488,8455.040000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",421,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.184,8468.224000000007,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",422,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210130304.0,196608.0,99.68,8567.904000000008,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6566572.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.728,8573.632000000007,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.728,8579.360000000006,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.512,8583.872000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",426,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.384,8600.256000000007,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86272.0,3.04,8603.296000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2696.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",428,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,837091.0,0.7626800012587649,72093216.0,1329888.0,76.16,8679.456000000007,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2252913.0,41559.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",429,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.0,8683.456000000007,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.264,8686.720000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.992,8699.712000000007,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",432,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277190400.0,262144.0,108.64,8808.352000000006,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662200.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,8811.872000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",434,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,8815.296000000008,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,8818.880000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.776,8822.656000000008,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,8826.080000000009,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",438,372539.0,925302.0,32768.0,0,0.0,958070.0,958070.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,8829.568000000008,65536.0,147456.0,356155.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",439,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,8833.024000000009,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",440,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.584,8836.60800000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",441,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86272.0,3.008,8839.616000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2696.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",442,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3627169.0,0.7477663199652467,284014880.0,2128192.0,174.528,9014.14400000001,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8875465.0,66506.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",443,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.448,9018.59200000001,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.712,9022.30400000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.28,9035.58400000001,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210091008.0,196608.0,99.488,9135.07200000001,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565344.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.696,9140.76800000001,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.824,9146.59200000001,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.48,9151.07200000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",450,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.128,9167.20000000001,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,84352.0,3.04,9170.24000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2636.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",452,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,855302.0,0.7587625702373558,72008896.0,1330112.0,74.976,9245.216000000011,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2250278.0,41566.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",453,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.0,9249.216000000011,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.456,9252.672000000011,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.376,9266.048000000012,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",456,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277208448.0,262144.0,109.344,9375.39200000001,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662764.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",457,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,9378.912000000011,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",458,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.584,9382.496000000012,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",459,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.392,9385.888000000012,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,9389.408000000012,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",461,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.456,9392.864000000012,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,372432.0,925088.0,32768.0,0,0.0,957856.0,957856.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,9396.288000000013,65536.0,147456.0,356048.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",463,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.488,9399.776000000013,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.52,9403.296000000013,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,84992.0,3.04,9406.336000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2656.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",466,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3482216.0,0.7553805907030721,284145504.0,2128704.0,175.488,9581.824000000013,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8879547.0,66522.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",467,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.192,9586.016000000012,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.296,9589.312000000013,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",469,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,13.12,9602.432000000013,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,202162176.0,407568384.0,1671168.0,0,0.0,409239552.0,409239552.0,1777152.0,1674240.0,0.5149087672452158,210084352.0,196608.0,99.968,9702.400000000014,1769472.0,3145728.0,201326592.0,835584.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6565136.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.856,9708.256000000014,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",472,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,0.0,2048.0,0.0,131072.0,131072.0,5.952,9714.208000000013,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1024.0,0.0,65536.0,65536.0,4.672,9718.880000000014,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",474,524288.0,17432576.0,0.0,0,154618822656.0,17432576.0,154636255232.0,136192.0,256.0,0.99812382739212,327680.0,65536.0,16.288,9735.168000000014,13189120.0,3194880.0,524288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,603979776.0,10240.0,2048.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",475,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,86400.0,3.04,9738.208000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2700.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",476,134873728.0,269418496.0,656640.0,0,0.0,270075136.0,270075136.0,2690176.0,858155.0,0.7581524947926223,71980800.0,1329600.0,74.816,9813.024000000016,0.0,327680.0,134545408.0,328320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2249400.0,41550.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",477,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.256,9817.280000000015,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",478,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,9820.704000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",479,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.992,9833.696000000016,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",480,269549568.0,543424512.0,2228224.0,0,0.0,545652736.0,545652736.0,2369536.0,2232320.0,0.5149087672452158,277193216.0,262144.0,109.12,9942.816000000017,2359296.0,4194304.0,268435456.0,1114112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8662288.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",481,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,9946.336000000018,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",482,0.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,9949.856000000018,0.0,131072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",483,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.424,9953.280000000019,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",484,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1536.0,0.0,524288.0,262144.0,3.552,9956.832000000019,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",485,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,262144.0,262144.0,3.52,9960.352000000019,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,372396.0,925016.0,32768.0,0,0.0,957784.0,957784.0,0.0,1024.0,0.0,262144.0,262144.0,3.552,9963.904000000019,65536.0,147456.0,356012.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",487,65536.0,131072.0,0.0,0,0.0,131072.0,131072.0,0.0,1024.0,0.0,262144.0,262144.0,3.328,9967.232000000018,0.0,0.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,3.392,9970.624000000018,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4096.0,0.0,0.0,89216.0,3.104,9973.728000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2788.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",490,537920512.0,1075314688.0,1050624.0,0,0.0,1076365312.0,1076365312.0,10753024.0,3432577.0,0.758023858136148,284706080.0,2128736.0,177.376,10151.104000000018,0.0,524288.0,537395200.0,525312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8897065.0,66523.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",491,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,5120.0,0.0,81920.0,0.0,4.256,10155.360000000017,16384.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,3.424,10158.784000000018,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",493,96324.0,306420.0,8192.0,0,0.0,314612.0,314612.0,80.0,1416.0,0.053475935828877004,196608.0,65792.0,12.992,10171.776000000018,92720.0,29244.0,92228.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,2056.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",494,837884816.0,1804441664.0,28948256.0,0,0.0,1833389920.0,1833389920.0,10880956.0,9750436.0,0.5273980543823703,907923584.0,1416480.0,346.08,10517.856000000018,54679616.0,102940672.0,823410688.0,14474128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,28372612.0,44265.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,10520.576000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.936,10524.512000000017,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,10527.872000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",498,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.584,10531.456000000018,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",499,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,10534.336000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,5.92,10540.256000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",501,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.416,10548.672000000017,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53568.0,5.952,10554.624000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1674.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",503,84800.0,0.0,169600.0,0,0.0,169600.0,169600.0,13200.0,82958.0,0.13727406976018636,5134848.0,0.0,8.384,10563.008000000016,0.0,0.0,0.0,84800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53504.0,5.856,10568.864000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1672.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",505,80000.0,0.0,160000.0,0,0.0,160000.0,160000.0,13200.0,83108.0,0.13706026498317897,5134848.0,0.0,8.448,10577.312000000016,0.0,0.0,0.0,80000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53696.0,5.92,10583.232000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1678.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",507,75200.0,0.0,150400.0,0,0.0,150400.0,150400.0,13200.0,83258.0,0.13684712517365072,5134848.0,128.0,8.544,10591.776000000016,0.0,0.0,0.0,75200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.904,10595.680000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,10598.688000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.504,10604.192000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",511,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,10607.072000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.472,10612.544000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",513,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,52316.0,13016.0,0.8007714443151901,831584.0,8640.0,9.28,10621.824000000017,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,270.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.416,10630.240000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,69344.0,6.144,10636.384000000016,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2167.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.096,10640.480000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",517,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.0,10644.480000000016,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.176,10650.656000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",519,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,10654.112000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,64451.0,27692.0,0.6994671326090968,2739904.0,1998496.0,14.944,10669.056000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85622.0,62453.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",521,0.0,0.0,0.0,0,0.0,0.0,0.0,15614.0,28310.0,0.3554776432018942,2719808.0,2140000.0,11.776,10680.832000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84994.0,66875.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28240.0,0.35156483203600375,2719168.0,1900864.0,12.928,10693.760000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84974.0,59402.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,13907.0,28180.0,0.33043457599733883,2727232.0,2451264.0,13.76,10707.520000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85226.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.928,10712.448000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.456,10715.904000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15206.0,0.4937914045074736,1873696.0,1341280.0,9.76,10725.664000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58553.0,41915.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429312.0,2412352.0,5.184,10730.848000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75916.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",528,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1066912.0,753216.0,32.0,10762.848000000015,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33341.0,23538.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",529,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804256.0,613504.0,98.592,10861.440000000015,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,19172.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200832.0,3.616,10865.056000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6276.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,10868.128000000015,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,90272.0,11.52,10879.648000000016,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2821.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.288,10883.936000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",534,3122055.0,6655044.0,615326.0,0,0.0,7270370.0,7270370.0,528.0,6704.0,0.07300884955752213,1033152.0,752832.0,31.872,10915.808000000015,825232.0,201028.0,2814392.0,307663.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32286.0,23526.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",535,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.632,10925.440000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,10928.800000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",537,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.408,10938.208000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,10941.632000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,10944.992000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",540,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,10949.440000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",541,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.448,10965.888000000017,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,10969.216000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.472,10974.688000000016,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,10977.888000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",545,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,10982.496000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",546,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.984,10988.480000000018,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",547,1256415.0,2010280.0,502550.0,0,0.0,2512830.0,2512830.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,10993.888000000017,0.0,0.0,1005140.0,251275.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",548,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,22.528,11016.416000000017,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",549,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11019.712000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,11023.168000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,11027.040000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",552,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,11030.400000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",553,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.904,11034.304000000018,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,11037.120000000019,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",555,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,11039.93600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,11043.52000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",557,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,11046.27200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.872,11050.14400000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",559,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.328,11057.47200000002,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,11060.80000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,11064.128000000019,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",562,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.064,11068.19200000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",563,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.768,11072.96000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",564,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,11076.25600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
