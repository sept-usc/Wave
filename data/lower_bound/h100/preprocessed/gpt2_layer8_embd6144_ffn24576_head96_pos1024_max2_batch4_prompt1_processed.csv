Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,11.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.168,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.936,19.104,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.672,23.776,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.056,28.832,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,32.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,35.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,37.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,41.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.744,44.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,48.288000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,51.68000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.936,55.61600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,58.88000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,62.20800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.68,65.88800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,26112.0,98304.0,5.952,71.84000000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,816.0,3072.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,26112.0,98304.0,5.632,77.47200000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,816.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,80.96000000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,84.28800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,89.53600000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.664,107.20000000000003,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466556672.0,294912.0,176.256,283.456,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14579896.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,5.088,288.54400000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,293.02400000000006,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.544,297.56800000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,22.112,319.68000000000006,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",31,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123520.0,3.072,322.75200000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3860.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",32,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1784480.0,0.7721999362739892,158551392.0,1396896.0,123.968,446.7200000000001,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4954731.0,43653.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",33,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.576,451.2960000000001,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,454.8480000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.856,472.7040000000001,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617681792.0,393216.0,211.04,683.7440000000001,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19302556.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,687.3600000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,690.9760000000001,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,694.4640000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,698.0480000000001,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,701.5680000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,551960.0,1374256.0,49152.0,0,0.0,1423408.0,1423408.0,0.0,1536.0,0.0,393216.0,393216.0,3.808,705.3760000000001,98304.0,221184.0,527384.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,708.7680000000001,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.488,712.2560000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",45,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126080.0,3.072,715.3280000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3940.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",46,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,8628184.0,0.7370950808211234,635934816.0,3193920.0,276.96,992.2880000000002,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19872963.0,99810.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",47,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.608,996.8960000000002,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,1000.4480000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",49,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,1018.2080000000002,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466528768.0,294912.0,175.328,1193.5360000000003,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14579024.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,1198.0160000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,1202.4960000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.512,1207.0080000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.416,1227.4240000000002,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,127232.0,3.04,1230.4640000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3976.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",56,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1787288.0,0.7719232335895413,158369312.0,1397024.0,122.4,1352.8640000000003,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4949041.0,43657.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",57,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.416,1357.2800000000002,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,1360.736,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",59,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,1378.496,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617643776.0,393216.0,207.872,1586.3680000000002,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19301368.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,1589.8880000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",62,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,1593.4080000000001,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,1596.96,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.648,1600.608,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",65,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.36,1603.9679999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,550920.0,1372176.0,49152.0,0,0.0,1421328.0,1421328.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,1607.552,98304.0,221184.0,526344.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,1610.944,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,1614.4959999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",69,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124032.0,3.072,1617.5679999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3876.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",70,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,8918610.0,0.7306294340941096,636176832.0,3193632.0,279.392,1896.9599999999998,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19880526.0,99801.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.32,1901.2799999999997,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,1904.7039999999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.984,1922.6879999999996,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466682112.0,294912.0,174.24,2096.928,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14583816.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,2101.408,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.64,2106.048,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.448,2110.4959999999996,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",78,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.48,2130.9759999999997,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",79,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,128896.0,3.072,2134.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4028.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",80,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1772930.0,0.7733401721762223,158775296.0,1396992.0,121.952,2256.0,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4961728.0,43656.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",81,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.704,2260.704,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,2264.0,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",83,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.952,2281.952,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617688576.0,393216.0,210.656,2492.608,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19302768.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.68,2496.288,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",86,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,2499.808,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,2503.392,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",88,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.52,2506.912,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",89,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,2510.464,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,551520.0,1373376.0,49152.0,0,0.0,1422528.0,1422528.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,2514.016,98304.0,221184.0,526944.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",91,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.328,2517.344,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.456,2520.8,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",93,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,122624.0,3.072,2523.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3832.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",94,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9513900.0,0.717724980658291,635726688.0,3194016.0,278.656,2802.5280000000002,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19866459.0,99813.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",95,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.864,2807.3920000000003,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.68,2811.072,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.44,2828.512,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466542464.0,294912.0,173.984,3002.496,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14579452.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,3006.976,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,3011.456,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.416,3015.8720000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",102,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.448,3036.32,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",103,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126464.0,3.04,3039.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3952.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",104,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1755406.0,0.7750766164278845,158661600.0,1396992.0,122.848,3162.208,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4958175.0,43656.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",105,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.288,3166.496,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.808,3170.304,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",107,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.696,3188.0,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617787520.0,393216.0,209.664,3397.6639999999998,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19305860.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",109,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,3401.1839999999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",110,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,3404.736,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",111,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,3408.2239999999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.648,3411.872,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",113,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,3415.296,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",114,551944.0,1374224.0,49152.0,0,0.0,1423376.0,1423376.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,3418.8799999999997,98304.0,221184.0,527368.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",115,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,3422.432,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",116,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.456,3425.888,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",117,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126720.0,3.072,3428.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3960.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",118,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9392292.0,0.7203239662641149,636108000.0,3193600.0,279.84,3708.8,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19878375.0,99800.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",119,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.512,3713.3120000000004,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.68,3716.992,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.6,3734.592,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",122,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466585216.0,294912.0,173.984,3908.576,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14580788.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.384,3912.96,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.512,3917.472,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.608,3922.0800000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",126,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.352,3942.4320000000002,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",127,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,125568.0,3.04,3945.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3924.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",128,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1806461.0,0.7700391966563117,158692384.0,1397120.0,122.432,4067.904,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4959137.0,43660.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",129,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.16,4072.064,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,4075.488,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",131,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,4093.248,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",132,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617698688.0,393216.0,209.056,4302.304,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19303084.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,4305.728,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",134,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,4309.216,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",135,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,4312.704000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",136,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.68,4316.384000000001,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,4319.936000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,551540.0,1373416.0,49152.0,0,0.0,1422568.0,1422568.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,4323.424000000001,98304.0,221184.0,526964.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",139,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,4326.816000000001,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,4330.400000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",141,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123904.0,3.072,4333.472000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3872.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",142,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9199491.0,0.7244832764824032,636117824.0,3193984.0,278.816,4612.2880000000005,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19878682.0,99812.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",143,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.576,4616.8640000000005,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,4620.416,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.632,4638.048,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466641792.0,294912.0,175.648,4813.696,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14582556.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.512,4818.208,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.576,4822.784,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.704,4827.487999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",150,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.128,4847.615999999999,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",151,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126080.0,3.04,4850.655999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3940.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",152,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1831702.0,0.7675728654527902,158465472.0,1396992.0,124.608,4975.263999999999,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4952046.0,43656.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",153,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.672,4979.935999999999,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,4983.359999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",155,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.696,5001.055999999999,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",156,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617662720.0,393216.0,209.76,5210.815999999999,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19301960.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",157,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,5214.239999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",158,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.744,5217.983999999999,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",159,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,5221.503999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.744,5225.247999999999,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,5228.6399999999985,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,551564.0,1373464.0,49152.0,0,0.0,1422616.0,1422616.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,5232.223999999998,98304.0,221184.0,526988.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",163,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,5235.743999999999,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,5239.2959999999985,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124160.0,3.072,5242.367999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3880.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",166,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9360440.0,0.7210078154675057,635924864.0,3193600.0,276.608,5518.975999999999,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19872652.0,99800.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",167,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.288,5523.263999999998,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.328,5526.591999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",169,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,5544.351999999999,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466668032.0,294912.0,175.072,5719.423999999999,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14583376.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.416,5723.839999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.576,5728.415999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.416,5732.831999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",174,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.256,5753.088,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124928.0,3.072,5756.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3904.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",176,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1790006.0,0.7716555883854471,158185696.0,1396960.0,123.04,5879.2,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4943303.0,43655.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",177,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.352,5883.552,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,5886.911999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,5904.672,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617622656.0,393216.0,209.184,6113.856,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19300708.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",181,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,6117.344,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",182,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,6120.832,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,6124.352000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.68,6128.032000000001,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,6131.456000000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,551384.0,1373104.0,49152.0,0,0.0,1422256.0,1422256.0,0.0,1536.0,0.0,393216.0,393216.0,3.712,6135.1680000000015,98304.0,221184.0,526808.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,6138.656000000002,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.648,6142.304000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",189,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,121728.0,3.072,6145.376000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3804.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",190,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,8548261.0,0.7388945049020693,635966560.0,3193376.0,274.944,6420.320000000002,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19873955.0,99793.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.352,6424.672000000002,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,6428.128000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.12,6445.248000000002,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466494336.0,294912.0,173.568,6618.8160000000025,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14577948.0,9216.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.48,6623.296000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.768,6628.064000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.544,6632.608000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",198,786432.0,26124288.0,0.0,0,231928233984.0,26124288.0,231954358272.0,204288.0,384.0,0.99812382739212,294912.0,98304.0,20.16,6652.768000000002,19759104.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,9216.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124160.0,3.072,6655.840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3880.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",200,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1827294.0,0.7680024376773505,158012416.0,1396832.0,122.592,6778.432000000002,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4937888.0,43651.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",201,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.416,6782.848000000002,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,6786.272000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",203,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.536,6803.808000000002,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617679488.0,393216.0,208.096,7011.904000000002,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19302484.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",205,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,7015.392000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",206,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.68,7019.072000000003,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",207,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,7022.464000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.776,7026.2400000000025,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",209,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.456,7029.696000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,551644.0,1373624.0,49152.0,0,0.0,1422776.0,1422776.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,7033.312000000003,98304.0,221184.0,527068.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,7036.736000000003,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",212,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.52,7040.256000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,121984.0,3.072,7043.328000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3812.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",214,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,10441124.0,0.6985086563168862,635241216.0,3193920.0,275.616,7318.944000000003,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19851288.0,99810.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",215,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.32,7323.264000000003,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,7326.784000000003,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",217,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.12,7343.904000000003,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,1256023056.0,2705054272.0,41814048.0,0,0.0,2746868320.0,2746868320.0,16107836.0,14575396.0,0.5249719455890436,1364146688.0,1411648.0,517.312,7861.216000000003,80411200.0,154411008.0,1235116032.0,20907024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42629584.0,44114.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,7864.1600000000035,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",220,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.84,7868.000000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,7871.264000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",222,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.744,7875.008000000003,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,7878.016000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55360.0,5.984,7884.000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1730.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",225,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.0,7892.000000000004,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54976.0,5.856,7897.856000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1718.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",227,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.48,7906.336000000003,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54656.0,5.856,7912.192000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1708.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",229,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,0.0,8.256,7920.448000000003,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55040.0,5.792,7926.240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1720.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",231,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,128.0,8.512,7934.752000000003,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.584,7938.336000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,7941.568000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.504,7947.072000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.976,7950.0480000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.92,7955.968000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",237,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,63960.0,13004.0,0.8310378878436672,831584.0,9024.0,8.992,7964.960000000003,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,282.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.992,7973.952000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,74912.0,6.112,7980.064000000003,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2341.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.288,7984.352000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",241,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,3.904,7988.256000000003,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,7994.496000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",243,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.776,7998.272000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28353.0,0.6990382982336957,2740032.0,1948608.0,15.2,8013.4720000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85626.0,60894.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,19826.0,28138.0,0.4133516804269869,2709440.0,1632800.0,12.256,8025.728000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84670.0,51025.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28236.0,0.35159712494546125,2712256.0,2243808.0,12.896,8038.6240000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84758.0,70119.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28232.0,0.3516294237879797,2723392.0,2244640.0,12.608,8051.232000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85106.0,70145.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.928,8056.160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,8059.552000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15182.0,0.4941862402132267,1861664.0,1338336.0,9.472,8069.024000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58177.0,41823.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429184.0,2412352.0,5.056,8074.080000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75912.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",252,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1069120.0,753344.0,31.456,8105.536000000002,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33410.0,23542.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",253,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804256.0,619008.0,97.696,8203.232000000002,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,19344.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.616,8206.848000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,8209.920000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,90528.0,11.488,8221.408000000001,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2829.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.064,8225.472000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",258,3122060.0,6655044.0,615336.0,0,0.0,7270380.0,7270380.0,528.0,6704.0,0.07300884955752213,1062976.0,752448.0,31.808,8257.280000000002,825232.0,201028.0,2814392.0,307668.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33218.0,23514.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",259,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.44,8266.720000000003,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,8270.240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",261,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.312,8279.552000000003,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8282.912000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,8286.432000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.704,8291.136000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",265,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.32,8307.456000000004,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,8310.688000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.184,8315.872000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,8319.488000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,8324.064000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",270,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,8330.080000000002,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,1256420.0,2010280.0,502560.0,0,0.0,2512840.0,2512840.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,8335.488000000001,0.0,0.0,1005140.0,251280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",272,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.848,8358.336000000001,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,8361.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,8364.704000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.096,8368.800000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,8372.160000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.032,8376.192000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8378.912,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,8381.824,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",280,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,8385.248000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",281,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8387.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.744,8391.712000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",283,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.456,8399.168000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",284,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,8402.464000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,8405.792000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.128,8409.920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.152,8415.072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,8418.400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8421.760000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.088,8426.848000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",291,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.192,8431.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.104,8434.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,8437.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.328,8440.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.424,8444.256000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",296,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,99840.0,98304.0,6.656,8450.912000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3120.0,3072.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",297,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,26112.0,98304.0,5.696,8456.608000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,816.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,8460.064000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.424,8463.488000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",300,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.96,8468.448000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",301,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.632,8486.080000000002,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",302,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466484608.0,294912.0,174.56,8660.640000000001,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14577644.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",303,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.952,8666.592,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",304,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,6.048,8672.640000000001,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.608,8677.248000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",306,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.32,8697.568000000001,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124160.0,3.072,8700.640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3880.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",308,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1828385.0,0.76789607183348,158131232.0,1396960.0,124.992,8825.632000000001,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4941601.0,43655.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",309,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.32,8829.952000000001,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",310,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,8833.248000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",311,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,18.08,8851.328000000001,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",312,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617653504.0,393216.0,207.904,9059.232000000002,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19301672.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,9062.816000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",314,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,9066.368000000002,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",315,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,9069.792000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,9073.344000000003,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.648,9076.992000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",318,551488.0,1373312.0,49152.0,0,0.0,1422464.0,1422464.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,9080.512000000002,98304.0,221184.0,526912.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,9084.064000000002,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",320,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,9087.648000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126720.0,3.072,9090.720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3960.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",322,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9279733.0,0.7227463883765011,636246272.0,3194048.0,276.448,9367.168000000003,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19882696.0,99814.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",323,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.352,9371.520000000004,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,9374.816000000004,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.984,9392.800000000005,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",326,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466581760.0,294912.0,176.608,9569.408000000005,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14580680.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",327,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,6.016,9575.424000000005,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.696,9581.120000000004,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.8,9585.920000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",330,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.352,9606.272000000004,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,126080.0,3.072,9609.344000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3940.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",332,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1819030.0,0.7688090852082705,158317696.0,1396896.0,124.16,9733.504000000004,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4947428.0,43653.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",333,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.288,9737.792000000005,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",334,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,9741.248000000005,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",335,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,9759.008000000005,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",336,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617729664.0,393216.0,208.256,9967.264000000005,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19304052.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",337,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,9970.816000000004,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",338,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,9974.304000000004,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",339,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,9977.824000000004,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",340,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.936,9981.760000000004,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,9985.184000000005,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,551482.0,1373300.0,49152.0,0,0.0,1422452.0,1422452.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,9988.768000000005,98304.0,221184.0,526906.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",343,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,9992.256000000005,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",344,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,9995.808000000005,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123520.0,3.04,9998.848000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3860.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",346,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9447657.0,0.7191383846915825,636479200.0,3194240.0,277.088,10275.936000000005,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19889975.0,99820.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",347,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.448,10280.384000000005,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.584,10283.968000000006,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.76,10301.728000000006,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466729344.0,294912.0,176.352,10478.080000000007,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14585292.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.76,10483.840000000007,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.824,10489.664000000008,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.64,10494.304000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",354,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.352,10514.656000000008,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,127616.0,3.072,10517.728000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3988.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",356,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1836553.0,0.7671006766883826,158399360.0,1396992.0,120.48,10638.208000000008,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4949980.0,43656.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",357,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.352,10642.560000000009,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,10646.016000000009,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.984,10664.00000000001,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",360,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617855744.0,393216.0,210.848,10874.848000000009,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19307992.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,10878.400000000009,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",362,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.712,10882.112000000008,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,10885.664000000008,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",364,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.712,10889.376000000007,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,10892.992000000007,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,551354.0,1373044.0,49152.0,0,0.0,1422196.0,1422196.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,10896.512000000008,98304.0,221184.0,526778.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",367,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,10900.032000000008,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",368,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.52,10903.552000000009,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123264.0,3.04,10906.59200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3852.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",370,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9510116.0,0.7178055689249265,636567008.0,3193824.0,279.616,11186.20800000001,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19892719.0,99807.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",371,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.448,11190.65600000001,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,11194.01600000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.536,11211.55200000001,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466654848.0,294912.0,174.432,11385.984000000011,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14582964.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.824,11391.808000000012,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.728,11397.536000000011,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.576,11402.11200000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.224,11422.33600000001,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124544.0,3.232,11425.56800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3892.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",380,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1735359.0,0.7770726509313802,158315456.0,1396768.0,125.056,11550.62400000001,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4947358.0,43649.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",381,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.512,11555.136000000011,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,11558.62400000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.6,11576.224000000011,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",384,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617738624.0,393216.0,207.808,11784.03200000001,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19304332.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,11787.61600000001,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",386,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,11791.040000000012,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.36,11794.400000000012,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.648,11798.048000000012,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",389,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.36,11801.408000000012,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,551443.0,1373222.0,49152.0,0,0.0,1422374.0,1422374.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,11804.992000000013,98304.0,221184.0,526867.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",391,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,11808.512000000013,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.616,11812.128000000013,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,125184.0,3.232,11815.360000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3912.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",394,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9403568.0,0.7200821860263752,636273856.0,3193888.0,276.096,12091.456000000013,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19883558.0,99809.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",395,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.448,12095.904000000013,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,12099.392000000013,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",397,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.984,12117.376000000013,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",398,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466542720.0,294912.0,173.12,12290.496000000014,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14579460.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.76,12296.256000000014,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.728,12301.984000000013,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.544,12306.528000000013,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",402,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.192,12326.720000000012,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123392.0,3.072,12329.792000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3856.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",404,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1824044.0,0.7683194675540765,158344032.0,1396672.0,123.744,12453.536000000013,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4948251.0,43646.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",405,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.288,12457.824000000013,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,12461.248000000014,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",407,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.632,12478.880000000014,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",408,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617717376.0,393216.0,210.592,12689.472000000014,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19303668.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,12693.024000000014,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",410,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,12696.640000000014,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",411,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,12700.160000000014,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",412,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,12703.712000000014,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,12707.296000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,551755.0,1373846.0,49152.0,0,0.0,1422998.0,1422998.0,0.0,1536.0,0.0,393216.0,393216.0,3.456,12710.752000000015,98304.0,221184.0,527179.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",415,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,12714.144000000015,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.616,12717.760000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,122368.0,3.04,12720.800000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3824.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",418,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,8994548.0,0.7289575185327641,636486112.0,3194016.0,276.512,12997.312000000016,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19890191.0,99813.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",419,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.64,13001.952000000016,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,13005.248000000016,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",421,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.44,13022.688000000016,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",422,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466522368.0,294912.0,175.136,13197.824000000017,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14578824.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.76,13203.584000000017,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.824,13209.408000000018,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.576,13213.984000000017,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",426,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.192,13234.176000000016,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,127232.0,3.136,13237.312000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3976.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",428,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1825270.0,0.7681998433897708,158310144.0,1397280.0,123.744,13361.056000000017,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4947192.0,43665.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",429,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.416,13365.472000000016,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,13368.768000000016,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.632,13386.400000000016,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",432,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617858048.0,393216.0,209.728,13596.128000000015,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19308064.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.616,13599.744000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",434,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.744,13603.488000000016,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,13607.008000000016,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.808,13610.816000000017,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.456,13614.272000000017,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",438,551369.0,1373074.0,49152.0,0,0.0,1422226.0,1422226.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,13617.792000000018,98304.0,221184.0,526793.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",439,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,13621.344000000017,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",440,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.488,13624.832000000017,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",441,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123904.0,3.04,13627.872000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3872.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",442,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9427290.0,0.7195740679166134,636635392.0,3193472.0,280.384,13908.256000000018,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19894856.0,99796.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",443,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.48,13912.736000000017,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,13916.096000000018,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,18.112,13934.208000000017,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466616960.0,294912.0,175.232,14109.440000000017,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14581780.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.792,14115.232000000016,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.824,14121.056000000017,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.608,14125.664000000017,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",450,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.448,14146.112000000017,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123904.0,3.232,14149.344000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3872.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",452,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1820754.0,0.7686406660389514,158184416.0,1396800.0,123.104,14272.448000000017,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4943263.0,43650.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",453,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.416,14276.864000000016,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,14280.288000000017,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.6,14297.888000000017,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",456,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617884160.0,393216.0,209.6,14507.488000000018,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19308880.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",457,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.424,14510.912000000018,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",458,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.584,14514.49600000002,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",459,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.52,14518.01600000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.84,14521.85600000002,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",461,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.328,14525.18400000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,551409.0,1373154.0,49152.0,0,0.0,1422306.0,1422306.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,14528.672000000019,98304.0,221184.0,526833.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",463,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,14532.224000000018,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.68,14535.904000000019,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124288.0,3.04,14538.94400000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3884.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",466,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,9412858.0,0.7198831115566491,636432512.0,3193760.0,281.312,14820.25600000002,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19888516.0,99805.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",467,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.48,14824.736000000019,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.68,14828.41600000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",469,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.28,14845.69600000002,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,454828032.0,916881408.0,3686400.0,0,0.0,920567808.0,920567808.0,3992832.0,3764736.0,0.5147015147015147,466594816.0,294912.0,174.432,15020.12800000002,3833856.0,7077888.0,452984832.0,1843200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14581088.0,9216.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.952,15026.08000000002,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",472,98304.0,0.0,196608.0,0,0.0,196608.0,196608.0,0.0,3072.0,0.0,196608.0,196608.0,5.824,15031.90400000002,0.0,0.0,0.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,98304.0,98304.0,4.576,15036.48000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",474,786432.0,26148864.0,0.0,0,231928233984.0,26148864.0,231954382848.0,204288.0,384.0,0.99812382739212,491520.0,98304.0,20.416,15056.896000000019,19783680.0,4792320.0,786432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,905969664.0,15360.0,3072.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",475,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,123008.0,3.264,15060.160000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3844.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",476,302678688.0,605011968.0,689472.0,0,0.0,605701440.0,605701440.0,6049056.0,1816797.0,0.7690273388022888,158651456.0,1397184.0,124.352,15184.512000000019,0.0,344064.0,302333952.0,344736.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4957858.0,43662.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",477,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.544,15189.056000000019,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",478,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.328,15192.384000000018,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",479,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.344,15209.728000000017,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",480,606437376.0,1222508544.0,4915200.0,0,0.0,1227423744.0,1227423744.0,5323776.0,5019648.0,0.5147015147015147,617905408.0,393216.0,209.344,15419.072000000016,5111808.0,9437184.0,603979776.0,2457600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19309544.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",481,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,15422.624000000016,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",482,0.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,15426.176000000016,0.0,196608.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",483,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.488,15429.664000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",484,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,2304.0,0.0,786432.0,393216.0,3.712,15433.376000000015,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",485,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,393216.0,393216.0,3.456,15436.832000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,551430.0,1373196.0,49152.0,0,0.0,1422348.0,1422348.0,0.0,1536.0,0.0,393216.0,393216.0,3.552,15440.384000000015,98304.0,221184.0,526854.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",487,98304.0,196608.0,0.0,0,0.0,196608.0,196608.0,0.0,1536.0,0.0,393216.0,393216.0,3.392,15443.776000000014,0.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,15447.360000000015,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6144.0,0.0,0.0,124800.0,3.072,15450.432000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3900.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",490,1209533952.0,2418278400.0,1575936.0,0,0.0,2419854336.0,2419854336.0,24190464.0,8890511.0,0.7312500311735068,636621952.0,3193728.0,277.984,15728.416000000016,0.0,786432.0,1208745984.0,787968.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19894436.0,99804.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",491,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,7680.0,0.0,122880.0,0.0,4.256,15732.672000000015,24576.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,15736.192000000015,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",493,137284.0,437492.0,8192.0,0,0.0,445684.0,445684.0,80.0,2120.0,0.03636363636363636,294912.0,98560.0,17.408,15753.600000000015,133680.0,37436.0,133188.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9216.0,3080.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",494,1256023056.0,2705054272.0,41814048.0,0,0.0,2746868320.0,2746868320.0,16107836.0,14575396.0,0.5249719455890436,1362987264.0,1410784.0,516.736,16270.336000000016,80411200.0,154411008.0,1235116032.0,20907024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42593352.0,44087.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,16273.056000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,16276.896000000015,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,16280.224000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",498,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.712,16283.936000000014,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",499,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,16287.008000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55488.0,5.888,16292.896000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1734.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",501,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.224,16301.120000000015,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55296.0,6.048,16307.168000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1728.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",503,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.16,16315.328000000016,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53888.0,6.016,16321.344000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1684.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",505,81600.0,0.0,163200.0,0,0.0,163200.0,163200.0,13200.0,83058.0,0.1371314592033909,5134848.0,0.0,8.544,16329.888000000015,0.0,0.0,0.0,81600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53952.0,5.856,16335.744000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1686.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",507,76800.0,0.0,153600.0,0,0.0,153600.0,153600.0,13200.0,83208.0,0.13691809808314662,5134848.0,128.0,8.128,16343.872000000016,0.0,0.0,0.0,76800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,4.064,16347.936000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,16351.008000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.728,16356.736000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",511,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,16359.776000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.856,16365.632000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",513,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,53054.0,13014.0,0.8030211297451111,831584.0,8416.0,9.088,16374.720000000016,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,263.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.32,16383.040000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,68512.0,5.888,16388.928000000014,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.032,16392.960000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",517,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.064,16397.024000000012,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.24,16403.264000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",519,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.648,16406.912000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28374.0,0.698882509630793,2739136.0,1991168.0,15.168,16422.080000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85598.0,62224.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",521,0.0,0.0,0.0,0,0.0,0.0,0.0,17018.0,28311.0,0.37543294579628933,2729024.0,1959968.0,12.096,16434.176000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85282.0,61249.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28258.0,0.35141958732126055,2719552.0,2246336.0,12.768,16446.944000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84986.0,70198.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28224.0,0.35169403927874127,2744256.0,2246848.0,12.768,16459.712000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85758.0,70214.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.8,16464.512000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.68,16468.192000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15130.0,0.49504388746120215,1865632.0,1337344.0,9.632,16477.82400000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58301.0,41792.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429408.0,2412352.0,5.216,16483.04000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75919.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",528,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1035968.0,754112.0,31.84,16514.88000000002,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32374.0,23566.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",529,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804256.0,616160.0,98.528,16613.408000000018,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,19255.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.808,16617.21600000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.976,16620.192000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,92320.0,11.552,16631.744000000017,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2885.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.384,16636.128000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",534,3122058.0,6655044.0,615332.0,0,0.0,7270376.0,7270376.0,528.0,6704.0,0.07300884955752213,1084736.0,752704.0,31.584,16667.712000000014,825232.0,201028.0,2814392.0,307666.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33898.0,23522.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",535,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.184,16676.896000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,16680.288000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",537,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.216,16689.504000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,16692.992000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,16696.448000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",540,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,16700.992000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",541,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.776,16716.76800000002,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,16720.160000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.12,16725.280000000017,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,16728.672000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",545,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,16733.280000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",546,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,16739.296000000017,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",547,1256418.0,2010280.0,502556.0,0,0.0,2512836.0,2512836.0,0.0,4737.0,0.0,1608256.0,0.0,5.44,16744.736000000015,0.0,0.0,1005140.0,251278.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",548,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.72,16767.456000000017,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",549,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,16770.880000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,16774.208000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.904,16778.112000000016,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",552,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,16781.376000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",553,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.968,16785.344000000016,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,16788.128000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",555,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,16790.912000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,16794.304000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",557,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,16797.120000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.0,16801.120000000014,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",559,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.392,16808.512000000013,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,16811.776000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,16815.104000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",562,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.128,16819.232000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",563,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.768,16824.000000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",564,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,16827.520000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
