Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,2.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,5.824,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,8.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,12.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.808,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.808,19.616,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.416,24.032,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.928,28.96,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,32.704,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,35.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,38.176,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,41.312000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.776,45.08800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,48.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.968,52.41600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.288,56.70400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,59.93600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,63.55200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,67.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,2176.0,8192.0,5.504,72.54400000000001,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68.0,256.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,2176.0,8192.0,5.568,78.11200000000001,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,81.44000000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,84.99200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.992,89.98400000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.6,95.58400000000002,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,14.912,110.49600000000002,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,5.056,115.55200000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.416,119.96800000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.352,124.32000000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.96,137.28000000000003,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.472,150.75200000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.84,154.59200000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,160.12800000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.984,174.11200000000005,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.52,177.63200000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.296,180.92800000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,184.16000000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,187.68000000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,191.13600000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,50336.0,123200.0,4096.0,0,0.0,127296.0,127296.0,0.0,128.0,0.0,32768.0,32768.0,3.68,194.81600000000006,8192.0,18432.0,48288.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.136,197.95200000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.392,201.34400000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),43,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.736,214.08000000000004,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",44,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.12,219.20000000000005,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,222.40000000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",46,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.696,228.09600000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.888,241.98400000000004,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.448,246.43200000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.256,250.68800000000005,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.512,255.20000000000005,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",51,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.256,267.456,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",52,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.024,280.48,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",53,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,283.68,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",54,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.6,289.28000000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.76,303.04,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",56,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,306.432,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",57,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.232,309.66400000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.488,313.15200000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,316.576,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,319.80800000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,50256.0,123040.0,4096.0,0,0.0,127136.0,127136.0,0.0,128.0,0.0,32768.0,32768.0,3.456,323.26400000000007,8192.0,18432.0,48208.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.392,326.65600000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",63,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.584,330.24000000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),64,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.512,342.75200000000007,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",65,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,4.864,347.61600000000004,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",66,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,351.07200000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",67,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.568,356.64000000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.696,370.33600000000007,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.256,374.5920000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.576,379.1680000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.672,383.84000000000015,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",72,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.544,396.3840000000001,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",73,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.12,409.50400000000013,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,412.86400000000015,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",75,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.568,418.43200000000013,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",76,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.696,432.12800000000016,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",77,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.2,435.32800000000015,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",78,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.392,438.72000000000014,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,442.1440000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",80,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,445.37600000000015,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,448.54400000000015,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,50260.0,123048.0,4096.0,0,0.0,127144.0,127144.0,0.0,128.0,0.0,32768.0,32768.0,3.744,452.2880000000002,8192.0,18432.0,48212.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",83,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.328,455.61600000000016,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.456,459.0720000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),85,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.448,471.52000000000015,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",86,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.024,476.54400000000015,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,479.8720000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",88,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.44,485.3120000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.952,499.2640000000001,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.64,503.9040000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.448,508.3520000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",92,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.224,512.5760000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",93,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.32,524.8960000000002,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.248,538.1440000000002,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",95,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,541.5360000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",96,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.44,546.9760000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",97,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,14.08,561.0560000000004,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",98,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.488,564.5440000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",99,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.52,568.0640000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",100,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,571.2960000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",101,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,574.5280000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.488,578.0160000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",103,50256.0,123040.0,4096.0,0,0.0,127136.0,127136.0,0.0,128.0,0.0,32768.0,32768.0,3.584,581.6000000000004,8192.0,18432.0,48208.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",104,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.232,584.8320000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",105,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.456,588.2880000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),106,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.576,600.8640000000004,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",107,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,4.992,605.8560000000003,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,609.0880000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",109,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.728,614.8160000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",110,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.76,628.5760000000002,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.576,633.1520000000003,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.256,637.4080000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.32,641.7280000000003,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",114,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.288,654.0160000000003,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.344,667.3600000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,670.7840000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.472,676.2560000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,14.048,690.3040000000003,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",119,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,693.6640000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",120,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.296,696.9600000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",121,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,700.3520000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,703.8400000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,707.2640000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,50376.0,123280.0,4096.0,0,0.0,127376.0,127376.0,0.0,128.0,0.0,32768.0,32768.0,3.456,710.7200000000005,8192.0,18432.0,48328.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",125,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.36,714.0800000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.456,717.5360000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),127,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.768,730.3040000000005,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",128,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.216,735.5200000000006,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.168,738.6880000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",130,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,744.2240000000005,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",131,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.536,757.7600000000004,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.64,762.4000000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.576,766.9760000000005,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.704,771.6800000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",135,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.416,784.0960000000005,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.376,797.4720000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.168,800.6400000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",138,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.76,806.4000000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.536,819.9360000000004,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",140,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,823.2960000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",141,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.264,826.5600000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",142,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,829.8880000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,833.2800000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",144,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,836.6400000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",145,50332.0,123192.0,4096.0,0,0.0,127288.0,127288.0,0.0,128.0,0.0,32768.0,32768.0,3.616,840.2560000000004,8192.0,18432.0,48284.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.328,843.5840000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",147,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.552,847.1360000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),148,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.416,859.5520000000005,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",149,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,4.928,864.4800000000005,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,867.8720000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",151,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.664,873.5360000000005,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.536,887.0720000000005,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",153,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.352,891.4240000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.512,895.9360000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.704,900.6400000000003,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",156,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.448,913.0880000000003,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.344,926.4320000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,929.7920000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",159,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.376,935.1680000000003,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.856,949.0240000000003,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,952.3520000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",162,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.36,955.7120000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",163,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,959.1680000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,962.5600000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",165,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,965.7920000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,50340.0,123208.0,4096.0,0,0.0,127304.0,127304.0,0.0,128.0,0.0,32768.0,32768.0,3.776,969.5680000000003,8192.0,18432.0,48292.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",167,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.552,973.1200000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",168,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,976.6400000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),169,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.416,989.0560000000004,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,4.864,993.9200000000004,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,997.3760000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.408,1002.7840000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.664,1016.4480000000004,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.832,1021.2800000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.704,1025.9840000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.288,1030.2720000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",177,65536.0,2177024.0,0.0,0,19327352832.0,2177024.0,19329529856.0,17024.0,32.0,0.99812382739212,24576.0,8192.0,12.224,1042.4960000000003,1646592.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,768.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.44,1055.9360000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,1059.2320000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",180,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.28,1064.5120000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,14.176,1078.6880000000003,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",182,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,1082.1440000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",183,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.488,1085.6320000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",184,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.456,1089.0880000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,1092.2880000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",186,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.712,1096.0000000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,50356.0,123240.0,4096.0,0,0.0,127336.0,127336.0,0.0,128.0,0.0,32768.0,32768.0,3.616,1099.6160000000002,8192.0,18432.0,48308.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.2,1102.8160000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.328,1106.1440000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),190,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.704,1118.8480000000002,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.056,1123.9040000000002,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1127.2640000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.312,1132.576,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,106142896.0,228369600.0,6433120.0,0,0.0,234802720.0,234802720.0,1733916.0,1306756.0,0.5702410519779838,104701568.0,1376096.0,51.36,1183.936,9649344.0,12867584.0,102926336.0,3216560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3271924.0,43003.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",195,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,1186.944,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.064,1191.008,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,1194.112,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",198,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.84,1197.952,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,1200.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54016.0,6.112,1207.0400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1688.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",201,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.32,1215.3600000000001,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",202,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54784.0,5.856,1221.2160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1712.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",203,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,0.0,8.16,1229.3760000000002,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",204,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54144.0,5.824,1235.2000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1692.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",205,76800.0,0.0,153600.0,0,0.0,153600.0,153600.0,13200.0,83208.0,0.13691809808314662,5134848.0,0.0,8.288,1243.4880000000003,0.0,0.0,0.0,76800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",206,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54272.0,6.048,1249.5360000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1696.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",207,57600.0,0.0,115200.0,0,0.0,115200.0,115200.0,13200.0,83808.0,0.13607125185551708,5134848.0,128.0,8.352,1257.8880000000004,0.0,0.0,0.0,57600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.968,1261.8560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,1264.8960000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.888,1270.7840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,1273.8560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.76,1279.6160000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",213,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,49692.0,13020.0,0.7923842326827402,831584.0,9568.0,9.152,1288.7680000000003,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,299.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,9.056,1297.8240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,72096.0,6.048,1303.8720000000003,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2253.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.512,1308.3840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",217,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.064,1312.4480000000003,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.208,1318.6560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.552,1322.2080000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,64754.0,28566.0,0.6938919845692242,2752320.0,1996288.0,14.976,1337.1840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86010.0,62384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,19826.0,28208.0,0.41274930257734105,2719040.0,1781760.0,12.224,1349.4080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84970.0,55680.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28247.0,0.3515083337159649,2732608.0,2450944.0,13.44,1362.8480000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85394.0,76592.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28190.0,0.3519689202547068,2721472.0,1897536.0,13.312,1376.1600000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85046.0,59298.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.992,1381.1520000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.328,1384.4800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15170.0,0.49438389494383894,1867936.0,1333792.0,9.6,1394.0800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58373.0,41681.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2430592.0,2412352.0,5.28,1399.3600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75956.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",228,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1058080.0,753472.0,31.616,1430.976,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33065.0,23546.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",229,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804352.0,614080.0,98.432,1529.4080000000001,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25136.0,19190.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.68,1533.0880000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,1536.16,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,92448.0,11.744,1547.904,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2889.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.672,1552.576,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",234,3122048.0,6655044.0,615312.0,0,0.0,7270356.0,7270356.0,528.0,6704.0,0.07300884955752213,1082176.0,753920.0,32.128,1584.704,825232.0,201028.0,2814392.0,307656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33818.0,23560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",235,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,10.016,1594.72,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,1598.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",237,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.824,1608.2240000000002,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1611.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.552,1615.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,1619.712,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",241,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.0,1635.712,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,1639.2,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",243,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.184,1644.384,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.904,1648.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,1652.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",246,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.952,1658.72,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",247,1256408.0,2010280.0,502536.0,0,0.0,2512816.0,2512816.0,0.0,4737.0,0.0,1608256.0,0.0,5.504,1664.224,0.0,0.0,1005140.0,251268.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",248,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804384.0,128.0,22.656,1686.8799999999999,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25137.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,1690.368,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1693.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.904,1697.504,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,1700.9279999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",253,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.968,1704.896,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,1707.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1710.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,1713.856,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1716.608,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.84,1720.4479999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.36,1727.8079999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,1731.1999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1734.4959999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.936,1738.4319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.248,1743.6799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,1746.8159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1750.2079999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",266,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.216,1755.4239999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",267,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.0,1759.4239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.232,1762.6559999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.392,1766.0479999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.392,1769.4399999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.84,1773.2799999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",272,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,6272.0,8192.0,5.92,1779.1999999999998,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196.0,256.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",273,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,2176.0,8192.0,5.536,1784.7359999999999,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1788.0959999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,1791.3599999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",276,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.672,1796.0319999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",277,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.472,1801.5039999999997,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",278,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.536,1815.0399999999997,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.664,1820.7039999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.536,1826.2399999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.512,1830.7519999999997,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",282,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.608,1843.3599999999997,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",283,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.248,1856.6079999999997,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",284,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1859.9679999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,1865.5039999999997,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.984,1879.4879999999996,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",287,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,1882.8479999999995,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",288,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.456,1886.3039999999994,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",289,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,1889.7279999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1893.1199999999994,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,1896.3519999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",292,50375.0,123278.0,4096.0,0,0.0,127374.0,127374.0,0.0,128.0,0.0,32768.0,32768.0,3.52,1899.8719999999994,8192.0,18432.0,48327.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",293,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.328,1903.1999999999994,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",294,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.424,1906.6239999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),295,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.544,1919.1679999999994,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",296,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.152,1924.3199999999995,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,1927.7759999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",298,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,1933.3119999999994,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",299,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.376,1946.6879999999994,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",300,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,1952.0959999999993,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",301,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,1957.5679999999993,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.64,1962.2079999999994,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",303,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.352,1974.5599999999995,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",304,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,12.928,1987.4879999999996,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",305,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,1990.8799999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",306,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,1996.4159999999997,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",307,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.44,2009.8559999999998,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,2013.0879999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",309,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2016.4799999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",310,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,2019.7759999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",311,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,2023.1359999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,2026.3679999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",313,50394.0,123316.0,4096.0,0,0.0,127412.0,127412.0,0.0,128.0,0.0,32768.0,32768.0,3.584,2029.9519999999998,8192.0,18432.0,48346.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",314,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2033.3439999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",315,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.328,2036.6719999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),316,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.416,2049.0879999999997,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",317,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,4.864,2053.9519999999998,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",318,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,2057.3759999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",319,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.472,2062.848,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",320,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.696,2076.544,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",321,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.344,2081.888,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,2087.456,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.384,2091.84,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",324,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.768,2104.608,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",325,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.376,2117.9840000000004,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",326,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,2121.2160000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",327,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,2126.7520000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",328,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.728,2140.4800000000005,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,2143.8080000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",330,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2147.2320000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,2150.4640000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",332,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.168,2153.6320000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",333,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2157.0240000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,50274.0,123076.0,4096.0,0,0.0,127172.0,127172.0,0.0,128.0,0.0,32768.0,32768.0,3.68,2160.704,8192.0,18432.0,48226.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",335,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.456,2164.1600000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",336,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.424,2167.5840000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),337,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.512,2180.0960000000005,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",338,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.056,2185.1520000000005,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",339,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2188.4480000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",340,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.408,2193.856,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",341,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.632,2207.4880000000003,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,2212.9600000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",343,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.632,2218.5920000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",344,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.288,2222.8800000000006,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",345,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.384,2235.2640000000006,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",346,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.472,2248.736000000001,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,2252.096000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.312,2257.408000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.632,2271.040000000001,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2274.400000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2277.792000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2281.1840000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,2284.544000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2287.9360000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,50349.0,123226.0,4096.0,0,0.0,127322.0,127322.0,0.0,128.0,0.0,32768.0,32768.0,3.456,2291.3920000000007,8192.0,18432.0,48301.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.168,2294.560000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2298.0480000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),358,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.384,2310.4320000000007,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.056,2315.4880000000007,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,2318.7200000000007,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.6,2324.3200000000006,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.728,2338.0480000000007,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",363,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,2343.5520000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,2348.9600000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.544,2353.5040000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",366,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.576,2366.0800000000004,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",367,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.376,2379.4560000000006,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",368,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,2382.8480000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",369,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,2388.3840000000005,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",370,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,14.144,2402.5280000000002,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",371,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2405.952,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",372,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2409.376,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,2412.704,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",374,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,2416.032,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2419.3920000000003,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,50330.0,123188.0,4096.0,0,0.0,127284.0,127284.0,0.0,128.0,0.0,32768.0,32768.0,3.52,2422.9120000000003,8192.0,18432.0,48282.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",377,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2426.2720000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",378,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.584,2429.856,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),379,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.48,2442.3360000000002,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.248,2447.5840000000003,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2450.88,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.504,2456.384,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.632,2470.016,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",384,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.536,2475.552,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",385,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,2480.992,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.544,2485.536,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",387,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.224,2497.76,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",388,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.216,2510.976,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",389,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,2514.4,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",390,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.6,2520.0,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.376,2533.376,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",392,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.232,2536.608,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",393,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2540.032,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.392,2543.424,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,2546.88,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.328,2550.208,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,50322.0,123172.0,4096.0,0,0.0,127268.0,127268.0,0.0,128.0,0.0,32768.0,32768.0,3.552,2553.76,8192.0,18432.0,48274.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.296,2557.056,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",399,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.424,2560.48,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),400,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.672,2573.152,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",401,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.088,2578.2400000000002,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,2581.568,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.376,2586.9440000000004,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.504,2600.4480000000003,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,2605.9200000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,2611.3920000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.416,2615.808000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",408,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.672,2628.480000000001,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.376,2641.856000000001,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,2645.184000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",411,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.504,2650.688000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.6,2664.288000000001,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,2667.5840000000007,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",414,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.456,2671.040000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",415,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,2674.208000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,2677.536000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",417,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.424,2680.960000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,50349.0,123226.0,4096.0,0,0.0,127322.0,127322.0,0.0,128.0,0.0,32768.0,32768.0,3.744,2684.704000000001,8192.0,18432.0,48301.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",419,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.264,2687.968000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.296,2691.264000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),421,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.416,2703.680000000001,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",422,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.12,2708.800000000001,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",423,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,2712.000000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",424,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.632,2717.632000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",425,3164160.0,6389760.0,36864.0,0,0.0,6426624.0,6426624.0,28608.0,26496.0,0.519163763066202,3348480.0,24576.0,13.856,2731.488000000001,49152.0,49152.0,3145728.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,104640.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",426,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,2736.8640000000014,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",427,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,2742.4320000000016,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,128.0,0.0,8192.0,8192.0,4.352,2746.7840000000015,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",429,65536.0,2179072.0,0.0,0,19327352832.0,2179072.0,19329531904.0,17024.0,32.0,0.99812382739212,40960.0,8192.0,12.736,2759.5200000000013,1648640.0,399360.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,75497472.0,1280.0,256.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,1054720.0,2129920.0,12288.0,0,0.0,2142208.0,2142208.0,9536.0,8832.0,0.519163763066202,1116160.0,8192.0,13.504,2773.0240000000013,16384.0,16384.0,1048576.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,2776.4480000000012,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",432,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.312,2781.760000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",433,4218880.0,8519680.0,49152.0,0,0.0,8568832.0,8568832.0,38144.0,35328.0,0.519163763066202,4464640.0,32768.0,13.952,2795.7120000000014,65536.0,65536.0,4194304.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139520.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.36,2799.0720000000015,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",435,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.584,2802.6560000000013,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",436,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.168,2805.8240000000014,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",437,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,2809.2480000000014,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",438,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,3.296,2812.5440000000012,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,50402.0,123332.0,4096.0,0,0.0,127428.0,127428.0,0.0,128.0,0.0,32768.0,32768.0,3.648,2816.1920000000014,8192.0,18432.0,48354.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",440,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,128.0,0.0,32768.0,32768.0,3.2,2819.392000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",441,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.424,2822.816000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),442,67108864.0,134578176.0,0.0,0,0.0,134578176.0,134578176.0,220192.0,704.0,0.9968129798638273,4456448.0,90112.0,12.576,2835.392000000001,0.0,360448.0,67108864.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,139264.0,2816.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,10240.0,26624.0,20480.0,0,0.0,47104.0,47104.0,0.0,1152.0,0.0,92160.0,8192.0,5.152,2840.5440000000012,24576.0,2048.0,0.0,10240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2880.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,2843.744000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,25156.0,77044.0,9216.0,0,0.0,86260.0,86260.0,80.0,184.0,0.30303030303030304,24576.0,8448.0,5.536,2849.280000000001,21040.0,14908.0,20548.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,264.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,106142896.0,228369600.0,6433120.0,0,0.0,234802720.0,234802720.0,1733916.0,1306756.0,0.5702410519779838,104641792.0,1378240.0,50.752,2900.032000000001,9649344.0,12867584.0,102926336.0,3216560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3270056.0,43070.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",447,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2902.880000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,2906.752000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",449,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2910.080000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.744,2913.824000000001,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2916.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",452,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55232.0,5.92,2922.592000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1726.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",453,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.0,2930.592000000001,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",454,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55168.0,6.08,2936.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1724.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",455,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,13200.0,82408.0,0.13806376035478202,5134848.0,0.0,8.48,2945.152000000001,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",456,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54848.0,5.888,2951.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1714.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",457,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,0.0,8.384,2959.424000000001,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",458,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,5.92,2965.344000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",459,80000.0,0.0,160000.0,0,0.0,160000.0,160000.0,13200.0,83108.0,0.13706026498317897,5134848.0,128.0,8.416,2973.760000000001,0.0,0.0,0.0,80000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.808,2977.568000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",461,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,2980.576000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",462,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.472,2986.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,2988.896000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",464,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.952,2994.8480000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",465,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,42148.0,13014.0,0.764076719480802,831584.0,8288.0,9.184,3004.0320000000015,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,259.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",466,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.608,3012.6400000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816576.0,68768.0,6.208,3018.848000000002,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25518.0,2149.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",468,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.288,3023.136000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",469,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.0,3027.136000000002,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.208,3033.344000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",471,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,3036.768000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28327.0,0.6992312756152981,2733248.0,2005952.0,15.04,3051.808000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85414.0,62686.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",473,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28314.0,0.33416423666635314,2732992.0,2451264.0,11.68,3063.4880000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85406.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28208.0,0.35182334152898737,2720704.0,2451136.0,12.96,3076.4480000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85022.0,76598.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",475,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28216.0,0.35175867852137754,2734784.0,1899872.0,13.504,3089.9520000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85462.0,59371.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.864,3094.8160000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,3098.3040000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15189.0,0.4940710145893012,1864352.0,1340032.0,9.408,3107.7120000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58261.0,41876.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428480.0,2412352.0,5.248,3112.9600000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75890.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",480,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1057440.0,752576.0,31.936,3144.8960000000015,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33045.0,23518.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",481,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804320.0,619936.0,97.568,3242.4640000000018,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25135.0,19373.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.712,3246.1760000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.008,3249.1840000000016,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,88768.0,11.744,3260.9280000000017,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2774.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",485,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.448,3265.3760000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",486,3122050.0,6655044.0,615316.0,0,0.0,7270360.0,7270360.0,528.0,6704.0,0.07300884955752213,1082176.0,753088.0,32.096,3297.4720000000016,825232.0,201028.0,2814392.0,307658.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33818.0,23534.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",487,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.856,3307.328000000002,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,3310.7200000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",489,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.408,3320.1280000000015,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,3323.6800000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,3327.136000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,3331.552000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",493,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.32,3347.872000000002,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3351.2320000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",495,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.184,3356.4160000000024,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3359.7760000000026,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,3364.1600000000026,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",498,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,3370.1760000000027,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",499,1256410.0,2010280.0,502540.0,0,0.0,2512820.0,2512820.0,0.0,4737.0,0.0,1608256.0,0.0,5.632,3375.8080000000027,0.0,0.0,1005140.0,251270.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",500,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.56,3398.3680000000027,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,3401.632000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3405.088000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,3408.9600000000028,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,3412.224000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,3416.064000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,3418.848000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,3421.6320000000032,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,3425.2480000000032,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,3428.000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.256,3432.256000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.944,3439.200000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,3442.688000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3446.144000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.904,3450.048000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",515,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.896,3454.944000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3458.176000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
