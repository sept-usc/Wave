Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002816,0.002816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002592,0.005408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003904,0.009311999999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004448,0.013759999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.004736,0.018496,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,0.022015999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002688,0.024703999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002784,0.027488,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003072,0.030559999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003744,0.034303999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,0.037599999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003616,0.041215999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.004096,0.045312,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,0.048479999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003424,0.05190399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,0.003456,0.05535999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,0.005824,0.061183999999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003456,0.06463999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005344,0.06998399999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003584,0.073568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003424,0.07699199999999999,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.004608,0.08159999999999999,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004352,0.08595199999999999,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003584,0.08953599999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,0.004448,0.09398399999999998,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003456,0.09743999999999998,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,0.10102399999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008288,0.10931199999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003136,0.11244799999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.00336,0.115808,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,0.12038399999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004576,0.12495999999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75822848.0,83968.0,0.037088,0.162048,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369464.0,2624.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75821056.0,86400.0,0.034976,0.197024,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369408.0,2700.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75834368.0,84032.0,0.035264,0.232288,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369824.0,2626.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00448,0.236768,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004608,0.241376,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006272,0.247648,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,0.252224,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,0.255712,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,0.260544,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004576,0.26512,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006208,0.271328,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,0.276096,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003264,0.27936,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.016,0.29536,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75774336.0,96224.0,0.037568,0.332928,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367948.0,3007.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,0.336384,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003232,0.33961600000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,0.34816,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,0.351424,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,0.354656,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,0.3592,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004768,0.363968,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400203264.0,506016.0,0.171936,0.535904,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12506352.0,15813.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.004064,0.539968,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400643968.0,506816.0,0.174592,0.71456,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12520124.0,15838.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003648,0.718208,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407717504.0,93760.0,0.16096,0.879168,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12741172.0,2930.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,0.8826879999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,0.8860799999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,0.8946239999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,0.8978239999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,0.9009599999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004704,0.9056639999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004672,0.9103359999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75808768.0,85600.0,0.035424,0.9457599999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369024.0,2675.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75820800.0,84256.0,0.035648,0.981408,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369400.0,2633.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75800576.0,82784.0,0.03824,1.0196479999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368768.0,2587.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,1.024192,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,1.028448,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,1.034368,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,1.0389439999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,1.042368,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,1.04704,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,1.05136,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005888,1.057248,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,1.061792,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,1.065152,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015968,1.08112,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75795328.0,93216.0,0.038304,1.119424,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368604.0,2913.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,1.122784,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00352,1.126304,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00816,1.134464,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,1.137568,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,1.1408319999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,1.1453119999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,1.149792,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399192320.0,501504.0,0.173408,1.3232,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12474760.0,15672.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003808,1.327008,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399658112.0,500960.0,0.173184,1.500192,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12489316.0,15655.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003648,1.50384,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407614848.0,96192.0,0.163744,1.6675840000000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12737964.0,3006.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,1.6708800000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00336,1.6742400000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008,1.6822400000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00336,1.6856000000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,1.6888960000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004384,1.6932800000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004384,1.697664,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75807232.0,83040.0,0.03712,1.734784,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368976.0,2595.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75788416.0,85760.0,0.036736,1.7715200000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368388.0,2680.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75804160.0,84448.0,0.035456,1.8069760000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368880.0,2639.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004416,1.8113920000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004352,1.815744,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006272,1.822016,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,1.8267840000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,1.8302720000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,1.835104,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,1.839584,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006048,1.8456320000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,1.8501760000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,1.8536000000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015936,1.8695360000000003,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75778176.0,96768.0,0.036032,1.9055680000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368068.0,3024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,1.9090240000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,1.9124160000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008512,1.9209280000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,1.9241280000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,1.9272640000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,1.9318080000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,1.9362240000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400895360.0,497632.0,0.172288,2.1085120000000006,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12527980.0,15551.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003776,2.1122880000000004,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400444160.0,501632.0,0.176576,2.2888640000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12513880.0,15676.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003712,2.2925760000000004,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407620736.0,98240.0,0.164512,2.4570880000000006,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12738148.0,3070.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003264,2.4603520000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,2.463616000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008608,2.472224000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,2.475456000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,2.4786240000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,2.4831680000000014,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,2.4876480000000014,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75847552.0,85056.0,0.036512,2.5241600000000015,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370236.0,2658.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75850752.0,83392.0,0.03648,2.5606400000000016,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370336.0,2606.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75838464.0,83616.0,0.036832,2.5974720000000016,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369952.0,2613.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,2.6021440000000013,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,2.606432000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006048,2.612480000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00448,2.616960000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,2.6202560000000013,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,2.6248000000000014,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,2.6292800000000014,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,2.6352320000000016,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,2.6398400000000017,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,2.6433280000000017,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015904,2.6592320000000016,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75772800.0,95200.0,0.036992,2.6962240000000017,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367900.0,2975.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003648,2.699872000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,2.703136000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008128,2.711264000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003136,2.714400000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,2.7176960000000023,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,2.7223360000000025,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.0048,2.7271360000000024,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399104256.0,506304.0,0.175264,2.9024000000000023,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12472008.0,15822.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003808,2.906208000000002,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399654400.0,502784.0,0.17136,3.077568000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12489200.0,15712.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003552,3.081120000000002,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407609728.0,94720.0,0.167808,3.248928000000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12737804.0,2960.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,3.252384000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00352,3.255904000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008064,3.263968000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,3.267072000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,3.270304000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,3.274816000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004512,3.2793280000000022,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75807616.0,83808.0,0.036832,3.316160000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368988.0,2619.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75810688.0,84448.0,0.03648,3.3526400000000023,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369084.0,2639.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75818240.0,85504.0,0.037472,3.3901120000000025,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369320.0,2672.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,3.3946880000000026,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,3.3991040000000026,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005376,3.4044800000000026,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,3.4090560000000028,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,3.4124160000000026,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,3.4171840000000024,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,3.4216640000000025,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005664,3.4273280000000024,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,3.4320640000000022,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,3.435488000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.016064,3.451552000000002,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75780224.0,91744.0,0.039136,3.4906880000000022,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368132.0,2867.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,3.4939840000000024,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,3.4973760000000023,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008608,3.5059840000000024,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,3.5092160000000026,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,3.5124480000000027,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,3.5169280000000027,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00432,3.5212480000000026,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399889152.0,502496.0,0.1744,3.6956480000000025,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12496536.0,15703.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003808,3.6994560000000023,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400628480.0,502144.0,0.173344,3.8728000000000025,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12519640.0,15692.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003552,3.8763520000000025,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407652480.0,97664.0,0.162176,4.038528000000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12739140.0,3052.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003744,4.042272000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003168,4.045440000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008416,4.053856000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003392,4.057248000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,4.060384000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004832,4.065216000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,4.069760000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75844736.0,85280.0,0.037376,4.107136000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370148.0,2665.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75834240.0,83936.0,0.036352,4.143488000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369820.0,2623.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75809920.0,82688.0,0.03648,4.179968000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369060.0,2584.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,4.1845760000000025,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,4.1890560000000026,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005376,4.194432000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004448,4.198880000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,4.2023360000000025,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004448,4.2067840000000025,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,4.211104000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005472,4.2165760000000025,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,4.221088000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,4.2244800000000025,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015808,4.240288000000002,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75791872.0,94240.0,0.035232,4.275520000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368496.0,2945.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003584,4.279104000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003328,4.282432000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008,4.290432000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00304,4.293472000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,4.296640000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004672,4.301312000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004384,4.305696000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399052672.0,501248.0,0.174656,4.480352000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12470396.0,15664.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003808,4.484160000000002,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400133248.0,507072.0,0.171168,4.655328000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12504164.0,15846.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003584,4.658912000000002,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407756288.0,95680.0,0.159808,4.818720000000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12742384.0,2990.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,4.822240000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,4.8256960000000015,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008192,4.833888000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,4.8371520000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003424,4.840576000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004416,4.844992000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004576,4.849568000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75792640.0,84352.0,0.036,4.885568000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368520.0,2636.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75818880.0,83872.0,0.037344,4.922912000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369340.0,2621.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75819904.0,82656.0,0.037408,4.960320000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369372.0,2583.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,4.964864000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,4.969280000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006176,4.975456000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,4.980032000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,4.983552000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00448,4.988032000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,4.992416000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00624,4.998656000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,5.0032640000000015,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,5.0067840000000015,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.016096,5.022880000000002,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75788800.0,96224.0,0.035776,5.058656000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368400.0,3007.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,5.062112000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,5.065504000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,5.073952000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003424,5.077376000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,5.080608000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,5.085120000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,5.089664000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399883520.0,503008.0,0.171776,5.261440000000001,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12496360.0,15719.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.004,5.265440000000001,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399553024.0,505248.0,0.174208,5.439648000000001,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12486032.0,15789.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003616,5.443264000000001,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407652608.0,95840.0,0.159616,5.602880000000001,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12739144.0,2995.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,5.606304000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,5.609568,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,5.618144,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00336,5.621504,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,5.624639999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,5.6291519999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,5.6336319999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75829248.0,84480.0,0.036128,5.669759999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369664.0,2640.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75807616.0,82656.0,0.037664,5.707424,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368988.0,2583.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75841664.0,86048.0,0.03632,5.7437439999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370052.0,2689.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,5.748416,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,5.7528,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006048,5.7588479999999995,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00448,5.763328,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003648,5.766976,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,5.771712,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,5.776032,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006112,5.782144,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,5.78672,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,5.790208,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.016032,5.80624,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75778944.0,92928.0,0.037888,5.8441279999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368092.0,2904.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,5.847423999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00336,5.850783999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008288,5.859071999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,5.862303999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,5.865535999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004768,5.870303999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,5.874719999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400287360.0,505472.0,0.1712,6.045919999999999,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12508980.0,15796.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003744,6.049663999999999,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400964736.0,501824.0,0.169248,6.218911999999999,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12530148.0,15682.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003456,6.222367999999999,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407907456.0,94144.0,0.164768,6.387135999999998,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12747108.0,2942.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,6.390495999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,6.394079999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007808,6.401887999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003008,6.404895999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,6.408063999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,6.412607999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004608,6.417215999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,2740993536.0,3479232.0,1.034848,7.452063999999998,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85656048.0,108726.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002848,7.454911999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.004416,7.459327999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,7.462559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004672,7.467231999999998,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002976,7.470207999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172160.0,0.006368,7.476575999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5380.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38126464.0,0.0,0.015296,7.491871999999999,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191452.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173952.0,0.006368,7.498239999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5436.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38133920.0,32.0,0.01472,7.512959999999999,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191685.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171328.0,0.006208,7.519167999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5354.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38103456.0,32.0,0.014912,7.5340799999999986,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190733.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172160.0,0.006176,7.5402559999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5380.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38134848.0,128.0,0.014784,7.555039999999998,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191714.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.0048,7.559839999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003136,7.562975999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006048,7.569023999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002944,7.571967999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006048,7.578015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,165476.0,38400.0,0.811650218760423,2488288.0,11456.0,0.009664,7.587679999999998,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,358.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.008896,7.596575999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,196384.0,0.0064,7.602975999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6137.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005568,7.608543999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005568,7.614111999999999,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.007136,7.621247999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.003456,7.624703999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,174606.0,84393.0,0.6741570430773864,8859776.0,6018624.0,0.018112,7.642815999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276868.0,188082.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91224.0,0.30387802756284055,8883840.0,7409664.0,0.014208,7.657023999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277620.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91298.0,0.3085161173048958,8904448.0,5726944.0,0.014656,7.6716799999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,278264.0,178967.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,91515.0,0.30058466124039895,8877184.0,7409664.0,0.014912,7.686591999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277412.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.006208,7.692799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.00352,7.696319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51408.0,0.4289649656765823,6148352.0,4009248.0,0.01216,7.708479999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192136.0,125289.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7330080.0,7292928.0,0.008416,7.716895999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229065.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086752,7.803647999999998,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.285184,8.088831999999998,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,0.004288,8.093119999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003296,8.096416,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,281984.0,0.012096,8.108512,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8812.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005216,8.113728,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424712.0,20076672.0,1832592.0,0,0.0,21909264.0,21909264.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086784,8.200512,2452096.0,607744.0,8508416.0,916296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009504,8.210016,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003328,8.213344,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009696,8.22304,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003424,8.226464,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003424,8.229888,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004768,8.234656000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009664,8.244320000000002,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003392,8.247712000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005088,8.252800000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,8.256096000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004576,8.260672000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.007232,8.267904000000003,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798344.0,6077440.0,1519248.0,0,0.0,7596688.0,7596688.0,0.0,14280.0,0.0,4861952.0,2560.0,0.006944,8.274848000000004,0.0,0.0,3038720.0,759624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,80.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,0.013248,8.288096000000005,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.00448,8.292576000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002656,8.295232000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002848,8.298080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003648,8.301728000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,8.305248000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003936,8.309184000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004736,8.313920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,8.317216000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,8.320736000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,0.004544,8.325280000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.004224,8.329504000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.003296,8.332800000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.003264,8.336064000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,0.003296,8.339360000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.00384,8.343200000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,50176.0,65536.0,0.007232,8.350432000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1568.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.003264,8.353696000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.005024,8.358720000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003648,8.362368000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003584,8.365952000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.00416,8.370112000000006,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004512,8.374624000000006,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003328,8.377952000000006,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,0.004352,8.382304000000007,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003232,8.385536000000007,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003296,8.388832000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,8.397280000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003296,8.400576000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,8.403776000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,8.408320000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004672,8.412992000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75858176.0,82624.0,0.034688,8.447680000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370568.0,2582.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75829760.0,83776.0,0.036064,8.483744000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369680.0,2618.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75825664.0,84704.0,0.035776,8.519520000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369552.0,2647.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,8.524096000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,8.528576000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,8.534528000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004448,8.538976000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,8.542336000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,8.546912000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,8.551296000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005856,8.557152000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,8.561792000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,8.565344000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004544,8.569888000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004512,8.574400000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016032,8.590432000000005,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75800704.0,96544.0,0.03744,8.627872000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368772.0,3017.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,8.631392000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,8.634656000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008768,8.643424000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,8.646688000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003392,8.650080000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,8.654560000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004352,8.658912000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400079872.0,509536.0,0.171264,8.830176000000005,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12502496.0,15923.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.004,8.834176000000005,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,398717696.0,506720.0,0.179488,9.013664000000004,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12459928.0,15835.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003616,9.017280000000003,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407712640.0,94272.0,0.163072,9.180352000000003,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12741020.0,2946.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,9.183712000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003424,9.187136000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,9.195712000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,9.198880000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,9.202112000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.0048,9.206912000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,9.211456000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75799808.0,84864.0,0.036416,9.247872000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368744.0,2652.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75802240.0,83328.0,0.03616,9.284032000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368820.0,2604.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75811072.0,83360.0,0.036992,9.321024000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369096.0,2605.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,9.325568000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,9.329792000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005728,9.335520000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,9.340032000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,9.343456000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,9.348160000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,9.352608000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005856,9.358464000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,9.363072000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,9.366528000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004832,9.371360000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004832,9.376192000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016,9.392192000000003,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75801472.0,97984.0,0.034304,9.426496000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368796.0,3062.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,9.429824000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.0032,9.433024000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,9.441600000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003296,9.444896000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,9.448224000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004672,9.452896000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,9.457376000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400577152.0,503456.0,0.169856,9.627232000000001,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12518036.0,15733.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003712,9.630944000000001,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400732544.0,500512.0,0.171264,9.802208000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12522892.0,15641.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003616,9.805824000000001,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407724288.0,94752.0,0.1632,9.969024000000001,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12741384.0,2961.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,9.972320000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,9.975584000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,9.984128000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.987392000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003488,9.990880000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004416,9.995296000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,9.999776000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75812608.0,84512.0,0.035104,10.034880000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369144.0,2641.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75839488.0,84960.0,0.034624,10.069504000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369984.0,2655.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75837568.0,83904.0,0.034912,10.104416000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369924.0,2622.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,10.109056000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,10.113472000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005728,10.119200000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004448,10.123648000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,10.127072000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004384,10.131456000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,10.135744000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,10.141696000000007,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,10.146400000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,10.149824000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004512,10.154336000000008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004608,10.158944000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016064,10.175008000000007,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75798016.0,95648.0,0.034688,10.209696000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368688.0,2989.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003264,10.212960000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,10.216224000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,64.0,0.00896,10.225184000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,10.228416000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003552,10.231968000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,10.236544000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004384,10.240928000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399895808.0,508608.0,0.1704,10.411328000000008,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12496744.0,15894.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.00368,10.415008000000007,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400114432.0,509152.0,0.171456,10.586464000000007,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12503576.0,15911.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,10.589984000000007,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407668480.0,95328.0,0.161664,10.751648000000007,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12739640.0,2979.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,10.755040000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003232,10.758272000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008416,10.766688000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,10.769856000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,10.772992000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004448,10.777440000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,10.781856000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75810304.0,84576.0,0.03424,10.816096000000009,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369072.0,2643.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75818368.0,84448.0,0.035808,10.851904000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369324.0,2639.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75841664.0,85472.0,0.034656,10.886560000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370052.0,2671.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,10.891168000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,10.895584000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005408,10.900992000000008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00448,10.905472000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,10.908928000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,10.913696000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,10.918016000000007,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005664,10.923680000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,10.928288000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,10.931584000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004512,10.936096000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.00464,10.940736000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016096,10.956832000000006,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793408.0,96032.0,0.034496,10.991328000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368544.0,3001.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,10.994624000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003168,10.997792000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00832,11.006112000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,11.009280000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,11.012416000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004416,11.016832000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004448,11.021280000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399644160.0,508896.0,0.169888,11.191168000000008,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12488880.0,15903.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003872,11.195040000000008,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400043008.0,510880.0,0.174304,11.369344000000007,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12501344.0,15965.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003648,11.372992000000007,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407672320.0,98464.0,0.161504,11.534496000000008,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12739760.0,3077.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,11.537984000000009,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,11.541568000000009,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008512,11.550080000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,11.553344000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,11.556544000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,11.561088000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,11.565504000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75806080.0,84096.0,0.033984,11.599488000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368940.0,2628.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75810560.0,85024.0,0.035136,11.634624000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369080.0,2657.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75809920.0,84512.0,0.034688,11.669312000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369060.0,2641.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,11.673984000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,11.678464000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005888,11.684352000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,11.689152000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,11.692480000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004352,11.696832000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004576,11.701408000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006112,11.707520000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,11.712096000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,11.715584000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004704,11.720288000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004544,11.724832000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.015936,11.740768000000006,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75809152.0,93152.0,0.035104,11.775872000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369036.0,2911.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,11.779296000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003488,11.782784000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,11.791232000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,11.794464000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,11.797632000000009,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004448,11.802080000000009,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004672,11.806752000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400797952.0,503168.0,0.173152,11.979904000000008,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12524936.0,15724.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.00384,11.983744000000009,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400083712.0,506880.0,0.168448,12.152192000000008,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12502616.0,15840.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,12.155712000000008,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407700992.0,97472.0,0.16288,12.318592000000008,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12740656.0,3046.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,12.322112000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.0032,12.325312000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008672,12.333984000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,12.337216000000009,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003104,12.340320000000009,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,12.344800000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004608,12.349408000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75851136.0,81088.0,0.036288,12.385696000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370348.0,2534.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75851264.0,84288.0,0.034432,12.420128000000009,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370352.0,2634.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75804032.0,84544.0,0.035424,12.45555200000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368876.0,2642.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,12.460160000000009,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,12.464640000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005888,12.470528000000009,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,12.475168000000009,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,12.478688000000009,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,12.483264000000009,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,12.487584000000009,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,12.493504000000009,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004384,12.497888000000009,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,12.501344000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004544,12.505888000000008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004768,12.510656000000008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016064,12.526720000000008,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75800448.0,96800.0,0.034912,12.561632000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368764.0,3025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,12.565088000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.0032,12.568288000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,12.576736000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,12.579904000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,12.583040000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,12.587552000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,12.592192000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399606912.0,508928.0,0.17264,12.764832000000007,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12487716.0,15904.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.00384,12.768672000000008,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399239424.0,504928.0,0.17104,12.939712000000007,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12476232.0,15779.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,12.943232000000007,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407712128.0,94944.0,0.162816,13.106048000000007,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12741004.0,2967.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,13.109472000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003616,13.113088000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00896,13.122048000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,13.125280000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,13.128480000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004352,13.132832000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004512,13.137344000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75837440.0,86080.0,0.034336,13.171680000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369920.0,2690.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75818112.0,83936.0,0.03424,13.205920000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369316.0,2623.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75815552.0,84640.0,0.035744,13.241664000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369236.0,2645.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,13.246336000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,13.250656000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,13.256576000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,13.261120000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,13.264576000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,13.269120000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,13.273568000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006016,13.279584000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,13.284224000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,13.287744000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004544,13.292288000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.00464,13.296928000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016032,13.312960000000004,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75799680.0,97024.0,0.035232,13.348192000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368740.0,3032.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,13.351584000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,13.354848000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008384,13.363232000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003328,13.366560000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003392,13.369952000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004416,13.374368000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004352,13.378720000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400550784.0,501472.0,0.170944,13.549664000000005,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12517212.0,15671.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.003744,13.553408000000005,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,400370176.0,501888.0,0.17392,13.727328000000005,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12511568.0,15684.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,13.730848000000005,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407691648.0,94720.0,0.167904,13.898752000000005,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12740364.0,2960.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,13.902112000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003328,13.905440000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00864,13.914080000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,13.917280000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,13.920576000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,13.925152000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,13.929696000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75872000.0,84160.0,0.034464,13.964160000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2371000.0,2630.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75822208.0,83488.0,0.035072,13.999232000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369444.0,2609.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75824512.0,84064.0,0.035328,14.034560000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369516.0,2627.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,14.039136000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,14.043584000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,14.049504000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,14.054176000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,14.057504000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,14.062048000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004672,14.066720000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006016,14.072736000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004384,14.077120000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003264,14.080384000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004864,14.085248000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004736,14.089984000000001,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016096,14.10608,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75831424.0,96768.0,0.035392,14.141472,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369732.0,3024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,14.144960000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003552,14.148512000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008384,14.156896000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003488,14.160384000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003104,14.163488000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004608,14.168096000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,14.172736000000002,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399779840.0,506720.0,0.168384,14.341120000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12493120.0,15835.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,1100800.0,2113536.0,176128.0,0,0.0,2289664.0,2289664.0,0.0,1376.0,0.0,352256.0,352256.0,0.00384,14.344960000000002,88064.0,0.0,1012736.0,88064.0,0,0,0,0,0,0,0,0.0,0.0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,399188608.0,511968.0,0.168704,14.513664000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12474644.0,15999.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003616,14.517280000000001,0.0,88064.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,407727360.0,94720.0,0.165728,14.683008000000001,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12741480.0,2960.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,14.686560000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003424,14.689984000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00864,14.698624000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,14.701888000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,14.705056000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,14.709568000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004512,14.714080000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,2742142592.0,3495136.0,1.010272,15.724352000000003,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85691956.0,109223.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002688,15.727040000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.00416,15.731200000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,15.734432000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004512,15.738944000000004,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.0032,15.742144000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170880.0,0.006272,15.748416000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5340.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38123328.0,0.0,0.01488,15.763296000000002,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191354.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172992.0,0.0064,15.769696000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5406.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38127648.0,0.0,0.015296,15.784992,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191489.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169920.0,0.006336,15.791328,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5310.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38137792.0,0.0,0.01488,15.806208,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191806.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172352.0,0.006208,15.812416,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5386.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,224096.0,0.0,448192.0,0,0.0,448192.0,448192.0,39336.0,720125.0,0.051794628032249185,38165088.0,128.0,0.014624,15.82704,0.0,0.0,0.0,224096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192659.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.005056,15.832096,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002912,15.835008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.005984,15.840992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003456,15.844448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006304,15.850752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,128248.0,38390.0,0.7696203747044492,2488288.0,11168.0,0.009536,15.860288,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,349.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.008512,15.8688,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,200192.0,0.0064,15.8752,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6256.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.00592,15.88112,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005568,15.886688,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.00688,15.893568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.00352,15.897088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,168990.0,84738.0,0.6660281876655316,8845824.0,5965824.0,0.017632,15.91472,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276432.0,186432.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91022.0,0.30434716150530405,8896384.0,7409664.0,0.014464,15.929184000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,278012.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91116.0,0.3089419795221843,8889472.0,6843392.0,0.014592,15.943776000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277796.0,213856.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,90340.0,0.3107710148465752,8831616.0,7363360.0,0.014528,15.958304000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275988.0,230105.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.005824,15.964128000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.003488,15.967616000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51581.0,0.42814221887160614,6263040.0,4006720.0,0.012768,15.980384000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,195720.0,125210.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7331808.0,7292928.0,0.008256,15.988640000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229119.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.087648,16.076288,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.285888,16.362176,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607392.0,0.004192,16.366368,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18981.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003168,16.369536,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,284672.0,0.011712,16.381248,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8896.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005888,16.387135999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424713.0,20076672.0,1832594.0,0,0.0,21909266.0,21909266.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.08688,16.474016,2452096.0,607744.0,8508416.0,916297.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009472,16.483487999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,16.486687999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009792,16.49648,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,16.5,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003392,16.503392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004448,16.50784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009536,16.517376000000002,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,16.520544,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005024,16.525568,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,16.5288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004384,16.533184000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.0072,16.540384000000003,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798345.0,6077440.0,1519250.0,0,0.0,7596690.0,7596690.0,0.0,14280.0,0.0,4861952.0,0.0,0.00688,16.547264000000002,0.0,0.0,3038720.0,759625.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,0.013088,16.560352,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.00384,16.564192000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002912,16.567104,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002784,16.569888,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003136,16.573024,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,16.576288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003936,16.580224,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004928,16.585152,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003136,16.588288000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
