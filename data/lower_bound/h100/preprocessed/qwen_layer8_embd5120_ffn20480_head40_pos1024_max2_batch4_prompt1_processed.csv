Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.003008,0.003008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002592,0.0056,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003712,0.009312,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00464,0.013952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00496,0.018912,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,0.022208000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002688,0.024896,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002784,0.027680000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003296,0.030976000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003872,0.034848000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003392,0.03824,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003744,0.041984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.004064,0.046048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,0.049248,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,0.052768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,0.003616,0.056384000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,21760.0,81920.0,0.005824,0.062208000000000006,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,680.0,2560.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003552,0.06576000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.004992,0.07075200000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003584,0.07433600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003968,0.07830400000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.004384,0.08268800000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004256,0.08694400000000001,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003616,0.09056,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,0.004448,0.095008,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003552,0.09856,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003456,0.102016,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,64.0,0.0088,0.110816,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00352,0.114336,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,0.11766399999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,0.12227199999999999,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004736,0.12700799999999998,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115827072.0,106848.0,0.04992,0.17692799999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619596.0,3339.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115815808.0,105152.0,0.052544,0.22947199999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619244.0,3286.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115848064.0,106048.0,0.051008,0.28047999999999995,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620252.0,3314.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,0.28521599999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00464,0.28985599999999995,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006176,0.29603199999999996,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,0.30063999999999996,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003296,0.303936,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004512,0.308448,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004416,0.312864,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006368,0.31923199999999996,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,0.323968,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,0.327424,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.027872,0.355296,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115863424.0,117312.0,0.053536,0.408832,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620732.0,3666.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003744,0.412576,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003264,0.41584,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009984,0.425824,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,0.429056,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,0.432224,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,0.436832,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004512,0.441344,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463290880.0,469216.0,0.181792,0.623136,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477840.0,14663.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003904,0.62704,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463109248.0,471744.0,0.184768,0.8118080000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14472164.0,14742.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003552,0.8153600000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463723776.0,119360.0,0.172352,0.9877120000000001,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14491368.0,3730.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,0.9911680000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.0032,0.9943680000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009472,1.00384,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,1.0070080000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003136,1.0101440000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,1.014752,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004608,1.01936,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115841792.0,105312.0,0.0504,1.06976,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620056.0,3291.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115831168.0,108128.0,0.053088,1.122848,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619724.0,3379.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115839616.0,105152.0,0.050912,1.1737600000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619988.0,3286.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,1.178336,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004256,1.182592,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005536,1.188128,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,1.1926720000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003648,1.1963200000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,1.2009920000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,1.2054720000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005504,1.2109760000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,1.2155200000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,1.2190400000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028,1.2470400000000004,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115806592.0,119808.0,0.04912,1.2961600000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618956.0,3744.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,1.2995840000000005,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003392,1.3029760000000006,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009184,1.3121600000000007,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,1.3152640000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,1.3185280000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.00464,1.3231680000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00448,1.3276480000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463045632.0,470048.0,0.181696,1.5093440000000007,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14470176.0,14689.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,1.5131840000000008,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463131264.0,471456.0,0.182976,1.6961600000000008,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14472852.0,14733.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003616,1.6997760000000008,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463588736.0,116768.0,0.178272,1.8780480000000008,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14487148.0,3649.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,1.8815680000000008,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003424,1.884992000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.008992,1.893984000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,1.897152000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,1.900416000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,1.904960000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004672,1.909632000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115824768.0,106720.0,0.047456,1.957088000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619524.0,3335.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115828864.0,103776.0,0.055488,2.012576000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619652.0,3243.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115849728.0,104960.0,0.049184,2.061760000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620304.0,3280.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,2.0664320000000007,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,2.070944000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006112,2.0770560000000007,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,2.0817280000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,2.0852480000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,2.0897920000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004256,2.0940480000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006048,2.100096,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004832,2.104928,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,2.108448,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028032,2.13648,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115806080.0,115424.0,0.052576,2.1890560000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618940.0,3607.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,2.1925440000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003488,2.196032,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009472,2.2055040000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,2.2087040000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003104,2.2118080000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004576,2.2163840000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00464,2.2210240000000008,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463289472.0,469408.0,0.181824,2.402848000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477796.0,14669.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,2.406688000000001,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463427072.0,470592.0,0.18368,2.5903680000000007,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14482096.0,14706.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003488,2.5938560000000006,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,464447360.0,120608.0,0.178144,2.7720000000000007,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14513980.0,3769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,2.7754880000000006,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003296,2.778784000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009216,2.7880000000000007,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003456,2.7914560000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,2.7946240000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.00448,2.7991040000000007,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004576,2.803680000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115817600.0,102912.0,0.053312,2.856992000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619300.0,3216.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115827456.0,104320.0,0.05024,2.907232000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619608.0,3260.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115822848.0,100160.0,0.051744,2.9589760000000007,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619464.0,3130.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,2.963616000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,2.968096000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005664,2.973760000000001,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004704,2.9784640000000007,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00336,2.9818240000000005,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,2.9863680000000006,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,2.9908800000000006,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.00576,2.9966400000000006,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,3.001280000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,3.0047360000000007,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028128,3.032864000000001,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115810816.0,116224.0,0.051584,3.084448000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619088.0,3632.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,3.087872000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.00336,3.0912320000000006,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009056,3.100288000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,3.103392000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,3.106720000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.00448,3.111200000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004544,3.115744000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463326848.0,466176.0,0.178912,3.294656000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478964.0,14568.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,3.298496000000001,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463070848.0,469984.0,0.180896,3.479392000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14470964.0,14687.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003456,3.482848000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463844480.0,118432.0,0.177312,3.660160000000001,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14495140.0,3701.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003712,3.6638720000000013,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.00352,3.6673920000000013,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009056,3.6764480000000015,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003072,3.6795200000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,3.6827200000000015,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004576,3.6872960000000017,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004672,3.6919680000000015,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115852416.0,105472.0,0.04656,3.7385280000000014,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620388.0,3296.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115848192.0,104960.0,0.052352,3.7908800000000014,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620256.0,3280.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115833344.0,102784.0,0.053056,3.8439360000000016,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619792.0,3212.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004768,3.8487040000000015,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004352,3.8530560000000014,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006336,3.8593920000000015,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,3.8639680000000016,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,3.8673920000000015,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004704,3.8720960000000013,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,3.8765760000000014,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006304,3.8828800000000014,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00496,3.8878400000000015,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,3.8912960000000014,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028128,3.9194240000000016,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115820160.0,118752.0,0.051232,3.9706560000000017,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619380.0,3711.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,3.9741120000000016,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003552,3.9776640000000016,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009664,3.9873280000000015,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,3.9905600000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,3.993888000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,3.998432000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004416,4.002848000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463234304.0,469472.0,0.179872,4.1827200000000015,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476072.0,14671.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003744,4.186464000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463430912.0,464288.0,0.184384,4.370848000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14482216.0,14509.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003584,4.374432000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463524864.0,120160.0,0.179456,4.5538880000000015,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14485152.0,3755.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003392,4.557280000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003648,4.560928000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.0096,4.570528000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,4.573696000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,4.5768640000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,4.581408000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004608,4.586016000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115848192.0,105280.0,0.052352,4.638368000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620256.0,3290.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115841664.0,107200.0,0.04896,4.687328000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620052.0,3350.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115832192.0,103744.0,0.049792,4.737120000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619756.0,3242.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,4.741760000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004576,4.746336000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006112,4.752448000000001,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.0048,4.7572480000000015,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,4.760704000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,4.7653120000000015,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004576,4.769888000000002,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006016,4.7759040000000015,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.0048,4.780704000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,4.784128000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028064,4.812192000000001,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115811968.0,117632.0,0.051616,4.8638080000000015,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619124.0,3676.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,4.867296000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003328,4.870624000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009184,4.8798080000000015,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,4.882912000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,4.886144000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.00448,4.890624000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00448,4.895104000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463392768.0,471712.0,0.181472,5.076576000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14481024.0,14741.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003808,5.080384000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463117696.0,471072.0,0.185376,5.265760000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14472428.0,14721.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003552,5.269312000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463760256.0,118016.0,0.178432,5.447744000000002,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14492508.0,3688.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,5.451232000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003648,5.454880000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.008832,5.463712000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,5.466816000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,5.470112000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,5.474656000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00448,5.479136000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115849728.0,107264.0,0.048672,5.527808000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620304.0,3352.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115837824.0,107584.0,0.051232,5.579040000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619932.0,3362.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115845248.0,106176.0,0.0528,5.631840000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620164.0,3318.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,5.6365760000000025,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004576,5.641152000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005728,5.646880000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,5.651520000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,5.655040000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,5.659648000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004416,5.664064000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005824,5.669888000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,5.674624000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,5.678048000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028096,5.706144000000003,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115809280.0,117760.0,0.05232,5.758464000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619040.0,3680.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003552,5.762016000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.0032,5.765216000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009376,5.774592000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003392,5.777984000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,5.7812800000000015,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004768,5.786048000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00464,5.790688000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463207424.0,469632.0,0.181568,5.9722560000000025,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475232.0,14676.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003872,5.976128000000003,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463060224.0,470816.0,0.179584,6.155712000000003,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14470632.0,14713.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003712,6.159424000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463795840.0,117248.0,0.172928,6.332352000000003,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14493620.0,3664.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003392,6.335744000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003616,6.339360000000003,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009792,6.349152000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,6.3524160000000025,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,6.355616000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,6.360224000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004608,6.3648320000000025,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115850752.0,106144.0,0.050656,6.4154880000000025,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620336.0,3317.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115825024.0,104896.0,0.051808,6.467296000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619532.0,3278.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115853184.0,102848.0,0.051168,6.5184640000000025,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620412.0,3214.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004768,6.523232000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004544,6.527776000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006176,6.533952000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,6.538624000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,6.542112000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00448,6.546592000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004416,6.551008000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006144,6.557152000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,6.561824000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00336,6.565184000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,0.028032,6.593216000000003,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115816960.0,117728.0,0.051104,6.644320000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619280.0,3679.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,6.647648000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003264,6.650912000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009216,6.660128000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003136,6.663264000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,6.666528000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,6.6711360000000015,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004544,6.675680000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463374848.0,467296.0,0.18128,6.856960000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14480464.0,14603.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003648,6.860608000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463269120.0,464832.0,0.183232,7.043840000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477160.0,14526.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003648,7.047488000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463768064.0,120736.0,0.172736,7.220224000000002,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14492752.0,3773.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,7.223712000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003328,7.2270400000000015,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.00896,7.2360000000000015,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,7.239200000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,7.242464000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004416,7.246880000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004448,7.251328000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,3165130752.0,6816456704.0,106962944.0,0,0.0,6923419648.0,6923419648.0,40794816.0,36768512.0,0.5259549461312438,3430932608.0,3496256.0,1.241056,8.492384000000001,204201984.0,388956160.0,3111649280.0,53481472.0,0,0,0,0,0,0,0,0.0,0.0,0.0,107216644.0,109258.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002848,8.495232000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.00432,8.499552000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,8.502816000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004544,8.50736,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.003008,8.510368,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173824.0,0.006272,8.516639999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5432.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,37967424.0,0.0,0.015168,8.531807999999998,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1186482.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171264.0,0.006432,8.538239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5352.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,37967680.0,0.0,0.014912,8.553151999999999,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1186490.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170560.0,0.006336,8.559487999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5330.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,171648.0,0.0,343296.0,0,0.0,343296.0,343296.0,39336.0,721764.0,0.051683090264091444,38040768.0,64.0,0.014752,8.574239999999998,0.0,0.0,0.0,171648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188774.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169472.0,0.006528,8.580767999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5296.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,190720.0,0.0,381440.0,0,0.0,381440.0,381440.0,39336.0,721168.0,0.051723593827251405,38030976.0,128.0,0.014912,8.595679999999998,0.0,0.0,0.0,190720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188468.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.005088,8.600767999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003136,8.603903999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006208,8.610111999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003168,8.61328,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.00592,8.6192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,150716.0,38384.0,0.7970174510840825,2488224.0,11136.0,0.00944,8.628639999999999,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77757.0,348.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.00864,8.637279999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,195840.0,0.0064,8.643679999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6120.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005824,8.649503999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005536,8.655039999999998,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.006976,8.662015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.003456,8.665471999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,159162.0,84933.0,0.6520494069931789,8604800.0,5975328.0,0.016384,8.681855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,268900.0,186729.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91300.0,0.30370189594423513,8844672.0,7409664.0,0.014016,8.695871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276396.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91745.0,0.3074751470044309,8817152.0,5716256.0,0.014304,8.710175999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275536.0,178633.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,91571.0,0.3004560698543174,8858112.0,7409664.0,0.014464,8.724639999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276816.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.00608,8.730719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.003744,8.734463999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51524.0,0.4284129484590979,6172416.0,4008864.0,0.012288,8.746751999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192888.0,125277.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7332352.0,7292928.0,0.008256,8.755007999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229136.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086176,8.841183999999997,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.285472,9.126655999999997,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607424.0,0.004288,9.130943999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18982.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003328,9.134271999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,280768.0,0.011712,9.145983999999997,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8774.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005536,9.151519999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424712.0,20076672.0,1832592.0,0,0.0,21909264.0,21909264.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086592,9.238111999999996,2452096.0,607744.0,8508416.0,916296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009728,9.247839999999997,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003488,9.251327999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00944,9.260767999999997,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,9.264127999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00336,9.267487999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004704,9.272191999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009376,9.281567999999998,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,9.284735999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005056,9.289791999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,9.293152,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004768,9.29792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.007232,9.305152,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798344.0,6077440.0,1519248.0,0,0.0,7596688.0,7596688.0,0.0,14280.0,0.0,4861952.0,0.0,0.006688,9.31184,0.0,0.0,3038720.0,759624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,0.013088,9.324928,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.004224,9.329152,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00272,9.331872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002752,9.334624,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003552,9.338176,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,9.341536000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00416,9.345696000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004704,9.350400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003424,9.353824000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003456,9.357280000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,0.004608,9.361888000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.003968,9.365856000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.003232,9.369088000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.003232,9.372320000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,0.003328,9.375648000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.003936,9.379584000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,83200.0,81920.0,0.00768,9.387264000000004,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2600.0,2560.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.003296,9.390560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.004896,9.395456000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003744,9.399200000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003552,9.402752000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.004064,9.406816000000005,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004256,9.411072000000004,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.00336,9.414432000000005,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,0.00432,9.418752000000005,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003456,9.422208000000005,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003264,9.425472000000005,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009408,9.434880000000005,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.438144000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,9.441440000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004576,9.446016000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004704,9.450720000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115835904.0,107872.0,0.048832,9.499552000000007,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619872.0,3371.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115842688.0,105952.0,0.049024,9.548576000000006,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620084.0,3311.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115879680.0,104448.0,0.04816,9.596736000000005,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3621240.0,3264.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,9.601344000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004544,9.605888000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005824,9.611712000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.0048,9.616512000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,9.619840000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,9.624576000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,9.629088000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005728,9.634816000000002,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,9.639552000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,9.643072000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004736,9.647808000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.0048,9.652608,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,326848.0,29427588.0,0.0,0,322122547200.0,29427588.0,322151974788.0,166442.0,320.0,0.9980810976121658,409600.0,81920.0,0.027872,9.680480000000001,24811078.0,3962814.0,326848.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115817216.0,116992.0,0.051296,9.731776000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619288.0,3656.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00336,9.735136000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003264,9.738400000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.00928,9.747680000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.750944000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,9.754240000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004736,9.758976000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004608,9.763584000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463275904.0,469760.0,0.18,9.943584000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477372.0,14680.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,9.947424000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463322624.0,474528.0,0.180416,10.12784,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478832.0,14829.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003936,10.131776,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,464034048.0,117440.0,0.174336,10.306112,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14501064.0,3670.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003584,10.309696,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.00352,10.313216,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009376,10.322592,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003392,10.325984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,10.329248,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,10.333855999999999,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004672,10.338527999999998,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115839872.0,105376.0,0.047488,10.386015999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619996.0,3293.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115841280.0,105536.0,0.050528,10.436543999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620040.0,3298.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115821952.0,105216.0,0.052,10.488543999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619436.0,3288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,10.493119999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004576,10.497695999999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.00576,10.503455999999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,10.508127999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003552,10.511679999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,10.516319999999999,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,10.520831999999999,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005792,10.526623999999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,10.531231999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,10.534751999999997,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004832,10.539583999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.00464,10.544223999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,327488.0,29429262.0,0.0,0,322122547200.0,29429262.0,322151976462.0,166412.0,320.0,0.9980807523450808,409600.0,81920.0,0.027968,10.572191999999998,24811418.0,3962868.0,327488.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115801344.0,115936.0,0.053088,10.625279999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618792.0,3623.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003392,10.628671999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003392,10.632063999999998,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009376,10.641439999999998,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003328,10.644767999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,10.648095999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.0048,10.652895999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00464,10.657535999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463368832.0,469696.0,0.184256,10.841791999999996,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14480276.0,14678.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,10.845631999999997,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463050624.0,467424.0,0.18592,11.031551999999996,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14470332.0,14607.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003584,11.035135999999996,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,464047616.0,116672.0,0.176096,11.211231999999995,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14501488.0,3646.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003296,11.214527999999996,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003264,11.217791999999996,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009632,11.227423999999996,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,11.230687999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,11.233951999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,11.238495999999994,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00448,11.242975999999993,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115831680.0,101600.0,0.051456,11.294431999999993,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619740.0,3175.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115833088.0,106080.0,0.04992,11.344351999999994,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619784.0,3315.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115826304.0,106176.0,0.05328,11.397631999999994,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619572.0,3318.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,11.402303999999994,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004416,11.406719999999995,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005888,11.412607999999995,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,11.417183999999995,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,11.420511999999995,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,11.425183999999994,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,11.429663999999994,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005888,11.435551999999994,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004736,11.440287999999994,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,11.443775999999994,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004736,11.448511999999994,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004736,11.453247999999993,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,327456.0,29429176.0,0.0,0,322122547200.0,29429176.0,322151976376.0,166409.0,320.0,0.9980807178115385,409600.0,81920.0,0.028096,11.481343999999993,24811401.0,3962863.0,327456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115817088.0,118720.0,0.050976,11.532319999999993,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619284.0,3710.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,11.535647999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003616,11.539263999999992,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009696,11.548959999999992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003456,11.552415999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,11.555679999999992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,11.560223999999991,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004576,11.564799999999991,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,462934272.0,466912.0,0.18032,11.745119999999991,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14466696.0,14591.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,11.748959999999991,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463276800.0,467360.0,0.1792,11.928159999999991,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477400.0,14605.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.00368,11.93183999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463686016.0,117248.0,0.174368,12.10620799999999,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14490188.0,3664.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003552,12.10975999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.00336,12.113119999999991,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009408,12.122527999999992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,12.125695999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,12.128991999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004704,12.133695999999993,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004608,12.138303999999993,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115903616.0,107040.0,0.04688,12.185183999999992,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3621988.0,3345.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115826688.0,106496.0,0.050016,12.235199999999992,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619584.0,3328.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115864960.0,105216.0,0.050368,12.285567999999992,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620780.0,3288.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,12.290111999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004384,12.294495999999992,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006112,12.300607999999992,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004832,12.305439999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00336,12.308799999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,12.313439999999993,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004384,12.317823999999993,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.00624,12.324063999999993,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,12.328671999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,12.332095999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004768,12.336863999999993,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004608,12.341471999999992,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,327456.0,29429176.0,0.0,0,322122547200.0,29429176.0,322151976376.0,166409.0,320.0,0.9980807178115385,409600.0,81920.0,0.027968,12.369439999999992,24811401.0,3962863.0,327456.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115823104.0,116416.0,0.049952,12.419391999999991,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619472.0,3638.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,12.422879999999992,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.00336,12.426239999999993,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009248,12.435487999999992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,12.438687999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,12.441919999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004672,12.446591999999992,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00464,12.451231999999992,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463352704.0,470528.0,0.179744,12.630975999999992,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14479772.0,14704.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003904,12.634879999999992,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463424512.0,469760.0,0.184672,12.819551999999993,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14482016.0,14680.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003488,12.823039999999994,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463627648.0,118944.0,0.1784,13.001439999999993,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14488364.0,3717.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,13.004895999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003392,13.008287999999993,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009856,13.018143999999992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003296,13.021439999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,13.024735999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,13.029279999999993,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004544,13.033823999999992,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115838080.0,105376.0,0.049472,13.083295999999992,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619940.0,3293.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115825024.0,106720.0,0.051072,13.134367999999991,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619532.0,3335.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115832192.0,104480.0,0.05152,13.185887999999991,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619756.0,3265.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,13.190463999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,13.194975999999992,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006208,13.201183999999992,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,13.205823999999993,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,13.209151999999992,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004448,13.213599999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,13.218079999999992,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.006112,13.224191999999992,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,13.228831999999992,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,13.232287999999992,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004832,13.237119999999992,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004704,13.241823999999992,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,327552.0,29429424.0,0.0,0,322122547200.0,29429424.0,322151976624.0,166406.0,320.0,0.9980806832767535,409600.0,81920.0,0.028032,13.269855999999992,24811452.0,3962868.0,327552.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115809792.0,119232.0,0.051392,13.321247999999992,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619056.0,3726.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,13.324703999999992,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003232,13.327935999999992,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009696,13.337631999999992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,13.340863999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,13.344191999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004608,13.348799999999992,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.0048,13.353599999999991,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463187712.0,467552.0,0.182368,13.535967999999992,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14474616.0,14611.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,13.539807999999992,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,462953856.0,465984.0,0.1816,13.721407999999991,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14467308.0,14562.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003584,13.724991999999991,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,464072576.0,117120.0,0.173792,13.898783999999992,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14502268.0,3660.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003616,13.902399999999991,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003392,13.905791999999991,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.00944,13.91523199999999,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003456,13.91868799999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,13.92195199999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,13.92649599999999,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004736,13.931231999999989,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115843968.0,104608.0,0.047808,13.979039999999989,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620124.0,3269.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115850880.0,106304.0,0.049152,14.028191999999988,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620340.0,3322.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115829120.0,105952.0,0.048288,14.076479999999988,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619660.0,3311.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00448,14.080959999999987,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004544,14.085503999999986,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.0056,14.091103999999985,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004704,14.095807999999986,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003616,14.099423999999985,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,14.104063999999985,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,14.108575999999985,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005472,14.114047999999984,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,14.118655999999984,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,14.122111999999984,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004768,14.126879999999984,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004576,14.131455999999984,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,327552.0,29429424.0,0.0,0,322122547200.0,29429424.0,322151976624.0,166406.0,320.0,0.9980806832767535,409600.0,81920.0,0.028096,14.159551999999984,24811452.0,3962868.0,327552.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115818752.0,115968.0,0.052928,14.212479999999983,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619336.0,3624.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,14.215999999999983,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003296,14.219295999999984,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009472,14.228767999999985,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,14.231967999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,14.235263999999985,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004512,14.239775999999985,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004448,14.244223999999985,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463448576.0,474976.0,0.182432,14.426655999999985,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14482768.0,14843.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.00384,14.430495999999986,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463318784.0,466112.0,0.1824,14.612895999999985,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478712.0,14566.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.00352,14.616415999999985,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463738624.0,119072.0,0.172128,14.788543999999986,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14491832.0,3721.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003296,14.791839999999986,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003712,14.795551999999986,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009632,14.805183999999986,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,14.808447999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003744,14.812191999999985,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004544,14.816735999999985,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004448,14.821183999999985,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115820288.0,105056.0,0.052864,14.874047999999984,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619384.0,3283.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115833984.0,102624.0,0.048896,14.922943999999983,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619812.0,3207.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115825408.0,105568.0,0.050592,14.973535999999983,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619544.0,3299.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004768,14.978303999999984,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00448,14.982783999999983,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005856,14.988639999999982,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004576,14.993215999999983,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,14.996639999999983,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004608,15.001247999999983,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004512,15.005759999999983,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005696,15.011455999999983,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00464,15.016095999999983,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,15.019551999999983,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004672,15.024223999999982,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004736,15.028959999999982,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,327552.0,29429424.0,0.0,0,322122547200.0,29429424.0,322151976624.0,166406.0,320.0,0.9980806832767535,409600.0,81920.0,0.028096,15.057055999999982,24811452.0,3962868.0,327552.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115802880.0,116352.0,0.050208,15.107263999999981,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618840.0,3636.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003328,15.110591999999981,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003424,15.114015999999982,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.00976,15.123775999999982,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,15.127039999999981,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003488,15.130527999999982,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004672,15.135199999999982,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.00448,15.13967999999998,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463215744.0,473568.0,0.183264,15.32294399999998,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475492.0,14799.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003744,15.32668799999998,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463420672.0,469760.0,0.182496,15.50918399999998,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14481896.0,14680.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003712,15.51289599999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463504384.0,119168.0,0.174176,15.68707199999998,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14484512.0,3724.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003552,15.69062399999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003232,15.69385599999998,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.0096,15.703455999999981,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,15.706623999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,15.709887999999982,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004672,15.714559999999981,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004576,15.719135999999981,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115819136.0,106784.0,0.050976,15.770111999999981,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619348.0,3337.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115867008.0,105472.0,0.046752,15.816863999999981,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620844.0,3296.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1241600.0,0.525440313111546,115861888.0,107520.0,0.047072,15.863935999999981,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620684.0,3360.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.00448,15.86841599999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.00432,15.87273599999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005696,15.87843199999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004704,15.88313599999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003424,15.886559999999982,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004544,15.89110399999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,0.004608,15.89571199999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,0.005536,15.90124799999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,0.004672,15.905919999999979,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003456,15.909375999999979,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.004672,15.914047999999978,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,0.0048,15.918847999999977,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,327552.0,29429424.0,0.0,0,322122547200.0,29429424.0,322151976624.0,166406.0,320.0,0.9980806832767535,409600.0,81920.0,0.028032,15.946879999999977,24811452.0,3962868.0,327552.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115826432.0,117024.0,0.051392,15.998271999999977,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619576.0,3657.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.00352,16.001791999999977,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003232,16.005023999999977,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009792,16.01481599999998,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,16.017983999999977,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003456,16.021439999999977,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004512,16.025951999999975,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004576,16.030527999999975,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,462933632.0,474944.0,0.1832,16.213727999999975,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14466676.0,14842.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,0.003904,16.217631999999973,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463251712.0,466400.0,0.179008,16.396639999999973,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476616.0,14575.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,0.003584,16.400223999999973,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463996800.0,118592.0,0.173696,16.573919999999973,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14499900.0,3706.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,0.003488,16.577407999999973,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,0.003296,16.580703999999972,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,0.009792,16.590495999999973,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,16.593759999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.00352,16.597279999999976,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,0.004576,16.601855999999977,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,0.004512,16.606367999999975,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,3165130752.0,6816456704.0,106962944.0,0,0.0,6923419648.0,6923419648.0,40794816.0,36768512.0,0.5259549461312438,3429971200.0,3503040.0,1.250048,17.856415999999975,204201984.0,388956160.0,3111649280.0,53481472.0,0,0,0,0,0,0,0,0.0,0.0,0.0,107186600.0,109470.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002848,17.859263999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.003744,17.863007999999976,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003136,17.866143999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.00448,17.870623999999978,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.003104,17.87372799999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171712.0,0.006336,17.88006399999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5366.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38120704.0,32.0,0.014784,17.89484799999998,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191272.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174080.0,0.006656,17.901503999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5440.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38121408.0,0.0,0.01456,17.916063999999977,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191294.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170688.0,0.00656,17.922623999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5334.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,224096.0,0.0,448192.0,0,0.0,448192.0,448192.0,39336.0,720125.0,0.051794628032249185,38160800.0,0.0,0.014848,17.93747199999998,0.0,0.0,0.0,224096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192525.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171648.0,0.006272,17.943743999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5364.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,271776.0,0.0,543552.0,0,0.0,543552.0,543552.0,39336.0,718635.0,0.05189644458693011,38129952.0,128.0,0.01488,17.95862399999998,0.0,0.0,0.0,271776.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191561.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.005152,17.963775999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002912,17.966687999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006144,17.972831999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003168,17.975999999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.00608,17.982079999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,150224.0,38400.0,0.7964203918907456,2488288.0,10976.0,0.009664,17.991743999999976,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,343.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.008416,18.000159999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,201664.0,0.006528,18.006687999999976,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6302.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005472,18.012159999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005568,18.017727999999977,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.006848,18.02457599999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.003488,18.02806399999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,164778.0,84877.0,0.6600228315074803,8562944.0,6010624.0,0.016576,18.04463999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,267592.0,187832.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,95012.0,0.29534093774567244,8895872.0,7409664.0,0.014656,18.05929599999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277996.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91278.0,0.3085628579220071,8867840.0,6836768.0,0.014784,18.074079999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277120.0,213649.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,90738.0,0.3098302300109529,8855168.0,7355200.0,0.014656,18.088735999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276724.0,229850.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.005856,18.094591999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.003456,18.098047999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,52041.0,0.42596984303819807,6204544.0,4014080.0,0.012608,18.110655999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193892.0,125440.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7331712.0,7292928.0,0.00832,18.11897599999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229116.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.085632,18.20460799999998,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.284576,18.48918399999998,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,0.004192,18.49337599999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003264,18.49663999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,284224.0,0.01168,18.50831999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8882.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005024,18.51334399999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424712.0,20076672.0,1832592.0,0,0.0,21909264.0,21909264.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086176,18.599519999999977,2452096.0,607744.0,8508416.0,916296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.0096,18.609119999999976,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,18.612351999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009408,18.621759999999977,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,18.625119999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.00352,18.62863999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004512,18.633151999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009856,18.643007999999977,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003552,18.646559999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00512,18.651679999999978,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00336,18.65503999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004608,18.65964799999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.007232,18.666879999999978,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798344.0,6077440.0,1519248.0,0,0.0,7596688.0,7596688.0,0.0,14280.0,0.0,4861952.0,1536.0,0.006784,18.673663999999977,0.0,0.0,3038720.0,759624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,48.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,0.01312,18.686783999999978,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.003872,18.69065599999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002816,18.69347199999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002944,18.696415999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003232,18.69964799999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,18.70287999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.004096,18.70697599999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.005248,18.71222399999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003392,18.715615999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
