Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,11.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,14.943999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.712,18.656,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.416,23.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.248,28.32,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.808,32.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,34.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,40.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.648,44.416000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,47.776,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,51.168000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.32,55.48800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,58.62400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,61.88800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.36,65.24800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,21760.0,81920.0,5.76,71.00800000000002,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,680.0,2560.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,21760.0,81920.0,5.44,76.44800000000002,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,680.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,79.93600000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,83.55200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.992,88.54400000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.2,103.74400000000003,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325639808.0,245760.0,132.8,236.54400000000004,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10176244.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.448,240.99200000000005,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.64,245.63200000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,250.20800000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,21.632,271.84000000000003,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",31,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104960.0,3.104,274.944,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3280.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",32,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1355247.0,0.7561473407720929,111698016.0,1663296.0,86.56,361.504,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3490563.0,51978.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",33,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.416,365.92,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",34,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.808,369.728,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",35,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.296,385.024,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430802048.0,327680.0,156.064,541.088,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13462564.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.648,544.736,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",38,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,548.352,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,551.904,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.584,555.4879999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",41,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,559.0079999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",42,462244.0,1149768.0,40960.0,0,0.0,1190728.0,1190728.0,0.0,1280.0,0.0,327680.0,327680.0,3.648,562.656,81920.0,184320.0,441764.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",43,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,566.144,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",44,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,569.696,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",45,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105216.0,3.008,572.7040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3288.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",46,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5817670.0,0.7427820814434024,442903968.0,2661408.0,214.72,787.4240000000001,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13840749.0,83169.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",47,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.256,791.6800000000001,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,795.0400000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",49,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.392,810.4320000000001,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325615872.0,245760.0,132.736,943.1680000000001,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175496.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,947.7440000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,952.3200000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.704,957.0240000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",54,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.256,977.2800000000001,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,103552.0,3.072,980.3520000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3236.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",56,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1378445.0,0.7530042493565042,111688256.0,1662912.0,87.936,1068.288,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3490258.0,51966.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",57,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.448,1072.736,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",58,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,1076.2240000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",59,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.488,1091.7120000000002,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430842368.0,327680.0,154.752,1246.4640000000002,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463824.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,1249.9520000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",62,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,1253.3760000000002,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,1256.7680000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",64,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.68,1260.4480000000003,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",65,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,1264.0000000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,462632.0,1150544.0,40960.0,0,0.0,1191504.0,1191504.0,0.0,1280.0,0.0,327680.0,327680.0,3.648,1267.6480000000001,81920.0,184320.0,442152.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",67,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,1271.1680000000001,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",68,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.648,1274.816,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",69,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,103168.0,2.976,1277.7920000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3224.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",70,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5631318.0,0.7489528702682562,443193696.0,2661824.0,214.176,1491.968,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13849803.0,83182.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",71,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.16,1496.1280000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",72,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,1499.6480000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",73,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.52,1515.1680000000001,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",74,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325609344.0,245760.0,132.608,1647.776,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175292.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.448,1652.2240000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.704,1656.928,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,1661.5040000000001,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",78,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.064,1681.5680000000002,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",79,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104320.0,3.072,1684.64,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3260.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",80,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1376825.0,0.7532228938607065,111924640.0,1663232.0,88.064,1772.7040000000002,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3497645.0,51976.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",81,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.48,1777.1840000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,1780.64,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",83,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.072,1795.712,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430845952.0,327680.0,156.288,1952.0,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463936.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",85,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,1955.424,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",86,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,1958.9759999999999,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",87,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,1962.368,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",88,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.648,1966.0159999999998,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",89,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,1969.4719999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,462652.0,1150584.0,40960.0,0,0.0,1191544.0,1191544.0,0.0,1280.0,0.0,327680.0,327680.0,3.68,1973.1519999999998,81920.0,184320.0,442172.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",91,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,1976.5759999999998,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.488,1980.0639999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",93,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,102144.0,3.2,1983.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3192.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",94,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5772559.0,0.7442665229050902,442892992.0,2661376.0,214.24,2197.504,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13840406.0,83168.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",95,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.448,2201.9519999999998,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.584,2205.5359999999996,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",97,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.04,2220.5759999999996,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",98,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325604864.0,245760.0,133.312,2353.8879999999995,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175152.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,2358.4639999999995,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.384,2362.8479999999995,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.608,2367.4559999999997,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",102,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.16,2387.6159999999995,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",103,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104448.0,3.136,2390.7519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3264.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",104,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1387702.0,0.7517573024606706,111815296.0,1663232.0,86.56,2477.3119999999994,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3494228.0,51976.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",105,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.768,2482.0799999999995,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",106,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,2485.3759999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",107,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.552,2500.9279999999994,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",108,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430803328.0,327680.0,156.832,2657.7599999999993,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13462604.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",109,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,2661.2799999999993,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",110,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,2664.7999999999993,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",111,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,2668.3519999999994,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.68,2672.0319999999992,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",113,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,2675.615999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",114,462440.0,1150160.0,40960.0,0,0.0,1191120.0,1191120.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,2679.231999999999,81920.0,184320.0,441960.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",115,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,2682.655999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",116,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,2686.271999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",117,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105984.0,3.04,2689.311999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3312.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",118,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,6045860.0,0.735362993557695,443112352.0,2661568.0,215.648,2904.959999999999,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13847261.0,83174.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",119,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.384,2909.343999999999,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,2912.7039999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,14.912,2927.615999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",122,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325618560.0,245760.0,132.544,3060.159999999999,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175580.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.352,3064.511999999999,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,3069.087999999999,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.544,3073.6319999999987,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",126,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.192,3093.8239999999987,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",127,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104576.0,3.072,3096.895999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3268.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",128,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1405549.0,0.7493648747518924,111800384.0,1663392.0,89.856,3186.7519999999986,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3493762.0,51981.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",129,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.32,3191.0719999999988,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",130,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,3194.527999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",131,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.04,3209.567999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",132,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430843264.0,327680.0,155.808,3365.375999999999,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463852.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",133,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,3368.7679999999987,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",134,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.648,3372.415999999999,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",135,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,3375.871999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",136,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.904,3379.775999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",137,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.68,3383.4559999999988,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,461948.0,1149176.0,40960.0,0,0.0,1190136.0,1190136.0,0.0,1280.0,0.0,327680.0,327680.0,3.808,3387.2639999999988,81920.0,184320.0,441468.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",139,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,3390.719999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",140,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.776,3394.4959999999987,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",141,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104832.0,3.008,3397.5039999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3276.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",142,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5793147.0,0.7435883102075156,443153184.0,2661376.0,214.912,3612.4159999999983,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13848537.0,83168.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",143,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.224,3616.6399999999985,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",144,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,3620.1279999999983,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",145,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.52,3635.6479999999983,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",146,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325612032.0,245760.0,133.024,3768.671999999998,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175376.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.48,3773.151999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.48,3777.6319999999982,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,3782.2079999999983,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",150,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.096,3802.3039999999983,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",151,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,107392.0,3.296,3805.599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3356.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",152,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1367392.0,0.7544985521900998,111776064.0,1663072.0,85.952,3891.551999999998,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3493002.0,51971.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",153,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.736,3896.2879999999977,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,3899.647999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",155,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.36,3915.007999999998,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",156,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430771328.0,327680.0,154.784,4069.791999999998,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13461604.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",157,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,4073.375999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",158,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,4076.799999999998,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",159,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,4080.319999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.744,4084.063999999998,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",161,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,4087.519999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,461884.0,1149048.0,40960.0,0,0.0,1190008.0,1190008.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,4091.135999999998,81920.0,184320.0,441404.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",163,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,4094.5919999999983,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,4098.143999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",165,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106624.0,3.04,4101.183999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3332.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",166,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5825621.0,0.742521056107145,443449056.0,2661728.0,214.496,4315.6799999999985,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13857783.0,83179.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",167,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.704,4320.383999999998,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,4323.903999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",169,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.136,4339.039999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325608704.0,245760.0,134.304,4473.343999999999,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175272.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.448,4477.7919999999995,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.704,4482.495999999999,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.416,4486.911999999999,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",174,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.0,4506.911999999999,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105344.0,3.168,4510.079999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3292.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",176,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1388139.0,0.751698539264282,111869984.0,1663296.0,86.848,4596.927999999999,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3495937.0,51978.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",177,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.48,4601.4079999999985,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,4604.799999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.296,4620.095999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430789888.0,327680.0,155.232,4775.327999999999,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13462184.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",181,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,4778.847999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",182,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,4782.399999999999,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",183,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,4785.887999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.744,4789.631999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",185,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,4793.087999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,462276.0,1149832.0,40960.0,0,0.0,1190792.0,1190792.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,4796.799999999999,81920.0,184320.0,441796.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,4800.288,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",188,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.52,4803.808,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",189,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106752.0,3.008,4806.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",190,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5886674.0,0.7405228285115747,443245568.0,2661408.0,214.304,5021.12,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13851424.0,83169.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",191,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.48,5025.599999999999,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.552,5029.151999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",193,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,14.944,5044.096,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325627136.0,245760.0,132.448,5176.544,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175848.0,7680.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.512,5181.056,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",196,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.608,5185.664,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.416,5190.08,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",198,655360.0,21770240.0,0.0,0,193273528320.0,21770240.0,193295298560.0,170240.0,320.0,0.99812382739212,245760.0,81920.0,20.192,5210.272,16465920.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",199,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106880.0,3.072,5213.344,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3340.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",200,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1436851.0,0.7452053473058745,111631936.0,1663232.0,87.168,5300.512,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3488498.0,51976.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",201,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.416,5304.928,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,5308.32,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",203,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.52,5323.84,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430808448.0,327680.0,154.88,5478.72,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13462764.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",205,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,5482.112,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",206,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,5485.664,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",207,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,5489.215999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.584,5492.799999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",209,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,5496.255999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,462316.0,1149912.0,40960.0,0,0.0,1190872.0,1190872.0,0.0,1280.0,0.0,327680.0,327680.0,4.032,5500.288,81920.0,184320.0,441836.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",211,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,5503.744,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",212,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,5507.295999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105344.0,3.008,5510.303999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3292.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",214,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5816145.0,0.7428321670205068,441912736.0,2661568.0,213.568,5723.871999999999,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13809773.0,83174.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",215,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.224,5728.096,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",216,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.584,5731.679999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",217,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.392,5747.071999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,1046953936.0,2254747968.0,35381152.0,0,0.0,2290129120.0,2290129120.0,13494396.0,12162916.0,0.5259473790551403,1136463616.0,1408320.0,442.08,6189.151999999999,67545408.0,128675840.0,1029263360.0,17690576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,35514488.0,44010.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,6191.935999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",220,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.936,6195.8719999999985,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6199.231999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",222,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.776,6203.007999999998,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,6205.983999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54720.0,5.952,6211.935999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1710.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",225,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.128,6220.063999999998,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,5.952,6226.015999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",227,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,13200.0,82808.0,0.13748854262144822,5134848.0,0.0,8.352,6234.367999999998,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54912.0,5.984,6240.351999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1716.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",229,76800.0,0.0,153600.0,0,0.0,153600.0,153600.0,13200.0,83208.0,0.13691809808314662,5134848.0,0.0,8.16,6248.511999999998,0.0,0.0,0.0,76800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54016.0,5.856,6254.367999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1688.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",231,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,128.0,8.192,6262.559999999998,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.968,6266.5279999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,6269.663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.696,6275.359999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,6278.495999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.632,6284.127999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",237,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,46904.0,13020.0,0.7827247847273213,831584.0,10592.0,9.088,6293.215999999998,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,331.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,9.024,6302.239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816576.0,68608.0,6.048,6308.287999999998,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25518.0,2144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.224,6312.511999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",241,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.352,6316.863999999998,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.208,6323.071999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",243,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.808,6326.879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28251.0,0.6997959747518755,2738368.0,2009440.0,15.168,6342.047999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85574.0,62795.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28273.0,0.3344867358708189,2732096.0,2451264.0,11.616,6353.663999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85378.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28238.0,0.35158097774920205,2727488.0,1899552.0,12.96,6366.623999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85234.0,59361.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,13907.0,28243.0,0.32994068801897986,2726592.0,2451264.0,13.44,6380.063999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85206.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.088,6385.151999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.36,6388.511999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15212.0,0.49369279414212014,1862560.0,1345120.0,9.344,6397.855999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58205.0,42035.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428960.0,2412352.0,5.088,6402.943999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75905.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",252,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1088288.0,753856.0,32.192,6435.135999999996,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34009.0,23558.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",253,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804256.0,614496.0,97.6,6532.735999999996,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,19203.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.648,6536.383999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,6539.4559999999965,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,89152.0,11.552,6551.007999999996,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2786.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.608,6555.615999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",258,3122056.0,6655044.0,615328.0,0,0.0,7270372.0,7270372.0,528.0,6704.0,0.07300884955752213,1084480.0,752832.0,31.968,6587.583999999996,825232.0,201028.0,2814392.0,307664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33890.0,23526.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",259,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.824,6597.407999999996,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,6600.9599999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",261,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.216,6610.175999999996,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,6613.471999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,6616.991999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,6621.599999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",265,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.776,6637.375999999997,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,6640.6079999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.312,6645.919999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,6649.471999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,6653.951999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",270,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.984,6659.935999999996,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",271,1256416.0,2010280.0,502552.0,0,0.0,2512832.0,2512832.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,6665.343999999996,0.0,0.0,1005140.0,251276.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",272,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804256.0,128.0,23.296,6688.639999999997,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,6691.903999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6695.2639999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.0,6699.2639999999965,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,6702.719999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.936,6706.655999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,6709.503999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,6712.319999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",280,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,6715.679999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",281,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,6718.399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.808,6722.207999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",283,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.392,6729.599999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",284,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,6732.895999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,6736.127999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.256,6740.383999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",287,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.312,6745.695999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",288,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,6748.991999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,6752.255999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.184,6757.439999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",291,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.0,6761.439999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",292,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.104,6764.543999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.392,6767.935999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",294,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.232,6771.167999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.488,6774.655999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",296,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,83200.0,81920.0,6.368,6781.023999999998,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2600.0,2560.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",297,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,21760.0,81920.0,5.856,6786.879999999997,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,680.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,6790.399999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.328,6793.727999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",300,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.024,6798.751999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",301,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.232,6813.983999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",302,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325627904.0,245760.0,132.064,6946.047999999999,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175872.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",303,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.304,6952.351999999999,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",304,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.464,6958.815999999999,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",305,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.672,6963.4879999999985,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",306,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.288,6983.775999999998,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104192.0,3.008,6986.783999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3256.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",308,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1378655.0,0.7529759158438682,111841792.0,1663296.0,87.264,7074.047999999998,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3495056.0,51978.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",309,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.224,7078.271999999998,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",310,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,7081.663999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",311,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.072,7096.735999999998,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",312,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430816384.0,327680.0,154.784,7251.519999999998,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463012.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,7254.9119999999975,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",314,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,7258.623999999998,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",315,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,7262.111999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.488,7265.5999999999985,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,7269.151999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",318,462311.0,1149902.0,40960.0,0,0.0,1190862.0,1190862.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,7272.735999999998,81920.0,184320.0,441831.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,7276.191999999998,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",320,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.712,7279.903999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105472.0,3.168,7283.071999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3296.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",322,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5859242.0,0.7414193290313947,442252800.0,2661536.0,214.336,7497.4079999999985,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13820400.0,83173.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",323,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.32,7501.727999999998,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,7505.183999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.104,7520.287999999999,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",326,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325674368.0,245760.0,133.824,7654.111999999998,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10177324.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",327,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.112,7660.223999999998,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",328,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.24,7666.463999999998,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.448,7670.911999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",330,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.128,7691.039999999998,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104192.0,3.04,7694.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3256.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",332,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1400297.0,0.7500673336430651,112077760.0,1663200.0,88.384,7782.463999999998,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3502430.0,51975.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",333,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.288,7786.751999999998,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",334,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,7790.207999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",335,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.072,7805.279999999998,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",336,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430775936.0,327680.0,156.384,7961.663999999998,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13461748.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",337,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,7965.215999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",338,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,7968.927999999998,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",339,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,7972.4479999999985,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",340,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,7976.0639999999985,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.744,7979.807999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,462186.0,1149652.0,40960.0,0,0.0,1190612.0,1190612.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,7983.519999999999,81920.0,184320.0,441706.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",343,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,7986.975999999999,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",344,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.488,7990.463999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106240.0,3.072,7993.535999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3320.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",346,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5882617.0,0.7406552780042973,442498976.0,2661600.0,215.392,8208.928,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13828093.0,83175.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",347,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.416,8213.344,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",348,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.584,8216.928,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",349,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.04,8231.968,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",350,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325661440.0,245760.0,132.544,8364.512,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10176920.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",351,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.112,8370.624,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.208,8376.832,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",353,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.608,8381.44,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",354,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.352,8401.792000000001,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105728.0,3.168,8404.960000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3304.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",356,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1324270.0,0.7603855486215026,111991168.0,1663392.0,87.52,8492.480000000001,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3499724.0,51981.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",357,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.288,8496.768000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.68,8500.448000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.04,8515.488000000003,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",360,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430827136.0,327680.0,153.696,8669.184000000003,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463348.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,8672.672000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",362,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,8676.384000000002,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,8679.936000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",364,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,8683.552000000001,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,8687.04,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,462402.0,1150084.0,40960.0,0,0.0,1191044.0,1191044.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,8690.656,81920.0,184320.0,441922.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",367,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,8694.144,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",368,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,8697.76,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,103808.0,3.232,8700.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3244.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",370,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5808646.0,0.7430785549917496,442804736.0,2661376.0,214.848,8915.84,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13837648.0,83168.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",371,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.512,8920.352,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,8923.776000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,14.88,8938.656,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325623808.0,245760.0,132.736,9071.392000000002,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10175744.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.112,9077.504,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.24,9083.744,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.64,9088.384,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.096,9108.48,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105344.0,3.04,9111.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3292.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",380,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1356557.0,0.7559691503280201,111791136.0,1663200.0,86.72,9198.24,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3493473.0,51975.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",381,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.352,9202.592,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,9206.08,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.328,9221.408,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",384,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430931072.0,327680.0,155.392,9376.8,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13466596.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,9380.384,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",386,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,9383.808,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,9387.392000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.776,9391.168000000001,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",389,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.712,9394.880000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,462295.0,1149870.0,40960.0,0,0.0,1190830.0,1190830.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,9398.496000000001,81920.0,184320.0,441815.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",391,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,9401.952000000001,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.456,9405.408000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105088.0,3.232,9408.640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3284.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",394,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,6026538.0,0.7359854569273712,443114432.0,2661728.0,216.48,9625.12,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13847326.0,83179.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",395,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.352,9629.472000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",396,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,9632.896000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",397,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.616,9648.512000000002,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",398,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325680640.0,245760.0,132.576,9781.088000000002,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10177520.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.336,9787.424,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",400,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.304,9793.728000000001,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.736,9798.464000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",402,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.064,9818.528000000002,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106752.0,3.104,9821.632000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",404,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1322529.0,0.7606251591649413,111740960.0,1663392.0,86.4,9908.032000000001,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3491905.0,51981.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",405,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.256,9912.288,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",406,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,9915.584,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",407,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,14.88,9930.464,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",408,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430837376.0,327680.0,155.328,10085.792,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463668.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,10089.344,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",410,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,10092.864,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",411,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,10096.351999999999,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",412,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.52,10099.872,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",413,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.456,10103.328,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,462333.0,1149946.0,40960.0,0,0.0,1190906.0,1190906.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,10106.848,81920.0,184320.0,441853.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",415,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,10110.368,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,10113.92,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,107008.0,3.072,10116.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3344.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",418,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5816414.0,0.7428233317624978,443046848.0,2661440.0,215.808,10332.8,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13845214.0,83170.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",419,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.896,10337.696,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.616,10341.312,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",421,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.456,10356.768,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",422,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325648000.0,245760.0,132.608,10489.376,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10176500.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.24,10495.616,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.272,10501.888,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.48,10506.368,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",426,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.16,10526.528,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,108032.0,3.04,10529.568000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3376.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",428,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1355581.0,0.7561019010320474,111695936.0,1663232.0,87.36,10616.928000000002,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3490498.0,51976.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",429,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.352,10621.280000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,10624.704000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.488,10640.192000000003,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",432,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430780800.0,327680.0,156.32,10796.512000000002,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13461900.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,10800.000000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",434,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,10803.552000000001,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,10807.136000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,10810.752000000002,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",437,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,10814.240000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",438,461746.0,1148772.0,40960.0,0,0.0,1189732.0,1189732.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,10817.824000000002,81920.0,184320.0,441266.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",439,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.616,10821.440000000002,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",440,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,10824.992000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",441,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104832.0,3.072,10828.064000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3276.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",442,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5862907.0,0.7412994281801536,442566176.0,2661408.0,214.848,11042.912000000002,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13830193.0,83169.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",443,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.448,11047.360000000002,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,11050.816000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",445,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.2,11066.016000000003,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325651200.0,245760.0,132.896,11198.912000000004,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10176600.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.112,11205.024000000003,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.176,11211.200000000003,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.576,11215.776000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",450,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.288,11236.064000000002,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",451,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105856.0,3.008,11239.072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3308.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",452,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1349306.0,0.7569565103051207,111692864.0,1663264.0,87.84,11326.912000000002,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3490402.0,51977.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",453,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.192,11331.104000000001,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,11334.528000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",455,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,14.88,11349.408000000001,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",456,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430817920.0,327680.0,154.976,11504.384000000002,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13463060.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",457,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.424,11507.808000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",458,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,11511.392000000003,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",459,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,11514.976000000004,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,11518.592000000004,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",461,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.488,11522.080000000004,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,462581.0,1150442.0,40960.0,0,0.0,1191402.0,1191402.0,0.0,1280.0,0.0,327680.0,327680.0,3.584,11525.664000000004,81920.0,184320.0,442101.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",463,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.36,11529.024000000005,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,11532.640000000005,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,106496.0,3.264,11535.904000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3328.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",466,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5817543.0,0.7427862522467626,442532608.0,2661440.0,213.824,11749.728000000005,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13829144.0,83170.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",467,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.576,11754.304000000004,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,11757.792000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",469,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.36,11773.152000000004,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,315863040.0,636764160.0,2580480.0,0,0.0,639344640.0,639344640.0,2774400.0,2615040.0,0.5147844674029213,325637760.0,245760.0,132.512,11905.664000000004,2703360.0,4915200.0,314572800.0,1290240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10176180.0,7680.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.24,11911.904000000004,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",472,81920.0,0.0,163840.0,0,0.0,163840.0,163840.0,0.0,2560.0,0.0,163840.0,163840.0,6.272,11918.176000000005,0.0,0.0,0.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1280.0,0.0,81920.0,81920.0,4.448,11922.624000000005,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",474,655360.0,21790720.0,0.0,0,193273528320.0,21790720.0,193295319040.0,170240.0,320.0,0.99812382739212,409600.0,81920.0,20.48,11943.104000000005,16486400.0,3993600.0,655360.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,12800.0,2560.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",475,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,104704.0,3.072,11946.176000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3272.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",476,210535200.0,420659200.0,820800.0,0,0.0,421480000.0,421480000.0,4202400.0,1365892.0,0.7547018008394675,111711936.0,1663200.0,86.368,12032.544000000005,0.0,409600.0,210124800.0,410400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3490998.0,51975.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",477,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.352,12036.896000000006,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",478,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,12040.320000000007,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",479,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.04,12055.360000000008,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",480,421150720.0,849018880.0,3440640.0,0,0.0,852459520.0,852459520.0,3699200.0,3486720.0,0.5147844674029213,430763904.0,327680.0,154.656,12210.016000000009,3604480.0,6553600.0,419430400.0,1720320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13461372.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",481,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,12213.53600000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",482,0.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,12217.088000000009,0.0,163840.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",483,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,12220.640000000009,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",484,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1920.0,0.0,655360.0,327680.0,3.648,12224.288000000008,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",485,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,327680.0,327680.0,3.392,12227.680000000008,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,462299.0,1149878.0,40960.0,0,0.0,1190838.0,1190838.0,0.0,1280.0,0.0,327680.0,327680.0,3.552,12231.232000000007,81920.0,184320.0,441819.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",487,81920.0,163840.0,0.0,0,0.0,163840.0,163840.0,0.0,1280.0,0.0,327680.0,327680.0,3.52,12234.752000000008,0.0,0.0,81920.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.776,12238.528000000008,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,5120.0,0.0,0.0,105216.0,3.104,12241.632000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,3288.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",490,840172800.0,1679687680.0,1313280.0,0,0.0,1681000960.0,1681000960.0,16800000.0,5667316.0,0.7477528691010533,442515456.0,2661600.0,216.672,12458.304000000007,0.0,655360.0,839516160.0,656640.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13828608.0,83175.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",491,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,6400.0,0.0,102400.0,0.0,4.48,12462.784000000007,20480.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3200.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,12466.144000000008,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",493,117316.0,371956.0,9216.0,0,0.0,381172.0,381172.0,80.0,1768.0,0.04329004329004329,245760.0,82176.0,15.616,12481.760000000007,113200.0,33340.0,112708.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7680.0,2568.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",494,1046953936.0,2254747968.0,35381152.0,0,0.0,2290129120.0,2290129120.0,13494396.0,12162916.0,0.5259473790551403,1135702912.0,1415424.0,444.832,12926.592000000008,67545408.0,128675840.0,1029263360.0,17690576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,35490716.0,44232.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,12929.344000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.128,12933.472000000009,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,12936.83200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",498,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.68,12940.51200000001,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",499,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,12943.36000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54656.0,5.952,12949.312000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1708.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",501,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.256,12957.568000000008,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,6.048,12963.616000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",503,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,13200.0,82808.0,0.13748854262144822,5134848.0,0.0,8.064,12971.68000000001,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,5.92,12977.60000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",505,84800.0,0.0,169600.0,0,0.0,169600.0,169600.0,13200.0,82958.0,0.13727406976018636,5134848.0,0.0,8.384,12985.98400000001,0.0,0.0,0.0,84800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55040.0,6.048,12992.03200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1720.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",507,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,13200.0,82808.0,0.13748854262144822,5134848.0,128.0,8.128,13000.16000000001,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.968,13004.128000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,13007.200000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.568,13012.768000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",511,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,13015.71200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.664,13021.376000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",513,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,43870.0,13014.0,0.7712186203501863,831584.0,8960.0,9.184,13030.56000000001,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,280.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.672,13039.23200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,68512.0,6.176,13045.40800000001,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",516,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,13049.60000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",517,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,3.968,13053.56800000001,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.432,13060.000000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",519,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,13063.456000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28280.0,0.6995803898656185,2737216.0,1968416.0,15.392,13078.84800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85538.0,61513.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",521,0.0,0.0,0.0,0,0.0,0.0,0.0,17018.0,28246.0,0.37597207493814067,2728256.0,1672192.0,12.544,13091.39200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85258.0,52256.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28210.0,0.3518071735484019,2723392.0,2264992.0,12.928,13104.32000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85106.0,70781.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28198.0,0.3519042037279643,2715840.0,2430816.0,13.024,13117.34400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84870.0,75963.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.928,13122.27200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.456,13125.72800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15159.0,0.4945652173913043,1868704.0,1328160.0,9.952,13135.68000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58397.0,41505.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429952.0,2412352.0,5.376,13141.05600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75936.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",528,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1050688.0,752832.0,32.352,13173.40800000001,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32834.0,23526.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",529,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804224.0,613312.0,97.184,13270.59200000001,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,19166.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.712,13274.30400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.008,13277.312000000009,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,94112.0,11.552,13288.864000000009,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2941.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.128,13292.99200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",534,3122059.0,6655044.0,615334.0,0,0.0,7270378.0,7270378.0,528.0,6704.0,0.07300884955752213,1072064.0,753920.0,32.0,13324.99200000001,825232.0,201028.0,2814392.0,307667.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33502.0,23560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",535,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.824,13334.81600000001,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,13338.33600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",537,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.152,13347.48800000001,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,13350.94400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,13354.368000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",540,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.352,13358.720000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",541,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.0,13374.720000000012,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",542,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,13378.080000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.344,13383.424000000012,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,13386.688000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",545,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.352,13391.040000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",546,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.984,13397.024000000012,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",547,1256419.0,2010280.0,502558.0,0,0.0,2512838.0,2512838.0,0.0,4737.0,0.0,1608256.0,0.0,5.344,13402.368000000011,0.0,0.0,1005140.0,251279.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",548,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.624,13424.992000000011,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",549,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,13428.288000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",550,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,13431.584000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.064,13435.648000000012,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",552,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,13439.168000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",553,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,13443.008000000013,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",554,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,13445.824000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",555,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,13448.608000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,13451.904000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",557,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,13454.720000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.16,13458.880000000014,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",559,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.04,13465.920000000015,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",560,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,13469.216000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",561,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,13472.448000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",562,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.256,13476.704000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",563,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.736,13481.440000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",564,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,13484.832000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
