Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,2.944,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,11.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,15.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,4.128,19.168,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.512,23.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.28,28.96,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,32.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,35.328,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,38.016000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,41.34400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.648,44.99200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,48.192000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,51.552000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.128,55.680000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,58.78400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,62.304000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.616,65.92000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,21760.0,81920.0,6.08,72.00000000000001,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,680.0,2560.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,75.61600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,80.89600000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,84.60800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,4.0,88.60800000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.096,92.70400000000002,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.448,97.15200000000002,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.296,100.44800000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.128,104.57600000000002,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,107.84000000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.424,111.26400000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.888,121.15200000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.648,124.80000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.648,128.44800000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,133.12000000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.576,137.69600000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115792256.0,118176.0,55.168,192.86400000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618508.0,3693.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115821312.0,118688.0,49.696,242.56000000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619416.0,3709.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115833472.0,117568.0,52.256,294.81600000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619796.0,3674.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,299.52000000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.544,304.064,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.632,309.696,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.48,314.17600000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,317.63200000000006,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,322.36800000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.64,327.00800000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.24,333.24800000000005,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,337.9200000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,341.3760000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,27.968,369.3440000000001,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115792384.0,121280.0,46.624,415.96800000000013,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618512.0,3790.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,419.4880000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,422.8800000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.408,432.2880000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,435.6160000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,439.1360000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.8,443.9360000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.544,448.4800000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463359616.0,470912.0,177.728,626.2080000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14479988.0,14716.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.776,629.984,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463324800.0,478048.0,181.472,811.456,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478900.0,14939.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.52,814.976,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463328128.0,118176.0,173.92,988.896,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14479004.0,3693.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,992.256,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.232,995.4879999999999,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.056,1004.544,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,1008.0,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,1011.52,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.704,1016.2239999999999,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.608,1020.8319999999999,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115825152.0,117504.0,48.608,1069.4399999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619536.0,3672.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115800192.0,118176.0,50.368,1119.8079999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618756.0,3693.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115808512.0,119136.0,54.944,1174.7519999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619016.0,3723.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.448,1179.1999999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,1183.6799999999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.048,1189.7279999999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,1194.368,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,1197.7279999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,1202.3999999999999,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.672,1207.072,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.824,1212.896,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,1217.6,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,1221.088,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,27.872,1248.96,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115796224.0,117408.0,52.16,1301.1200000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618632.0,3669.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.264,1304.384,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.52,1307.904,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.664,1317.568,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1320.8319999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1324.0639999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.608,1328.6719999999998,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.448,1333.12,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463233280.0,467904.0,184.928,1518.0479999999998,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476040.0,14622.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.84,1521.8879999999997,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463195008.0,472032.0,184.192,1706.0799999999997,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14474844.0,14751.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.68,1709.7599999999998,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463607040.0,116384.0,175.392,1885.1519999999998,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14487720.0,3637.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,1888.5759999999998,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.456,1892.0319999999997,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.344,1901.3759999999997,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1904.5759999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1907.8399999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.768,1912.6079999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.768,1917.3759999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115800192.0,115392.0,52.928,1970.3039999999996,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618756.0,3606.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115809408.0,119840.0,50.848,2021.1519999999996,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619044.0,3745.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115792768.0,119104.0,52.16,2073.3119999999994,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618524.0,3722.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.48,2077.7919999999995,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,2082.2719999999995,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.176,2088.4479999999994,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,2093.1839999999993,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.616,2096.7999999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,2101.4079999999994,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.416,2105.8239999999996,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.824,2111.6479999999997,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.96,2116.6079999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,2120.064,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,28.096,2148.16,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115802752.0,115872.0,49.312,2197.4719999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618836.0,3621.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,2200.9919999999997,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.424,2204.4159999999997,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.152,2213.5679999999998,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2216.8639999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,2220.3839999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,2225.0559999999996,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.64,2229.6959999999995,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463155200.0,467904.0,180.864,2410.5599999999995,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14473600.0,14622.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.904,2414.4639999999995,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463256064.0,468480.0,181.344,2595.8079999999995,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476752.0,14640.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.488,2599.2959999999994,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463674752.0,120640.0,175.744,2775.0399999999995,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14489836.0,3770.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,2778.3359999999993,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.424,2781.7599999999993,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.12,2790.879999999999,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,2794.2399999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2797.631999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.8,2802.4319999999993,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.704,2807.1359999999995,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115772672.0,116320.0,52.0,2859.1359999999995,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3617896.0,3635.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115816832.0,116832.0,52.608,2911.7439999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619276.0,3651.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115806080.0,115840.0,51.968,2963.7119999999995,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618940.0,3620.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,2968.3199999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.672,2972.9919999999997,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.792,2978.7839999999997,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,2983.4239999999995,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,2986.7519999999995,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,2991.3919999999994,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.448,2995.8399999999992,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.048,3001.887999999999,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.8,3006.687999999999,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,3010.175999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,27.936,3038.111999999999,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115805952.0,117056.0,52.896,3091.0079999999994,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618936.0,3658.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,3094.3679999999995,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.488,3097.8559999999993,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.376,3107.2319999999995,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3110.5279999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3113.7919999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,3118.4639999999995,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.896,3123.3599999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463269632.0,465632.0,182.496,3305.8559999999998,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477176.0,14551.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.744,3309.6,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463325952.0,468832.0,181.568,3491.168,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478936.0,14651.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,3494.784,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463545472.0,120064.0,177.664,3672.4480000000003,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14485796.0,3752.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,3675.744,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.488,3679.232,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.76,3688.992,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3692.224,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3695.4880000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.736,3700.224,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.544,3704.768,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115818112.0,119712.0,50.944,3755.712,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619316.0,3741.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115804160.0,118752.0,53.824,3809.536,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618880.0,3711.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115807232.0,117600.0,51.488,3861.024,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618976.0,3675.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.544,3865.5679999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,3870.048,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.664,3875.712,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.48,3880.192,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,3883.648,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.896,3888.5440000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.544,3893.088,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.304,3899.3920000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,3904.0640000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,3907.552,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,27.904,3935.456,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115800320.0,118176.0,52.416,3987.8720000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618760.0,3693.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,3991.168,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.328,3994.496,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.184,4003.6800000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4007.0400000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,4010.4640000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.864,4015.3280000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.608,4019.9360000000006,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463371776.0,474848.0,179.296,4199.232000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14480368.0,14839.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.968,4203.200000000001,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463374208.0,474560.0,181.12,4384.320000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14480444.0,14830.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.68,4388.000000000001,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463935744.0,114784.0,171.072,4559.072000000001,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14497992.0,3587.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.648,4562.720000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.264,4565.984000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.408,4575.392000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4578.720000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4582.0480000000025,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.64,4586.688000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.512,4591.200000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115821184.0,115776.0,53.888,4645.0880000000025,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619412.0,3618.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115807488.0,118016.0,52.224,4697.312000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618984.0,3688.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115825152.0,117664.0,52.544,4749.8560000000025,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619536.0,3677.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,4754.464000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.352,4758.8160000000025,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.112,4764.928000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,4769.568000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,4772.928000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,4777.632000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.448,4782.080000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.664,4787.744000000002,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.48,4792.224000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.648,4795.872000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,27.872,4823.744000000002,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115801984.0,118112.0,52.032,4875.776000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618812.0,3691.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,4879.232000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.744,4882.976000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.696,4892.672000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,4896.096000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4899.360000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.576,4903.936000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.736,4908.672000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463236992.0,471808.0,180.064,5088.736000000003,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476156.0,14744.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.84,5092.576000000003,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463242240.0,474400.0,181.952,5274.528000000003,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476320.0,14825.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.584,5278.112000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463741312.0,118816.0,177.408,5455.520000000003,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14491916.0,3713.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,5458.816000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.424,5462.240000000003,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.344,5471.5840000000035,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,5474.816000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,5478.112000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.768,5482.880000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.768,5487.648000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115811328.0,117472.0,52.448,5540.096000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619104.0,3671.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115823616.0,116480.0,49.312,5589.408000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619488.0,3640.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115838080.0,120320.0,49.76,5639.168000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619940.0,3760.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.512,5643.680000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.416,5648.096000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.664,5653.760000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,5658.400000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,5661.856000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.576,5666.432000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.384,5670.816000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.24,5677.056000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,5681.760000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,5685.088000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,28.192,5713.280000000004,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115779840.0,117248.0,53.472,5766.752000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618120.0,3664.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,5770.112000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,5773.5040000000035,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.344,5782.848000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,5786.176000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,5789.504000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.704,5794.208000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.64,5798.8480000000045,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463271296.0,473664.0,181.152,5980.000000000005,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477228.0,14802.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.872,5983.872000000005,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463273344.0,471776.0,179.84,6163.712000000005,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477292.0,14743.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,6167.328000000005,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463427840.0,119200.0,180.896,6348.224000000005,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14482120.0,3725.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,6351.648000000005,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,6355.0400000000045,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.248,6364.288000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,6367.648000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,6371.168000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,6375.840000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.48,6380.320000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115813248.0,114656.0,51.424,6431.744000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619164.0,3583.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115795712.0,117312.0,51.584,6483.328000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618616.0,3666.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115815296.0,118432.0,52.448,6535.7760000000035,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619228.0,3701.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,6540.384000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.544,6544.9280000000035,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.208,6551.136000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.768,6555.904000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,6559.296000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.928,6564.224000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,6568.704000000002,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.76,6574.464000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,6579.136000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,6582.6240000000025,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,327680.0,29419520.0,0.0,0,322122547200.0,29419520.0,322151966720.0,166400.0,320.0,0.9980806142034548,245760.0,81920.0,28.0,6610.6240000000025,24801280.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,7680.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115821312.0,113536.0,53.248,6663.872000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619416.0,3548.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.264,6667.136000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.52,6670.656000000003,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.664,6680.320000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,6683.648000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,6687.072000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.832,6691.904000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.704,6696.608000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463201536.0,468672.0,182.56,6879.168000000003,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475048.0,14646.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.872,6883.040000000004,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463199488.0,471328.0,181.536,7064.576000000004,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14474984.0,14729.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.584,7068.1600000000035,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463641472.0,120160.0,176.192,7244.3520000000035,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14488796.0,3755.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,7247.840000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.424,7251.264000000004,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.632,7260.896000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,7264.128000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,7267.424000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.512,7271.936000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.48,7276.416000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,666624000.0,1435648000.0,22528000.0,0,0.0,1458176000.0,1458176000.0,8592000.0,7744000.0,0.5259549461312438,724257664.0,742368.0,292.256,7568.672000000003,43008000.0,81920000.0,655360000.0,11264000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22633052.0,23199.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,7571.424000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.448,7575.872000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,7579.168000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.648,7582.816000000004,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.2,7586.016000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34176.0,5.824,7591.840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1068.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.464,7598.304000000004,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34560.0,5.984,7604.288000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1080.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,8448.0,34568.0,0.19639204017109912,2109440.0,0.0,6.464,7610.752000000004,0.0,0.0,0.0,57344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34560.0,5.696,7616.448000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1080.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.432,7622.880000000004,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,5.632,7628.512000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,8448.0,34824.0,0.19523017193566278,2109440.0,128.0,6.464,7634.976000000003,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.128,7639.104000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,7641.984000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.408,7647.3920000000035,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,7650.496000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.536,7656.032000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,34276.0,8416.0,0.8028670476904338,527232.0,7136.0,8.896,7664.9280000000035,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,223.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.32,7673.248000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42464.0,6.048,7679.296000000003,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1327.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.584,7682.880000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.648,7686.528000000003,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.76,7692.288000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,7695.808000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17659.0,0.7024449424570745,1711104.0,1302432.0,14.784,7710.592000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53472.0,40701.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17664.0,0.34953601414052143,1697280.0,1560576.0,11.104,7721.696000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53040.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17586.0,0.3804692454026633,1692672.0,1211776.0,13.024,7734.720000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52896.0,37868.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,9396.0,17594.0,0.34812893664320116,1690624.0,1560576.0,12.768,7747.488000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52832.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.672,7752.1600000000035,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,7755.648000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9403.0,0.5285771583274842,1164288.0,849440.0,9.056,7764.704000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36384.0,26545.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549632.0,1536000.0,4.896,7769.600000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48426.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,515584.0,512000.0,23.232,7792.832000000003,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16112.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.392,7856.224000000003,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,7859.776000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,7862.976000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,60512.0,11.968,7874.944000000002,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1891.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.712,7878.656000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994572.0,4245120.0,405144.0,0,0.0,4650264.0,4650264.0,528.0,5248.0,0.09141274238227147,516096.0,512000.0,22.816,7901.4720000000025,533120.0,128000.0,1792000.0,202572.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.256,7933.728000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,7937.0880000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.256,7969.344000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,7972.704000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,7976.224000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,7980.832000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.904,7992.7360000000035,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,7996.256000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.12,8001.376000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,8004.672000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.8,8009.472000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,8014.592000000004,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799820.0,1280000.0,319640.0,0,0.0,1599640.0,1599640.0,0.0,3000.0,0.0,1024000.0,0.0,5.152,8019.744000000004,0.0,0.0,640000.0,159820.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.512,8036.256000000004,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,8039.712000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,8043.104000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,8046.976000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,8050.304000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.288,8054.592000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,8057.440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8060.160000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,8063.584000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,8066.496000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.936,8070.432000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.296,8077.728000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,8081.184000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8084.544000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.064,8088.608000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.704,8093.312000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,8096.768000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,8100.192000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.704,8104.896000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.968,8108.864000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.168,8112.032000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.2,8115.232000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.232,8118.464000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,4.0,8122.464000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,5120.0,0.0,10240.0,0,0.0,10240.0,10240.0,0.0,1920.0,0.0,83200.0,81920.0,7.232,8129.696000000004,0.0,0.0,0.0,5120.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2600.0,2560.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.744,8133.440000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.024,8138.464000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,8141.856000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.488,8145.344000000004,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.128,8149.472000000003,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.224,8153.696000000004,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.456,8157.152000000004,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.16,8161.3120000000035,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,8164.576000000004,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.2,8167.7760000000035,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.376,8177.152000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,8180.576000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,8183.808000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.64,8188.448000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.576,8193.024000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115815168.0,117472.0,52.8,8245.824000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619224.0,3671.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115821696.0,115648.0,52.096,8297.920000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619428.0,3614.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115798912.0,118208.0,51.776,8349.696000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618716.0,3694.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,8354.400000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,8358.880000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.696,8364.576000000001,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,8369.248000000001,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,8372.640000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,8377.28,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.448,8381.728000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.568,8387.296,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.544,8391.84,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,8395.136,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.8,8399.936,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.704,8404.64,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,327328.0,29428836.0,0.0,0,322122547200.0,29428836.0,322151976036.0,166421.0,320.0,0.9980808559382516,409600.0,81920.0,27.808,8432.448,24811333.0,3962847.0,327328.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115795968.0,120672.0,49.056,8481.504,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618624.0,3771.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,8484.960000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.2,8488.160000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.664,8497.824000000002,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,8501.280000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,8504.544000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.576,8509.12,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.608,8513.728000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463239168.0,470688.0,183.456,8697.184000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476224.0,14709.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.808,8700.992000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463363200.0,465472.0,183.936,8884.928000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14480100.0,14546.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.616,8888.544000000002,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463959552.0,117024.0,171.296,9059.840000000002,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14498736.0,3657.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.648,9063.488000000001,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.616,9067.104000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.408,9076.512,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,9079.872000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,9083.168000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.544,9087.712000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.608,9092.320000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115799168.0,117888.0,50.528,9142.848000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618724.0,3684.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115777152.0,116736.0,51.84,9194.688000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618036.0,3648.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115815168.0,117472.0,50.56,9245.248000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619224.0,3671.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,9249.984000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.576,9254.560000000001,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.696,9260.256000000001,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,9264.992000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,9268.416000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,9273.056000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.672,9277.728000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.76,9283.488000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.832,9288.320000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.616,9291.936000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.8,9296.736000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.704,9301.440000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,327520.0,29429340.0,0.0,0,322122547200.0,29429340.0,322151976540.0,166406.0,320.0,0.9980806832767535,409600.0,81920.0,27.904,9329.344000000003,24811435.0,3962865.0,327520.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115799040.0,119680.0,51.072,9380.416000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618720.0,3740.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,9383.776000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,9387.168000000003,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.472,9396.640000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,9400.000000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,9403.296000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,9407.968000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.576,9412.544000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463204096.0,468192.0,183.136,9595.680000000004,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475128.0,14631.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.776,9599.456000000004,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463206144.0,468192.0,184.768,9784.224000000004,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475192.0,14631.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.584,9787.808000000005,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463836032.0,116960.0,180.8,9968.608000000004,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14494876.0,3655.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,9971.968000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.232,9975.200000000004,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.472,9984.672000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,9987.936000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,9991.200000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.768,9995.968000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.672,10000.640000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115793664.0,118208.0,50.272,10050.912000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618552.0,3694.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115815680.0,117024.0,49.248,10100.160000000003,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619240.0,3657.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115805184.0,120352.0,51.424,10151.584000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618912.0,3761.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.576,10156.160000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.352,10160.512000000004,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.208,10166.720000000005,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.832,10171.552000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,10175.040000000005,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,10179.680000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.416,10184.096000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.984,10190.080000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,10194.688000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,10198.176000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.64,10202.816000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.704,10207.520000000002,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,327584.0,29429508.0,0.0,0,322122547200.0,29429508.0,322151976708.0,166403.0,320.0,0.9980806487407257,409600.0,81920.0,28.192,10235.712000000001,24811469.0,3962871.0,327584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115797888.0,117632.0,49.888,10285.600000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618684.0,3676.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,10289.120000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.328,10292.448000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.664,10302.112000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,10305.408000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,10308.672000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.512,10313.184000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.576,10317.760000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463163392.0,470240.0,182.688,10500.448000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14473856.0,14695.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.84,10504.288000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463193088.0,467904.0,184.608,10688.896000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14474784.0,14622.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.52,10692.416000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463655808.0,114880.0,175.936,10868.352000000003,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14489244.0,3590.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,10871.744000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.264,10875.008000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.568,10884.576000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,10888.128,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,10891.552000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.512,10896.064000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.544,10900.608000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115816064.0,116512.0,50.752,10951.360000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619252.0,3641.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115827968.0,117088.0,51.168,11002.528000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619624.0,3659.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115817472.0,118592.0,50.784,11053.312000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619296.0,3706.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.512,11057.824000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.704,11062.528000000002,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.272,11068.800000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,11073.504000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.52,11077.024000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.928,11081.952000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.608,11086.560000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.016,11092.576000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,11097.216000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,11100.672000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.736,11105.408000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.608,11110.016000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,327584.0,29429508.0,0.0,0,322122547200.0,29429508.0,322151976708.0,166403.0,320.0,0.9980806487407257,409600.0,81920.0,28.16,11138.176000000003,24811469.0,3962871.0,327584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115823232.0,121600.0,50.432,11188.608000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619476.0,3800.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,11191.936000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.36,11195.296000000004,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.472,11204.768000000004,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,11208.128000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,11211.424000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.672,11216.096000000005,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.672,11220.768000000005,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463336704.0,474720.0,184.576,11405.344000000005,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14479272.0,14835.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.808,11409.152000000006,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463231616.0,467328.0,179.808,11588.960000000006,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14475988.0,14604.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,11592.512000000006,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463825152.0,118464.0,176.384,11768.896000000006,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14494536.0,3702.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,11772.224000000006,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.2,11775.424000000006,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.984,11785.408000000007,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,11788.768000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,11792.032000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.768,11796.800000000007,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.832,11801.632000000007,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115795456.0,117760.0,52.384,11854.016000000007,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618608.0,3680.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115817344.0,116864.0,52.192,11906.208000000006,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619292.0,3652.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115813504.0,118368.0,48.992,11955.200000000006,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619172.0,3699.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.864,11960.064000000006,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.48,11964.544000000005,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.112,11970.656000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,11975.328000000005,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,11978.816000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,11983.520000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.672,11988.192000000005,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.112,11994.304000000004,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.544,11998.848000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,12002.304000000004,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.608,12006.912000000004,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.832,12011.744000000004,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,327680.0,29429760.0,0.0,0,322122547200.0,29429760.0,322151976960.0,166400.0,320.0,0.9980806142034548,409600.0,81920.0,28.0,12039.744000000004,24811520.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115819776.0,118144.0,48.32,12088.064000000004,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619368.0,3692.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,12091.488000000005,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.232,12094.720000000005,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.76,12104.480000000005,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,12107.744000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,12111.008000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.608,12115.616000000004,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.64,12120.256000000003,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463141376.0,470624.0,183.392,12303.648000000003,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14473168.0,14707.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.872,12307.520000000002,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,462980608.0,467872.0,188.928,12496.448000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14468144.0,14621.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.52,12499.968000000003,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463903616.0,118272.0,175.008,12674.976000000002,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14496988.0,3696.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,12678.272000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,12681.664000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.76,12691.424000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,12694.976000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,12698.368000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.8,12703.168000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.512,12707.680000000002,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115791360.0,115840.0,53.856,12761.536000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618480.0,3620.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115796352.0,120256.0,52.864,12814.400000000001,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618636.0,3758.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115802496.0,118304.0,52.608,12867.008000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618828.0,3697.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,12871.744000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.32,12876.064000000002,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.664,12881.728000000003,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,12886.400000000003,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,12889.728000000003,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,12894.464000000004,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.576,12899.040000000003,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.728,12904.768000000002,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,12909.440000000002,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,12912.832000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.672,12917.504000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.768,12922.272000000003,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,327680.0,29429760.0,0.0,0,322122547200.0,29429760.0,322151976960.0,166400.0,320.0,0.9980806142034548,409600.0,81920.0,28.096,12950.368000000002,24811520.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115815168.0,116800.0,50.688,13001.056000000002,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619224.0,3650.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.488,13004.544000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.328,13007.872000000001,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.696,13017.568000000001,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,13020.896,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,13024.192000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.544,13028.736,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.672,13033.408000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463315200.0,469952.0,181.76,13215.168000000001,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478600.0,14686.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,4.032,13219.2,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463403008.0,469408.0,185.12,13404.320000000002,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14481344.0,14669.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.488,13407.808,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463709184.0,119872.0,175.744,13583.552000000001,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14490912.0,3746.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,13587.008000000002,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.52,13590.528000000002,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.44,13599.968000000003,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,13603.264000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,13606.528000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.576,13611.104000000001,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.48,13615.584,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115792768.0,117344.0,50.496,13666.08,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618524.0,3667.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115810944.0,120096.0,51.456,13717.536,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619092.0,3753.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115783936.0,118112.0,51.872,13769.408,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618248.0,3691.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,13774.047999999999,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.352,13778.4,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.6,13784.0,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.64,13788.64,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.552,13792.192,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,13796.8,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.512,13801.312,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.472,13806.784,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.704,13811.488,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.36,13814.848,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.832,13819.68,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.96,13824.64,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,327680.0,29429760.0,0.0,0,322122547200.0,29429760.0,322151976960.0,166400.0,320.0,0.9980806142034548,409600.0,81920.0,27.968,13852.608,24811520.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115794176.0,118400.0,51.392,13904.0,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618568.0,3700.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,13907.328,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.456,13910.784,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.408,13920.192,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,13923.455999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,13926.719999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.576,13931.295999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.512,13935.807999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463259008.0,472576.0,178.464,14114.271999999997,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14476844.0,14768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.872,14118.143999999997,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463344000.0,464672.0,180.96,14299.103999999996,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14479500.0,14521.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.552,14302.655999999995,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463607296.0,119584.0,187.04,14489.695999999996,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14487728.0,3737.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.456,14493.151999999996,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.392,14496.543999999996,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.312,14505.855999999996,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,14509.183999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,14512.479999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.64,14517.119999999995,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.896,14522.015999999996,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115813504.0,119936.0,50.208,14572.223999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3619172.0,3748.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115799296.0,117920.0,52.448,14624.671999999997,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618728.0,3685.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115787392.0,118496.0,51.2,14675.871999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3618356.0,3703.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.672,14680.543999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.544,14685.087999999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,6.144,14691.231999999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.8,14696.031999999997,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.328,14699.359999999997,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.736,14704.095999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,15360.0,10240.0,30720.0,0,0.0,40960.0,40960.0,0.0,640.0,0.0,40960.0,40960.0,4.544,14708.639999999998,10240.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,1280.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,0.0,1280.0,0.0,81920.0,81920.0,5.984,14714.623999999998,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,40960.0,20480.0,81920.0,0,0.0,102400.0,102400.0,0.0,1920.0,0.0,122880.0,81920.0,4.608,14719.231999999998,0.0,20480.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3840.0,2560.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.424,14722.655999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.64,14727.295999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1600.0,0.0,163840.0,163840.0,4.64,14731.935999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,5120.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,327680.0,29429760.0,0.0,0,322122547200.0,29429760.0,322151976960.0,166400.0,320.0,0.9980806142034548,409600.0,81920.0,28.128,14760.063999999998,24811520.0,3962880.0,327680.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1258291200.0,12800.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,106659840.0,229703680.0,3604480.0,0,0.0,233308160.0,233308160.0,1374720.0,1239040.0,0.5259549461312438,115847552.0,117792.0,47.392,14807.455999999998,6881280.0,13107200.0,104857600.0,1802240.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3620236.0,3681.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.296,14810.751999999999,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.232,14813.983999999999,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.408,14823.391999999998,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,14826.943999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,14830.271999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.48,14834.751999999997,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.576,14839.327999999996,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463311232.0,470464.0,183.36,15022.687999999996,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14478476.0,14702.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,1024000.0,1966080.0,163840.0,0,0.0,2129920.0,2129920.0,0.0,1280.0,0.0,327680.0,327680.0,3.904,15026.591999999997,81920.0,0.0,942080.0,81920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10240.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,426639360.0,918814720.0,14417920.0,0,0.0,933232640.0,933232640.0,5498880.0,4956160.0,0.5259549461312438,463287168.0,473984.0,182.336,15208.927999999996,27525120.0,52428800.0,419430400.0,7208960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14477724.0,14812.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,81920.0,0.0,0,0.0,81920.0,81920.0,0.0,1920.0,0.0,655360.0,327680.0,3.68,15212.607999999997,0.0,81920.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20480.0,10240.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,426147840.0,917831680.0,13434880.0,0,0.0,931266560.0,931266560.0,5368320.0,4925440.0,0.5215120616761999,463664384.0,119328.0,172.416,15385.023999999996,26542080.0,52428800.0,419430400.0,6717440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14489512.0,3729.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,20480.0,40960.0,0.0,0,0.0,40960.0,40960.0,0.0,480.0,0.0,163840.0,81920.0,3.392,15388.415999999996,0.0,0.0,20480.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,20480.0,0.0,0,0.0,20480.0,20480.0,0.0,320.0,0.0,81920.0,81920.0,3.36,15391.775999999996,0.0,20480.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,24964.0,4096.0,0,0.0,29060.0,29060.0,40.0,164.0,0.19607843137254902,81920.0,32.0,9.888,15401.663999999997,24960.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2560.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,15405.151999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,15408.447999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,84480.0,81920.0,4.8,15413.247999999996,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2640.0,2560.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,20480.0,20480.0,40960.0,0,0.0,61440.0,61440.0,0.0,1920.0,0.0,163840.0,81920.0,4.704,15417.951999999996,0.0,20480.0,0.0,20480.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5120.0,2560.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,666624000.0,1435648000.0,22528000.0,0,0.0,1458176000.0,1458176000.0,8592000.0,7744000.0,0.5259549461312438,723608320.0,730560.0,293.664,15711.615999999996,43008000.0,81920000.0,655360000.0,11264000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,22612760.0,22830.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,15714.367999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.808,15718.175999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,15721.375999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.552,15724.927999999998,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,15727.839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33408.0,5.792,15733.631999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1044.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.304,15739.935999999998,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33600.0,5.92,15745.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1050.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,8448.0,34568.0,0.19639204017109912,2109440.0,0.0,6.24,15752.095999999998,0.0,0.0,0.0,57344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33600.0,5.824,15757.919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1050.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,8448.0,35112.0,0.19393939393939394,2109440.0,0.0,6.656,15764.576,0.0,0.0,0.0,39936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33856.0,5.696,15770.271999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1058.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,45056.0,0.0,90112.0,0,0.0,90112.0,90112.0,8448.0,34952.0,0.19465437788018433,2109440.0,128.0,6.336,15776.607999999998,0.0,0.0,0.0,45056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.032,15780.639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,15783.775999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.216,15788.991999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,15791.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.312,15797.183999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,29643.0,8422.0,0.7787468803362669,527232.0,7392.0,8.832,15806.015999999998,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,231.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.352,15814.367999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,41440.0,6.016,15820.383999999998,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1295.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.648,15824.031999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.552,15827.583999999997,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.632,15833.215999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,15836.639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17678.0,0.7022201259980461,1702400.0,1275360.0,15.232,15851.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53200.0,39855.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17669.0,0.3494716689370789,1694464.0,1560576.0,11.552,15863.423999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52952.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17578.0,0.3805765029248009,1696384.0,1438272.0,13.184,15876.607999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53012.0,44946.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17632.0,0.3798536859876196,1690880.0,1546016.0,12.96,15889.567999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52840.0,48313.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.768,15894.335999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,15897.759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9420.0,0.5281270350147773,1159808.0,855040.0,9.024,15906.783999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36244.0,26720.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549248.0,1536000.0,4.896,15911.679999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48414.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,23.04,15934.719999999998,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,62.784,15997.503999999997,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,16001.055999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.136,16004.191999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,58624.0,11.712,16015.903999999997,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1832.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.52,16019.423999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994567.0,4245120.0,405134.0,0,0.0,4650254.0,4650254.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.816,16042.239999999998,533120.0,128000.0,1792000.0,202567.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.384,16074.623999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,16077.919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.928,16110.847999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,16114.463999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,16118.047999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.672,16122.72,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.712,16134.431999999999,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,16137.759999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,16142.911999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,16146.112,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,16150.687999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.056,16155.743999999999,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799815.0,1280000.0,319630.0,0,0.0,1599630.0,1599630.0,0.0,3000.0,0.0,1024000.0,0.0,5.152,16160.895999999999,0.0,0.0,640000.0,159815.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.64,16177.535999999998,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,16180.767999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,16184.159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.032,16188.191999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,16191.519999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,16195.359999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,16198.207999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,16201.087999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,16204.703999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,16207.551999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.872,16211.423999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.616,16219.039999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,16222.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,16225.983999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.384,16230.367999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,16234.975999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,16238.463999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
