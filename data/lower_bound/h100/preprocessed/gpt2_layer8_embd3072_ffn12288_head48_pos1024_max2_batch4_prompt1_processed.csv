Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.592,5.3759999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.712,18.72,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.256,22.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.024,28.0,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.936,31.936,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,34.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,37.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,40.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.968,44.416,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,48.096,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,51.647999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.128,55.775999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,59.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,62.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.424,65.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,13056.0,49152.0,5.92,71.616,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,408.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,13056.0,49152.0,6.08,77.696,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,81.024,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,84.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.992,89.44000000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.688,100.12800000000001,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119777280.0,147456.0,72.256,172.38400000000001,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743040.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.96,177.34400000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.544,181.88800000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,186.46400000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,17.024,203.48800000000003,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),31,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.96,252.44800000000004,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",32,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.992,257.44000000000005,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,261.02400000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.784,271.80800000000005,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157558400.0,196608.0,75.808,347.61600000000004,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923700.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.488,351.10400000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.52,354.624,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,357.88800000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,361.28000000000003,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.616,364.896,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,282612.0,700392.0,24576.0,0,0.0,724968.0,724968.0,0.0,768.0,0.0,196608.0,196608.0,3.456,368.35200000000003,49152.0,110592.0,270324.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.232,371.58400000000006,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,375.0400000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",44,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,63872.0,2.912,377.95200000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1996.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",45,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1910403.0,0.7599977839026153,161545536.0,1596640.0,132.128,510.08000000000004,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5048298.0,49895.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",46,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.192,514.272,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.68,517.952,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",48,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.624,528.576,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",49,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119776768.0,147456.0,71.04,599.616,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743024.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.448,604.064,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,608.64,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.512,613.1519999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",53,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.584,628.7359999999999,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),54,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.96,677.6959999999999,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",55,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.928,682.6239999999999,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",56,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,686.016,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",57,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.88,696.896,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157568768.0,196608.0,77.472,774.3679999999999,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924024.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.36,777.728,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",60,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,781.088,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.52,784.608,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,787.968,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",63,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.424,791.3919999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,281976.0,699120.0,24576.0,0,0.0,723696.0,723696.0,0.0,768.0,0.0,196608.0,196608.0,3.584,794.9759999999999,49152.0,110592.0,269688.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.296,798.2719999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",66,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,801.728,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61952.0,3.008,804.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1936.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",68,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2054444.0,0.7464895026888023,161589088.0,1597024.0,128.64,933.376,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5049659.0,49907.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",69,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.16,937.536,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,940.896,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",71,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.848,951.7439999999999,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119777664.0,147456.0,71.232,1022.9759999999999,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743052.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.512,1027.4879999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.608,1032.0959999999998,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.512,1036.6079999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",76,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.424,1052.0319999999997,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),77,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.608,1100.6399999999996,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.96,1105.5999999999997,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,1109.1839999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",80,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.944,1120.1279999999997,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157558016.0,196608.0,76.352,1196.4799999999998,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923688.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.232,1199.7119999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",83,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.392,1203.1039999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",84,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,1206.3679999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,1209.7279999999996,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",86,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,1213.1839999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",87,282488.0,700144.0,24576.0,0,0.0,724720.0,724720.0,0.0,768.0,0.0,196608.0,196608.0,3.552,1216.7359999999994,49152.0,110592.0,270200.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.424,1220.1599999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",89,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,1223.6159999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",90,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61824.0,2.976,1226.5919999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1932.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",91,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1912920.0,0.7597575421452878,161598080.0,1596800.0,129.856,1356.4479999999994,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5049940.0,49900.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",92,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.256,1360.7039999999995,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1364.1599999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",94,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.88,1375.0399999999995,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",95,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119779712.0,147456.0,70.912,1445.9519999999995,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743116.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",96,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.416,1450.3679999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",97,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.416,1454.7839999999994,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.448,1459.2319999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",99,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.744,1474.9759999999994,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),100,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.768,1523.7439999999995,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",101,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.832,1528.5759999999996,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",102,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1532.0959999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",103,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.592,1542.6879999999996,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157570560.0,196608.0,75.616,1618.3039999999996,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924080.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",105,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,1621.5679999999995,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",106,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,1624.9279999999994,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",107,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,1628.1919999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,1631.5199999999993,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",109,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.52,1635.0399999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",110,282436.0,700040.0,24576.0,0,0.0,724616.0,724616.0,0.0,768.0,0.0,196608.0,196608.0,3.552,1638.5919999999992,49152.0,110592.0,270148.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",111,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.328,1641.9199999999992,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",112,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,1645.5359999999991,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",113,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61056.0,2.912,1648.4479999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1908.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",114,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1907438.0,0.7602809811870693,161671616.0,1596864.0,131.232,1779.6799999999992,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5052238.0,49902.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",115,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.096,1783.7759999999992,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,1787.1679999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",117,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.528,1797.6959999999992,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119774592.0,147456.0,71.424,1869.1199999999992,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742956.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",119,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.544,1873.6639999999993,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,1878.2399999999993,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,1882.8159999999993,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",122,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.68,1898.4959999999994,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),123,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.704,1947.1999999999994,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",124,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.768,1951.9679999999994,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",125,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,1955.2319999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",126,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.72,1965.9519999999993,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157580032.0,196608.0,75.648,2041.5999999999992,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924376.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",128,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.52,2045.1199999999992,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",129,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.264,2048.383999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",130,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.424,2051.807999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,2055.135999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",132,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,2058.399999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",133,282252.0,699672.0,24576.0,0,0.0,724248.0,724248.0,0.0,768.0,0.0,196608.0,196608.0,3.456,2061.8559999999993,49152.0,110592.0,269964.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.456,2065.3119999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",135,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,2068.8319999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",136,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,63872.0,2.944,2071.7759999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1996.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",137,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2039136.0,0.7479022514449838,161329024.0,1596672.0,131.36,2203.1359999999995,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5041532.0,49896.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",138,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.192,2207.3279999999995,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",139,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,2210.7519999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",140,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.56,2221.3119999999994,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119775360.0,147456.0,70.816,2292.1279999999992,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742980.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.64,2296.767999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.48,2301.247999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,2305.823999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",145,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.68,2321.503999999999,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),146,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.608,2370.111999999999,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",147,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.896,2375.0079999999994,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,2378.3679999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",149,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.688,2389.0559999999996,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",150,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157569664.0,196608.0,76.768,2465.8239999999996,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924052.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",151,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,2469.2799999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",152,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.296,2472.5759999999996,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",153,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.296,2475.8719999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",154,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,2479.3279999999995,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",155,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,2482.7839999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",156,282348.0,699864.0,24576.0,0,0.0,724440.0,724440.0,0.0,768.0,0.0,196608.0,196608.0,3.424,2486.2079999999996,49152.0,110592.0,270060.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",157,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.488,2489.6959999999995,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",158,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,2493.3119999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",159,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61696.0,3.008,2496.3199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1928.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",160,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1909590.0,0.7600754153157018,161284544.0,1596800.0,129.28,2625.5999999999995,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5040142.0,49900.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",161,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.16,2629.7599999999993,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,2633.2799999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",163,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.784,2644.0639999999994,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119775360.0,147456.0,71.168,2715.2319999999995,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742980.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.48,2719.7119999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.608,2724.3199999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.672,2728.9919999999997,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",168,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.776,2744.7679999999996,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),169,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.608,2793.3759999999997,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",170,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.8,2798.176,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,2801.536,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",172,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.784,2812.32,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157562112.0,196608.0,75.712,2888.032,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923816.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",174,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.584,2891.616,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",175,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.328,2894.944,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",176,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.488,2898.432,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",177,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,2901.9199999999996,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",178,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.36,2905.2799999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,282728.0,700624.0,24576.0,0,0.0,725200.0,725200.0,0.0,768.0,0.0,196608.0,196608.0,3.584,2908.8639999999996,49152.0,110592.0,270440.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",180,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.296,2912.1599999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",181,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,2915.6479999999992,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",182,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,62464.0,3.04,2918.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1952.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",183,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1896951.0,0.7612843260172703,161238752.0,1596672.0,128.928,3047.615999999999,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5038711.0,49896.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",184,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.192,3051.807999999999,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,3055.071999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",186,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.816,3065.887999999999,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",187,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119777024.0,147456.0,71.04,3136.927999999999,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743032.0,4608.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.416,3141.343999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.608,3145.9519999999993,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.64,3150.591999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",191,393216.0,13062144.0,0.0,0,115964116992.0,13062144.0,115977179136.0,102144.0,192.0,0.99812382739212,147456.0,49152.0,15.712,3166.303999999999,9879552.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),192,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.576,3214.879999999999,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.992,3219.8719999999994,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",194,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,3223.3279999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",195,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.816,3234.1439999999993,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157581696.0,196608.0,75.744,3309.8879999999995,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924428.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",197,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.584,3313.4719999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",198,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.456,3316.9279999999994,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",199,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.328,3320.2559999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,3323.8719999999994,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",201,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.328,3327.1999999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",202,282284.0,699736.0,24576.0,0,0.0,724312.0,724312.0,0.0,768.0,0.0,196608.0,196608.0,3.424,3330.6239999999993,49152.0,110592.0,269996.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",203,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.392,3334.015999999999,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",204,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,3337.343999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,63232.0,2.944,3340.287999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1976.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",206,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1942196.0,0.7569743329731278,161246720.0,1596800.0,129.12,3469.407999999999,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5038960.0,49900.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",207,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.192,3473.599999999999,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",208,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3477.023999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",209,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.592,3487.615999999999,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",210,628815696.0,1354135360.0,22515360.0,0,0.0,1376650720.0,1376650720.0,8267516.0,7337956.0,0.5297831427335232,681339776.0,1410112.0,265.312,3752.927999999999,41813824.0,77205504.0,617558016.0,11257680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21291868.0,44066.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,3755.711999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.064,3759.775999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3763.039999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",214,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.712,3766.751999999999,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",215,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,3769.759999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54912.0,5.92,3775.679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1716.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",217,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.256,3783.935999999999,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,5.952,3789.887999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",219,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,0.0,8.064,3797.951999999999,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54208.0,5.824,3803.775999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1694.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",221,70400.0,0.0,140800.0,0,0.0,140800.0,140800.0,13200.0,83408.0,0.1366346472341835,5134848.0,0.0,8.192,3811.967999999999,0.0,0.0,0.0,70400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54528.0,5.952,3817.919999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1704.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",223,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,13200.0,83608.0,0.13635236757292785,5134848.0,128.0,8.096,3826.015999999999,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.616,3829.631999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,3832.639999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.504,3838.143999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.784,3840.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.76,3846.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",229,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,49036.0,13020.0,0.7901895062524171,831584.0,8320.0,9.088,3855.7759999999994,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,260.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.8,3864.5759999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,72224.0,6.08,3870.6559999999995,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2257.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.352,3875.0079999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",233,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.192,3879.1999999999994,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.336,3885.535999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.744,3889.2799999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28325.0,0.6992461244425568,2717632.0,1995808.0,15.136,3904.4159999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84926.0,62369.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28309.0,0.3342035325383946,2734272.0,2451264.0,11.52,3915.9359999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85446.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28179.0,0.35205794435502413,2705856.0,1895264.0,12.928,3928.863999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84558.0,59227.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,13907.0,28275.0,0.3296903892655635,2719296.0,2451264.0,13.024,3941.887999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84978.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",240,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.088,3946.975999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.296,3950.271999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15140.0,0.4948787241850999,1865632.0,1337856.0,9.76,3960.0319999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58301.0,41808.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",243,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429056.0,2412352.0,5.248,3965.2799999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75908.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",244,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1092160.0,753408.0,31.84,3997.1199999999994,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,34130.0,23544.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",245,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804224.0,615840.0,96.512,4093.6319999999996,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,19245.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.808,4097.44,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.04,4100.48,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,95264.0,11.648,4112.128,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2977.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.608,4116.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",250,3122056.0,6655044.0,615328.0,0,0.0,7270372.0,7270372.0,528.0,6704.0,0.07300884955752213,1083072.0,753792.0,32.32,4149.056,825232.0,201028.0,2814392.0,307664.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33846.0,23556.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",251,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.536,4158.592,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4162.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",253,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.248,4171.263999999999,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4174.687999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",255,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.552,4178.239999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,4182.815999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",257,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.968,4198.783999999999,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,4201.983999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",259,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,4207.135999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,4210.591999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,4215.039999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",262,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.112,4221.151999999999,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",263,1256416.0,2010280.0,502552.0,0,0.0,2512832.0,2512832.0,0.0,4737.0,0.0,1608256.0,0.0,5.344,4226.495999999999,0.0,0.0,1005140.0,251276.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",264,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.688,4249.183999999999,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,4252.415999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,4255.679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.84,4259.5199999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,4262.911999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",269,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.936,4266.847999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,4269.535999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,4272.351999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",272,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,4275.871999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,4278.5599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.744,4282.303999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",275,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.648,4289.951999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,4293.343999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,4296.575999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.872,4300.447999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,4305.472,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",280,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,4308.672,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",281,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4312.096,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",282,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.992,4317.088,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.0,4321.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",284,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.072,4324.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",285,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.456,4327.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",286,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.232,4330.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.52,4334.368,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",288,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,37632.0,49152.0,6.08,4340.448,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1176.0,1536.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",289,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,1152.0,0.0,13056.0,49152.0,5.312,4345.76,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,408.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",290,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,4349.376,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",291,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,4352.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",292,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.896,4357.568,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",293,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.752,4368.320000000001,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",294,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119775872.0,147456.0,71.648,4439.968000000001,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742996.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.792,4445.760000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",296,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.696,4451.456000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",297,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.48,4455.936000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",298,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.52,4471.456000000001,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),299,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,49.088,4520.544000000001,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.736,4525.280000000001,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,4528.704000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",302,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.976,4539.68,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",303,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157571584.0,196608.0,75.968,4615.648,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924112.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",304,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.328,4618.976000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",305,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,4622.336,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",306,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.488,4625.8240000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",307,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,4629.2480000000005,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,4632.512000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",309,282448.0,700064.0,24576.0,0,0.0,724640.0,724640.0,0.0,768.0,0.0,196608.0,196608.0,3.52,4636.032000000001,49152.0,110592.0,270160.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",310,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.456,4639.488000000001,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",311,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,4642.9760000000015,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,62592.0,2.944,4645.920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1956.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",313,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1919465.0,0.759133547605277,161285344.0,1596928.0,129.088,4775.008000000002,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5040167.0,49904.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",314,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.32,4779.328000000001,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",315,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,4782.7840000000015,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",316,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.624,4793.408000000001,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",317,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119778816.0,147456.0,70.976,4864.384000000001,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743088.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",318,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.24,4870.624000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",319,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.696,4876.320000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.576,4880.896000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",321,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.456,4896.352000000001,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),322,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.832,4945.184000000001,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",323,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.8,4949.984000000001,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4953.504000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",325,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.912,4964.416000000002,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",326,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157566464.0,196608.0,75.328,5039.744000000002,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923952.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",327,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.584,5043.328000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",328,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.552,5046.880000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",329,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.488,5050.368000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",330,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.712,5054.080000000003,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",331,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.296,5057.376000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,282340.0,699848.0,24576.0,0,0.0,724424.0,724424.0,0.0,768.0,0.0,196608.0,196608.0,3.488,5060.864000000003,49152.0,110592.0,270052.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",333,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.232,5064.096000000003,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",334,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,5067.616000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61824.0,2.912,5070.528000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1932.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",336,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2005051.0,0.7510671869333586,161443232.0,1596704.0,126.88,5197.408000000004,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5045101.0,49897.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",337,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.192,5201.600000000004,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,5204.960000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",339,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.688,5215.648000000004,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",340,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119779712.0,147456.0,70.816,5286.464000000004,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743116.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",341,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.92,5292.384000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.952,5298.336000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.48,5302.816000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",344,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.872,5318.688000000004,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),345,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,49.248,5367.936000000003,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",346,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.832,5372.768000000004,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",347,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.264,5376.032000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",348,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.912,5386.944000000004,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",349,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157554688.0,196608.0,74.912,5461.856000000004,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923584.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",350,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.616,5465.472000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",351,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,5468.832000000004,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,5472.288000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",353,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,5475.680000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",354,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.584,5479.264000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,282128.0,699424.0,24576.0,0,0.0,724000.0,724000.0,0.0,768.0,0.0,196608.0,196608.0,3.488,5482.752000000004,49152.0,110592.0,269840.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",356,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.264,5486.016000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,5489.504000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,62208.0,2.944,5492.448000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1944.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",359,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2018269.0,0.7498366656110305,161431872.0,1597088.0,125.92,5618.368000000005,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5044746.0,49909.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",360,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.128,5622.496000000005,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",361,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,5626.0800000000045,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",362,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.848,5636.928000000004,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",363,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119775104.0,147456.0,70.816,5707.744000000004,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742972.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",364,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.696,5713.440000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",365,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.952,5719.392000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.608,5724.000000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",367,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.968,5739.968000000004,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),368,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.96,5788.928000000004,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",369,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.864,5793.792000000004,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",370,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,5797.216000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",371,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.816,5808.032000000004,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",372,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157573888.0,196608.0,75.68,5883.712000000004,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924184.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",373,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.424,5887.136000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",374,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,5890.496000000004,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.584,5894.080000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",376,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,5897.536000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",377,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,5900.992000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",378,282385.0,699938.0,24576.0,0,0.0,724514.0,724514.0,0.0,768.0,0.0,196608.0,196608.0,3.52,5904.512000000004,49152.0,110592.0,270097.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",379,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,5907.872000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",380,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,5911.232000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,63488.0,2.976,5914.208000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1984.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",382,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1910495.0,0.759989000042839,161134016.0,1596832.0,128.48,6042.688000000003,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5035438.0,49901.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",383,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.16,6046.848000000003,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",384,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,6050.272000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",385,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.656,6060.928000000003,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",386,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119773312.0,147456.0,71.616,6132.544000000003,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742916.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",387,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.696,6138.2400000000025,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.76,6144.000000000003,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.512,6148.512000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",390,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.68,6164.192000000003,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),391,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.96,6213.152000000003,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",392,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,5.024,6218.176000000003,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",393,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,6221.728000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",394,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,11.104,6232.832000000003,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",395,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157569280.0,196608.0,75.456,6308.288000000003,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924040.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.392,6311.680000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",397,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.456,6315.136000000003,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.264,6318.400000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",399,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,6321.824000000003,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,6325.280000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",401,282346.0,699860.0,24576.0,0,0.0,724436.0,724436.0,0.0,768.0,0.0,196608.0,196608.0,3.648,6328.9280000000035,49152.0,110592.0,270058.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",402,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.456,6332.384000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,6335.872000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,63616.0,2.88,6338.752000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1988.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",405,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1919800.0,0.7591016365729842,161236800.0,1596704.0,129.728,6468.480000000004,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5038650.0,49897.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",406,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.256,6472.736000000004,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",407,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,6476.160000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",408,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,11.104,6487.264000000005,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119778304.0,147456.0,71.36,6558.624000000004,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743072.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",410,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.24,6564.864000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",411,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.728,6570.592000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.416,6575.008000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",413,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.552,6590.560000000004,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),414,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.896,6639.456000000004,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",415,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.8,6644.256000000004,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,6647.712000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,11.136,6658.8480000000045,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157572224.0,196608.0,76.384,6735.2320000000045,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924132.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",419,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.488,6738.720000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",420,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,6742.0800000000045,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",421,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.36,6745.440000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,6748.800000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.424,6752.224000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,282146.0,699460.0,24576.0,0,0.0,724036.0,724036.0,0.0,768.0,0.0,196608.0,196608.0,3.52,6755.744000000004,49152.0,110592.0,269858.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.584,6759.328000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.552,6762.880000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,61952.0,2.944,6765.824000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1936.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",428,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2017861.0,0.7498745878007491,161159392.0,1596768.0,126.208,6892.032000000004,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5036231.0,49899.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",429,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.0,6896.032000000004,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,6899.424000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",431,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.816,6910.240000000003,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",432,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119776512.0,147456.0,71.04,6981.280000000003,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3743016.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",433,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,6987.488000000003,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.984,6993.472000000003,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.48,6997.952000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",436,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.552,7013.504000000003,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),437,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,48.544,7062.0480000000025,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",438,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.832,7066.880000000003,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,7070.304000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",440,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.784,7081.0880000000025,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157570688.0,196608.0,75.488,7156.576000000003,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4924084.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",442,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.392,7159.968000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",443,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.36,7163.328000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",444,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.296,7166.6240000000025,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.552,7170.176000000002,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",446,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.392,7173.568000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,282542.0,700252.0,24576.0,0,0.0,724828.0,724828.0,0.0,768.0,0.0,196608.0,196608.0,3.424,7176.992000000002,49152.0,110592.0,270254.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",448,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.744,7180.736000000002,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",449,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.712,7184.448000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",450,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,62720.0,3.04,7187.488000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1960.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",451,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,2032158.0,0.7485480148097664,161594720.0,1596736.0,126.08,7313.568000000002,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5049835.0,49898.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",452,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.128,7317.696000000002,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,7321.152000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",454,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.752,7331.904000000002,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,113725440.0,229294080.0,958464.0,0,0.0,230252544.0,230252544.0,1001088.0,942336.0,0.5151155898043864,119775488.0,147456.0,71.264,7403.168000000002,1032192.0,1769472.0,113246208.0,479232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3742984.0,4608.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",456,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.08,7409.248000000002,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",457,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.144,7415.392000000003,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,768.0,0.0,49152.0,49152.0,4.448,7419.840000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",459,393216.0,13074432.0,0.0,0,115964116992.0,13074432.0,115977191424.0,102144.0,192.0,0.99812382739212,245760.0,49152.0,15.488,7435.328000000003,9891840.0,2396160.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,452984832.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),460,603979776.0,1211105280.0,0.0,0,0.0,1211105280.0,1211105280.0,1975296.0,6144.0,0.9968992248062015,40108032.0,786432.0,49.024,7484.3520000000035,0.0,3145728.0,603979776.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1253376.0,24576.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",461,61440.0,221184.0,122880.0,0,0.0,344064.0,344064.0,0.0,8832.0,0.0,798720.0,49152.0,4.832,7489.184000000004,208896.0,12288.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24960.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,7492.5440000000035,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",463,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,10.624,7503.168000000003,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,151633920.0,305725440.0,1277952.0,0,0.0,307003392.0,307003392.0,1334784.0,1256448.0,0.5151155898043864,157566464.0,196608.0,75.296,7578.464000000004,1376256.0,2359296.0,150994944.0,638976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4923952.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",465,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,7581.920000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",466,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.392,7585.3120000000035,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",467,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.456,7588.768000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,1152.0,0.0,393216.0,196608.0,3.68,7592.448000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",469,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,196608.0,196608.0,3.424,7595.872000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,282291.0,699750.0,24576.0,0,0.0,724326.0,724326.0,0.0,768.0,0.0,196608.0,196608.0,3.456,7599.328000000004,49152.0,110592.0,270003.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,49152.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,768.0,0.0,196608.0,196608.0,3.424,7602.752000000004,0.0,0.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",472,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.456,7606.208000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",473,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3072.0,0.0,0.0,62336.0,3.008,7609.216000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1948.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",474,302777088.0,605159424.0,787968.0,0,0.0,605947392.0,605947392.0,6049536.0,1984870.0,0.752953734227521,161250272.0,1596640.0,128.96,7738.176000000004,0.0,393216.0,302383104.0,393984.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5039071.0,49895.0
"void epilogue::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",475,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,3840.0,0.0,61440.0,0.0,4.32,7742.496000000004,12288.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1920.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,7745.856000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",477,76356.0,240884.0,9216.0,0,0.0,250100.0,250100.0,80.0,1064.0,0.06993006993006994,147456.0,49408.0,11.392,7757.248000000003,72240.0,25148.0,71748.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",478,628815696.0,1354135360.0,22515360.0,0,0.0,1376650720.0,1376650720.0,8267516.0,7337956.0,0.5297831427335232,681240960.0,1406816.0,270.528,8027.7760000000035,41813824.0,77205504.0,617558016.0,11257680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21288780.0,43963.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8030.496000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,8034.368000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",481,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8037.728000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",482,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.936,8041.664000000003,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",483,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,8044.5440000000035,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54400.0,5.856,8050.400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1700.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",485,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.16,8058.560000000003,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55680.0,6.08,8064.640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1740.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",487,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,0.0,8.128,8072.768000000003,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,6.24,8079.0080000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",489,67200.0,0.0,134400.0,0,0.0,134400.0,134400.0,13200.0,83508.0,0.13649336145923813,5134848.0,0.0,8.096,8087.104000000002,0.0,0.0,0.0,67200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54528.0,5.888,8092.992000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1704.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",491,78400.0,0.0,156800.0,0,0.0,156800.0,156800.0,13200.0,83158.0,0.13698914464808318,5134848.0,128.0,7.968,8100.960000000002,0.0,0.0,0.0,78400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.936,8104.896000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,8107.904000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.984,8113.888000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,8116.768000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.984,8122.752000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",497,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,49241.0,13014.0,0.790956549674725,831584.0,8512.0,9.12,8131.872000000002,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,266.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.448,8140.320000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,67072.0,6.304,8146.6240000000025,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.288,8150.912000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",501,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.192,8155.104000000002,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",502,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.112,8161.216000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",503,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,8164.800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28360.0,0.6989863609828584,2736832.0,1965984.0,15.328,8180.128000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85526.0,61437.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",505,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28240.0,0.3347467608951708,2730432.0,2451264.0,11.392,8191.520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85326.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28234.0,0.3516132736249856,2718272.0,1904704.0,12.896,8204.416000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84946.0,59522.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,13907.0,28239.0,0.3299720020879799,2722752.0,2451264.0,13.088,8217.504000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85086.0,76602.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.8,8222.304000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.52,8225.824000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15131.0,0.4950273661727406,1864096.0,1334528.0,9.984,8235.808000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58253.0,41704.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",511,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429472.0,2412352.0,5.44,8241.248000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75921.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",512,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1064512.0,753216.0,31.744,8272.992000000004,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33266.0,23538.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",513,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804288.0,616192.0,97.6,8370.592000000004,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25134.0,19256.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.616,8374.208000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.04,8377.248000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,94080.0,11.456,8388.704000000005,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2940.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.904,8392.608000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",518,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1075744.0,753664.0,32.0,8424.608000000006,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33617.0,23552.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",519,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.152,8433.760000000006,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,8437.216000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",521,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.248,8446.464000000005,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,8449.792000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,8453.152000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.384,8457.536000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",525,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.904,8473.440000000006,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8476.800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.376,8482.176000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8485.536000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",529,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,8490.016000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",530,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.208,8496.224000000007,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",531,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.344,8501.568000000007,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",532,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.624,8524.192000000006,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",533,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,8527.680000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,8531.072000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.808,8534.880000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",536,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,8538.336000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.776,8542.112000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",538,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,8544.960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",539,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,8547.776000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",540,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,8551.360000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",541,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,8554.144000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.096,8558.240000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",543,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.776,8566.016000000007,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,8569.376000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",545,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,8572.768000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",546,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,8576.800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",547,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.736,8581.536000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",548,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,8584.896000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
