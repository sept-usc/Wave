Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.904,15.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.712,19.072,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.352,23.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.928,28.352,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,31.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,34.624,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,37.312000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,40.38400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.936,44.32000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,47.55200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,50.88000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.0,54.88000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.072,57.95200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,61.152000000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.36,64.51200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,26112.0,98304.0,5.632,70.14400000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,816.0,3072.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,73.60000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.504,79.10400000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,82.75200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,4.096,86.84800000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.968,90.81600000000003,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.256,95.07200000000003,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.392,98.46400000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.448,102.91200000000003,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,106.17600000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,109.63200000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,119.93600000000004,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,123.20000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,126.49600000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,131.13600000000002,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,135.68000000000004,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171424640.0,139040.0,98.176,233.85600000000005,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5357020.0,4345.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171228800.0,138784.0,99.104,332.96000000000004,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5350900.0,4337.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,172092544.0,137600.0,100.0,432.96000000000004,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5377892.0,4300.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,437.696,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.608,442.30400000000003,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.92,448.22400000000005,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,452.80000000000007,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,456.1600000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,460.7360000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.8,465.5360000000001,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.24,471.7760000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,476.5120000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,479.8080000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.064,507.8720000000001,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171407616.0,136320.0,100.384,608.2560000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5356488.0,4260.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.392,611.6480000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.552,615.2000000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,9.664,624.8640000000001,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,628.1280000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,631.5520000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,636.1920000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,640.8320000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666790656.0,561696.0,275.968,916.8000000000002,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20837208.0,17553.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.84,920.6400000000002,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666852608.0,561280.0,260.16,1180.8000000000002,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20839144.0,17540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,1184.3840000000002,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,677732224.0,144000.0,363.008,1547.3920000000003,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21179132.0,4500.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,1550.9120000000003,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,1554.3360000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.048,1564.3840000000002,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1567.6160000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1570.9120000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.896,1575.8080000000002,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,1580.3520000000003,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170419968.0,137408.0,94.88,1675.2320000000004,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5325624.0,4294.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,169193856.0,143360.0,94.304,1769.5360000000005,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5287308.0,4480.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171609088.0,137952.0,99.904,1869.4400000000005,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5362784.0,4311.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,1874.1120000000005,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.64,1878.7520000000006,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,1884.9600000000007,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,1889.6320000000007,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.776,1893.4080000000008,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.544,1897.952000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.736,1902.688000000001,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.92,1908.608000000001,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,1913.280000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,1916.736000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.096,1944.832000000001,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171892096.0,141856.0,99.872,2044.704000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5371628.0,4433.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.616,2048.320000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.552,2051.872000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,2062.1760000000013,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2065.472000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2068.704000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.48,2073.184000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.576,2077.760000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666432640.0,564640.0,264.032,2341.7920000000013,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20826020.0,17645.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.872,2345.664000000001,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667201152.0,568736.0,262.304,2607.968000000001,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20850036.0,17773.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,2611.5200000000013,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,679869056.0,141632.0,349.536,2961.0560000000014,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21245908.0,4426.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,2964.4160000000015,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.392,2967.8080000000014,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.496,2978.3040000000015,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2981.4400000000014,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2984.7360000000012,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,2989.376000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.672,2994.048000000001,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170056704.0,142592.0,94.88,3088.9280000000012,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5314272.0,4456.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170533760.0,139424.0,98.176,3187.104000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5329180.0,4357.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170262272.0,143232.0,96.192,3283.296000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5320696.0,4476.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,3287.936000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.608,3292.5440000000012,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,3298.7520000000013,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.512,3303.2640000000015,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,3306.8160000000016,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.864,3311.6800000000017,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.416,3316.096000000002,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.824,3321.920000000002,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.512,3326.432000000002,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.328,3329.760000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.128,3357.888000000002,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171963008.0,138048.0,98.144,3456.032000000002,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5373844.0,4314.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,3459.552000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,3463.008000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.048,3473.056000000002,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3476.2560000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3479.5840000000017,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.576,3484.1600000000017,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,3488.8000000000015,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666899072.0,564032.0,266.656,3755.4560000000015,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20840596.0,17626.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.808,3759.2640000000015,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667037440.0,571648.0,265.76,4025.0240000000013,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20844920.0,17864.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.616,4028.6400000000012,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,681148544.0,141792.0,351.904,4380.544000000002,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21285892.0,4431.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,4383.968000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,4387.328000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.048,4397.376000000001,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4400.736000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,4404.160000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.512,4408.6720000000005,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,4413.216,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171049216.0,140192.0,98.304,4511.52,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5345288.0,4381.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,172670208.0,137952.0,101.216,4612.736000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5395944.0,4311.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170354688.0,138432.0,93.6,4706.336000000001,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5323584.0,4326.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.768,4711.104000000001,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.512,4715.616000000001,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.824,4721.4400000000005,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.768,4726.2080000000005,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,4729.76,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.512,4734.272,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.512,4738.784,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.176,4744.96,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.928,4749.888,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,4753.344,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.096,4781.44,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170869888.0,138112.0,94.784,4876.223999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5339684.0,4316.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.584,4879.807999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.616,4883.423999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,4893.727999999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4896.959999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4900.351999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.672,4905.0239999999985,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.96,4909.983999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667988864.0,557152.0,274.752,5184.735999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20874652.0,17411.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.808,5188.543999999999,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667748864.0,556640.0,262.048,5450.591999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20867152.0,17395.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.52,5454.111999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,677566848.0,139200.0,346.72,5800.831999999999,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21173964.0,4350.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,5804.191999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,5807.647999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.688,5818.335999999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,5821.503999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,5824.895999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.736,5829.631999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.8,5834.431999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171638528.0,136384.0,96.864,5931.2959999999985,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5363704.0,4262.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171311744.0,140352.0,100.928,6032.223999999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5353492.0,4386.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170959744.0,140224.0,96.192,6128.415999999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5342492.0,4382.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.8,6133.2159999999985,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.512,6137.727999999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.824,6143.551999999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.8,6148.351999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.328,6151.6799999999985,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.544,6156.223999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.64,6160.863999999999,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.336,6167.199999999999,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,6171.839999999999,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,6175.263999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.128,6203.391999999999,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171977344.0,139872.0,97.088,6300.479999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5374292.0,4371.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,6303.839999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.2,6307.039999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,9.952,6316.991999999998,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,6320.2559999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,6323.775999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.672,6328.4479999999985,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.608,6333.055999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666990592.0,563520.0,264.768,6597.823999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20843456.0,17610.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.712,6601.535999999999,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666921344.0,564288.0,262.624,6864.159999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20841292.0,17634.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,6867.743999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,679608576.0,139936.0,363.84,7231.583999999999,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21237768.0,4373.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,7235.071999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,7238.3679999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.08,7248.447999999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,7251.647999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,7255.168,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.896,7260.063999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.896,7264.959999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170750080.0,141632.0,95.04,7359.999999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5335940.0,4426.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171207040.0,140480.0,101.536,7461.535999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5350220.0,4390.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171718144.0,138880.0,101.088,7562.623999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5366192.0,4340.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.48,7567.103999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.576,7571.6799999999985,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.304,7577.983999999999,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.704,7582.687999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,7586.143999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.608,7590.751999999999,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,7595.2959999999985,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.792,7601.087999999999,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.512,7605.5999999999985,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.392,7608.991999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.224,7637.2159999999985,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170772608.0,138368.0,99.072,7736.287999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5336644.0,4324.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.328,7739.615999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,7742.911999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.272,7753.183999999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,7756.32,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,7759.552,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.768,7764.32,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,7768.864,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666752768.0,569696.0,270.304,8039.168,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20836024.0,17803.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.936,8043.103999999999,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667205888.0,562080.0,277.184,8320.287999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20850184.0,17565.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.648,8323.935999999998,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,676185856.0,144448.0,370.944,8694.879999999997,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21130808.0,4514.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,8698.303999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.648,8701.951999999997,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.112,8712.063999999997,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,8715.391999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,8718.655999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.704,8723.359999999995,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,8727.999999999995,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171121792.0,140512.0,99.616,8827.615999999995,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5347556.0,4391.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171375488.0,136928.0,97.408,8925.023999999994,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5355484.0,4279.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171513344.0,137184.0,99.712,9024.735999999994,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5359792.0,4287.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,9029.375999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,9033.919999999993,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.76,9039.679999999993,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,9044.415999999994,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,9047.871999999994,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,9052.543999999994,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,9057.087999999994,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,9063.295999999995,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.448,9067.743999999995,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,9071.231999999995,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.16,9099.391999999994,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171819648.0,138880.0,96.32,9195.711999999994,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5369364.0,4340.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,9199.231999999995,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,9202.591999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,9.824,9212.415999999996,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,9215.647999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,9219.167999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.544,9223.711999999996,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.672,9228.383999999996,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667280128.0,558880.0,262.944,9491.327999999996,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20852504.0,17465.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.904,9495.231999999996,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667393024.0,562784.0,266.144,9761.375999999997,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20856032.0,17587.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,9764.927999999996,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,677112576.0,139040.0,360.768,10125.695999999996,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21159768.0,4345.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,10128.991999999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,10132.287999999997,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,9.504,10141.791999999998,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,10145.023999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,10148.415999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.48,10152.895999999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,10157.439999999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170631424.0,137536.0,93.632,10251.071999999996,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5332232.0,4298.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170169472.0,143776.0,97.632,10348.703999999996,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5317796.0,4493.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170651520.0,140512.0,94.56,10443.263999999996,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5332860.0,4391.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,10447.839999999995,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.64,10452.479999999994,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.4,10458.879999999994,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,10463.455999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,10466.911999999993,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.544,10471.455999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.64,10476.095999999992,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.792,10481.887999999992,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,10486.46399999999,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,10489.95199999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,393216.0,35303424.0,0.0,0,386547056640.0,35303424.0,386582360064.0,199680.0,384.0,0.9980806142034548,294912.0,98304.0,28.288,10518.23999999999,29761536.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,9216.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170888960.0,138592.0,97.344,10615.58399999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5340280.0,4331.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,10618.94399999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,10622.27199999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.272,10632.54399999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,10635.743999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,10639.00799999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.704,10643.71199999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.576,10648.28799999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666907008.0,564224.0,267.584,10915.87199999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20840844.0,17632.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.936,10919.80799999999,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666897792.0,569376.0,260.032,11179.83999999999,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20840556.0,17793.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,11183.391999999989,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,678995200.0,142976.0,352.768,11536.159999999989,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21218600.0,4468.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,11539.67999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,11542.97599999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.176,11553.15199999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,11556.319999999989,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,11559.551999999989,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.544,11564.095999999989,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.704,11568.799999999988,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,799744000.0,1722368000.0,26624000.0,0,0.0,1748992000.0,1748992000.0,10256000.0,9280000.0,0.5249795249795249,869533568.0,737312.0,344.8,11913.599999999988,51200000.0,98304000.0,786432000.0,13312000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,27172924.0,23041.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,11916.319999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.384,11920.703999999987,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,11923.999999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.744,11927.743999999988,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.2,11930.943999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35008.0,5.76,11936.703999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1094.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.368,11943.07199999999,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34624.0,6.176,11949.247999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1082.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,8448.0,34568.0,0.19639204017109912,2109440.0,0.0,6.464,11955.711999999989,0.0,0.0,0.0,57344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34176.0,5.952,11961.663999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1068.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.56,11968.223999999987,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,5.664,11973.887999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,128.0,6.752,11980.639999999989,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.192,11984.831999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,11987.743999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.408,11993.151999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,11996.287999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.728,12002.015999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,34276.0,8432.0,0.8025662639318161,527232.0,7744.0,8.768,12010.783999999987,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,242.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.224,12019.007999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,44864.0,6.048,12025.055999999988,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1402.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.68,12028.735999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.68,12032.415999999988,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.76,12038.175999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,12041.59999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17679.0,0.7022082975390368,1706880.0,1278240.0,14.752,12056.35199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53340.0,39945.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17706.0,0.3489962497242444,1696384.0,1560576.0,11.328,12067.67999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53012.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17622.0,0.3799873337555415,1693440.0,1560576.0,13.088,12080.76799999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52920.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17591.0,0.3804022401465253,1690368.0,1207360.0,12.992,12093.75999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52824.0,37730.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.832,12098.59199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.36,12101.95199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9421.0,0.5281005810458825,1172352.0,853376.0,9.152,12111.10399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36636.0,26668.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549312.0,1536000.0,4.672,12115.77599999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48416.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.88,12138.65599999999,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.296,12201.95199999999,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,12205.50399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,12208.73599999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,61312.0,11.968,12220.70399999999,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1916.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.776,12224.47999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994572.0,4245120.0,405144.0,0,0.0,4650264.0,4650264.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.656,12247.135999999991,533120.0,128000.0,1792000.0,202572.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.968,12279.103999999992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,12282.719999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.704,12315.423999999992,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,12318.911999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,12322.23999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,12326.84799999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,12.032,12338.87999999999,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,12342.14399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.056,12347.19999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,12350.39999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.704,12355.10399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.024,12360.12799999999,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799820.0,1280000.0,319640.0,0,0.0,1599640.0,1599640.0,0.0,3000.0,0.0,1024000.0,0.0,5.056,12365.18399999999,0.0,0.0,640000.0,159820.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.544,12381.72799999999,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,12385.18399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,12388.79999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,12392.67199999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.104,12395.775999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.352,12400.12799999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,12402.91199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,12405.631999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,12409.087999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,12411.935999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,4.064,12415.999999999989,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.04,12423.03999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,12426.30399999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,12429.59999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.0,12433.59999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,12438.20799999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,12441.63199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,12445.151999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.64,12449.79199999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.968,12453.759999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.136,12456.895999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.392,12460.287999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.296,12463.583999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.936,12467.519999999991,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,2304.0,0.0,75264.0,98304.0,6.976,12474.495999999992,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2352.0,3072.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,12477.791999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.928,12482.719999999992,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,12486.367999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.52,12489.887999999992,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,12493.887999999992,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.704,12498.591999999991,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.776,12502.367999999991,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.48,12506.84799999999,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.36,12510.207999999991,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.232,12513.439999999991,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.24,12523.679999999991,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,12526.751999999991,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,12530.07999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.672,12534.751999999991,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.672,12539.423999999992,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171050112.0,139264.0,97.408,12636.831999999991,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5345316.0,4352.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171443328.0,138976.0,97.6,12734.431999999992,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5357604.0,4343.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,172015104.0,136416.0,98.592,12833.023999999992,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5375472.0,4263.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.608,12837.631999999992,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.64,12842.271999999992,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,12848.479999999992,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,12853.215999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.584,12856.799999999994,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,12861.375999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.48,12865.855999999992,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.176,12872.031999999992,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.512,12876.543999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,12879.903999999993,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.672,12884.575999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.768,12889.343999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,393024.0,35315208.0,0.0,0,386547056640.0,35315208.0,386582371848.0,199695.0,384.0,0.9980807581005503,491520.0,98304.0,28.0,12917.343999999994,29773722.0,4755438.0,393024.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170954752.0,139040.0,92.832,13010.175999999994,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5342336.0,4345.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.68,13013.855999999994,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.2,13017.055999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.656,13027.711999999996,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,13030.815999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,13034.047999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.704,13038.751999999995,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.736,13043.487999999996,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666557184.0,563616.0,260.608,13304.095999999996,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20829912.0,17613.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,4.064,13308.159999999996,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666572288.0,566240.0,261.344,13569.503999999995,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20830384.0,17695.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.488,13572.991999999995,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,680613504.0,142816.0,355.008,13927.999999999995,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21269172.0,4463.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,13931.423999999995,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,13934.879999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.4,13945.279999999995,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,13948.447999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,13951.743999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.8,13956.543999999994,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.608,13961.151999999995,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170638208.0,139936.0,93.856,14055.007999999994,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5332444.0,4373.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170852608.0,138592.0,97.12,14152.127999999995,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5339144.0,4331.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171631488.0,137632.0,96.448,14248.575999999995,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5363484.0,4301.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,14253.151999999995,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.512,14257.663999999995,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.824,14263.487999999996,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,14268.223999999997,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,14271.647999999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.768,14276.415999999997,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.352,14280.767999999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.856,14286.623999999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.832,14291.455999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.392,14294.847999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,5.024,14299.871999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.576,14304.447999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,27.968,14332.415999999997,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171697920.0,136736.0,94.976,14427.391999999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5365560.0,4273.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,14430.751999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,14434.047999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.56,14444.607999999998,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,14447.839999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,14451.455999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.544,14455.999999999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.608,14460.607999999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666676608.0,567648.0,262.944,14723.551999999998,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20833644.0,17739.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.84,14727.391999999998,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666665088.0,565280.0,262.848,14990.239999999998,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20833284.0,17665.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.584,14993.823999999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,681263744.0,139680.0,350.08,15343.903999999999,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21289492.0,4365.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,15347.423999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,15350.784,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,15361.088,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,15364.192,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,15367.423999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,15372.063999999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.672,15376.735999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171111424.0,141472.0,96.672,15473.408,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5347232.0,4421.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170941824.0,139680.0,97.792,15571.199999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5341932.0,4365.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170839552.0,138624.0,98.688,15669.887999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5338736.0,4332.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,15674.56,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.448,15679.008,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.92,15684.928,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.768,15689.696,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,15693.248,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,15697.823999999999,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.576,15702.399999999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.76,15708.159999999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.8,15712.959999999997,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,15716.447999999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.768,15721.215999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.768,15725.983999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.224,15754.207999999997,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171700864.0,142656.0,95.712,15849.919999999996,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5365652.0,4458.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,15853.407999999996,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.232,15856.639999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.496,15867.135999999995,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,15870.271999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,15873.535999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.544,15878.079999999994,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,15882.719999999994,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667426560.0,560608.0,268.512,16151.231999999995,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20857080.0,17519.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.84,16155.071999999995,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667614976.0,561728.0,265.92,16420.991999999995,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20862968.0,17554.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,16424.543999999994,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,678843776.0,144128.0,349.856,16774.399999999994,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21213868.0,4504.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,16777.855999999992,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,16781.27999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.464,16791.74399999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,16794.97599999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,16798.27199999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.608,16802.87999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,16807.51999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171526528.0,138016.0,98.88,16906.39999999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5360204.0,4313.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171964544.0,138976.0,101.184,17007.58399999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5373892.0,4343.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171825664.0,137952.0,97.12,17104.70399999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5369552.0,4311.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.864,17109.567999999992,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,17114.111999999994,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.272,17120.383999999995,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,17125.023999999994,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,17128.447999999993,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.608,17133.055999999993,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,17137.599999999995,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,17143.807999999994,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.768,17148.575999999994,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,17152.031999999992,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.64,17156.67199999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.672,17161.34399999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.128,17189.47199999999,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170761600.0,141952.0,93.76,17283.23199999999,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5336300.0,4436.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,17286.655999999988,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,17289.919999999987,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.336,17300.255999999987,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,17303.423999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,17306.687999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.608,17311.295999999988,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,17315.83999999999,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666946432.0,566816.0,262.368,17578.207999999988,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20842076.0,17713.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.968,17582.17599999999,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667036288.0,568480.0,259.904,17842.079999999987,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20844884.0,17765.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.616,17845.69599999999,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,674660352.0,141152.0,361.696,18207.39199999999,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21083136.0,4411.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,18210.94399999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.2,18214.14399999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,18224.44799999999,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,18227.55199999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,18230.815999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.672,18235.487999999987,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.608,18240.095999999987,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170350336.0,141504.0,97.728,18337.823999999986,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5323448.0,4422.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170828800.0,138144.0,99.232,18437.055999999986,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5338400.0,4317.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171335040.0,137984.0,98.368,18535.423999999985,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5354220.0,4312.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.576,18539.999999999985,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.704,18544.703999999987,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.952,18550.655999999988,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.832,18555.487999999987,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,18559.039999999986,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,18563.679999999986,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.48,18568.159999999985,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.728,18573.887999999984,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.704,18578.591999999986,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.296,18581.887999999984,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.768,18586.655999999984,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.8,18591.455999999984,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.16,18619.615999999984,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170688896.0,136288.0,95.2,18714.815999999984,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5334028.0,4259.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,18718.239999999983,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.232,18721.471999999983,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.304,18731.775999999983,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,18734.879999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,18738.33599999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.672,18743.00799999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.704,18747.71199999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666691456.0,564544.0,266.944,19014.65599999998,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20834108.0,17642.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.776,19018.431999999983,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667049728.0,566944.0,269.184,19287.615999999984,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20845304.0,17717.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.552,19291.167999999983,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,678632192.0,143552.0,348.928,19640.095999999983,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21207256.0,4486.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.264,19643.359999999982,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.392,19646.751999999982,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.016,19656.767999999982,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,19659.935999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,19663.487999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,19668.127999999982,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.512,19672.63999999998,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171938432.0,138784.0,95.424,19768.06399999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5373076.0,4337.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171206016.0,139040.0,93.6,19861.66399999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5350188.0,4345.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171724544.0,140800.0,95.552,19957.21599999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5366392.0,4400.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.832,19962.047999999977,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.704,19966.75199999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.824,19972.57599999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,19977.247999999978,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,19980.671999999977,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.864,19985.53599999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.544,19990.07999999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,5.792,19995.87199999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,20000.54399999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.744,20004.28799999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.768,20009.05599999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.736,20013.79199999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.384,20042.175999999978,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171824768.0,139744.0,98.656,20140.831999999977,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5369524.0,4367.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,20144.191999999977,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,20147.51999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.368,20157.887999999977,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,20161.05599999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,20164.351999999977,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.448,20168.799999999977,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.448,20173.247999999978,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667465728.0,566816.0,264.448,20437.695999999978,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20858304.0,17713.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.84,20441.53599999998,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667202048.0,566240.0,259.392,20700.927999999978,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20850064.0,17695.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.712,20704.639999999978,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,681785216.0,138976.0,349.664,21054.30399999998,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21305788.0,4343.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,21057.79199999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,21061.15199999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.144,21071.29599999998,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,21074.39999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,21077.82399999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.64,21082.463999999978,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,21087.103999999978,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171722624.0,140544.0,96.864,21183.96799999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5366332.0,4392.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170773120.0,140864.0,94.272,21278.23999999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5336660.0,4402.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171612032.0,138432.0,97.184,21375.42399999998,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5362876.0,4326.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,21380.09599999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.608,21384.70399999998,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.048,21390.75199999998,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.608,21395.35999999998,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,21398.87999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.672,21403.551999999978,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.48,21408.031999999977,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.048,21414.079999999976,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.544,21418.623999999978,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,21422.047999999977,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.64,21426.687999999976,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.8,21431.487999999976,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.192,21459.679999999975,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171043840.0,137408.0,95.136,21554.815999999973,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5345120.0,4294.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,21558.239999999972,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.2,21561.439999999973,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.368,21571.80799999997,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,21575.007999999973,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,21578.239999999972,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.832,21583.07199999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.64,21587.71199999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666797440.0,572960.0,264.96,21852.67199999997,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20837420.0,17905.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.776,21856.44799999997,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,667426176.0,565056.0,262.816,22119.26399999997,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20857068.0,17658.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.52,22122.78399999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,686010240.0,137312.0,361.504,22484.28799999997,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21437820.0,4291.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,22487.71199999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.584,22491.29599999997,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.528,22501.823999999968,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,22505.215999999968,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,22508.54399999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.576,22513.11999999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.544,22517.66399999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171617152.0,137216.0,99.808,22617.471999999972,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5363036.0,4288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,170922496.0,142464.0,99.456,22716.92799999997,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5341328.0,4452.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171462144.0,139968.0,96.288,22813.21599999997,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5358192.0,4374.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.736,22817.951999999972,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.576,22822.527999999973,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.24,22828.767999999975,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.704,22833.471999999976,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,22836.959999999977,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.64,22841.599999999977,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,18432.0,12288.0,36864.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,4.608,22846.207999999977,12288.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,0.0,1536.0,0.0,98304.0,98304.0,6.208,22852.415999999976,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,49152.0,24576.0,98304.0,0,0.0,122880.0,122880.0,0.0,2304.0,0.0,147456.0,98304.0,4.8,22857.215999999975,0.0,24576.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,22860.735999999975,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.64,22865.375999999975,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1920.0,0.0,196608.0,196608.0,4.672,22870.047999999973,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,393216.0,35315712.0,0.0,0,386547056640.0,35315712.0,386582372352.0,199680.0,384.0,0.9980806142034548,491520.0,98304.0,28.0,22898.047999999973,29773824.0,4755456.0,393216.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1509949440.0,15360.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,153550848.0,330694656.0,5111808.0,0,0.0,335806464.0,335806464.0,1969152.0,1781760.0,0.5249795249795249,171779968.0,141536.0,95.808,22993.855999999974,9830400.0,18874368.0,150994944.0,2555904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5368124.0,4423.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,22997.311999999973,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,23000.575999999972,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.208,23010.78399999997,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,23013.91999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,23017.215999999968,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.512,23021.727999999966,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.576,23026.303999999967,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666161920.0,567872.0,262.56,23288.86399999997,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20817560.0,17746.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,1228800.0,2359296.0,196608.0,0,0.0,2555904.0,2555904.0,0.0,1536.0,0.0,393216.0,393216.0,3.808,23292.67199999997,98304.0,0.0,1130496.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,614203392.0,1322778624.0,20447232.0,0,0.0,1343225856.0,1343225856.0,7876608.0,7127040.0,0.5249795249795249,666722048.0,569696.0,267.648,23560.31999999997,39321600.0,75497472.0,603979776.0,10223616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20835064.0,17803.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,98304.0,0.0,0,0.0,98304.0,98304.0,0.0,2304.0,0.0,786432.0,393216.0,3.712,23564.03199999997,0.0,98304.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24576.0,12288.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,613613568.0,1321598976.0,19267584.0,0,0.0,1340866560.0,1340866560.0,7719936.0,7090176.0,0.5212611491391828,677912064.0,142080.0,346.688,23910.71999999997,38141952.0,75497472.0,603979776.0,9633792.0,0,0,0,0,0,0,0,0.0,0.0,0.0,21184752.0,4440.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,23914.175999999967,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,23917.503999999968,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,29060.0,4096.0,0,0.0,33156.0,33156.0,40.0,196.0,0.1694915254237288,98304.0,32.0,10.336,23927.839999999967,29056.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,23931.071999999967,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,23934.55999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,101376.0,98304.0,4.704,23939.26399999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,24576.0,24576.0,49152.0,0,0.0,73728.0,73728.0,0.0,2304.0,0.0,196608.0,98304.0,4.672,23943.93599999997,0.0,24576.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,799744000.0,1722368000.0,26624000.0,0,0.0,1748992000.0,1748992000.0,10256000.0,9280000.0,0.5249795249795249,869357568.0,735168.0,348.128,24292.06399999997,51200000.0,98304000.0,786432000.0,13312000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,27167424.0,22974.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,24294.81599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,24298.65599999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,24301.79199999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.584,24305.375999999967,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,24308.319999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34304.0,6.112,24314.431999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1072.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.752,24321.18399999997,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34816.0,5.792,24326.97599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1088.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,8448.0,34568.0,0.19639204017109912,2109440.0,0.0,6.592,24333.56799999997,0.0,0.0,0.0,57344.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34240.0,5.888,24339.45599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1070.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,47104.0,0.0,94208.0,0,0.0,94208.0,94208.0,8448.0,34888.0,0.19494184973232417,2109440.0,0.0,6.464,24345.91999999997,0.0,0.0,0.0,47104.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34752.0,5.792,24351.71199999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1086.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,58368.0,0.0,116736.0,0,0.0,116736.0,116736.0,8448.0,34536.0,0.19653824678950307,2109440.0,128.0,6.816,24358.52799999997,0.0,0.0,0.0,58368.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.872,24362.39999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,24365.535999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,24370.975999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,24373.887999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,24379.327999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,33169.0,8422.0,0.7975042677502344,527232.0,7488.0,8.736,24388.063999999966,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,234.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.352,24396.415999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,41952.0,6.112,24402.527999999966,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1311.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.616,24406.143999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.552,24409.695999999967,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.632,24415.32799999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,24418.751999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17703.0,0.7019245340203061,1711616.0,1285696.0,14.592,24433.34399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53488.0,40178.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17661.0,0.34957463263727767,1706752.0,1560576.0,11.552,24444.895999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53336.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17561.0,0.380804626071013,1693568.0,1215744.0,12.768,24457.663999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52924.0,37992.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,9396.0,17626.0,0.3477166753016061,1690112.0,1560576.0,12.768,24470.431999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52816.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.992,24475.423999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.616,24479.039999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9420.0,0.5281270350147773,1165312.0,856800.0,9.056,24488.09599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36416.0,26775.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549024.0,1536000.0,4.64,24492.735999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48407.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,514048.0,512000.0,22.56,24515.29599999997,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16064.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.456,24578.751999999968,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.52,24582.271999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,24585.34399999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,59616.0,11.84,24597.18399999997,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1863.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.552,24600.735999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994569.0,4245120.0,405138.0,0,0.0,4650258.0,4650258.0,528.0,5248.0,0.09141274238227147,520192.0,512000.0,22.848,24623.58399999997,533120.0,128000.0,1792000.0,202569.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16256.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.512,24656.09599999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,24659.74399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.128,24691.87199999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,24695.39199999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,24698.84799999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,24703.42399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.744,24715.16799999997,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,24718.463999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,24723.711999999967,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,24727.039999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,24731.58399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,24736.70399999997,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799817.0,1280000.0,319634.0,0,0.0,1599634.0,1599634.0,0.0,3000.0,0.0,1024000.0,0.0,5.152,24741.855999999967,0.0,0.0,640000.0,159817.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.48,24758.335999999967,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,24761.823999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,24765.02399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,24768.895999999968,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,24772.127999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.0,24776.127999999968,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,24778.97599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,24781.82399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.552,24785.37599999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,24788.06399999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,4.064,24792.127999999968,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.944,24799.071999999967,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,24802.527999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,24805.983999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.096,24810.079999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.736,24814.815999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,24817.919999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
