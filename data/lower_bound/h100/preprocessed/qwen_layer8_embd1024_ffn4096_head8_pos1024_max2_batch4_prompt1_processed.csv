Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,2.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.592,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.808,9.28,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.256,13.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.216,18.752,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,22.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,24.735999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,27.615999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,30.783999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.0,34.78399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,38.14399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,41.791999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.872,45.663999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,49.087999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,52.672,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.712,56.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,4352.0,16384.0,5.728,62.112,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,65.824,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.632,71.456,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,75.00800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.552,78.56000000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.448,83.00800000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.48,87.48800000000001,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,90.75200000000001,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.32,95.072,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,98.4,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.424,101.82400000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.696,107.52000000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,110.75200000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,114.36800000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.608,118.97600000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.32,123.29600000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.592,133.88800000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.632,143.52000000000004,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.984,153.50400000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,158.14400000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.192,162.33600000000004,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,167.71200000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.288,172.00000000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,175.42400000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,179.90400000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.544,184.44800000000006,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,189.92000000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,194.40000000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.264,197.66400000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.52,213.18400000000008,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19712.0,9.472,222.6560000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,616.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,226.2400000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.232,229.4720000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.272,235.74400000000009,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,239.1040000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,242.3680000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,246.65600000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,251.16800000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,96416.0,13.344,264.5120000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,3013.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.872,268.3840000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940416.0,92032.0,14.208,282.59200000000016,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591888.0,2876.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.872,286.46400000000017,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20512.0,26.272,312.73600000000016,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,641.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.68,316.41600000000017,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.552,319.9680000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.56,326.5280000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,329.7600000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,333.12000000000023,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.544,337.6640000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.384,342.04800000000023,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.952,352.0000000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.6,361.60000000000025,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.824,371.42400000000026,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,376.0000000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,380.3840000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,385.7920000000003,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,390.2400000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,393.66400000000027,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,398.0480000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.192,402.2400000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,407.61600000000027,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,412.03200000000027,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,415.36000000000024,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.712,431.07200000000023,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18528.0,9.728,440.80000000000024,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,579.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,444.19200000000023,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.36,447.55200000000025,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.824,453.37600000000026,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,456.54400000000027,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,459.84000000000026,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.48,464.3200000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,468.8960000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94528.0,13.472,482.3680000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2954.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.808,486.1760000000003,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18943744.0,95968.0,13.504,499.6800000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591992.0,2999.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.456,503.1360000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20256.0,27.2,530.3360000000004,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,633.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,533.8880000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.36,537.2480000000004,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.696,542.9440000000004,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,546.3680000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,549.6960000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,554.0800000000004,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.672,558.7520000000004,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.76,568.5120000000004,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.632,578.1440000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.952,588.0960000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,592.5120000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,596.7360000000004,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,602.2400000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,606.7200000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,610.2720000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.32,614.5920000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.48,619.0720000000006,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,624.5760000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,629.1840000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,632.4800000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.744,648.2240000000006,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18976.0,9.728,657.9520000000006,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,593.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,661.5360000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,664.7360000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,670.9120000000006,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,674.2080000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,677.5680000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.512,682.0800000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.288,686.3680000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93152.0,12.864,699.2320000000007,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2911.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.84,703.0720000000007,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,95648.0,13.696,716.7680000000007,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2989.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,720.1600000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19104.0,25.632,745.7920000000007,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,597.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.648,749.4400000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.488,752.9280000000008,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,759.0720000000008,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,762.4320000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,765.6960000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,770.0800000000008,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,774.5920000000008,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16512.0,9.728,784.3200000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,516.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.08,794.4000000000008,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16448.0,9.984,804.3840000000008,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,514.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,808.8320000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.672,813.5040000000008,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,819.0080000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,823.4240000000009,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,826.8160000000009,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,831.392000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,835.616000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.664,841.280000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,845.696000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.648,849.3440000000011,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.616,864.9600000000011,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18400.0,9.408,874.3680000000011,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,575.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,877.888000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.328,881.216000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.696,886.9120000000011,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,890.144000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,893.504000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,897.856000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,902.2720000000011,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,92480.0,13.056,915.3280000000011,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2890.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.744,919.0720000000011,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941056.0,94016.0,13.568,932.6400000000011,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591908.0,2938.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,936.1280000000012,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19776.0,26.752,962.8800000000011,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,618.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,966.3360000000011,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.36,969.6960000000012,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.568,975.2640000000011,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,978.4320000000012,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,981.9200000000012,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,986.2080000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.384,990.5920000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.24,1000.8320000000012,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16480.0,10.304,1011.1360000000012,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,515.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.696,1020.8320000000012,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,1025.3120000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.064,1029.3760000000013,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,1034.8800000000012,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,1039.2320000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,1042.5280000000014,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,1046.9760000000015,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.48,1051.4560000000015,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.536,1056.9920000000016,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,1061.4080000000015,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.264,1064.6720000000014,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.584,1080.2560000000014,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19424.0,9.472,1089.7280000000014,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,607.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,1093.0240000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.456,1096.4800000000014,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,1102.5600000000013,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,1106.0480000000014,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1109.3120000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.256,1113.5680000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,1118.0800000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,92352.0,13.568,1131.6480000000013,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2886.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,1135.2960000000012,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941312.0,93280.0,13.376,1148.6720000000012,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591916.0,2915.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.616,1152.2880000000011,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20448.0,26.048,1178.3360000000011,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,639.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,1181.7600000000011,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.168,1184.928000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.112,1191.040000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1194.4320000000012,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1197.6640000000011,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,1202.0480000000011,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,1206.5280000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.112,1216.6400000000012,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.208,1226.8480000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.792,1236.6400000000012,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,1241.1840000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.448,1245.6320000000014,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,1251.0080000000014,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,1255.5840000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1259.0400000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,1263.4880000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.192,1267.6800000000014,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,1273.1840000000013,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,1277.6640000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1281.1200000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.36,1296.4800000000012,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19232.0,9.568,1306.0480000000011,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,601.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,1309.4400000000012,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.552,1312.992000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.632,1318.6240000000012,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1321.792000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1325.088000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,1329.408000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.544,1333.9520000000011,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93824.0,13.408,1347.360000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2932.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,4.064,1351.4240000000011,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93760.0,13.44,1364.8640000000012,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2930.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1368.3840000000012,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20320.0,26.112,1394.4960000000012,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,635.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,1398.0800000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.456,1401.5360000000012,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.568,1407.1040000000012,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1410.368000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1413.696000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,1418.1440000000011,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.352,1422.4960000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16640.0,10.112,1432.6080000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,520.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16512.0,9.92,1442.5280000000014,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,516.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.632,1452.1600000000014,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1456.6720000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,1461.0560000000014,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,1466.4960000000015,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,1471.0400000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,1474.3360000000016,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,1478.7200000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,1483.1040000000016,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.344,1488.4480000000017,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,1493.1520000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,1496.5120000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.424,1511.9360000000015,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19328.0,9.632,1521.5680000000016,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,604.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,1524.8960000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,1528.0960000000016,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.304,1534.4000000000017,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1537.6640000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1540.9280000000015,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,1545.3760000000016,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,1549.7920000000015,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942336.0,93280.0,13.92,1563.7120000000016,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591948.0,2915.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.584,1567.2960000000016,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940416.0,93888.0,13.088,1580.3840000000016,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591888.0,2934.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1583.9040000000016,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20512.0,25.632,1609.5360000000016,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,641.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1612.9920000000016,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.232,1616.2240000000015,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,1622.3680000000015,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,1625.7280000000014,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1628.9920000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,1633.3760000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,1637.7920000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.632,1647.4240000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16448.0,9.76,1657.1840000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,514.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16416.0,9.536,1666.7200000000014,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,513.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,1671.2640000000015,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.864,1676.1280000000015,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.536,1681.6640000000016,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,1686.0480000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,1689.5360000000016,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.32,1693.8560000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,1698.0800000000015,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,1703.4880000000014,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,1707.9040000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1711.3600000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.488,1726.8480000000013,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18144.0,10.048,1736.8960000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,567.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,1740.4480000000012,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,1743.7440000000013,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.728,1749.4720000000013,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1752.7040000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1756.0320000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,1760.4800000000014,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,1764.8960000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,97216.0,12.96,1777.8560000000014,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,3038.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,1781.5040000000013,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940288.0,94400.0,13.376,1794.8800000000012,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591884.0,2950.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,1798.4000000000012,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20320.0,27.52,1825.9200000000012,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,635.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,1829.3120000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.36,1832.6720000000012,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.76,1838.4320000000012,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1841.600000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,1845.120000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,1849.440000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,1853.952000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,636915712.0,1371070464.0,29171712.0,0,0.0,1400242176.0,1400242176.0,9192128.0,7596800.0,0.5475113122171946,651012224.0,3425088.0,264.864,2118.8160000000007,48619520.0,77791232.0,622329856.0,14585856.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20344132.0,107034.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,2121.7600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.672,2126.4320000000007,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2129.792000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.64,2134.4320000000007,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,2137.408000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173632.0,6.368,2143.7760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5426.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38122368.0,0.0,14.688,2158.464000000001,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191324.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172928.0,6.304,2164.768000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5404.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,190720.0,0.0,381440.0,0,0.0,381440.0,381440.0,39336.0,721168.0,0.051723593827251405,38184832.0,32.0,15.36,2180.128000000001,0.0,0.0,0.0,190720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1193276.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170496.0,6.176,2186.304000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5328.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38160576.0,32.0,15.008,2201.312000000001,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192518.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169408.0,6.432,2207.7440000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5294.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38128320.0,128.0,14.336,2222.0800000000004,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191510.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.704,2226.7840000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,2229.9200000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.016,2235.9360000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.976,2238.9120000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,5.76,2244.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,105780.0,38400.0,0.7336662505201831,2488288.0,10624.0,9.664,2254.336000000001,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,332.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,9.056,2263.392000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,203552.0,6.336,2269.728000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6361.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,6.048,2275.7760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.6,2281.3760000000007,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,7.008,2288.3840000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,2291.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,173202.0,84700.0,0.6715806779319277,8829312.0,5950400.0,17.408,2309.28,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275916.0,185950.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,92084.0,0.3018968053007445,8878080.0,7409664.0,14.592,2323.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277440.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,92004.0,0.30687519775798944,8836352.0,7409664.0,14.56,2338.4320000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276136.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91825.0,0.3072895842605934,8825088.0,5719136.0,14.784,2353.2160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275784.0,178723.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.144,2359.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.552,2362.9120000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51505.0,0.4285032677562886,6240640.0,4017152.0,12.736,2375.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,195020.0,125536.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7332928.0,7292928.0,8.224,2383.8720000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229154.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.68,2471.552,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,285.44,2756.992,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607488.0,4.224,2761.2160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,2764.4480000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,292768.0,11.936,2776.3840000000005,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9149.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.568,2781.9520000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424708.0,20076672.0,1832584.0,0,0.0,21909256.0,21909256.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.976,2868.928000000001,2452096.0,607744.0,8508416.0,916292.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.376,2878.304000000001,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,2881.824000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.344,2891.168000000001,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2894.496000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2897.856000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.8,2902.6560000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.504,2912.160000000001,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2915.456000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.216,2920.672000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2923.9680000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.8,2928.768000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.264,2936.032000000001,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798340.0,6077440.0,1519240.0,0,0.0,7596680.0,7596680.0,0.0,14280.0,0.0,4861952.0,0.0,6.784,2942.816000000001,0.0,0.0,3038720.0,759620.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,12.992,2955.8080000000014,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.384,2960.1920000000014,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2962.9440000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2965.664000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,2969.1200000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2972.608000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,2976.576000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.832,2981.408000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2984.8000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,2988.448000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.768,2993.216000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.968,2997.1840000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.264,3000.448000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.392,3003.8400000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.2,3007.0400000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.808,3010.8480000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,16640.0,16384.0,7.84,3018.6880000000006,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.808,3022.4960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.992,3027.4880000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,3030.8800000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.808,3034.6880000000006,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,3.904,3038.5920000000006,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.256,3042.8480000000004,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,3046.1760000000004,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.128,3050.3040000000005,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,3053.6320000000005,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.232,3056.8640000000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.016,3062.8800000000006,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3066.1440000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3069.312000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,3073.632000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,3078.144000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.696,3087.840000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.016,3097.856000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.44,3107.296000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,3111.7120000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.544,3116.256000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,3121.6320000000014,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,3125.9840000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,3129.4400000000014,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,3133.8880000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.288,3138.1760000000013,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,3143.584000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,3148.224000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.616,3151.840000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.512,3156.352000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.544,3160.896000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.968,3176.864000000001,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18336.0,9.76,3186.624000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,573.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,3190.1760000000013,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.232,3193.4080000000013,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.016,3199.4240000000013,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3202.6560000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3205.7920000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,3210.0800000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.544,3214.624000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94080.0,13.024,3227.648000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2940.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.68,3231.328000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94016.0,13.056,3244.384000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2938.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.36,3247.744000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20032.0,25.408,3273.152000000001,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,626.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,3276.512000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,3279.776000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.016,3285.7920000000013,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3288.9280000000012,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3292.032000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.704,3296.7360000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,3301.2480000000014,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16512.0,9.856,3311.1040000000016,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,516.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16768.0,9.856,3320.960000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,524.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.792,3330.7520000000018,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,3335.264000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.768,3340.032000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.344,3345.376000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,3349.824000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,3353.3120000000017,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.832,3358.1440000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,3362.4000000000015,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,3367.9680000000017,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3372.5440000000017,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3375.9680000000017,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,3380.6400000000017,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.448,3385.0880000000016,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.712,3400.8000000000015,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19680.0,9.472,3410.2720000000018,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,615.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3413.5680000000016,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.168,3416.7360000000017,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,3422.9120000000016,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3426.1440000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3429.3440000000014,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,3433.7280000000014,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.352,3438.0800000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93696.0,13.216,3451.296000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2928.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.584,3454.880000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941696.0,92928.0,13.088,3467.968000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591928.0,2904.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.36,3471.3280000000013,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20672.0,25.472,3496.8000000000015,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,646.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,3500.1600000000017,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,3503.3600000000015,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,3509.4400000000014,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3512.7040000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3515.8080000000014,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,3520.256000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.288,3524.5440000000012,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.888,3534.432000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.728,3544.160000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.632,3553.7920000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3558.3680000000013,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.672,3563.0400000000013,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,3568.5120000000015,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,3573.2160000000017,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,3576.8000000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.288,3581.0880000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.288,3585.3760000000016,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,3590.8160000000016,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3595.3920000000016,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,3598.944000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,3603.616000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.448,3608.0640000000017,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.648,3623.712000000002,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19808.0,9.856,3633.568000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,619.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3636.864000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,3640.2560000000017,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.112,3646.3680000000018,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3649.6000000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3652.7360000000017,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,3657.056000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.352,3661.4080000000017,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,92544.0,13.216,3674.6240000000016,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2892.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.584,3678.2080000000014,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94400.0,12.928,3691.1360000000013,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2950.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,3694.528000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20224.0,26.144,3720.672000000001,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,632.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,3724.128000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.424,3727.552000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,3733.632000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3736.800000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3739.904000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,3744.288000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.32,3748.608000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.888,3758.496000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.304,3768.800000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.728,3778.528000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,3782.880000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,3787.264000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,3792.672000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,3797.184000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,3800.672000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,3805.312000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,3809.5680000000007,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,3814.9760000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3819.5520000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,3823.0720000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.512,3827.5840000000007,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,3832.2560000000008,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.744,3848.000000000001,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19168.0,9.536,3857.536000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,599.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,3861.088000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,3864.352000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.048,3870.400000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3873.536000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3876.640000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,3880.9920000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.352,3885.3440000000005,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940800.0,96736.0,13.344,3898.6880000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591900.0,3023.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.616,3902.3040000000005,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942464.0,92992.0,13.504,3915.8080000000004,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591952.0,2906.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.68,3919.4880000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19840.0,25.056,3944.5440000000003,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,620.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3947.84,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,3951.04,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,3957.216,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3960.448,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3963.584,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,3967.904,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,3972.384,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.856,3982.2400000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16512.0,9.856,3992.0960000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,516.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16480.0,9.824,4001.9200000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,515.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.672,4006.5920000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.64,4011.2320000000004,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,4016.6080000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,4021.0560000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,4024.6080000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,4028.9600000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.16,4033.1200000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,4038.5280000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,4043.1040000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,4046.592,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.544,4051.136,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.448,4055.584,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.52,4071.104,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18624.0,9.344,4080.448,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,582.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,4083.8399999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,4087.0399999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.24,4093.2799999999993,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4096.512,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,4099.648,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,4104.064,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.448,4108.512000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93184.0,13.184,4121.696000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2912.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.712,4125.408000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18943232.0,96416.0,13.216,4138.624000000002,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591976.0,3013.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.648,4142.272000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,21088.0,26.368,4168.640000000002,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,659.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,4171.936000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,4175.136000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,4181.120000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4184.288000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,4187.392000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,4191.744000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,4196.352000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.856,4206.208000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16448.0,9.856,4216.064000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,514.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16448.0,9.792,4225.8560000000025,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,514.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,4230.496000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.416,4234.912000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,4240.320000000003,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,4244.832000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.616,4248.448000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,4252.864000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.32,4257.184000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,4262.592000000003,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,4266.976000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,4270.336000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.48,4274.8160000000025,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.512,4279.328000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.968,4295.296000000002,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,21024.0,9.984,4305.2800000000025,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,657.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,4308.768000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,4312.064000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.048,4318.112000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4321.2800000000025,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,4324.480000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.544,4329.024000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,4333.504000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94304.0,13.248,4346.752000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2947.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.616,4350.368000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,95456.0,13.12,4363.488000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2983.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.296,4366.7840000000015,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20480.0,25.344,4392.1280000000015,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,640.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,4395.424000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,4398.688000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.272,4404.960000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,4408.416000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,4411.520000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,4415.936000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,4420.416000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.984,4430.400000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.824,4440.224000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,10.048,4450.272000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,4454.688000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.448,4459.136000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,4464.608000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,4468.960000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,4472.3200000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.288,4476.608000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,4480.864000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,4486.272000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,4490.848000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,4494.336000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.704,4499.040000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.64,4503.680000000002,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.616,4519.296000000002,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19584.0,9.6,4528.8960000000025,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,612.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,4532.352000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.2,4535.552000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.272,4541.824000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4545.152000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4548.480000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.512,4552.992000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.736,4557.728000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,95744.0,13.632,4571.360000000002,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2992.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.552,4574.912000000002,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941568.0,94880.0,12.96,4587.872000000002,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591924.0,2965.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,4591.360000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20832.0,26.208,4617.568000000002,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,651.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,4620.8960000000025,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,4624.288000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,4630.464000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4633.6640000000025,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4636.960000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,4641.376000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,4645.792000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16512.0,10.08,4655.872000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,516.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.568,4665.440000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51712.0,0.545045045045045,6295552.0,16384.0,9.856,4675.296000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196736.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,4679.680000000003,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.448,4684.128000000003,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,4689.536000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,4694.080000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,4697.536000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,4702.144000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.352,4706.496000000004,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,4712.064000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,4716.608000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,4720.1600000000035,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.832,4724.992000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.48,4729.472000000003,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.584,4745.056000000003,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18784.0,9.44,4754.496000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,587.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,4757.792000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,4761.056000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,4767.232000000004,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,4770.368000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.072,4773.440000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.48,4777.920000000004,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,4782.432000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941056.0,95712.0,12.928,4795.360000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591908.0,2991.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.68,4799.040000000004,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94240.0,13.248,4812.288000000003,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2945.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.296,4815.5840000000035,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,21056.0,26.4,4841.984000000003,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,658.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,4845.376000000003,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.36,4848.736000000003,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,4854.8160000000025,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,4858.2400000000025,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4861.536000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,4865.920000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,4870.400000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,636915712.0,1371070464.0,29171712.0,0,0.0,1400242176.0,1400242176.0,9192128.0,7596800.0,0.5475113122171946,651690496.0,3408896.0,265.888,5136.288000000002,48619520.0,77791232.0,622329856.0,14585856.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20365328.0,106528.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,5139.0080000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.032,5143.040000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,5146.560000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.48,5151.040000000003,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,5154.080000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171840.0,6.368,5160.448000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5370.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38122016.0,32.0,14.688,5175.136000000003,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191313.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173376.0,6.304,5181.440000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5418.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,190720.0,0.0,381440.0,0,0.0,381440.0,381440.0,39336.0,721168.0,0.051723593827251405,38182592.0,32.0,14.624,5196.064000000003,0.0,0.0,0.0,190720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1193206.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171456.0,6.4,5202.464000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5358.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,247936.0,0.0,495872.0,0,0.0,495872.0,495872.0,39336.0,719380.0,0.05184548632162759,38144032.0,0.0,14.592,5217.056000000002,0.0,0.0,0.0,247936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192001.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170112.0,6.176,5223.232000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5316.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,238400.0,0.0,476800.0,0,0.0,476800.0,476800.0,39336.0,719678.0,0.05182513102525118,38149408.0,128.0,14.848,5238.080000000003,0.0,0.0,0.0,238400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192169.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.928,5243.0080000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,5245.920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,5.92,5251.840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,5254.976000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.208,5261.184000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,138088.0,38398.0,0.7824303344174609,2488288.0,11008.0,9.888,5271.072000000003,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,344.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.32,5279.392000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,201792.0,6.24,5285.632000000002,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6306.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.856,5291.488000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.504,5296.992000000002,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.912,5303.904000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.648,5307.552000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,163374.0,86235.0,0.6545196687619437,8910720.0,5986784.0,17.344,5324.8960000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,278460.0,187087.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,90790.0,0.3048877591645484,8841472.0,7409664.0,14.4,5339.296000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276296.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91348.0,0.30839932769037415,8835840.0,7356288.0,14.208,5353.504000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276120.0,229884.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,90985.0,0.3092492351141445,8812672.0,6844992.0,14.592,5368.096000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275396.0,213906.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.016,5374.112000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.616,5377.728000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51570.0,0.42819443828447246,6222464.0,4026976.0,12.768,5390.496000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194452.0,125843.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7331072.0,7292928.0,8.416,5398.912000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229096.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.72,5485.632000000001,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,285.216,5770.848000000002,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.224,5775.072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,5778.304000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,288576.0,11.584,5789.888000000002,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9018.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.696,5795.584000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424708.0,20076672.0,1832584.0,0,0.0,21909256.0,21909256.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.304,5881.888000000002,2452096.0,607744.0,8508416.0,916292.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.344,5891.232000000002,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,5894.7840000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.376,5904.160000000002,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,5907.5520000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,5910.944000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,5915.488000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.728,5925.216000000001,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5928.480000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.216,5933.696000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5936.992000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,5941.536000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.264,5948.800000000002,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798340.0,6077440.0,1519240.0,0,0.0,7596680.0,7596680.0,0.0,14280.0,0.0,4861952.0,1536.0,6.848,5955.648000000002,0.0,0.0,3038720.0,759620.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,48.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,13.344,5968.992000000002,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.968,5972.960000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,5975.776000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5978.560000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,5981.952000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,5985.376000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.128,5989.504000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.344,5994.848000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,5998.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
