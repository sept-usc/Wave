Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,3.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,8.608,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,11.776,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.424,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.712,19.136,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.384,23.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.024,28.544,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.936,32.480000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,35.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,37.952000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,41.120000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.808,44.928000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,48.06400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,51.48800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.352,55.84,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.072,58.912000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,62.17600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,65.66400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,2176.0,8192.0,5.696,71.36000000000001,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,74.78400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.472,80.25600000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,83.87200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.488,87.36000000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.128,91.48800000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.672,96.16000000000001,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.616,99.77600000000001,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.224,104.00000000000001,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.456,107.45600000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,110.91200000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.504,116.41600000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,119.80800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.584,123.39200000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.672,128.06400000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.64,132.704,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),36,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,8.064,140.768,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,145.088,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),38,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,152.672,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,156.864,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),40,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.616,164.48000000000002,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,168.8,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,173.40800000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.768,178.17600000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,183.616,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,188.16000000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,191.52000000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,196.09600000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.416,200.51200000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.376,205.88800000000003,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,210.43200000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,213.72800000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.584,229.31200000000004,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),53,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,236.89600000000004,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,241.28000000000003,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,244.64000000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,248.12800000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.896,253.02400000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,256.35200000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,259.71200000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.256,263.9680000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.416,268.38400000000007,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47392.0,7.328,275.71200000000005,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1481.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,4.032,279.744,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43744.0,7.2,286.944,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1367.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.328,290.272,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),66,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,300.448,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.472,305.91999999999996,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,309.31199999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",69,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,312.60799999999995,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",70,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.44,318.04799999999994,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",71,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,321.40799999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",72,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,324.79999999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.224,329.02399999999994,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.768,333.7919999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),75,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.392,341.1839999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,345.5039999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),77,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,353.0879999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,357.4079999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),79,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,364.9279999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,369.18399999999986,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.416,373.59999999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",82,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,378.11199999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",83,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.248,383.35999999999984,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,387.64799999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,390.8799999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.864,395.74399999999986,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.768,400.51199999999983,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",88,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.536,406.04799999999983,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,410.3679999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,413.6639999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",91,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.52,429.1839999999998,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),92,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,436.7359999999998,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",93,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.416,441.1519999999998,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,444.51199999999983,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,447.99999999999983,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.216,453.21599999999984,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,456.4159999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,459.77599999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,464.3199999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,468.5759999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45792.0,7.36,475.9359999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1431.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,4.032,479.9679999999998,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,48864.0,7.424,487.39199999999977,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1527.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",104,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.648,491.0399999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),105,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.272,501.3119999999998,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",106,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.28,506.59199999999976,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,509.98399999999975,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",108,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,513.2479999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",109,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.248,518.4959999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",110,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,522.0479999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",111,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,525.4719999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.416,529.8879999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.416,534.3039999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),114,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,541.7599999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,546.0799999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),116,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,553.6639999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,557.9839999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),118,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.744,565.728,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,569.952,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.48,574.432,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.256,578.688,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",122,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.632,584.3199999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,588.8639999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,592.0959999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,596.4159999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.544,600.9599999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",127,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,606.304,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",128,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,610.8159999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",129,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,614.0479999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",130,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.616,629.6639999999999,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),131,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,637.1199999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",132,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,641.4719999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,644.7999999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",134,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,648.1919999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",135,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.408,653.5999999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",136,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,656.8319999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",137,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,660.0639999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,664.5759999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.576,669.1519999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45792.0,7.232,676.3839999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1431.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,680.0639999999997,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43232.0,7.456,687.5199999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1351.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",143,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,691.0399999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),144,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.4,701.4399999999997,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",145,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.536,706.9759999999997,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.712,710.6879999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,714.0159999999996,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.96,718.9759999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,722.2079999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,725.5999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,730.1119999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,734.5599999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),153,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,742.0479999999997,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",154,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,746.3999999999996,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),155,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,753.8879999999997,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,758.0799999999997,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),157,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.744,765.8239999999997,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",158,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.416,770.2399999999998,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,774.8799999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.288,779.1679999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",161,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,784.6079999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.672,789.2799999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",163,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.488,792.7679999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,797.2799999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.256,801.5359999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",166,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,806.8799999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,811.5839999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",168,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,814.9759999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",169,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.456,830.4319999999999,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),170,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,8.064,838.4959999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",171,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.48,842.9759999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,846.3999999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.552,849.9519999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",174,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.696,855.6479999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",175,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,859.0079999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",176,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,862.304,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.192,866.496,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.704,871.1999999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45952.0,7.168,878.3679999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1436.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",180,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,882.0479999999999,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",181,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45728.0,7.328,889.3759999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1429.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",182,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.552,892.9279999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),183,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.24,903.1679999999999,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",184,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.376,908.5439999999999,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",185,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,911.8719999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",186,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,915.2639999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",187,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,920.608,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",188,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,923.8399999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",189,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,927.1039999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.576,931.68,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",191,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.576,936.256,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),192,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,943.8399999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.288,948.1279999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),194,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.424,955.5519999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",195,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,959.7119999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),196,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.808,967.5199999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",197,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,971.9039999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,976.4159999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.576,980.9919999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",200,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,986.4959999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,990.8159999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",202,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,994.112,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,998.752,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.256,1003.0079999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,1008.448,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,1013.1519999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,1016.544,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",208,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.392,1031.936,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),209,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,1039.5839999999998,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",210,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,1043.744,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,1046.9759999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",212,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,1050.4319999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",213,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.152,1055.5839999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",214,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,1058.9439999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1062.3359999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.32,1066.6559999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.352,1071.0079999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45600.0,7.264,1078.2719999999997,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1425.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.872,1082.1439999999998,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43776.0,7.136,1089.2799999999997,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1368.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",221,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.36,1092.6399999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),222,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,1102.8159999999996,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",223,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.6,1108.4159999999995,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",224,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,1111.8399999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.424,1115.2639999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",226,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.376,1120.6399999999994,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",227,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1123.9359999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1127.1999999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",229,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.448,1131.6479999999995,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",230,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.48,1136.1279999999995,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),231,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,1143.6799999999994,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",232,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.416,1148.0959999999993,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),233,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1155.5519999999992,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",234,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,1159.9359999999992,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),235,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1167.3919999999991,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",236,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,1171.7439999999992,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,1176.2879999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.672,1180.9599999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,1186.3039999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,1190.8799999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.136,1194.0159999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.672,1198.6879999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.544,1203.2319999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",244,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.696,1208.9279999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,1213.4399999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",246,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,1216.7359999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",247,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.616,1232.3519999999994,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),248,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,1239.9359999999995,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",249,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.288,1244.2239999999995,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",250,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,1247.6479999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",251,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,1251.0079999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",252,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.992,1255.9999999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",253,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1259.2639999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",254,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1262.6559999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.8,1267.4559999999992,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.288,1271.7439999999992,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",257,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45792.0,7.2,1278.9439999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1431.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.904,1282.8479999999993,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45888.0,7.2,1290.0479999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1434.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",260,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,1293.5679999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),261,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,1303.7759999999994,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",262,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.44,1309.2159999999994,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1312.5759999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,1315.9039999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.896,1320.7999999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1324.1919999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1327.5199999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.48,1331.9999999999993,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.48,1336.4799999999993,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),270,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,1344.0639999999994,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",271,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.448,1348.5119999999995,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),272,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,1356.0959999999995,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",273,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.288,1360.3839999999996,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),274,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1367.8399999999995,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",275,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,1372.0319999999995,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,1376.4159999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.384,1380.7999999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",278,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,1386.1439999999996,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,1390.7839999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",280,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,1394.0159999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.256,1398.2719999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.48,1402.7519999999997,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",283,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,1408.1919999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.352,1412.5439999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,1415.7759999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",286,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.584,1431.36,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),287,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1438.8159999999998,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",288,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,1442.9759999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.168,1446.1439999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,1449.6319999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.632,1455.264,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1458.5279999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1461.7919999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,1466.3039999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.704,1471.0079999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,42880.0,7.232,1478.2399999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1340.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.616,1481.8559999999995,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44928.0,7.296,1489.1519999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1404.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1492.5439999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),300,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.368,1502.9119999999996,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",301,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.216,1508.1279999999995,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",302,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.648,1511.7759999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",303,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,1515.1679999999994,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",304,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.024,1520.1919999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",305,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1523.4879999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",306,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1526.8159999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.672,1531.4879999999994,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,1535.7439999999995,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),309,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,1543.2959999999994,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",310,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,1547.5199999999993,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),311,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1554.9759999999992,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",312,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,1559.3279999999993,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),313,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,1566.8159999999993,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,1571.1359999999993,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",315,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,1575.6799999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,1579.9999999999993,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",317,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.472,1585.4719999999993,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",318,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.672,1590.1439999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",319,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1593.5039999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,1597.8239999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,1602.143999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",322,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.28,1607.423999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",323,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,1612.0639999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",324,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,1615.2959999999991,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",325,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.456,1630.751999999999,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),326,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,1638.207999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,1642.591999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,1645.8559999999989,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,1649.1839999999988,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",330,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.44,1654.623999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",331,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1657.8879999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",332,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,1661.3439999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.256,1665.5999999999988,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,1670.2079999999987,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47616.0,7.296,1677.5039999999988,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1488.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",336,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,1681.1839999999988,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",337,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45280.0,7.328,1688.5119999999988,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1415.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",338,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.584,1692.0959999999989,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),339,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.048,1702.1439999999989,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",340,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.312,1707.4559999999988,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",341,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,1710.6559999999988,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,1714.0479999999989,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",343,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.44,1719.487999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",344,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1722.7519999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1725.9839999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.768,1730.7519999999988,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.64,1735.391999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",348,67584000.0,145408000.0,4096000.0,0,0.0,149504000.0,149504000.0,1104000.0,832000.0,0.5702479338842975,66958976.0,723968.0,34.912,1770.303999999999,6144000.0,8192000.0,65536000.0,2048000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2092468.0,22624.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,1773.087999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",350,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.352,1777.4399999999991,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1780.6719999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",352,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.584,1784.2559999999992,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.136,1787.3919999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34432.0,5.728,1793.1199999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1076.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",355,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.592,1799.7119999999993,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34880.0,5.76,1805.4719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1090.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",357,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.656,1812.1279999999992,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34496.0,5.728,1817.8559999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1078.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",359,53248.0,0.0,106496.0,0,0.0,106496.0,106496.0,8448.0,34696.0,0.19580938253291302,2109440.0,0.0,6.656,1824.5119999999993,0.0,0.0,0.0,53248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34240.0,5.824,1830.3359999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1070.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",361,40960.0,0.0,81920.0,0,0.0,81920.0,81920.0,8448.0,35080.0,0.19408197022606138,2109440.0,128.0,6.624,1836.9599999999994,0.0,0.0,0.0,40960.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.968,1840.9279999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,1843.8079999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.376,1849.1839999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,1852.2559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.376,1857.6319999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",367,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,37720.0,8432.0,0.8172993586410123,527232.0,6688.0,9.088,1866.7199999999993,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,209.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.704,1875.4239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",369,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42272.0,6.08,1881.5039999999992,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1321.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.648,1885.1519999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",371,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.68,1888.8319999999992,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.824,1894.6559999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.68,1898.3359999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17652.0,0.7025278058645096,1701760.0,1285696.0,14.976,1913.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53180.0,40178.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17684.0,0.34927877539005003,1703168.0,1560576.0,11.68,1924.9919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53224.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17599.0,0.3802950808127047,1703040.0,1372864.0,13.088,1938.0799999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53220.0,42902.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17611.0,0.3801344549646264,1696256.0,1059392.0,13.12,1951.1999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53008.0,33106.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.768,1955.9679999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,1959.3599999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9463.0,0.5269919024292712,1161728.0,852960.0,9.632,1968.9919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36304.0,26655.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549440.0,1536000.0,4.704,1973.6959999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48420.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",382,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,513024.0,512000.0,23.04,1996.7359999999994,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16032.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",383,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.616,2060.3519999999994,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.584,2063.9359999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,2067.135999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,61280.0,12.032,2079.167999999999,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1915.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.616,2082.783999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",388,1994560.0,4245120.0,405120.0,0,0.0,4650240.0,4650240.0,528.0,5248.0,0.09141274238227147,514304.0,512000.0,22.976,2105.7599999999993,533120.0,128000.0,1792000.0,202560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16072.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",389,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.392,2137.151999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2140.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",391,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.864,2173.3759999999993,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2176.7359999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2180.0959999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,2184.6079999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",395,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.712,2196.3199999999997,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2199.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",397,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.896,2204.576,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",398,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2207.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",399,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,2212.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",400,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.056,2217.44,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",401,799808.0,1280000.0,319616.0,0,0.0,1599616.0,1599616.0,0.0,3000.0,0.0,1024000.0,0.0,5.184,2222.6240000000003,0.0,0.0,640000.0,159808.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",402,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.896,2239.5200000000004,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2242.8800000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",404,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2246.2720000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.616,2249.8880000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2253.184,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.544,2257.728,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",408,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2260.512,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2263.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2266.592,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",411,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2269.44,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.904,2273.344,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.008,2280.352,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,2283.776,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2287.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",416,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.84,2290.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",417,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.704,2295.6800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",418,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2298.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",419,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,2302.7200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",420,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.832,2307.552,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",421,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.128,2311.6800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",422,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.104,2314.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",423,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,2318.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.2,2321.2799999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.808,2325.0879999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",426,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,8320.0,8192.0,7.072,2332.16,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,260.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.456,2335.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",428,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.832,2340.448,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",429,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.808,2344.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",430,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.456,2347.712,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",431,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.032,2351.744,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.16,2355.904,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.584,2359.488,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.192,2363.68,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",435,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.36,2367.04,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.232,2370.272,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",437,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.664,2375.936,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",438,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2379.168,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2382.4320000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.448,2386.88,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.8,2391.6800000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),442,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.936,2399.6160000000004,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",443,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,2403.8080000000004,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),444,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,2411.3600000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",445,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,2415.7120000000004,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),446,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,2423.1680000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,2427.3600000000006,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,2431.9040000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.768,2436.6720000000005,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,2442.0800000000004,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.256,2446.3360000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,2449.536,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.768,2454.304,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.64,2458.944,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.6,2464.544,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,2468.864,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.52,2472.384,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.608,2476.992,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.32,2481.3120000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.328,2496.6400000000003,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),461,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,2504.0960000000005,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,2508.2880000000005,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,2511.7440000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,2515.0400000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.632,2520.6720000000005,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,2524.0000000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2527.3920000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.288,2531.6800000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,2536.128,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43520.0,7.264,2543.3920000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1360.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.776,2547.168,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",472,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45792.0,7.36,2554.5280000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1431.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.648,2558.1760000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),474,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.144,2568.32,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.28,2573.6000000000004,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,2576.8320000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,2580.32,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.504,2585.824,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2589.024,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2592.384,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.704,2597.088,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.544,2601.632,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),483,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.68,2609.312,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",484,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,2613.4719999999998,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),485,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.424,2620.8959999999997,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",486,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,2625.0559999999996,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),487,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,2632.5759999999996,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",488,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,2636.8319999999994,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,2641.4719999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.544,2646.015999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.536,2651.551999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,2655.8399999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,2659.1039999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,2663.7439999999992,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,2668.0639999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.536,2673.5999999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,2678.2079999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,2681.5359999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.288,2685.8239999999996,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.32,2690.144,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.392,2705.5359999999996,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),502,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.424,2712.9599999999996,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",503,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,2717.2799999999997,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2720.5759999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,2724.0319999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.568,2729.6,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2732.832,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2736.064,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.736,2740.7999999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,2745.408,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46592.0,7.072,2752.48,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1456.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.648,2756.128,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45376.0,7.2,2763.328,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1418.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.744,2767.072,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),515,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,2777.28,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",516,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.248,2782.5280000000002,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,2785.9840000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,2789.28,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.152,2794.4320000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2797.664,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2801.056,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.8,2805.856,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.352,2810.208,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),524,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.456,2817.664,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",525,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,2821.9840000000004,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),526,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,2829.5040000000004,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",527,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,2833.664,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),528,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,2841.2160000000003,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",529,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,2845.568,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.864,2850.4320000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,2854.88,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,2860.32,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,2864.896,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,2868.3520000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.416,2872.7680000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,2877.2160000000003,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.568,2882.7840000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.832,2887.6160000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2890.9120000000003,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.128,2895.0400000000004,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.608,2899.6480000000006,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.52,2915.1680000000006,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),543,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,2922.6880000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",544,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,2926.8800000000006,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",545,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2930.1760000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.424,2933.6000000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",547,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.992,2938.5920000000006,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",548,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,2941.7600000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",549,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2945.120000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,2949.6640000000007,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.736,2954.4000000000005,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",552,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44832.0,7.328,2961.7280000000005,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1401.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.808,2965.5360000000005,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",554,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44896.0,7.264,2972.8000000000006,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1403.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",555,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,2976.3200000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),556,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.144,2986.4640000000004,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.6,2992.0640000000003,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,2995.3280000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,2998.5920000000006,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",560,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.28,3003.8720000000008,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",561,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,3007.232000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3010.6240000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.416,3015.040000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",564,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.384,3019.424000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),565,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,3026.9120000000007,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",566,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3031.2640000000006,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),567,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.616,3038.8800000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",568,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,3043.1360000000004,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),569,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3050.6880000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",570,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,3054.9440000000004,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,3059.4880000000003,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.352,3063.84,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.248,3069.088,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,3073.664,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.2,3076.864,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,3081.44,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.64,3086.08,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.312,3091.392,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,3095.8399999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,3099.296,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.608,3103.904,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",582,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.768,3108.672,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",583,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.456,3124.128,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),584,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3131.6800000000003,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",585,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.512,3136.1920000000005,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",586,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3139.5520000000006,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",587,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.488,3143.0400000000004,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",588,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.96,3148.0000000000005,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",589,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3151.3280000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",590,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3154.6560000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.448,3159.1040000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.384,3163.4880000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",593,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44992.0,7.232,3170.7200000000003,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1406.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.84,3174.5600000000004,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45632.0,7.168,3181.7280000000005,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1426.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.328,3185.0560000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),597,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.08,3195.1360000000004,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",598,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.504,3200.6400000000003,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,3203.9040000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,3207.2000000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.472,3212.6720000000005,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3216.0000000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,3219.4560000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,3224.0000000000005,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.768,3228.7680000000005,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),606,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.424,3236.1920000000005,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,3240.4160000000006,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),608,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,3248.0000000000005,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",609,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,3252.3840000000005,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),610,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3259.9360000000006,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",611,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3264.2880000000005,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,3268.6720000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,3273.1840000000007,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.184,3278.368000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,3282.656000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.68,3286.3360000000007,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,3291.040000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.576,3295.616000000001,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,3301.120000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.128,3305.248000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,3308.704000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.576,3313.280000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.288,3317.568000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.456,3333.0240000000013,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),625,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,3340.608000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",626,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3344.960000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,3348.192000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,3351.456000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.536,3356.992000000001,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3360.288000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3363.552000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.288,3367.840000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,3372.4480000000012,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43872.0,7.232,3379.680000000001,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1371.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,3383.360000000001,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",636,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44864.0,7.168,3390.528000000001,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1402.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",637,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.712,3394.240000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),638,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.144,3404.384000000001,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.376,3409.760000000001,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.616,3413.376000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",641,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.424,3416.800000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",642,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.408,3422.208000000001,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",643,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3425.600000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3428.928000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,3433.4720000000007,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.704,3438.176000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),647,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,3445.824000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",648,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3450.176000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),649,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,3457.6640000000007,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.416,3462.080000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),651,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.808,3469.888000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3474.2400000000007,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.96,3479.2000000000007,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.704,3483.904000000001,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,3489.344000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,3493.632000000001,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.488,3497.120000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,5.024,3502.1440000000007,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.384,3506.5280000000007,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,3511.9360000000006,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.416,3516.3520000000008,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,3519.616000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",663,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.32,3523.936000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.224,3528.160000000001,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",665,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.584,3543.744000000001,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),666,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,3551.264000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",667,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,3555.456000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",668,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,3558.720000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",669,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,3562.112000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",670,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,3567.456000000001,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",671,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3570.848000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3574.272000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.768,3579.040000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,3583.648000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",675,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46816.0,7.456,3591.104000000001,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1463.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.616,3594.720000000001,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",677,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45088.0,7.392,3602.112000000001,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1409.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",678,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.776,3605.888000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),679,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,3616.096000000001,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",680,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.312,3621.408000000001,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",681,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3624.768000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",682,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,3628.1600000000008,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",683,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.96,3633.120000000001,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",684,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3636.288000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,3639.744000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.64,3644.384000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.288,3648.672000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),688,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,3656.320000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",689,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,3660.576000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),690,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,3668.224000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",691,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,3672.608000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),692,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,3680.128000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,3684.352000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",694,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.768,3689.1200000000013,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",695,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.192,3693.3120000000013,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",696,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,3698.7520000000013,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,3703.3600000000015,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",698,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.552,3706.9120000000016,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,3711.2960000000016,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,3715.7440000000015,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",701,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.312,3721.0560000000014,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,3725.5040000000013,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",703,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,3728.7360000000012,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",704,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.128,3732.8640000000014,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",705,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.704,3737.5680000000016,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",706,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.52,3753.0880000000016,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),707,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3760.6400000000017,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",708,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,3764.8960000000015,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,3768.3520000000017,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,3771.712000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.152,3776.864000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3780.128000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,3783.584000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,5.024,3788.608000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,3792.864000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",716,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47584.0,7.296,3800.1600000000017,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1487.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.968,3804.1280000000015,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",718,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,42496.0,7.2,3811.3280000000013,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1328.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",719,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.36,3814.6880000000015,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),720,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.24,3824.9280000000012,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.344,3830.2720000000013,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",722,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.808,3834.0800000000013,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,3837.472000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",724,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.088,3842.5600000000013,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",725,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3845.856000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3849.184000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.288,3853.472000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.512,3857.9840000000013,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),729,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.68,3865.664000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",730,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,3870.048000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),731,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.616,3877.664000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",732,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.288,3881.952000000001,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),733,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.424,3889.376000000001,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.416,3893.7920000000013,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",735,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,3898.1120000000014,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",736,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,3902.5600000000013,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",737,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,3907.9040000000014,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.768,3912.6720000000014,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",739,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,3915.9360000000015,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,3920.4480000000017,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.608,3925.056000000002,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",742,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.312,3930.3680000000018,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.416,3934.784000000002,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",744,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,3938.112000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",745,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.672,3942.784000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",746,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.672,3947.456000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",747,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.296,3962.7520000000018,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),748,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,3970.2720000000018,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",749,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,3974.6240000000016,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",750,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.584,3978.2080000000014,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,3981.5680000000016,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",752,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,64.0,5.28,3986.848000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",753,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3990.1760000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",754,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,3993.7920000000017,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.32,3998.112000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.32,4002.432000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",757,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44416.0,7.104,4009.536000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1388.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",758,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.84,4013.376000000002,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",759,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44640.0,7.04,4020.416000000002,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1395.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",760,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,4023.936000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),761,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.144,4034.0800000000017,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.472,4039.552000000002,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",763,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,4042.912000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",764,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.232,4046.144000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",765,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,4051.488000000002,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",766,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4054.752000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,4057.984000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.192,4062.176000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",769,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.576,4066.752000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",770,67584000.0,145408000.0,4096000.0,0,0.0,149504000.0,149504000.0,1104000.0,832000.0,0.5702479338842975,66885376.0,712960.0,34.304,4101.056000000002,6144000.0,8192000.0,65536000.0,2048000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2090168.0,22280.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",771,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,4103.808000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.936,4107.744000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4111.072000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",774,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.52,4114.592000000003,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",775,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4117.440000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",776,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34432.0,5.92,4123.360000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1076.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",777,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.848,4130.208000000003,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",778,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34240.0,5.888,4136.096000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1070.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",779,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.56,4142.656000000004,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",780,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34304.0,5.76,4148.416000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1072.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",781,49152.0,0.0,98304.0,0,0.0,98304.0,98304.0,8448.0,34824.0,0.19523017193566278,2109440.0,0.0,6.56,4154.976000000004,0.0,0.0,0.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",782,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34368.0,5.728,4160.704000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1074.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",783,50176.0,0.0,100352.0,0,0.0,100352.0,100352.0,8448.0,34792.0,0.19537465309898241,2109440.0,128.0,6.656,4167.360000000004,0.0,0.0,0.0,50176.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",784,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.096,4171.456000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",785,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,4174.624000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",786,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.568,4180.192000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",787,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,4183.040000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",788,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.472,4188.512000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",789,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,32841.0,8418.0,0.7959717879735331,527232.0,6848.0,8.864,4197.376000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,214.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",790,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.512,4205.888000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,43168.0,5.952,4211.840000000003,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1349.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",792,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.68,4215.520000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",793,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.584,4219.104000000003,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",794,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.632,4224.736000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",795,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,4228.224000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",796,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17674.0,0.7022674438192783,1699584.0,1279200.0,14.592,4242.8160000000025,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53112.0,39975.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",797,0.0,0.0,0.0,0,0.0,0.0,0.0,10896.0,17664.0,0.3815126050420168,1700480.0,1256352.0,12.32,4255.136000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53140.0,39261.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",798,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17620.0,0.3800140745953554,1698944.0,1288256.0,13.024,4268.160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53092.0,40258.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17597.0,0.38032186498573795,1696768.0,1382080.0,12.992,4281.152000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53024.0,43190.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",800,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.864,4286.016000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",801,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.744,4289.760000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",802,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9405.0,0.5285241628233407,1163136.0,854208.0,9.088,4298.848000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36348.0,26694.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",803,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549408.0,1536000.0,4.64,4303.488000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48419.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",804,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,516352.0,512000.0,23.04,4326.528000000002,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16136.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",805,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,62.944,4389.4720000000025,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",806,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,4393.024000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",807,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,4396.096000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",808,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,59744.0,11.84,4407.936000000002,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1867.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.712,4411.648000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",810,1994560.0,4245120.0,405120.0,0,0.0,4650240.0,4650240.0,528.0,5248.0,0.09141274238227147,518400.0,512000.0,22.944,4434.592000000003,533120.0,128000.0,1792000.0,202560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16200.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",811,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.032,4466.624000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",812,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4470.016000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",813,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.096,4502.112000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",814,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,4505.632000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",815,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,4509.088000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",816,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,4513.536000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",817,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.712,4525.248000000004,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",818,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4528.576000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.056,4533.632000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",820,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4536.928000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",821,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,4541.408000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",822,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.088,4546.496000000004,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",823,799808.0,1280000.0,319616.0,0,0.0,1599616.0,1599616.0,0.0,3000.0,0.0,1024000.0,0.0,5.056,4551.552000000003,0.0,0.0,640000.0,159808.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",824,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.768,4568.320000000003,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",825,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,4571.648000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",826,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4574.944000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",827,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.872,4578.816000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",828,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,4582.176000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",829,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.032,4586.208000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",830,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,4589.216000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",831,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4592.096000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",832,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,4595.456000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,4598.144000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",834,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.84,4601.984000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",835,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.04,4609.024000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",836,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,4612.640000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",837,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4616.064000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",838,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.936,4620.000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",839,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.768,4624.768000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",840,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4628.064000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
