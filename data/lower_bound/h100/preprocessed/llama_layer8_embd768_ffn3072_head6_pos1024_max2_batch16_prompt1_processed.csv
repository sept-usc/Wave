Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.88,2.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.656,5.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.224,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,15.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,160.0,32.0,3.712,18.848,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,128.0,4.544,23.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,5.312,28.704,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,32.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.752,35.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,37.696000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,40.83200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.808,44.64000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,48.03200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,51.58400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,128.0,32.0,4.384,55.96800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.232,59.20000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.36,62.56000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,3.456,66.016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,1152.0,0.0,3840.0,49152.0,10.176,76.19200000000001,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,120.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.68,79.87200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.344,85.21600000000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,3.36,88.57600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,3.552,92.12800000000001,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,4.384,96.51200000000001,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,16384.0,36864.0,0.0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,4.128,100.64000000000001,0.0,4096.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,104.09600000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,14336.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,32.0,0.0,8192.0,8192.0,4.064,108.16000000000003,0.0,4096.0,14336.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,111.42400000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,114.97600000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.776,122.75200000000002,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.456,126.20800000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.456,129.66400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,134.36800000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,138.91200000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),36,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.456,150.36800000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,154.36800000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),38,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.168,165.53600000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,169.53600000000003,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),40,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,180.54400000000004,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,184.48000000000005,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,189.05600000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,193.53600000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,199.42400000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,204.00000000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.648,207.64800000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,212.38400000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,216.83200000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,222.30400000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,227.04000000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,230.56000000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.808,246.36800000000002,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),53,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,257.44,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,261.44,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,264.928,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,268.288,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.392,275.68,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,279.008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.552,282.56,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,287.072,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,291.776,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,62,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882656.0,1102688.0,15.648,307.42400000000004,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433833.0,34459.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,63,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.984,313.408,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.936,317.344,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,65,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881024.0,1106432.0,15.904,333.248,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433782.0,34576.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,66,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,339.008,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",67,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.424,342.43199999999996,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,68,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3064768.0,13.152,355.58399999999995,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95774.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,69,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.568,377.15199999999993,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,380.5759999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,384.12799999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",72,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.392,391.5199999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",73,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,394.75199999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",74,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,398.11199999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.416,402.52799999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,407.16799999999995,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),77,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.616,418.78399999999993,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",78,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.224,423.0079999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),79,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.2,434.2079999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",80,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,438.1119999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),81,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.944,449.0559999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",82,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.872,452.92799999999994,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,457.59999999999997,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",84,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.352,461.95199999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",85,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.568,467.5199999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,472.31999999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",87,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,475.71199999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,480.28799999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",89,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,484.768,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",90,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,490.75199999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,495.26399999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",92,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,498.78399999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",93,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.776,514.56,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),94,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,525.5999999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",95,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,529.5679999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",96,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,533.0239999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,536.4159999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",98,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.936,544.352,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",99,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,547.68,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",100,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,550.976,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.416,555.392,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,560.096,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,103,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882944.0,1102400.0,15.616,575.712,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433842.0,34450.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,104,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.824,581.536,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",105,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,585.3439999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,106,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881824.0,1100096.0,15.808,601.1519999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433807.0,34378.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,107,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.728,606.8799999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,610.3679999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,109,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3059008.0,13.152,623.52,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95594.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,110,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.632,645.1519999999999,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,648.544,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",112,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,651.872,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",113,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.2,659.072,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",114,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.36,662.432,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",115,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.488,665.9200000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,670.528,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,675.168,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),118,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.2,686.368,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",119,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,690.336,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),120,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,701.344,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",121,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,705.1840000000001,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),122,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,716.1920000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",123,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,720.1280000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,724.8640000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,729.2800000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",126,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.208,735.4880000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,740.1280000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,743.5200000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,748.1280000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",130,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,752.6080000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",131,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,758.5600000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,763.2960000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",133,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,766.8480000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",134,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.904,782.7520000000002,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),135,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,793.7920000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",136,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,797.6320000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",137,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,801.1520000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,804.6400000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",139,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.52,812.1600000000002,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",140,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,815.4240000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",141,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,818.6880000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,823.3920000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.768,828.1600000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,144,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881472.0,1102144.0,15.584,843.7440000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433796.0,34442.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,145,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.792,849.5360000000002,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",146,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.744,853.2800000000002,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,147,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882976.0,1102720.0,15.68,868.9600000000002,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433843.0,34460.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,148,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.952,874.9120000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",149,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.68,878.5920000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,150,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3068736.0,13.088,891.6800000000001,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95898.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,151,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.728,913.408,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",152,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,916.8000000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,920.224,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",154,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.064,928.288,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",155,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,931.616,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",156,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,934.88,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,939.552,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,944.256,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),159,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,955.3919999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",160,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,959.328,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),161,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.848,970.1759999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",162,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.032,974.208,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),163,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,985.2479999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,989.184,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",165,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,993.824,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,998.2719999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",167,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.016,1004.2879999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,1009.0559999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1012.544,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,1017.184,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.256,1021.4399999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",172,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.76,1027.2,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.864,1032.064,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",174,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1035.5520000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",175,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.872,1051.4240000000002,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),176,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,1062.4640000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,1066.3680000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1069.824,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",179,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,1073.184,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",180,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.2,1080.384,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",181,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,1083.648,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",182,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.616,1087.264,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,1091.904,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",184,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.736,1096.64,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,185,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881472.0,1101440.0,15.552,1112.192,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433796.0,34420.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,186,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.888,1118.08,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.872,1121.952,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,188,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881856.0,1104800.0,16.032,1137.984,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433808.0,34525.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,189,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.952,1143.936,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.584,1147.52,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,191,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3055168.0,13.024,1160.5439999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95474.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,192,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,20.96,1181.504,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1185.024,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.584,1188.608,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",195,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.648,1196.2559999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,1199.5199999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,1202.8799999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,1207.4879999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,1212.0959999999995,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),200,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.232,1223.3279999999995,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",201,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.128,1227.4559999999994,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),202,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.296,1238.7519999999995,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",203,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,1242.5919999999994,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),204,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,1253.6959999999995,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",205,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,1257.6319999999994,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1262.2399999999993,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.864,1267.1039999999994,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.824,1272.9279999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,1277.4079999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1280.8959999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,1285.4719999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,1289.8879999999995,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.696,1295.5839999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,1300.1279999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,1303.5199999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.84,1319.3599999999994,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),217,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.944,1330.3039999999994,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",218,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,1334.2399999999993,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",219,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1337.5999999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,1340.8959999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",221,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.264,1348.1599999999992,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",222,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.36,1351.519999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.424,1354.943999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,1359.455999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",225,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,1363.967999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,226,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881792.0,1099872.0,16.032,1379.9999999999989,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433806.0,34371.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,227,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.824,1385.823999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",228,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,1389.503999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,229,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882496.0,1108512.0,15.712,1405.215999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433828.0,34641.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,230,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,1411.071999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,1414.463999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,232,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3059904.0,13.024,1427.487999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95622.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,233,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.504,1448.9919999999988,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",234,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1452.3519999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",235,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,1455.8079999999986,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",236,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.488,1463.2959999999987,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",237,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.296,1466.5919999999987,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.392,1469.9839999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,1474.6559999999988,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,1479.103999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),241,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,1490.1439999999989,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",242,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,1494.0479999999989,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),243,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.944,1504.9919999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",244,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,1508.8959999999988,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),245,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,1519.9359999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",246,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,1523.8719999999987,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.96,1528.8319999999987,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1533.3119999999988,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",249,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.44,1538.7519999999988,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.48,1543.2319999999988,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1546.719999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1551.455999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,1555.903999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,1561.887999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.928,1566.8159999999991,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",256,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,1570.2079999999992,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",257,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.744,1585.951999999999,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),258,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,1596.9599999999991,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",259,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,1600.799999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1604.255999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,1607.8079999999989,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.712,1615.5199999999988,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.584,1619.103999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,1622.399999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,1626.847999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,1631.359999999999,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,267,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882304.0,1100032.0,15.68,1647.039999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433822.0,34376.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,268,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.952,1652.991999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.68,1656.6719999999991,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,270,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882496.0,1099104.0,15.84,1672.511999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433828.0,34347.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,271,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.696,1678.207999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",272,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.552,1681.7599999999989,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,273,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3051456.0,13.056,1694.815999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95358.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,274,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.12,1715.9359999999988,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",275,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1719.2639999999988,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",276,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,1722.5919999999987,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",277,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.52,1730.1119999999987,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",278,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.392,1733.5039999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",279,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.488,1736.9919999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.48,1741.4719999999988,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.864,1746.3359999999989,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),282,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,1757.4719999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",283,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,1761.4079999999988,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),284,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,1772.4479999999987,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",285,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,1776.4479999999987,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),286,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,1787.5519999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",287,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,1791.5199999999988,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,1796.1919999999989,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,1800.639999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",290,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.08,1806.719999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,1811.3279999999988,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,1814.815999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,1819.551999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,1823.967999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,1829.919999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,1834.559999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,1838.175999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",298,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.904,1854.079999999999,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),299,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.944,1865.023999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,1869.023999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1872.543999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,1875.935999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.808,1883.743999999999,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.296,1887.039999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,1890.271999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.736,1895.0079999999991,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,1899.5839999999992,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,308,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880768.0,1101504.0,15.936,1915.519999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433774.0,34422.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,309,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,1921.279999999999,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",310,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,4.032,1925.311999999999,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,311,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883488.0,1104704.0,16.064,1941.375999999999,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433859.0,34522.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,312,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.112,1947.4879999999991,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",313,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,1950.847999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,314,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3062592.0,13.056,1963.903999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95706.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,315,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.44,1985.3439999999991,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1988.703999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",317,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,1992.063999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",318,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.128,2000.1919999999989,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",319,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.52,2003.7119999999989,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",320,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,2006.9759999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",321,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,2011.4879999999987,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.768,2016.2559999999987,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),323,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,2027.2959999999987,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",324,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,2031.2959999999987,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),325,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.976,2042.2719999999988,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",326,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.032,2046.3039999999987,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),327,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,2057.4079999999985,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",328,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,2061.3439999999987,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,2066.0159999999987,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,2070.431999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.92,2076.351999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",332,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,2081.151999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,2084.543999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,2089.343999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",335,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,2093.791999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",336,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,2099.423999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",337,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.864,2104.287999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,2107.615999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",339,196608.0,17651712.0,0.0,0,193273528320.0,17651712.0,193291180032.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,15.904,2123.519999999999,14880768.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,4608.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),340,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,2134.559999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",341,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,2138.559999999999,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,2142.015999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,2145.535999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",344,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,2152.9919999999993,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,2156.2239999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.328,2159.551999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.704,2164.2559999999994,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",348,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.416,2168.6719999999996,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,349,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881152.0,1108544.0,15.648,2184.3199999999997,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433786.0,34642.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,350,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,2190.08,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.904,2193.984,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,352,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880224.0,1102720.0,15.744,2209.728,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433757.0,34460.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,353,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.984,2215.712,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",354,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,2219.2,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,355,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3056832.0,12.992,2232.192,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95526.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,356,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,20.992,2253.184,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",357,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,2256.576,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,2259.936,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",359,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,8.192,2268.128,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",360,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,2271.3920000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",361,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,2274.6240000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",362,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,2279.2960000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",363,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.64,2283.936,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,364,787488000.0,1574912000.0,64000.0,0,0.0,1574976000.0,1574976000.0,1962500.0,16000.0,0.9919130654536265,104876416.0,2048000.0,68.928,2352.864,0.0,0.0,787456000.0,32000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3277388.0,64000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.752,2355.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",366,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,256.0,512.0,4.48,2360.096,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2363.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",368,0.0,512000.0,0.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.288,2367.648,0.0,512000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,3.232,2370.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,149888.0,6.144,2377.024,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4684.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",371,245760.0,0.0,491520.0,0,0.0,491520.0,491520.0,33792.0,137760.0,0.1969781757134863,8421952.0,96.0,7.424,2384.448,0.0,0.0,0.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263186.0,3.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,149184.0,6.016,2390.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4662.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",373,147456.0,0.0,294912.0,0,0.0,294912.0,294912.0,33792.0,140832.0,0.19351291918636612,8421952.0,96.0,7.488,2397.9519999999998,0.0,0.0,0.0,147456.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263186.0,3.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,150144.0,6.08,2404.0319999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4692.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",375,262144.0,0.0,524288.0,0,0.0,524288.0,524288.0,33792.0,137248.0,0.19756782039289056,8422016.0,128.0,7.36,2411.392,0.0,0.0,0.0,262144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263188.0,4.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,147456.0,6.048,2417.4399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4608.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",377,245760.0,0.0,491520.0,0,0.0,491520.0,491520.0,33792.0,137760.0,0.1969781757134863,8421952.0,576.0,7.104,2424.5439999999994,0.0,0.0,0.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263186.0,18.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,48.0,0.0,16448.0,2048.0,4.672,2429.2159999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,2432.3199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,41.0,0.9397944199706314,2048.0,0.0,5.92,2438.2399999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,2441.4079999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,41.0,0.9397944199706314,2048.0,0.0,6.112,2447.5199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",383,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,102336.0,33664.0,0.7524705882352941,2100992.0,30464.0,9.504,2457.0239999999994,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65656.0,952.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,8.672,2465.6959999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,2080256.0,170592.0,6.272,2471.9679999999994,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65008.0,5331.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.416,2476.3839999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",387,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,16000.0,0.0,0.0,4096000.0,5.184,2481.5679999999998,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,16000.0,0.8941574936494496,2048000.0,0.0,6.592,2488.16,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,2491.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,166752.0,75668.0,0.6878640376206584,7361408.0,5133056.0,17.44,2509.056,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,230044.0,160408.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,33756.0,76083.0,0.30732253571135937,7365760.0,6242304.0,13.76,2522.8160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,230180.0,195072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,34776.0,75511.0,0.3153227488280577,7374336.0,6242304.0,14.976,2537.7920000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,230448.0,195072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",393,0.0,0.0,0.0,0,0.0,0.0,0.0,34776.0,75746.0,0.31465228642261267,7364224.0,6242304.0,15.136,2552.9280000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,230132.0,195072.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,16000.0,0.4802494802494803,4096000.0,0.0,5.792,2558.7200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",395,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,2562.1440000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",396,0.0,0.0,0.0,0,0.0,0.0,0.0,42241.0,41412.0,0.5049549926482015,5085824.0,3529664.0,12.224,2574.3680000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,158932.0,110302.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",397,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,64000.0,0.0,6197632.0,6144000.0,7.68,2582.0480000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193676.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",398,7978208.0,16980480.0,1620416.0,0,0.0,18600896.0,18600896.0,2112.0,20992.0,0.09141274238227147,2048640.0,2048000.0,23.072,2605.1200000000003,2132480.0,512000.0,7168000.0,810208.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64020.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",399,0.0,2621952.0,0.0,0,0.0,2621952.0,2621952.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,63.776,2668.896,2621952.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.064,2672.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,3.2,2676.16,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,4608000.0,253952.0,11.648,2687.808,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144000.0,7936.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.576,2692.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",404,7978256.0,16980480.0,1620512.0,0,0.0,18600992.0,18600992.0,2112.0,20992.0,0.09141274238227147,2048640.0,2048000.0,22.976,2715.36,2132480.0,512000.0,7168000.0,810256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64020.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",405,97280.0,0.0,194560.0,0,0.0,194560.0,194560.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,9.376,2724.7360000000003,0.0,0.0,0.0,97280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",406,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2728.032,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",407,97280.0,0.0,194560.0,0,0.0,194560.0,194560.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,9.76,2737.7920000000004,0.0,0.0,0.0,97280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2741.1520000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,2744.6400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,2749.1200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",411,16384.0,585216.0,32768.0,0,0.0,617984.0,617984.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,12.128,2761.2480000000005,585216.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,2764.6080000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",413,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.184,2769.792000000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2773.024000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",415,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,2777.5680000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",416,2973696.0,5890048.0,1081344.0,0,0.0,6971392.0,6971392.0,0.0,16000.0,0.0,0.0,2048000.0,7.136,2784.7040000000006,0.0,1024000.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",417,3199248.0,5120000.0,1278496.0,0,0.0,6398496.0,6398496.0,0.0,12000.0,0.0,4096000.0,0.0,6.4,2791.1040000000007,0.0,0.0,2560000.0,639248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",418,8704.0,0.0,17408.0,0,0.0,17408.0,17408.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,16.48,2807.5840000000007,0.0,0.0,0.0,8704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",419,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,3.456,2811.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",420,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.392,2814.4320000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,128.0,3.648,2818.080000000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",422,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,3.264,2821.344000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,256.0,512.0,4.544,2825.888000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,16.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2828.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",425,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2831.3920000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",426,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,2834.8800000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",427,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,2837.8240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,288.0,32.0,3.936,2841.7600000000007,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",429,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,5.0,0.0,32.0,32.0,7.456,2849.216000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,2852.7040000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2856.0320000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",432,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,4.48,2860.5120000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",433,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,4.896,2865.408000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",434,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2868.736000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2872.2240000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",436,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,288.0,128.0,4.864,2877.0880000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,4.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",437,0.0,0.0,0.0,0,0.0,0.0,0.0,176.0,16.0,0.9166666666666666,256.0,96.0,4.384,2881.4720000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,3.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",438,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,256.0,3.296,2884.7680000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",439,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,3.296,2888.0640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",440,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,288.0,0.0,3.36,2891.4240000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,256.0,128.0,3.808,2895.2320000000004,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",442,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,1152.0,0.0,43776.0,49152.0,14.624,2909.856,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1368.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",443,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,256.0,32.0,3.808,2913.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",444,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,32.0,32.0,5.152,2918.8160000000003,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",445,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,64.0,3.424,2922.2400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",446,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,128.0,96.0,0.5714285714285714,5120.0,4096.0,3.424,2925.664,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,80.0,0.0,8192.0,8192.0,4.16,2929.824,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,16384.0,36864.0,0.0,0,0.0,36864.0,36864.0,0.0,32.0,0.0,8192.0,8192.0,4.256,2934.08,0.0,4096.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",449,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.648,2937.728,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,14400.0,32896.0,0.0,0,0.0,32896.0,32896.0,0.0,32.0,0.0,8192.0,8192.0,4.224,2941.952,0.0,4096.0,14400.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,2945.28,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,2948.5440000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",453,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.936,2956.4800000000005,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",454,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.296,2959.7760000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.52,2963.2960000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,2967.8720000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.608,2972.4800000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),458,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.168,2983.6480000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",459,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,2987.5840000000007,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),460,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,2998.6240000000007,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",461,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,3002.6240000000007,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),462,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,3013.6640000000007,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",463,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,3017.600000000001,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",464,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,3022.176000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",465,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.64,3026.8160000000007,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",466,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.208,3033.024000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,3037.536000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,3040.896000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,3045.5040000000013,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",470,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,3049.8880000000013,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",471,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,3055.392000000001,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,3059.936000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",473,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,3063.392000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",474,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.768,3068.160000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.736,3072.896000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",476,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.776,3088.672000000001,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),477,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.976,3099.648000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",478,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,3103.584000000001,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",479,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.648,3107.2320000000013,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,3110.7840000000015,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",481,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.68,3118.4640000000013,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",482,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.392,3121.856000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,3125.1200000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.416,3129.5360000000014,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,3134.2400000000016,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,486,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880544.0,1104576.0,15.968,3150.2080000000014,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433767.0,34518.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,487,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.048,3156.256000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.872,3160.128000000001,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,489,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880320.0,1100736.0,15.808,3175.936000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433760.0,34398.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,490,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,3181.7920000000013,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",491,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,3185.4080000000013,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,492,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3061760.0,12.96,3198.3680000000013,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95680.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,493,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.184,3219.5520000000015,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,3222.8480000000013,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,3226.2080000000014,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.456,3233.6640000000016,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,3236.9920000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.392,3240.3840000000014,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,3244.9920000000016,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,3249.6960000000017,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),501,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,3260.8000000000015,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",502,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.096,3264.8960000000015,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),503,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,3275.9360000000015,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",504,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.128,3280.0640000000017,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),505,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,3291.136000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",506,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,3295.072000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,3299.776000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.384,3304.160000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.92,3310.080000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,3314.7840000000024,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,3318.272000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,3322.8480000000022,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.544,3327.392000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.016,3333.408000000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,3338.0160000000024,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3341.4400000000023,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",517,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,3346.0160000000024,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",518,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.544,3350.560000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",519,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.68,3366.240000000002,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),520,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,3377.312000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",521,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.064,3381.376000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,3384.960000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",523,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,3388.3520000000017,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",524,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.232,3395.5840000000017,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",525,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.424,3399.0080000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.264,3402.2720000000018,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,3406.9120000000016,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,3411.4560000000015,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,529,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881920.0,1110752.0,15.808,3427.2640000000015,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433810.0,34711.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,530,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,3433.0240000000017,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.648,3436.672000000002,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,532,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881856.0,1105504.0,15.712,3452.384000000002,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433808.0,34547.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,533,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.664,3458.048000000002,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",534,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.648,3461.696000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,535,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3059264.0,13.024,3474.720000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95602.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,536,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.344,3496.064000000002,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",537,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.808,3499.872000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",538,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,3503.360000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",539,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.424,3510.784000000002,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",540,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,3513.9840000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,3517.344000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",542,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,3521.856000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.544,3526.400000000002,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),544,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,3537.472000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",545,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.128,3541.600000000002,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),546,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,3552.6720000000023,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",547,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,3556.5120000000024,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),548,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,3567.5200000000023,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",549,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,3571.4560000000024,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,3576.1280000000024,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,3580.6400000000026,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,3586.112000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,3590.912000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3594.336000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,3598.944000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.32,3603.2640000000033,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,3609.2160000000035,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.576,3613.7920000000036,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,3617.1840000000034,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.864,3622.0480000000034,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.736,3626.7840000000033,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.936,3642.7200000000034,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),563,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.2,3653.9200000000033,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",564,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.064,3657.984000000003,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",565,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,3661.3440000000032,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",566,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,3664.7040000000034,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",567,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.488,3672.192000000003,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",568,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,3675.424000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",569,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,3678.7840000000033,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.512,3683.2960000000035,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.384,3687.6800000000035,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,572,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880672.0,1101536.0,15.872,3703.5520000000033,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433771.0,34423.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,573,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.696,3709.2480000000032,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",574,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,3713.056000000003,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,575,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881248.0,1097920.0,15.776,3728.832000000003,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433789.0,34310.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,576,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,3734.752000000003,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",577,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.616,3738.368000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,578,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3065344.0,13.12,3751.488000000003,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95792.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,579,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.984,3773.472000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.616,3777.088000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,3780.448000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.744,3788.192000000003,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.328,3791.520000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,3794.816000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,3799.424000000003,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,3804.1280000000033,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),587,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,3815.232000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",588,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.808,3819.040000000003,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),589,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.008,3830.048000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",590,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.808,3833.856000000003,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),591,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,3844.896000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",592,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.128,3849.024000000003,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,3853.696000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.544,3858.240000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,3863.744000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,3868.256000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",597,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,3871.584000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.512,3876.096000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.672,3880.768000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",600,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.472,3886.2400000000034,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,3891.0080000000034,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,3894.4640000000036,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",603,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.608,3899.0720000000038,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",604,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,3903.744000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",605,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.936,3919.680000000004,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),606,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,3930.752000000004,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",607,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,3934.592000000004,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",608,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,3938.080000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",609,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,3941.472000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",610,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.712,3949.184000000004,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",611,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,3952.416000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,3955.648000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,3960.2880000000036,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",614,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.48,3964.7680000000037,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,615,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881120.0,1099328.0,15.808,3980.5760000000037,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433785.0,34354.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,616,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.728,3986.3040000000037,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.712,3990.0160000000037,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,618,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883392.0,1106464.0,16.032,4006.048000000004,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433856.0,34577.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,619,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.048,4012.0960000000036,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",620,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.392,4015.4880000000035,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,621,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3056288.0,13.056,4028.5440000000035,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95509.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,622,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.376,4049.9200000000037,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",623,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,4053.376000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,4056.800000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",625,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.616,4064.416000000004,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",626,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.392,4067.8080000000036,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.296,4071.1040000000035,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.448,4075.5520000000033,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,4080.1280000000033,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),630,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.168,4091.2960000000035,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",631,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,4095.1360000000036,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),632,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,4106.176000000004,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",633,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,4110.176000000004,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),634,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,4121.248000000004,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",635,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.872,4125.120000000004,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,4129.760000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",637,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,4134.240000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",638,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.888,4140.128000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,4144.768000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",640,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,4148.192000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,4152.864000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.448,4157.312000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",643,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,4162.816000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,4167.360000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",645,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.456,4170.816000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",646,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.48,4175.296000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",647,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.832,4180.128000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",648,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,16.0,4196.128000000004,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),649,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,4207.264000000005,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",650,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.224,4211.488000000005,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",651,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,4214.816000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,4218.336000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",653,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.552,4225.888000000005,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",654,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,4229.1520000000055,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",655,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,4232.3840000000055,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.672,4237.056000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,4241.632000000005,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,658,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13880832.0,1099072.0,15.904,4257.5360000000055,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433776.0,34346.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,659,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,6.272,4263.808000000005,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.84,4267.648000000006,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,661,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13883744.0,1102624.0,15.648,4283.296000000006,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433867.0,34457.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,662,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.664,4288.9600000000055,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",663,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,4292.320000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,664,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3057184.0,12.992,4305.312000000005,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95537.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,665,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.824,4327.136000000005,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,4330.720000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,4334.240000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",668,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.136,4341.376000000006,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",669,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.36,4344.736000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.328,4348.064000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.64,4352.704000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,4357.408000000006,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),673,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,4368.512000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",674,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,4372.448000000006,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),675,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,4383.488000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",676,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.872,4387.360000000006,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),677,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,4398.400000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",678,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.936,4402.336000000006,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,4406.976000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.608,4411.584000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,4417.568000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.768,4422.336000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,4425.824000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.704,4430.528000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",685,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,4434.944000000007,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",686,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,4440.896000000007,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,4445.504000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4449.024000000008,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",689,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.48,4453.504000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,4458.080000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.872,4473.9520000000075,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),692,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.104,4485.056000000008,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",693,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,4488.960000000008,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",694,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.296,4492.2560000000085,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",695,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,4495.552000000009,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",696,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.296,4502.848000000009,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",697,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.36,4506.208000000009,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",698,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.392,4509.600000000009,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.576,4514.176000000009,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.448,4518.624000000009,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,701,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882336.0,1106752.0,15.84,4534.464000000009,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433823.0,34586.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,702,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,4540.384000000009,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.872,4544.256000000009,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,704,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881568.0,1100224.0,15.616,4559.872000000009,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433799.0,34382.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,705,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.792,4565.66400000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",706,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.584,4569.24800000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,707,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3067712.0,12.928,4582.1760000000095,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95866.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,708,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.12,4603.296000000009,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",709,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4606.81600000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,4610.08000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",711,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.296,4617.37600000001,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",712,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,4620.64000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",713,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.392,4624.03200000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",714,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.608,4628.64000000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",715,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.704,4633.34400000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),716,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,10.912,4644.25600000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",717,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.84,4648.0960000000105,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),718,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.2,4659.29600000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.904,4663.200000000011,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),720,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.2,4674.400000000011,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",721,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,4678.400000000011,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",722,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.672,4683.07200000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.416,4687.48800000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",724,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.76,4693.2480000000105,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.736,4697.98400000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",726,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,4701.312000000011,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.832,4706.144000000011,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.608,4710.752000000011,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",729,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.176,4716.928000000012,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.8,4721.728000000012,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",731,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,4725.280000000012,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",732,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.576,4729.856000000012,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",733,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.512,4734.368000000011,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",734,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.648,4750.016000000011,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),735,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.072,4761.088000000012,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",736,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.0,4765.088000000012,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",737,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,4768.5120000000115,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,4771.968000000012,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",739,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.712,4779.680000000012,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",740,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.2,4782.880000000012,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",741,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.36,4786.240000000012,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",742,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.48,4790.720000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",743,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.512,4795.232000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,744,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881568.0,1105600.0,15.616,4810.848000000011,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433799.0,34550.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,745,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,4816.608000000011,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",746,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,4.032,4820.640000000011,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,747,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882976.0,1100640.0,15.552,4836.192000000011,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433843.0,34395.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,748,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.92,4842.112000000011,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",749,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.52,4845.632000000011,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,750,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3069760.0,12.96,4858.5920000000115,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95930.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,751,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.376,4879.968000000012,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",752,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,4883.520000000011,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,4886.880000000011,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",754,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.904,4894.7840000000115,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",755,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.264,4898.048000000012,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",756,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.168,4901.216000000011,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",757,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.48,4905.696000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",758,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,4910.272000000011,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),759,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.04,4921.312000000011,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",760,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,4925.280000000011,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),761,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.36,4936.64000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",762,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,4.064,4940.704000000011,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),763,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.136,4951.840000000011,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",764,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.776,4955.616000000011,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",765,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.608,4960.224000000011,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",766,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.48,4964.704000000011,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",767,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.536,4970.240000000011,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",768,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.64,4974.880000000011,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",769,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4978.4000000000115,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",770,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.864,4983.264000000011,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",771,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,4.512,4987.776000000011,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.504,4993.280000000011,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",773,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,73728.0,49152.0,4.544,4997.8240000000105,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",774,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,5001.40800000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",775,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.64,5006.048000000011,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",776,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,960.0,0.0,98304.0,98304.0,4.672,5010.72000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",777,196608.0,17657856.0,0.0,0,193273528320.0,17657856.0,193291186176.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,15.904,5026.624000000011,14886912.0,2377728.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,754974720.0,7680.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_tn_align1>(T1::Params),778,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,3072.0,0.977961432506887,2949120.0,393216.0,11.168,5037.79200000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",779,12288.0,110592.0,24576.0,0,0.0,135168.0,135168.0,0.0,3456.0,0.0,393216.0,49152.0,3.968,5041.76000000001,98304.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",780,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.744,5045.50400000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",781,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,5049.02400000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",782,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.584,5056.60800000001,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",783,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.232,5059.84000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",784,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,5063.07200000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",785,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.736,5067.80800000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",786,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.736,5072.54400000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,787,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13881632.0,1104832.0,15.776,5088.32000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433801.0,34526.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,788,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.76,5094.08000000001,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",789,614400.0,1179648.0,98304.0,0,0.0,1277952.0,1277952.0,0.0,768.0,0.0,196608.0,196608.0,3.808,5097.88800000001,49152.0,0.0,565248.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,790,75515904.0,150994944.0,36864.0,0,0.0,151031808.0,151031808.0,296064.0,2304.0,0.9922779922779923,13882400.0,1103808.0,15.552,5113.44000000001,0.0,0.0,75497472.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,433825.0,34494.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,791,98304.0,491520.0,0.0,0,0.0,491520.0,491520.0,3840.0,3840.0,0.5,1179648.0,196608.0,5.856,5119.296000000009,294912.0,0.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,6144.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",792,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.552,5122.848000000009,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12288.0,6144.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,793,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,14155776.0,3060064.0,13.12,5135.968000000009,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,95627.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,794,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6720.0,0.125,3244032.0,49152.0,21.184,5157.152000000009,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",795,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.52,5160.67200000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,5163.93600000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",797,1536.0,16400.0,3072.0,0,0.0,19472.0,19472.0,0.0,112.0,0.0,49152.0,32.0,7.744,5171.680000000009,16384.0,16.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",798,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,64.0,64.0,3.296,5174.97600000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",799,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,64.0,64.0,3.232,5178.20800000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",800,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,50688.0,49152.0,4.96,5183.16800000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",801,12288.0,12288.0,24576.0,0,0.0,36864.0,36864.0,0.0,1152.0,0.0,98304.0,49152.0,4.576,5187.74400000001,0.0,12288.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,802,787488000.0,1574912000.0,64000.0,0,0.0,1574976000.0,1574976000.0,1962500.0,16000.0,0.9919130654536265,104872736.0,2048000.0,67.968,5255.7120000000095,0.0,0.0,787456000.0,32000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3277273.0,64000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",803,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,128.0,2.752,5258.46400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",804,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,384.0,640.0,4.0,5262.46400000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",805,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5265.79200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",806,0.0,512000.0,0.0,0,0.0,512000.0,512000.0,0.0,8000.0,0.0,2048000.0,2048000.0,4.256,5270.048000000011,0.0,512000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,64000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",807,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.88,5272.928000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",808,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,150400.0,6.24,5279.168000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4700.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",809,245760.0,0.0,491520.0,0,0.0,491520.0,491520.0,33792.0,137760.0,0.1969781757134863,8421952.0,128.0,7.52,5286.688000000011,0.0,0.0,0.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263186.0,4.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",810,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,149952.0,6.144,5292.832000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4686.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",811,147456.0,0.0,294912.0,0,0.0,294912.0,294912.0,33792.0,140832.0,0.19351291918636612,8421920.0,64.0,7.264,5300.096000000011,0.0,0.0,0.0,147456.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263185.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",812,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,147136.0,5.984,5306.080000000012,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4598.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",813,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,33792.0,139040.0,0.1955193482688391,8421952.0,160.0,7.168,5313.248000000011,0.0,0.0,0.0,204800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263186.0,5.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",814,0.0,0.0,0.0,0,0.0,0.0,0.0,8192.0,24192.0,0.25296442687747034,2056448.0,149312.0,6.208,5319.456000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64264.0,4666.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",815,205824.0,0.0,411648.0,0,0.0,411648.0,411648.0,33792.0,139008.0,0.19555555555555557,8421920.0,512.0,7.36,5326.816000000011,0.0,0.0,0.0,205824.0,0,0,0,0,0,0,0,0.0,0.0,0.0,263185.0,16.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",816,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,48.0,0.0,16448.0,2048.0,4.992,5331.808000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,514.0,64.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",817,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.36,5335.168000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",818,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,41.0,0.9397944199706314,2048.0,0.0,6.112,5341.280000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",819,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,5344.224000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",820,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,41.0,0.9397944199706314,2048.0,0.0,5.856,5350.080000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",821,131072.0,0.0,262144.0,0,0.0,262144.0,262144.0,115497.0,33698.0,0.7741345219343811,2100992.0,28480.0,9.312,5359.392000000011,0.0,0.0,0.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65656.0,890.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",822,0.0,0.0,0.0,0,0.0,0.0,0.0,7328.0,128.0,0.9828326180257511,10240.0,0.0,8.736,5368.128000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",823,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,2080256.0,170176.0,6.528,5374.656000000011,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65008.0,5318.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",824,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.736,5379.392000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",825,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,16000.0,0.0,0.0,4096000.0,5.184,5384.576000000011,0.0,0.0,0.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,128000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",826,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,16000.0,0.8941574936494496,2048000.0,0.0,6.464,5391.040000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",827,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,5394.560000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",828,0.0,0.0,0.0,0,0.0,0.0,0.0,166752.0,75377.0,0.6886907392340447,7347456.0,5103904.0,17.664,5412.224000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229608.0,159497.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",829,0.0,0.0,0.0,0,0.0,0.0,0.0,37968.0,75583.0,0.3343695784273146,7358464.0,4766112.0,14.08,5426.304000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229952.0,148941.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",830,0.0,0.0,0.0,0,0.0,0.0,0.0,34776.0,75669.0,0.31487165557517316,7323008.0,6242304.0,14.464,5440.768000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228844.0,195072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",831,0.0,0.0,0.0,0,0.0,0.0,0.0,34776.0,75941.0,0.31409810598191784,7335296.0,6242304.0,14.816,5455.584000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229228.0,195072.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",832,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,16000.0,0.4802494802494803,4096000.0,0.0,5.824,5461.40800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",833,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.584,5464.99200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",834,0.0,0.0,0.0,0,0.0,0.0,0.0,42241.0,41511.0,0.5043581048810775,5153152.0,3529888.0,12.576,5477.56800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,161036.0,110309.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",835,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,64000.0,0.0,6195424.0,6144000.0,7.744,5485.31200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193607.0,192000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",836,7978208.0,16980480.0,1620416.0,0,0.0,18600896.0,18600896.0,2112.0,20992.0,0.09141274238227147,2049920.0,2048000.0,23.072,5508.38400000001,2132480.0,512000.0,7168000.0,810208.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64060.0,64000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",837,0.0,2621952.0,0.0,0,0.0,2621952.0,2621952.0,287360.0,32000.0,0.8997995991983968,2048000.0,2048000.0,63.936,5572.32000000001,2621952.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,64000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",838,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,2048000.0,512000.0,4.064,5576.38400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",839,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,1.0,0.0,0.0,512.0,3.104,5579.48800000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",840,1024000.0,0.0,2048000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,4608000.0,262688.0,11.84,5591.32800000001,0.0,0.0,0.0,1024000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144000.0,8209.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",841,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12000.0,0.0,2560000.0,0.0,4.416,5595.744000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",842,7978255.0,16980480.0,1620510.0,0,0.0,18600990.0,18600990.0,2112.0,20992.0,0.09141274238227147,2049024.0,2048000.0,23.04,5618.784000000011,2132480.0,512000.0,7168000.0,810255.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64032.0,64000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",843,97280.0,0.0,194560.0,0,0.0,194560.0,194560.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,9.28,5628.06400000001,0.0,0.0,0.0,97280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",844,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5631.392000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",845,97280.0,0.0,194560.0,0,0.0,194560.0,194560.0,5039.0,4066.0,0.5534321801208127,2048256.0,2048.0,9.856,5641.2480000000105,0.0,0.0,0.0,97280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64008.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",846,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,5644.928000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",847,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.648,5648.576000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",848,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,5652.992000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",849,16384.0,585216.0,32768.0,0,0.0,617984.0,617984.0,736.0,4016.0,0.15488215488215487,2048000.0,512.0,11.776,5664.768000000011,585216.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",850,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,5668.064000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",851,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.12,5673.184000000011,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",852,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,5676.3200000000115,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",853,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,5680.800000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",854,2973696.0,5890048.0,1081344.0,0,0.0,6971392.0,6971392.0,0.0,16000.0,0.0,0.0,2048000.0,7.168,5687.968000000011,0.0,1024000.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,64000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",855,3199247.0,5120000.0,1278494.0,0,0.0,6398494.0,6398494.0,0.0,12000.0,0.0,4096000.0,0.0,6.4,5694.36800000001,0.0,0.0,2560000.0,639247.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",856,8704.0,0.0,17408.0,0,0.0,17408.0,17408.0,1472.0,4016.0,0.26822157434402333,2048000.0,512.0,16.864,5711.23200000001,0.0,0.0,0.0,8704.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64000.0,16.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",857,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,3.456,5714.68800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",858,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.456,5718.14400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",859,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,128.0,3.68,5721.8240000000105,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",860,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,256.0,128.0,3.296,5725.120000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,4.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",861,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,384.0,640.0,3.968,5729.088000000011,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12.0,20.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",862,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,5731.936000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",863,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,5734.784000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",864,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,5738.36800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",865,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5741.0560000000105,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",866,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,3.0,0.0,416.0,32.0,3.776,5744.83200000001,0.0,0.0,0.0,32.0,0,0,0,0,0,0,0,0.0,0.0,0.0,13.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",867,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,5.0,0.0,32.0,32.0,7.328,5752.160000000011,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",868,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.712,5755.872000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",869,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,5759.232000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",870,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,128.0,4.608,5763.840000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,4.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",871,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,4.928,5768.768000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",872,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5772.032000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
