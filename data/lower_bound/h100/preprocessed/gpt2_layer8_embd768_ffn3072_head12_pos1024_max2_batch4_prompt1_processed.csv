Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,11.68,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,15.168,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.872,19.04,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,23.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.992,28.64,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,32.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,34.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,37.504000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,40.57600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.904,44.480000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,48.00000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,51.26400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.064,55.32800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,58.59200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,62.01600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.488,65.50400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,3264.0,12288.0,5.664,71.16800000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,384.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,3264.0,12288.0,5.632,76.80000000000003,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,80.22400000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,83.64800000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.96,88.60800000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.656,95.26400000000004,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.104,114.36800000000004,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.384,118.75200000000004,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.16,122.91200000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.352,127.26400000000004,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,13.664,140.92800000000003,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),31,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.056,149.98400000000004,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",32,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.192,154.17600000000004,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,157.40800000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.528,163.93600000000004,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.456,183.39200000000002,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,186.65600000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.392,190.04800000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,193.60000000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,196.99200000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,200.38400000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,74528.0,182848.0,6144.0,0,0.0,188992.0,188992.0,0.0,192.0,0.0,49152.0,49152.0,3.36,203.74400000000003,12288.0,27648.0,71456.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.52,207.26400000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,210.59200000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),44,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.2,229.79200000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",45,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.544,234.33600000000004,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,237.76000000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",47,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.592,244.35200000000006,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",48,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.36,263.71200000000005,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.096,267.80800000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.416,272.22400000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.416,276.64000000000004,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",52,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.512,289.15200000000004,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),53,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.152,298.30400000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.096,302.40000000000003,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,305.824,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",56,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.816,312.64,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.008,331.64799999999997,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,335.104,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",59,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.488,338.592,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,341.824,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,345.184,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,348.54400000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,74560.0,182912.0,6144.0,0,0.0,189056.0,189056.0,0.0,192.0,0.0,49152.0,49152.0,3.456,352.00000000000006,12288.0,27648.0,71488.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.264,355.26400000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,358.7200000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),66,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.88,377.6000000000001,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.448,382.04800000000006,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,385.34400000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",69,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.432,391.77600000000007,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.968,411.7440000000001,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.448,416.19200000000006,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.352,420.54400000000004,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.352,424.896,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",74,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.48,437.37600000000003,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),75,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,8.896,446.27200000000005,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.128,450.40000000000003,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,453.88800000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",78,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.624,460.51200000000006,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",79,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.776,480.28800000000007,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,483.80800000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",81,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.264,487.07200000000006,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,490.56000000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.392,493.95200000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",84,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,497.1840000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,74372.0,182536.0,6144.0,0,0.0,188680.0,188680.0,0.0,192.0,0.0,49152.0,49152.0,3.84,501.02400000000006,12288.0,27648.0,71300.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",86,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.552,504.5760000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,508.0320000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),88,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.072,527.104,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",89,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.768,531.8720000000001,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,535.2320000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",91,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.464,541.6960000000001,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.136,560.8320000000001,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",93,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.352,565.1840000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",94,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.448,569.6320000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.288,573.9200000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",96,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.544,586.464,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),97,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.12,595.5840000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.16,599.744,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,603.1360000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",100,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.56,609.696,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,20.16,629.856,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.552,633.408,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",103,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.488,636.8960000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",104,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,640.224,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",105,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.648,643.8720000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,647.296,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",107,74500.0,182792.0,6144.0,0,0.0,188936.0,188936.0,0.0,192.0,0.0,49152.0,49152.0,3.36,650.6560000000001,12288.0,27648.0,71428.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",108,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.392,654.0480000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",109,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,657.3760000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),110,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.944,676.32,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",111,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.576,680.8960000000001,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,684.2880000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.496,690.7840000000001,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",114,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,20.032,710.8160000000001,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.256,715.0720000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.224,719.2960000000002,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.48,723.7760000000002,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",118,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.544,736.3200000000002,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),119,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.152,745.4720000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.032,749.5040000000002,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,752.9280000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",122,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.592,759.5200000000002,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.104,778.6240000000003,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,781.8560000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",125,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.52,785.3760000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",126,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,788.8320000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.36,792.1920000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",128,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,795.4880000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,74416.0,182624.0,6144.0,0,0.0,188768.0,188768.0,0.0,192.0,0.0,49152.0,49152.0,3.392,798.8800000000003,12288.0,27648.0,71344.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.52,802.4000000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,805.9200000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),132,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.784,824.7040000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.736,829.4400000000003,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,833.0240000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.56,839.5840000000002,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.168,858.7520000000002,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.224,862.9760000000002,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.416,867.3920000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.192,871.5840000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",140,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.48,884.0640000000003,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),141,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.216,893.2800000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.096,897.3760000000003,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,900.8640000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",144,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.72,907.5840000000004,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",145,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.648,927.2320000000004,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",146,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,930.6880000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",147,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.328,934.0160000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",148,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,937.3120000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,940.8000000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",150,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,944.2240000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,74512.0,182816.0,6144.0,0,0.0,188960.0,188960.0,0.0,192.0,0.0,49152.0,49152.0,3.488,947.7120000000006,12288.0,27648.0,71440.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,951.0080000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",153,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.712,954.7200000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),154,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.296,974.0160000000006,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.576,978.5920000000007,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.904,982.4960000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.72,989.2160000000007,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",158,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.2,1008.4160000000007,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.768,1013.1840000000008,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.224,1017.4080000000008,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.256,1021.6640000000008,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",162,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.48,1034.1440000000007,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),163,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,8.864,1043.0080000000007,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.064,1047.0720000000008,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1050.4960000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",166,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.688,1057.1840000000009,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",167,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.872,1077.056000000001,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",168,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.264,1080.3200000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",169,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.392,1083.712000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",170,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,1087.008000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,1090.432000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",172,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,1093.664000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,74448.0,182688.0,6144.0,0,0.0,188832.0,188832.0,0.0,192.0,0.0,49152.0,49152.0,3.392,1097.056000000001,12288.0,27648.0,71376.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",174,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.552,1100.6080000000009,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",175,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1103.9680000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),176,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.88,1122.8480000000009,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.768,1127.616000000001,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1131.008000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.368,1137.3760000000009,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.136,1156.5120000000009,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.16,1160.672000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.32,1164.9920000000009,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.48,1169.472000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",184,98304.0,3265536.0,0.0,0,28991029248.0,3265536.0,28994294784.0,25536.0,48.0,0.99812382739212,36864.0,12288.0,12.512,1181.9840000000008,2469888.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1152.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),185,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.248,1191.2320000000009,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.256,1195.488000000001,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1198.912000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",188,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.368,1205.2800000000009,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",189,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,20.064,1225.344000000001,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",190,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,1228.864000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",191,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.328,1232.192000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",192,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.616,1235.808000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.584,1239.392000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",194,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,1242.816000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,74536.0,182864.0,6144.0,0,0.0,189008.0,189008.0,0.0,192.0,0.0,49152.0,49152.0,3.424,1246.240000000001,12288.0,27648.0,71464.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.328,1249.568000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1253.0880000000009,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),198,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.072,1272.1600000000008,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",199,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.672,1276.8320000000008,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1280.1280000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",201,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.4,1286.528000000001,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,158410176.0,340946176.0,8041344.0,0,0.0,348987520.0,348987520.0,2387276.0,1909876.0,0.5555484190459169,159049088.0,1388704.0,72.704,1359.2320000000009,12865792.0,19301376.0,154389504.0,4020672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4970284.0,43397.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,1362.144000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",204,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.872,1366.016000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,1369.248000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",206,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.808,1373.056000000001,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",207,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,1376.000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54656.0,6.08,1382.0800000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1708.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",209,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.224,1390.3040000000008,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54848.0,5.824,1396.1280000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1714.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",211,57600.0,0.0,115200.0,0,0.0,115200.0,115200.0,13200.0,83808.0,0.13607125185551708,5134848.0,0.0,8.128,1404.2560000000008,0.0,0.0,0.0,57600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54720.0,5.792,1410.0480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1710.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",213,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,13200.0,82808.0,0.13748854262144822,5134848.0,0.0,8.256,1418.3040000000008,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54016.0,6.08,1424.3840000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1688.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",215,83200.0,0.0,166400.0,0,0.0,166400.0,166400.0,13200.0,83008.0,0.13720272742391484,5134848.0,128.0,8.032,1432.4160000000006,0.0,0.0,0.0,83200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.68,1436.0960000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,1439.1360000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.632,1444.7680000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,1447.6160000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.6,1453.2160000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",221,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,46740.0,13012.0,0.7822332306868389,831584.0,9024.0,9.024,1462.2400000000005,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,282.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.8,1471.0400000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,69152.0,6.336,1477.3760000000004,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2161.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,1481.5680000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",225,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,3.968,1485.5360000000005,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.112,1491.6480000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.648,1495.2960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,64754.0,28503.0,0.694360745037906,2746432.0,2020544.0,14.688,1509.9840000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85826.0,63142.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28424.0,0.33330205938921986,2732224.0,2451264.0,11.584,1521.5680000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85382.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28261.0,0.3513953915358487,2733376.0,2451264.0,13.376,1534.9440000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85418.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28228.0,0.3516617285651944,2718656.0,1903328.0,12.896,1547.8400000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84958.0,59479.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.12,1552.9600000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.392,1556.3520000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15223.0,0.4935121107266436,1864096.0,1336800.0,9.632,1565.9840000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58253.0,41775.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2428672.0,2412352.0,5.344,1571.3280000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75896.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",236,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1072960.0,753216.0,31.872,1603.2000000000007,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33530.0,23538.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",237,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804352.0,619936.0,98.048,1701.2480000000007,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25136.0,19373.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.68,1704.9280000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.136,1708.0640000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,91456.0,11.744,1719.8080000000007,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2858.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.384,1724.1920000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",242,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1066144.0,753344.0,31.712,1755.9040000000007,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33317.0,23542.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",243,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.696,1765.6000000000006,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,1769.1200000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",245,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.472,1778.5920000000006,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1781.8880000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.84,1785.7280000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.768,1790.4960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",249,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.808,1806.3040000000005,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1809.5040000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",251,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,1814.7520000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,1818.2720000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.704,1822.9760000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",254,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,1828.9920000000006,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.44,1834.4320000000007,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",256,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804320.0,128.0,23.392,1857.8240000000008,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25135.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.2,1861.0240000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1864.3520000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",259,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.0,1868.3520000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,1871.9360000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",261,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.872,1875.808000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,1878.528000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1881.344000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,1884.864000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1887.616000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.68,1891.296000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.008,1898.304000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,1901.632000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1905.0880000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.904,1908.9920000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,1914.0160000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",272,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1917.4080000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,1920.8960000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",274,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,5.024,1925.9200000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.872,1929.7920000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.296,1933.0880000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.36,1936.4480000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.392,1939.8400000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.584,1943.424000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",280,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,12480.0,12288.0,6.24,1949.664000000001,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,390.0,384.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",281,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,3264.0,12288.0,5.6,1955.2640000000008,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.552,1958.8160000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,1962.1120000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",284,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.184,1967.2960000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.816,1974.1120000000008,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.392,1993.5040000000008,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,1998.9760000000008,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.536,2004.5120000000009,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.512,2009.0240000000008,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",290,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.48,2021.5040000000008,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),291,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.152,2030.6560000000009,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",292,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.0,2034.6560000000009,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",293,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,2038.0160000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",294,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.368,2044.3840000000007,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.424,2063.808000000001,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",296,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2067.1040000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",297,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2070.4000000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",298,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.712,2074.1120000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",299,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2077.6000000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",300,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2081.0560000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,74555.0,182902.0,6144.0,0,0.0,189046.0,189046.0,0.0,192.0,0.0,49152.0,49152.0,3.616,2084.6720000000005,12288.0,27648.0,71483.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",302,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.488,2088.1600000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,2091.6160000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),304,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.008,2110.6240000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.736,2115.36,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,2118.944,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.592,2125.536,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.424,2144.96,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",309,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.536,2150.496,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,2155.9680000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.288,2160.2560000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",312,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.576,2172.8320000000003,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),313,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.184,2182.0160000000005,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",314,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.096,2186.1120000000005,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",315,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,2189.5680000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",316,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.624,2196.1920000000005,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",317,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.136,2215.3280000000004,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",318,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2218.6240000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",319,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.264,2221.8880000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",320,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2225.3440000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,2228.8960000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",322,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,2232.2560000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",323,74481.0,182754.0,6144.0,0,0.0,188898.0,188898.0,0.0,192.0,0.0,49152.0,49152.0,3.552,2235.808000000001,12288.0,27648.0,71409.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",324,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2239.136000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",325,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.392,2242.5280000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),326,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.136,2261.6640000000007,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",327,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.512,2266.176000000001,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.744,2269.920000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",329,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.432,2276.3520000000008,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",330,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.328,2295.6800000000007,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,2301.056000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,2306.400000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.48,2310.880000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",334,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.48,2323.360000000001,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),335,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.152,2332.512000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",336,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.16,2336.672000000001,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",337,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.616,2340.288000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",338,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.816,2347.1040000000007,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",339,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.552,2366.656000000001,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",340,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2369.9520000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",341,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2373.2480000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",342,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2376.5760000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",343,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.328,2379.9040000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",344,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2383.2320000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,74453.0,182698.0,6144.0,0,0.0,188842.0,188842.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2386.6880000000006,12288.0,27648.0,71381.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",346,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.52,2390.2080000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",347,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,2393.5360000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),348,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.816,2412.3520000000003,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",349,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.448,2416.8,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,2420.128,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",351,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.816,2426.944,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",352,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.008,2445.9519999999998,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.44,2451.392,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",354,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,2456.768,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",355,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.512,2461.28,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",356,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.512,2473.7920000000004,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),357,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,8.992,2482.7840000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",358,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.032,2486.8160000000007,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",359,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,2490.3040000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",360,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.432,2496.7360000000003,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",361,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.36,2516.0960000000005,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",362,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.68,2519.7760000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",363,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2523.1040000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",364,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.168,2526.2720000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",365,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2529.76,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",366,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.328,2533.088,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",367,74617.0,183026.0,6144.0,0,0.0,189170.0,189170.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2536.384,12288.0,27648.0,71545.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",368,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2539.84,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",369,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.584,2543.424,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),370,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.072,2562.496,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",371,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.704,2567.2000000000003,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,2570.6560000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.432,2577.088,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.424,2596.512,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.6,2602.112,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,2607.52,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.256,2611.776,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.576,2624.352,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),379,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.056,2633.408,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",380,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.064,2637.4719999999998,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",381,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2640.8959999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",382,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.688,2647.584,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",383,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.968,2667.5519999999997,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,2671.0399999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",385,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.552,2674.5919999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.36,2677.9519999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",387,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.424,2681.3759999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.2,2684.5759999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",389,74498.0,182788.0,6144.0,0,0.0,188932.0,188932.0,0.0,192.0,0.0,49152.0,49152.0,3.424,2687.9999999999995,12288.0,27648.0,71426.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",390,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2691.2959999999994,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",391,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2694.783999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),392,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.232,2714.015999999999,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",393,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.672,2718.687999999999,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.648,2722.3359999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.432,2728.767999999999,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",396,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.84,2748.6079999999993,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",397,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,2753.9519999999993,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.568,2759.5199999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.384,2763.9039999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",400,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.576,2776.4799999999996,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),401,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.088,2785.5679999999998,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",402,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.064,2789.6319999999996,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,2793.1199999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",404,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.624,2799.7439999999992,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.424,2819.167999999999,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",406,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2822.463999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",407,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2825.919999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",408,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.424,2829.343999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.552,2832.8959999999993,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",410,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,2836.287999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,74583.0,182958.0,6144.0,0,0.0,189102.0,189102.0,0.0,192.0,0.0,49152.0,49152.0,3.456,2839.7439999999992,12288.0,27648.0,71511.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",412,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.2,2842.943999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",413,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.36,2846.303999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),414,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.816,2865.119999999999,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",415,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.576,2869.695999999999,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,2873.087999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.88,2879.967999999999,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.616,2899.583999999999,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",419,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,2904.959999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,2910.303999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.544,2914.847999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",422,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.32,2927.167999999999,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),423,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,9.088,2936.2559999999994,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",424,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.608,2940.8639999999996,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",425,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.552,2944.4159999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",426,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.656,2951.0719999999997,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,19.488,2970.5599999999995,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",428,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.168,2973.7279999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",429,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2977.0239999999994,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",430,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.296,2980.3199999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2983.807999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",432,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.392,2987.199999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,74444.0,182680.0,6144.0,0,0.0,188824.0,188824.0,0.0,192.0,0.0,49152.0,49152.0,3.616,2990.815999999999,12288.0,27648.0,71372.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.392,2994.2079999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",435,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2997.6959999999985,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),436,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,19.072,3016.7679999999987,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",437,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.576,3021.3439999999987,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3024.703999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",439,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.208,3030.911999999999,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,7123968.0,14376960.0,92160.0,0,0.0,14469120.0,14469120.0,64512.0,59328.0,0.5209302325581395,7529472.0,36864.0,19.232,3050.143999999999,110592.0,110592.0,7077888.0,46080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,235296.0,1152.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,3055.5519999999988,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.504,3061.0559999999987,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,12288.0,12288.0,4.288,3065.3439999999987,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",444,98304.0,3268608.0,0.0,0,28991029248.0,3268608.0,28994297856.0,25536.0,48.0,0.99812382739212,61440.0,12288.0,12.448,3077.7919999999986,2472960.0,599040.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,113246208.0,1920.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),445,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,768.0,0.9943977591036415,2506752.0,98304.0,8.928,3086.7199999999984,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,78336.0,3072.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",446,15360.0,30720.0,30720.0,0,0.0,61440.0,61440.0,0.0,1440.0,0.0,101376.0,12288.0,4.192,3090.9119999999984,27648.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3168.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",447,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3094.2079999999983,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",448,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.496,3100.7039999999984,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",449,9498624.0,19169280.0,122880.0,0,0.0,19292160.0,19292160.0,86016.0,79104.0,0.5209302325581395,10039296.0,49152.0,20.224,3120.9279999999985,147456.0,147456.0,9437184.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313728.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",450,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.52,3124.4479999999985,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",451,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.488,3127.9359999999983,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",452,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.232,3131.1679999999983,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",453,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.488,3134.655999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",454,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.488,3138.143999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",455,74461.0,182714.0,6144.0,0,0.0,188858.0,188858.0,0.0,192.0,0.0,49152.0,49152.0,3.584,3141.727999999998,12288.0,27648.0,71389.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",456,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,192.0,0.0,49152.0,49152.0,3.296,3145.0239999999976,0.0,0.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",457,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.68,3148.7039999999974,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),458,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,1536.0,0.9968992248062015,10027008.0,196608.0,18.976,3167.6799999999976,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,313344.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",459,15360.0,55296.0,30720.0,0,0.0,86016.0,86016.0,0.0,2208.0,0.0,199680.0,12288.0,4.704,3172.3839999999977,52224.0,3072.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3175.743999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",461,30276.0,93428.0,9216.0,0,0.0,102644.0,102644.0,80.0,272.0,0.22727272727272727,36864.0,12544.0,6.688,3182.431999999998,26160.0,15932.0,25668.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,392.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,158410176.0,340946176.0,8041344.0,0,0.0,348987520.0,348987520.0,2387276.0,1909876.0,0.5555484190459169,159021568.0,1377280.0,72.128,3254.559999999998,12865792.0,19301376.0,154389504.0,4020672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4969424.0,43040.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,3257.471999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.064,3261.535999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3264.895999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",466,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.68,3268.5759999999977,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",467,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3271.3919999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",468,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,6.016,3277.4079999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",469,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.192,3285.5999999999976,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54592.0,6.016,3291.6159999999977,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1706.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",471,57600.0,0.0,115200.0,0,0.0,115200.0,115200.0,13200.0,83808.0,0.13607125185551708,5134848.0,0.0,8.352,3299.9679999999976,0.0,0.0,0.0,57600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54080.0,5.888,3305.8559999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1690.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",473,88000.0,0.0,176000.0,0,0.0,176000.0,176000.0,13200.0,82858.0,0.13741697724291574,5134848.0,0.0,8.352,3314.2079999999974,0.0,0.0,0.0,88000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54912.0,6.048,3320.255999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1716.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",475,72000.0,0.0,144000.0,0,0.0,144000.0,144000.0,13200.0,83358.0,0.1367053998632946,5134848.0,128.0,7.936,3328.1919999999973,0.0,0.0,0.0,72000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.744,3331.9359999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.008,3334.9439999999972,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.632,3340.5759999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,3343.487999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",480,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.792,3349.279999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",481,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,50881.0,13018.0,0.7962722421321148,831584.0,8672.0,9.408,3358.687999999997,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,271.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.768,3367.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816576.0,68544.0,6.048,3373.5039999999967,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25518.0,2142.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.968,3377.4719999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",485,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.0,3381.4719999999966,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.176,3387.6479999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",487,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.424,3391.0719999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28349.0,0.6990679801282323,2734016.0,1973824.0,14.944,3406.0159999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85438.0,61682.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,18422.0,28091.0,0.39606131619117235,2708544.0,1723424.0,12.224,3418.2399999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84642.0,53857.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28324.0,0.3508880485848516,2720448.0,2451264.0,13.024,3431.2639999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85014.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28148.0,0.35230907291930325,2717120.0,1901600.0,12.896,3444.1599999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84910.0,59425.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.896,3449.055999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,3452.5439999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15208.0,0.49375853000898773,1862304.0,1347040.0,9.568,3462.111999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58197.0,42095.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429568.0,2412352.0,5.152,3467.263999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75924.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",496,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1068736.0,752896.0,31.936,3499.199999999997,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33398.0,23528.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",497,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804224.0,617408.0,98.496,3597.695999999997,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,19294.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.808,3601.503999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.008,3604.511999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,93216.0,11.584,3616.095999999997,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2913.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.192,3620.287999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",502,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1080640.0,752960.0,32.064,3652.3519999999967,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33770.0,23530.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",503,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.504,3661.8559999999966,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3665.1519999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",505,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.28,3674.4319999999966,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,3677.8239999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,3681.4079999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.672,3686.0799999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",509,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.064,3702.143999999996,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,3705.727999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,3711.007999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3714.303999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,3718.815999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",514,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,3724.8319999999962,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",515,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.568,3730.3999999999965,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",516,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.208,3752.6079999999965,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,3755.9359999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3759.2959999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.936,3763.231999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,3766.6559999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,3770.495999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,3773.5039999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3776.3199999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,3779.6159999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,3782.335999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.904,3786.239999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.072,3793.3119999999963,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,3796.5759999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3799.9039999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.808,3803.7119999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.864,3808.5759999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,3811.9359999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
