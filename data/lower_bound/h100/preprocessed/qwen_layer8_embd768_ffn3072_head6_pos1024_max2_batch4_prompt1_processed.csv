Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,3.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.84,9.568,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.512,14.079999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.704,18.784,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,22.368,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,25.087999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,27.935999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,31.007999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.68,34.687999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,38.175999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.808,41.983999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.0,45.983999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,49.12,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,52.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.36,56.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,3264.0,12288.0,5.44,61.632,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,65.248,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.44,70.688,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,74.176,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.424,77.60000000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.512,82.11200000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.256,86.36800000000001,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,89.69600000000001,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.32,94.01600000000002,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,97.34400000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.552,100.89600000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.696,106.59200000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,110.08000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,113.50400000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.512,118.01600000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.768,122.78400000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.384,131.16800000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12384.0,8.0,139.16800000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,387.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.032,147.20000000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.8,152.00000000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.224,156.22400000000005,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,161.56800000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,165.95200000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,169.21600000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,173.69600000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.736,178.43200000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,184.03200000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,188.54400000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,191.80800000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.744,207.55200000000005,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14016.0,7.872,215.42400000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,438.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,218.78400000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,222.04800000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,227.90400000000005,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,231.23200000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,234.59200000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.608,239.20000000000007,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,243.64800000000008,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70496.0,9.792,253.44000000000008,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2203.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.68,257.12000000000006,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73696.0,10.048,267.16800000000006,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2303.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,270.6240000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14304.0,20.864,291.48800000000006,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,447.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,294.78400000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,298.14400000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.272,304.41600000000005,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,307.68000000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,310.9120000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,315.36000000000007,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.608,319.9680000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.32,328.28800000000007,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.192,336.4800000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.872,344.3520000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,348.80000000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,353.15200000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,358.75200000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,363.20000000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.68,366.88000000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,371.4560000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.32,375.77600000000007,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,381.21600000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,385.72800000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,389.0880000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.616,404.70400000000006,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,8.224,412.92800000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,416.32000000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,419.77600000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,64.0,5.6,425.3760000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,428.4800000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,431.9360000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.576,436.5120000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.352,440.8640000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71712.0,9.856,450.7200000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2241.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.712,454.4320000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,74784.0,10.336,464.7680000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2337.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.424,468.19200000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14880.0,21.056,489.24800000000005,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,465.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.616,492.86400000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,496.22400000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.792,502.016,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,505.184,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,508.576,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,512.96,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.48,517.44,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.936,525.3760000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.16,533.5360000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.224,541.7600000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,546.1760000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,550.5600000000002,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,556.0640000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,560.5440000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,563.9680000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,568.7360000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.544,573.2800000000002,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.312,578.5920000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,582.9760000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,586.5600000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.776,602.3360000000001,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13472.0,8.064,610.4000000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,421.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,613.6960000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,616.9280000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.984,622.9120000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,626.1440000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,629.3440000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.512,633.8560000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.576,638.4320000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69792.0,9.792,648.2240000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2181.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.68,651.9040000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73568.0,9.728,661.6320000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2299.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.424,665.056,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14240.0,20.448,685.504,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,445.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,688.8000000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,692.0640000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.048,698.1120000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,701.4080000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,704.6720000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.256,708.9280000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.736,713.6640000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.904,721.5680000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.256,729.8240000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12320.0,7.936,737.7600000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,385.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,742.3040000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.576,746.8800000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,752.3840000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.352,756.7360000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,760.0960000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,764.5440000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.16,768.7040000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,774.2080000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,778.7520000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,782.176,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.488,797.664,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14688.0,7.84,805.504,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,459.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,808.864,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,812.192,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.632,817.824,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,821.1519999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,824.4799999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.544,829.0239999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,833.4719999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72096.0,10.048,843.5199999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2253.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.744,847.2639999999999,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72672.0,9.856,857.1199999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2271.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.776,860.8959999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,13888.0,20.8,881.6959999999998,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,885.0879999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,888.4799999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.376,893.8559999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,896.9919999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,900.3519999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,904.6399999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,909.0879999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.256,917.3439999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.224,925.5679999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12320.0,8.256,933.8239999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,385.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.672,938.4959999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.16,942.6559999999998,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,947.9999999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,952.5759999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,955.872,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.352,960.2239999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.416,964.64,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,970.1759999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.32,974.496,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.552,978.048,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.68,993.728,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14784.0,8.064,1001.7919999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,462.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,1005.0559999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,1008.3199999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.888,1014.208,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,1017.632,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1020.992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,1025.344,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.48,1029.824,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71296.0,9.664,1039.488,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2228.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.68,1043.1680000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70784.0,9.792,1052.96,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2212.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1056.48,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14656.0,20.896,1077.376,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,458.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1080.672,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1083.904,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.016,1089.92,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1093.152,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1096.384,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,1100.736,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.8,1105.536,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.968,1113.5040000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.096,1121.6000000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.84,1129.44,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,1134.048,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.512,1138.56,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,1144.096,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.32,1148.416,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.648,1152.0639999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,1156.6399999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.192,1160.8319999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.568,1166.3999999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,1170.9119999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,1174.2399999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.36,1189.5999999999997,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14592.0,7.872,1197.4719999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,456.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1200.8639999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,1204.2559999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.632,1209.888,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,1212.992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1216.32,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.64,1220.96,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,1225.472,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,67520.0,9.792,1235.264,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2110.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.872,1239.136,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72288.0,10.08,1249.216,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2259.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.392,1252.608,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,13888.0,20.8,1273.408,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1276.8,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.52,1280.32,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.696,1286.0159999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1289.2479999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1292.6079999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,1296.9599999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.384,1301.3439999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.936,1309.2799999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12384.0,8.064,1317.3439999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,387.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12384.0,8.064,1325.408,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,387.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.736,1330.144,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,1334.528,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,1340.064,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,1344.6080000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1347.9040000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,1352.2880000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,1356.6720000000003,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.664,1362.3360000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.32,1366.6560000000002,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.52,1370.1760000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.712,1385.8880000000001,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13600.0,8.0,1393.8880000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,425.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.52,1397.4080000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,1400.64,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.272,1406.912,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1410.208,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1413.44,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,1417.8880000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.704,1422.592,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70336.0,9.696,1432.288,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2198.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.648,1435.936,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71840.0,9.888,1445.8239999999998,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2245.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1449.1519999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14208.0,20.704,1469.8559999999998,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,444.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,1473.2159999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,1476.6719999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.888,1482.5599999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,1485.8879999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1489.2479999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.256,1493.5039999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.416,1497.9199999999994,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.768,1506.6879999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.64,1515.3279999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.16,1523.4879999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,1528.1279999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.832,1532.9599999999998,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,1538.4959999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,1542.8799999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1546.272,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,1550.656,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.224,1554.8799999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,1560.2879999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,1564.7039999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,1568.1599999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.616,1583.7759999999996,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13920.0,7.968,1591.7439999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,435.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,1595.3279999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.52,1598.8479999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.568,1604.4159999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1607.5839999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1610.9439999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.736,1615.6799999999996,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,1620.1919999999996,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73120.0,9.92,1630.1119999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2285.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.648,1633.7599999999995,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73024.0,10.016,1643.7759999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2282.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,1647.1039999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14528.0,20.768,1667.8719999999996,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,454.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.616,1671.4879999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,1674.9119999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.632,1680.5439999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1683.7119999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1687.0399999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,1691.3919999999996,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,1695.8399999999997,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,478902272.0,1030733824.0,24309760.0,0,0.0,1055043584.0,1055043584.0,7216960.0,5773568.0,0.5555555555555556,478331008.0,3390592.0,203.776,1899.6159999999998,38895616.0,58343424.0,466747392.0,12154880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14947844.0,105956.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,1902.4959999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.384,1906.8799999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,1910.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.544,1914.624,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.944,1917.568,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173184.0,6.304,1923.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5412.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,37967936.0,0.0,14.688,1938.5600000000002,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1186498.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171520.0,6.528,1945.0880000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5360.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,171648.0,0.0,343296.0,0,0.0,343296.0,343296.0,39336.0,721764.0,0.051683090264091444,38043008.0,0.0,15.072,1960.16,0.0,0.0,0.0,171648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188844.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169920.0,6.24,1966.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5310.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,324224.0,0.0,648448.0,0,0.0,648448.0,648448.0,39336.0,716996.0,0.052008906141747274,37943040.0,0.0,14.784,1981.1840000000002,0.0,0.0,0.0,324224.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1185720.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169728.0,6.4,1987.5840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5304.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,190720.0,0.0,381440.0,0,0.0,381440.0,381440.0,39336.0,721168.0,0.051723593827251405,38031360.0,128.0,14.784,2002.3680000000004,0.0,0.0,0.0,190720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188480.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.96,2007.3280000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,2010.4320000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.144,2016.5760000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,2019.4880000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.24,2025.7280000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,184172.0,38400.0,0.82747155976493,2488224.0,10432.0,9.76,2035.4880000000005,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77757.0,326.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.576,2044.0640000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,196928.0,6.432,2050.4960000000005,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6154.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.312,2055.8080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,2061.3760000000007,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.912,2068.2880000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.392,2071.6800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,157758.0,85760.0,0.6478289079246708,8841472.0,5962368.0,17.312,2088.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276296.0,186324.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91862.0,0.30240575924182134,8856832.0,7409664.0,14.368,2103.36,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276776.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91833.0,0.3072710403041481,8868608.0,7409664.0,14.56,2117.92,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277144.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91668.0,0.30765396293107355,8808832.0,5721408.0,14.432,2132.352,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275276.0,178794.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.176,2138.528,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.456,2141.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51299.0,0.4294849694718463,6224384.0,4023648.0,12.672,2154.656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194512.0,125739.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7334048.0,7292928.0,8.416,2163.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229189.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.336,2249.408,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,286.432,2535.84,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607424.0,4.288,2540.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18982.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,2543.36,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,302176.0,11.744,2555.1040000000003,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9443.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.376,2560.4800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424704.0,20076672.0,1832576.0,0,0.0,21909248.0,21909248.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.136,2647.6160000000004,2452096.0,607744.0,8508416.0,916288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.504,2657.1200000000003,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2660.4800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.568,2670.0480000000007,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2673.312000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2676.6080000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.768,2681.3760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.696,2691.0720000000006,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2694.2080000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.024,2699.2320000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2702.4960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.736,2707.2320000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.2,2714.4320000000002,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798336.0,6077440.0,1519232.0,0,0.0,7596672.0,7596672.0,0.0,14280.0,0.0,4861952.0,4096.0,6.784,2721.2160000000003,0.0,0.0,3038720.0,759616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,128.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,13.28,2734.4960000000005,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.224,2738.7200000000007,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2741.4400000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2744.1920000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,2747.6480000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2750.9120000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.776,2754.6880000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.672,2759.3600000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2762.5600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2765.9840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.608,2770.5920000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.0,2774.5920000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.424,2778.0160000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,2781.2800000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.168,2784.448000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.808,2788.2560000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,12480.0,12288.0,7.52,2795.7760000000007,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,390.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.616,2799.3920000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.896,2804.288000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,2808.000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.648,2811.648000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.192,2815.840000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.16,2820.000000000001,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.424,2823.424000000001,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.288,2827.712000000001,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.296,2831.0080000000007,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,2834.272000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.824,2840.096000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,2843.616000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2846.784000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.16,2850.944000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,2855.3920000000007,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12416.0,8.128,2863.520000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,388.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.224,2871.744000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12416.0,8.0,2879.744000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,388.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,2884.288000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.736,2889.024000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,2894.5280000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,2899.0720000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,2902.4640000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,2906.9120000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.32,2911.2320000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.632,2916.8640000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,2921.3120000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,2924.896,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.672,2929.568,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.544,2934.112,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.936,2950.0480000000002,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,7.936,2957.9840000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2961.4080000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,2964.6720000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.048,2970.7200000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2973.952,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2977.152,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,2981.536,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.32,2985.856,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71104.0,10.048,2995.904,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2222.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.776,2999.68,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71872.0,9.984,3009.6639999999998,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2246.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.36,3013.024,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14368.0,20.992,3034.016,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,449.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,3037.504,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,3040.864,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,3046.7200000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3049.856,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3052.992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,3057.344,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.544,3061.888,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.872,3069.7599999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12352.0,8.064,3077.8239999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,386.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.288,3086.1119999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,3090.4959999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,3094.8799999999997,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,3100.4159999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,3104.7999999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,3108.2879999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,3112.8639999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.16,3117.0239999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,3122.5599999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,3126.9759999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,3130.3039999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.672,3134.9759999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.608,3139.584,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.84,3155.424,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,15168.0,8.0,3163.424,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,474.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.52,3166.944,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,3170.176,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,3176.032,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3179.168,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3182.304,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.256,3186.56,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,3191.072,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69856.0,9.76,3200.8320000000003,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2183.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.872,3204.704,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72832.0,9.824,3214.5280000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2276.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,3218.0480000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14400.0,20.48,3238.5280000000002,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,450.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3241.824,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,3245.12,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.792,3250.912,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3254.1119999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3257.5359999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,3261.8879999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.288,3266.1759999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.744,3273.9199999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.968,3281.8879999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.904,3289.7919999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,3294.2399999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.448,3298.687999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,3304.287999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,3308.7999999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3312.1599999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,3316.6719999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,3321.0239999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.632,3326.6559999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,3331.1679999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,3334.7519999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.704,3339.4559999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.608,3344.064,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.808,3359.872,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13920.0,7.968,3367.8399999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,435.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3371.1359999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,3374.4319999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.016,3380.4479999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3383.6479999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3386.847999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,3391.231999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.384,3395.615999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70880.0,9.696,3405.311999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2215.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.808,3409.119999999999,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72512.0,9.76,3418.879999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2266.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,3422.399999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,13952.0,20.544,3442.943999999999,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,436.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,3446.399999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,3449.631999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,3455.711999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3458.975999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3462.3359999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,3466.7519999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.704,3471.4559999999997,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.16,3479.6159999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.384,3487.9999999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.128,3496.1279999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,3500.6719999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,3505.0239999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,3510.5599999999995,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,3515.2639999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,3518.6879999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,3523.296,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.544,3527.8399999999997,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,3533.312,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,3537.728,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.648,3541.376,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.576,3545.952,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.672,3550.6240000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.84,3566.4640000000004,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14144.0,7.968,3574.4320000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,442.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,3577.76,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,3580.96,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.176,3587.136,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3590.272,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3593.44,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.48,3597.92,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.352,3602.272,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70688.0,9.76,3612.032,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2209.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.712,3615.744,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73536.0,9.632,3625.376,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2298.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.392,3628.768,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14848.0,20.448,3649.216,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,464.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,3652.48,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,3655.744,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.888,3661.632,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3665.024,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3668.192,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.192,3672.384,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.48,3676.864,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.352,3685.216,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.904,3693.12,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.872,3700.9919999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,3705.4719999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.416,3709.888,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,3715.424,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,3720.192,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.744,3723.936,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,3728.6400000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,3733.0240000000003,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.664,3738.6880000000006,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,3743.2640000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,3746.7200000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.704,3751.424000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.512,3755.936000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.68,3771.616000000001,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13856.0,7.712,3779.328000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,433.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,3782.8160000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,3786.1120000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.56,3792.6720000000005,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3795.9040000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3799.1040000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.192,3803.2960000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.576,3807.8720000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71648.0,10.176,3818.0480000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2239.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.616,3821.664,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71296.0,10.24,3831.904,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2228.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.552,3835.456,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14432.0,20.512,3855.9680000000003,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,451.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3859.264,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,3862.496,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.888,3868.384,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3871.648,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3874.8160000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.576,3879.3920000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.416,3883.8080000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.904,3891.7120000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.904,3899.6160000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12384.0,8.0,3907.6160000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,387.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,3912.1280000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.448,3916.5760000000005,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.568,3922.1440000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,3926.7200000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.52,3930.2400000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,3934.656000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.32,3938.976000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.376,3944.352000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,3949.0560000000014,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,3952.4800000000014,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.64,3957.1200000000013,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.64,3961.760000000001,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.648,3977.4080000000013,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13792.0,8.032,3985.4400000000014,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,431.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3988.7360000000012,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,3992.160000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.144,3998.304000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,4001.408000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4004.576000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,4008.864000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,4013.312000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,74944.0,10.016,4023.328000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2342.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.776,4027.1040000000007,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,74240.0,9.664,4036.768000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2320.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,4040.288000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14304.0,20.96,4061.248000000001,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,447.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,4064.576000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,4067.9680000000008,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,4074.0480000000007,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4077.3760000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4080.544000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,4084.928000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,4089.3760000000007,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.0,4097.376,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.0,4105.376,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12384.0,8.256,4113.6320000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,387.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,4118.112,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.576,4122.688,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,4128.192,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,4132.96,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,4136.544,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,4141.248,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,4145.632,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,4151.071999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,4155.583999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,4159.039999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.576,4163.615999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.672,4168.287999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.648,4183.935999999999,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,12928.0,8.0,4191.935999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,404.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,4195.263999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.52,4198.784,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.304,4205.088,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,4208.512,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4211.679999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,4216.063999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.544,4220.607999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,67840.0,9.76,4230.3679999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2120.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.808,4234.1759999999995,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73152.0,9.856,4244.031999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2286.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.424,4247.455999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14560.0,20.64,4268.096,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,455.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.68,4271.776,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,4275.2,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.112,4281.312,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,4284.416,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4287.584,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.544,4292.128,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.352,4296.48,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.064,4304.544,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,7.968,4312.512,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3542016.0,12288.0,8.288,4320.799999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110688.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,4325.375999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.576,4329.951999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,4335.391999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,4339.839999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.712,4343.552,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,4348.128,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.128,4352.255999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,4357.599999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.32,4361.919999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.584,4365.503999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.608,4370.111999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.64,4374.7519999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.904,4390.656,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14080.0,7.936,4398.592,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,440.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,4401.92,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,4405.28,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.792,4411.072,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,4414.24,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4417.407999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.48,4421.887999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,4426.399999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72640.0,9.728,4436.127999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2270.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.68,4439.807999999999,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,75424.0,9.824,4449.631999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2357.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.296,4452.927999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14272.0,20.704,4473.631999999999,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,446.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.552,4477.183999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.456,4480.6399999999985,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.112,4486.751999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4489.983999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4493.151999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,4497.503999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,4502.015999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,478902272.0,1030733824.0,24309760.0,0,0.0,1055043584.0,1055043584.0,7216960.0,5773568.0,0.5555555555555556,478650240.0,3405184.0,203.104,4705.119999999998,38895616.0,58343424.0,466747392.0,12154880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14957820.0,106412.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4707.839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.744,4711.583999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,4714.847999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.64,4719.4879999999985,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,4722.559999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171648.0,6.24,4728.799999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5364.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38125440.0,0.0,14.496,4743.2959999999985,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191420.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173248.0,6.368,4749.663999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5414.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,171648.0,0.0,343296.0,0,0.0,343296.0,343296.0,39336.0,721764.0,0.051683090264091444,38190528.0,0.0,14.624,4764.287999999999,0.0,0.0,0.0,171648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1193454.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171584.0,6.144,4770.431999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5362.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,271776.0,0.0,543552.0,0,0.0,543552.0,543552.0,39336.0,718635.0,0.05189644458693011,38137056.0,128.0,14.976,4785.4079999999985,0.0,0.0,0.0,271776.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191783.0,4.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173632.0,6.08,4791.4879999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5426.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,243168.0,0.0,486336.0,0,0.0,486336.0,486336.0,39336.0,719529.0,0.051835306675100314,38146528.0,128.0,14.4,4805.887999999998,0.0,0.0,0.0,243168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192079.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,5.056,4810.943999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,4813.791999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.08,4819.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,4822.943999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.272,4829.215999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,150101.0,38400.0,0.7962875528511785,2488288.0,11104.0,9.568,4838.783999999998,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,347.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.224,4847.007999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,201216.0,6.272,4853.279999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6288.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.088,4858.367999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,4863.935999999998,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,7.168,4871.1039999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,4874.559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,171798.0,84659.0,0.6698900790385912,8674944.0,5994688.0,17.472,4892.031999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,271092.0,187334.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91229.0,0.3038664336784916,8875008.0,7409664.0,14.304,4906.3359999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277344.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91688.0,0.30760749724366043,8891008.0,7409664.0,14.816,4921.151999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277844.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,90934.0,0.30936901904790837,8867200.0,5723616.0,14.336,4935.487999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277100.0,178863.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.176,4941.663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,4945.087999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51223.0,0.4298482875301922,6209792.0,4035552.0,12.768,4957.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194056.0,126111.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7332960.0,7292928.0,8.288,4966.1439999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229155.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.624,5052.767999999997,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,286.496,5339.263999999997,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.192,5343.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,5346.687999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,288896.0,11.904,5358.591999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9028.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.024,5363.615999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424705.0,20076672.0,1832578.0,0,0.0,21909250.0,21909250.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.008,5450.623999999998,2452096.0,607744.0,8508416.0,916289.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.472,5460.095999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,5463.327999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.408,5472.735999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,5476.287999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,5479.775999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,5484.351999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.696,5494.047999999998,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5497.343999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.12,5502.463999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,5505.631999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,5510.111999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.296,5517.407999999998,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798337.0,6077440.0,1519234.0,0,0.0,7596674.0,7596674.0,0.0,14280.0,0.0,4861952.0,7680.0,6.784,5524.191999999997,0.0,0.0,3038720.0,759617.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,240.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2592.0,12.928,5537.119999999997,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,81.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.776,5540.895999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,5543.679999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,5546.559999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,5549.887999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,5553.055999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.16,5557.215999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.992,5562.207999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5565.535999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
