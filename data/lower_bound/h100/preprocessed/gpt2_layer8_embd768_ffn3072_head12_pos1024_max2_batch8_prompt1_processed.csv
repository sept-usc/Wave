Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.592,5.4079999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,8.128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,11.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,15.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,32.0,3.84,18.976,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,64.0,4.576,23.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,5.12,28.672,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,32.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.752,35.008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,37.888000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.36,41.248000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.808,45.056000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,48.352000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,52.032000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,64.0,32.0,4.192,56.224000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.264,59.48800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,62.784000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.552,66.33600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,3456.0,24576.0,7.2,73.53600000000002,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,108.0,768.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,3456.0,24576.0,6.72,80.25600000000001,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,108.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,83.68000000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.424,87.10400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.056,92.16000000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,98.72000000000003,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,19.904,118.62400000000002,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.8,123.42400000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,127.71200000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,132.00000000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,14.272,146.27200000000002,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),31,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.12,155.39200000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",32,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.352,159.74400000000003,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",33,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.84,163.58400000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",34,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.496,170.08000000000004,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.584,189.66400000000004,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",36,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,192.99200000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",37,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.584,196.57600000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",38,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.52,200.09600000000006,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,203.64800000000005,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",40,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,206.94400000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",41,149056.0,365696.0,12288.0,0,0.0,377984.0,377984.0,0.0,384.0,0.0,98304.0,98304.0,3.552,210.49600000000004,24576.0,55296.0,142912.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",42,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.424,213.92000000000004,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",43,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.296,217.21600000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),44,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.424,236.64000000000004,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",45,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.704,241.34400000000005,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,244.86400000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",47,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.752,251.61600000000007,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",48,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,19.008,270.6240000000001,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.384,275.0080000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.224,279.2320000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.416,283.6480000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",52,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.928,296.5760000000001,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),53,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.504,306.0800000000001,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.352,310.4320000000001,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,314.0160000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",56,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.752,320.7680000000001,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.552,340.3200000000001,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",58,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,343.7440000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",59,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.456,347.2000000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",60,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.232,350.43200000000013,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",61,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,353.88800000000015,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",62,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,357.2160000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,149120.0,365824.0,12288.0,0,0.0,378112.0,378112.0,0.0,384.0,0.0,98304.0,98304.0,3.424,360.6400000000001,24576.0,55296.0,142976.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",64,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,363.9680000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.424,367.39200000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),66,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.232,386.624,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",67,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.736,391.36,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,394.752,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",69,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.592,401.344,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.976,420.32,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.576,424.896,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.32,429.216,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,433.504,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",74,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.576,446.08000000000004,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),75,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.248,455.32800000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",76,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.096,459.42400000000004,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.232,462.65600000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",78,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.592,469.24800000000005,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",79,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.552,488.80000000000007,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",80,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,492.0640000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",81,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.36,495.4240000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",82,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,498.7200000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",83,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,502.1760000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",84,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,505.5360000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,148744.0,365072.0,12288.0,0,0.0,377360.0,377360.0,0.0,384.0,0.0,98304.0,98304.0,3.456,508.99200000000013,24576.0,55296.0,142600.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",86,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.488,512.4800000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,515.8720000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),88,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.52,535.3920000000002,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",89,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.736,540.1280000000002,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,543.5840000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",91,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,550.1440000000001,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.656,568.8000000000001,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",93,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.32,573.1200000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",94,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,577.4080000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.448,581.8560000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",96,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.576,594.4320000000001,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),97,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.248,603.6800000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",98,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.064,607.7440000000001,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",99,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,611.2320000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",100,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.784,618.0160000000002,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.232,637.2480000000002,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",102,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,640.5760000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",103,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,643.9040000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",104,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,647.1680000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",105,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.392,650.5600000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",106,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,653.8240000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",107,149000.0,365584.0,12288.0,0,0.0,377872.0,377872.0,0.0,384.0,0.0,98304.0,98304.0,3.424,657.2480000000002,24576.0,55296.0,142856.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",108,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,660.5760000000001,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",109,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.488,664.0640000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),110,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.392,683.4560000000002,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",111,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.864,688.3200000000003,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,691.7760000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.4,698.1760000000003,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",114,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.656,716.8320000000002,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.192,721.0240000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,725.3120000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,729.6000000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",118,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.832,742.4320000000002,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),119,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.12,751.5520000000002,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.096,755.6480000000003,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,759.0720000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",122,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.976,766.0480000000002,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.488,785.5360000000003,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",124,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,788.8000000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",125,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,792.1280000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",126,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.488,795.6160000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,799.1040000000004,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",128,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,802.3680000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,148832.0,365248.0,12288.0,0,0.0,377536.0,377536.0,0.0,384.0,0.0,98304.0,98304.0,3.52,805.8880000000004,24576.0,55296.0,142688.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.712,809.6000000000004,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.328,812.9280000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),132,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.488,832.4160000000004,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.8,837.2160000000003,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.68,840.8960000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.688,847.5840000000003,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.944,866.5280000000002,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.352,870.8800000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.32,875.2000000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.32,879.5200000000003,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",140,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.576,892.0960000000003,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),141,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.568,901.6640000000003,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",142,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.352,906.0160000000003,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,909.4720000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",144,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.72,916.1920000000003,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",145,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,18.912,935.1040000000004,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",146,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,938.4000000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",147,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.456,941.8560000000004,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",148,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,945.2160000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,948.7040000000005,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",150,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.552,952.2560000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,149024.0,365632.0,12288.0,0,0.0,377920.0,377920.0,0.0,384.0,0.0,98304.0,98304.0,3.616,955.8720000000005,24576.0,55296.0,142880.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.584,959.4560000000005,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",153,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,962.9120000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),154,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.2,982.1120000000005,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.576,986.6880000000006,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,990.0800000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,996.6400000000006,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",158,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.848,1015.4880000000005,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.576,1020.0640000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.416,1024.4800000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.256,1028.7360000000006,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",162,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.832,1041.5680000000007,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),163,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,8.992,1050.5600000000006,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",164,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.64,1055.2000000000007,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,1058.4960000000008,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",166,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.752,1065.2480000000007,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",167,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,20.192,1085.4400000000007,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",168,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,1088.8640000000007,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",169,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,1092.3840000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",170,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,1095.6800000000007,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",171,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,1099.2000000000007,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",172,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.232,1102.4320000000007,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,148896.0,365376.0,12288.0,0,0.0,377664.0,377664.0,0.0,384.0,0.0,98304.0,98304.0,3.424,1105.8560000000007,24576.0,55296.0,142752.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",174,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,1109.3760000000007,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",175,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,1112.7360000000006,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),176,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.36,1132.0960000000005,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",177,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.704,1136.8000000000004,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,1140.1600000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.336,1146.4960000000003,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,19.008,1165.5040000000004,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1169.9840000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.544,1174.5280000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.48,1179.0080000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",184,196608.0,6531072.0,0.0,0,57982058496.0,6531072.0,57988589568.0,51072.0,96.0,0.99812382739212,73728.0,24576.0,12.576,1191.5840000000005,4939776.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,2304.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),185,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.088,1200.6720000000005,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",186,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.224,1204.8960000000004,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1208.3840000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",188,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,1214.9440000000004,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",189,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.296,1234.2400000000005,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",190,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,1237.6960000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",191,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.552,1241.2480000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",192,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.616,1244.8640000000003,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.424,1248.2880000000002,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",194,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,1251.6480000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,149072.0,365728.0,12288.0,0,0.0,378016.0,378016.0,0.0,384.0,0.0,98304.0,98304.0,3.584,1255.2320000000002,24576.0,55296.0,142928.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.584,1258.8160000000003,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.52,1262.3360000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),198,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.648,1281.9840000000002,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",199,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.704,1286.688,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,1289.9840000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",201,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.656,1296.64,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",202,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,74635.0,0.0,0.0,2513984.0,4.064,1300.7040000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,78562.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",203,310679076.0,620550144.0,1612872.0,0,0.0,622163016.0,622163016.0,6195252.0,1766703.0,0.7781068845528517,166226784.0,7085952.0,88.864,1389.5680000000002,0.0,804864.0,309872640.0,806436.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5194587.0,221436.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",204,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.784,1392.3520000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",205,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,4.352,1396.7040000000004,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",206,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1400.0640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",207,128.0,402432.0,256.0,0,0.0,402688.0,402688.0,0.0,6314.0,0.0,1608224.0,1608224.0,4.16,1404.2240000000004,0.0,402432.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,50257.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.168,1407.3920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",209,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,113728.0,6.016,1413.4080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3554.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",210,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,26400.0,165216.0,0.1377755511022044,10261248.0,0.0,8.288,1421.6960000000004,0.0,0.0,0.0,192000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",211,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,114368.0,5.984,1427.6800000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3574.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",212,115200.0,0.0,230400.0,0,0.0,230400.0,230400.0,26400.0,167616.0,0.13607125185551708,10261248.0,0.0,8.8,1436.4800000000002,0.0,0.0,0.0,115200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",213,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,115200.0,5.92,1442.4000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3600.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",214,179200.0,0.0,358400.0,0,0.0,358400.0,358400.0,26400.0,165616.0,0.13748854262144822,10261248.0,0.0,8.512,1450.9120000000003,0.0,0.0,0.0,179200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",215,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,113472.0,5.952,1456.8640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3546.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",216,166400.0,0.0,332800.0,0,0.0,332800.0,332800.0,26400.0,166016.0,0.13720272742391484,10261248.0,256.0,8.48,1465.3440000000003,0.0,0.0,0.0,166400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,8.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,39.0,0.0,12832.0,1600.0,4.448,1469.7920000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,401.0,50.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,1472.7360000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,35.0,0.9481481481481482,1600.0,0.0,5.856,1478.5920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,1481.9200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",221,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,35.0,0.9481481481481482,1600.0,0.0,5.792,1487.7120000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",222,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,93480.0,26024.0,0.7822332306868389,1660512.0,18240.0,9.184,1496.8960000000002,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51891.0,570.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",223,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,9.056,1505.9520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,804112.0,0.0,1608224.0,0,0.0,1608224.0,1608224.0,0.0,37695.0,0.0,1633344.0,135584.0,6.24,1512.1920000000002,0.0,0.0,0.0,804112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51042.0,4237.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9471.0,0.0,2010304.0,0.0,5.888,1518.0800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,62822.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",226,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,12565.0,0.0,0.0,3216448.0,4.8,1522.88,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,100514.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,12565.0,0.9149479127886119,1608224.0,0.0,6.528,1529.4080000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.712,1533.1200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,130470.0,58634.0,0.6899378119976309,5683040.0,3959904.0,17.536,1550.6560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,177595.0,123747.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,26679.0,58643.0,0.3126860598673261,5695200.0,4901472.0,13.056,1563.7120000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,177975.0,153171.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,27978.0,58499.0,0.3235311123188825,5675360.0,4901472.0,15.072,1578.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,177355.0,153171.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,27978.0,58479.0,0.32360595440508,5660256.0,4302976.0,15.2,1593.9840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,176883.0,134468.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,12565.0,0.5405682109035065,3216448.0,0.0,5.568,1599.5520000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.68,1603.2320000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,29664.0,32013.0,0.48095724500218884,3912768.0,2777600.0,11.328,1614.5600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,122274.0,86800.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",236,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,50260.0,0.0,4857280.0,4824672.0,7.296,1621.8560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151790.0,150771.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",237,6244080.0,13310088.0,1230592.0,0,0.0,14540680.0,14540680.0,1056.0,13408.0,0.07300884955752213,2190464.0,1484832.0,31.776,1653.6320000000003,1650464.0,402056.0,5628784.0,615296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68452.0,46401.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",238,0.0,2048400.0,0.0,0,0.0,2048400.0,2048400.0,224568.0,25136.0,0.8993368147887099,1608672.0,1169280.0,98.752,1752.3840000000002,2048400.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50271.0,36540.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",239,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6314.0,0.0,1608224.0,401760.0,4.064,1756.4480000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,12555.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.104,1759.5520000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,804112.0,0.0,1608224.0,0,0.0,1608224.0,1608224.0,0.0,37695.0,0.0,3618528.0,195360.0,12.192,1771.7440000000004,0.0,0.0,0.0,804112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113079.0,6105.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",242,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9471.0,0.0,2010304.0,0.0,6.208,1777.9520000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,62822.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",243,6244104.0,13310088.0,1230640.0,0,0.0,14540728.0,14540728.0,1056.0,13408.0,0.07300884955752213,2191744.0,1488224.0,32.192,1810.1440000000005,1650464.0,402056.0,5628784.0,615320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68492.0,46507.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",244,77312.0,0.0,154624.0,0,0.0,154624.0,154624.0,4012.0,3195.0,0.5566810045788816,1608448.0,1632.0,9.248,1819.3920000000005,0.0,0.0,0.0,77312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,51.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",245,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1822.6880000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",246,77312.0,0.0,154624.0,0,0.0,154624.0,154624.0,4012.0,3195.0,0.5566810045788816,1608448.0,1632.0,9.6,1832.2880000000005,0.0,0.0,0.0,77312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,51.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1835.7440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,1839.3600000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",249,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,1843.9040000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",250,8192.0,440456.0,16384.0,0,0.0,456840.0,456840.0,608.0,3164.0,0.16118769883351008,1608448.0,256.0,16.608,1860.5120000000004,440456.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",251,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1863.8080000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",252,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.088,1868.8960000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1872.2240000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",254,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.704,1876.9280000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",255,2973696.0,5670160.0,1081344.0,0,0.0,6751504.0,6751504.0,0.0,12565.0,0.0,0.0,1608224.0,7.104,1884.0320000000004,0.0,804112.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",256,2512568.0,4020560.0,1004576.0,0,0.0,5025136.0,5025136.0,0.0,9471.0,0.0,3216448.0,0.0,6.016,1890.0480000000005,0.0,0.0,2010280.0,502288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100514.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",257,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,1216.0,3164.0,0.2776255707762557,1608448.0,256.0,22.432,1912.4800000000005,0.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.264,1915.7440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.36,1919.1040000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,64.0,3.616,1922.7200000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",261,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.328,1926.0480000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",262,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,4.288,1930.3360000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,1933.2480000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1936.0640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,1939.2960000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",266,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,1942.1440000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",267,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,32.0,4.032,1946.1760000000002,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",268,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,5.0,0.0,32.0,32.0,7.424,1953.6000000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,1957.1200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1960.4160000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,4.288,1964.7040000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",272,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,4.768,1969.4720000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,1972.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",274,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1976.2240000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",275,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,160.0,64.0,4.576,1980.8000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,128.0,32.0,4.0,1984.8000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.552,1988.352,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.232,1991.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",279,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,3.296,1994.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,128.0,64.0,3.808,1998.688,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",281,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,18816.0,24576.0,8.512,2007.2,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,588.0,768.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",282,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,3456.0,24576.0,6.688,2013.8880000000001,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,108.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,2017.152,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",284,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.328,2020.48,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",285,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.12,2025.6,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",286,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.688,2032.288,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.816,2051.104,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.728,2056.832,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",289,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.664,2062.496,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.256,2066.752,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",291,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.64,2079.392,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),292,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.12,2088.5119999999997,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",293,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.256,2092.7679999999996,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,2096.1919999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",295,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.624,2102.8159999999993,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.392,2122.207999999999,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",297,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,2125.4719999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",298,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,2128.9919999999993,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,2132.287999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",300,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.552,2135.8399999999992,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",301,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.712,2139.551999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,149097.0,365778.0,12288.0,0,0.0,378066.0,378066.0,0.0,384.0,0.0,98304.0,98304.0,3.392,2142.943999999999,24576.0,55296.0,142953.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",303,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,2146.271999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",304,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,2149.663999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),305,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.36,2169.023999999999,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",306,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.608,2173.631999999999,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",307,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,2177.055999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",308,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.688,2183.7439999999992,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",309,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.592,2202.3359999999993,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.272,2208.6079999999993,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.952,2214.5599999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",312,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.352,2218.9119999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",313,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.608,2231.5199999999995,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),314,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.248,2240.7679999999996,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",315,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.256,2245.0239999999994,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",316,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,2248.5439999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",317,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.592,2255.1359999999995,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",318,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.296,2274.4319999999993,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",319,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,2277.8559999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",320,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.36,2281.2159999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",321,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,2284.6399999999994,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",322,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,2288.1279999999992,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",323,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.296,2291.423999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",324,149024.0,365632.0,12288.0,0,0.0,377920.0,377920.0,0.0,384.0,0.0,98304.0,98304.0,3.584,2295.007999999999,24576.0,55296.0,142880.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",325,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,2298.527999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",326,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.552,2302.079999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),327,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.552,2321.631999999999,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",328,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.672,2326.303999999999,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",329,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,2329.887999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",330,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.496,2336.383999999999,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",331,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,19.104,2355.487999999999,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,2361.087999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",333,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,2366.6879999999987,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",334,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,2370.9759999999987,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",335,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.512,2383.487999999999,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),336,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.152,2392.639999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",337,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.256,2396.895999999999,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",338,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,2400.319999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",339,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.592,2406.911999999999,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",340,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.136,2426.047999999999,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,2429.407999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",342,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,2432.927999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",343,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.392,2436.319999999999,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",344,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.488,2439.8079999999986,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",345,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,2443.0719999999988,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",346,148998.0,365580.0,12288.0,0,0.0,377868.0,377868.0,0.0,384.0,0.0,98304.0,98304.0,3.392,2446.4639999999986,24576.0,55296.0,142854.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",347,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.584,2450.0479999999984,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",348,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,2453.4079999999985,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),349,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.52,2472.9279999999985,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",350,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.8,2477.7279999999987,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",351,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,2481.0239999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",352,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,2487.5839999999985,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",353,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.944,2506.5279999999984,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",354,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,2512.5119999999984,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",355,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.24,2518.751999999998,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",356,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.352,2523.103999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",357,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.928,2536.031999999998,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),358,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.12,2545.1519999999978,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",359,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.032,2549.183999999998,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",360,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,2552.511999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",361,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.4,2558.911999999998,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",362,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,18.944,2577.855999999998,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,2581.119999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",364,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.456,2584.575999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.648,2588.2239999999983,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",366,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.36,2591.5839999999985,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,2594.9119999999984,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,149286.0,366156.0,12288.0,0,0.0,378444.0,378444.0,0.0,384.0,0.0,98304.0,98304.0,3.52,2598.4319999999984,24576.0,55296.0,143142.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",369,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.232,2601.6639999999984,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,2605.1199999999985,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),371,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.392,2624.5119999999984,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",372,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.704,2629.2159999999985,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",373,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,2632.5759999999987,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",374,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.4,2638.9759999999987,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",375,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.944,2657.9199999999987,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.632,2663.5519999999988,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",377,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,2669.1519999999987,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.32,2673.471999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",379,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.8,2686.271999999999,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),380,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.216,2695.487999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",381,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.128,2699.615999999999,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",382,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2703.071999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",383,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.656,2709.727999999999,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",384,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.232,2728.959999999999,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,2732.4159999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",386,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.36,2735.7759999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,2739.1999999999994,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",388,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,2742.6559999999995,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",389,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.584,2746.2399999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,149050.0,365684.0,12288.0,0,0.0,377972.0,377972.0,0.0,384.0,0.0,98304.0,98304.0,3.584,2749.823999999999,24576.0,55296.0,142906.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",391,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.232,2753.055999999999,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,2756.4159999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),393,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.264,2775.6799999999994,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",394,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.576,2780.2559999999994,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2783.7119999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",396,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.56,2790.2719999999995,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",397,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.784,2809.0559999999996,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.08,2815.1359999999995,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.984,2821.1199999999994,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.224,2825.3439999999996,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",401,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.576,2837.9199999999996,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),402,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.12,2847.0399999999995,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",403,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.16,2851.1999999999994,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",404,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,2854.7199999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",405,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.784,2861.5039999999995,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",406,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,18.976,2880.4799999999996,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.328,2883.8079999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",408,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.456,2887.2639999999997,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.456,2890.72,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.52,2894.24,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",411,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.36,2897.6,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,149164.0,365912.0,12288.0,0,0.0,378200.0,378200.0,0.0,384.0,0.0,98304.0,98304.0,3.776,2901.3759999999997,24576.0,55296.0,143020.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,2904.7039999999997,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",414,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.296,2907.9999999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),415,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.488,2927.4879999999994,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",416,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.608,2932.0959999999995,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2935.5519999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",418,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.464,2942.0159999999996,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,19.136,2961.1519999999996,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.568,2966.72,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",421,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,5.6,2972.3199999999997,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.288,2976.6079999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",423,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.608,2989.216,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),424,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,8.992,2998.208,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",425,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.096,3002.304,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",426,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3005.728,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",427,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.752,3012.48,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.52,3032.0,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",429,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,3035.424,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",430,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.488,3038.912,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",431,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.264,3042.176,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.68,3045.8559999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",433,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.392,3049.2479999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",434,148908.0,365400.0,12288.0,0,0.0,377688.0,377688.0,0.0,384.0,0.0,98304.0,98304.0,3.392,3052.6399999999994,24576.0,55296.0,142764.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.328,3055.9679999999994,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",436,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,3059.4239999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),437,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.136,3078.5599999999995,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",438,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.736,3083.2959999999994,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,3086.783999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",440,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.432,3093.215999999999,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,14247936.0,28753920.0,184320.0,0,0.0,28938240.0,28938240.0,129024.0,118656.0,0.5209302325581395,15058944.0,73728.0,18.656,3111.871999999999,221184.0,221184.0,14155776.0,92160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,470592.0,2304.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.016,3117.887999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,768.0,0.0,49152.0,49152.0,6.048,3123.935999999999,0.0,0.0,0.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,24576.0,24576.0,4.448,3128.3839999999987,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 64, 64, 1, 1>::Params)",445,196608.0,6537216.0,0.0,0,57982058496.0,6537216.0,57988595712.0,51072.0,96.0,0.99812382739212,122880.0,24576.0,12.768,3141.1519999999987,4945920.0,1198080.0,196608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,226492416.0,3840.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),446,37748736.0,75890688.0,0.0,0,0.0,75890688.0,75890688.0,136320.0,1536.0,0.9888579387186629,2654208.0,196608.0,9.184,3150.335999999999,0.0,393216.0,37748736.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,82944.0,6144.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",447,18432.0,61440.0,36864.0,0,0.0,98304.0,98304.0,0.0,2496.0,0.0,199680.0,24576.0,4.064,3154.3999999999987,55296.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,3157.951999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",449,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.528,3164.4799999999987,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",450,18997248.0,38338560.0,245760.0,0,0.0,38584320.0,38584320.0,172032.0,158208.0,0.5209302325581395,20078592.0,98304.0,19.808,3184.2879999999986,294912.0,294912.0,18874368.0,122880.0,0,0,0,0,0,0,0,0.0,0.0,0.0,627456.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.392,3187.6799999999985,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",452,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.52,3191.1999999999985,0.0,49152.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",453,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.584,3194.7839999999983,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",454,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,576.0,0.0,196608.0,98304.0,3.456,3198.2399999999984,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",455,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,98304.0,98304.0,3.424,3201.6639999999984,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,148928.0,365440.0,12288.0,0,0.0,377728.0,377728.0,0.0,384.0,0.0,98304.0,98304.0,3.392,3205.055999999998,24576.0,55296.0,142784.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",457,24576.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,384.0,0.0,98304.0,98304.0,3.424,3208.479999999998,0.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",458,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.616,3212.095999999998,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_64x64_8x5_nn_align1>(T1::Params),459,150994944.0,302776320.0,0.0,0,0.0,302776320.0,302776320.0,493824.0,3072.0,0.9938176197836167,10616832.0,393216.0,19.552,3231.6479999999983,0.0,786432.0,150994944.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,12288.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 1, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",460,18432.0,110592.0,36864.0,0,0.0,147456.0,147456.0,0.0,4032.0,0.0,396288.0,24576.0,4.736,3236.383999999998,104448.0,6144.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12384.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",461,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,3239.999999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",462,60552.0,186856.0,18432.0,0,0.0,205288.0,205288.0,160.0,544.0,0.22727272727272727,73728.0,25088.0,6.496,3246.4959999999983,52320.0,31864.0,51336.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2304.0,784.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,74635.0,0.0,0.0,2516320.0,3.84,3250.3359999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,78635.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",464,310679076.0,620550144.0,1612872.0,0,0.0,622163016.0,622163016.0,6195252.0,1751209.0,0.7796240364106739,166411008.0,7086112.0,89.888,3340.2239999999983,0.0,804864.0,309872640.0,806436.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5200344.0,221441.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.976,3343.1999999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",466,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,3.84,3347.0399999999986,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",467,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3350.3039999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",468,128.0,402432.0,256.0,0,0.0,402688.0,402688.0,0.0,6314.0,0.0,1608224.0,1608224.0,4.096,3354.3999999999987,0.0,402432.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,50257.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",469,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.264,3357.663999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,113216.0,6.048,3363.7119999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3538.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",471,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,26400.0,165216.0,0.1377755511022044,10261248.0,0.0,8.768,3372.4799999999987,0.0,0.0,0.0,192000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,114176.0,6.08,3378.5599999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3568.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",473,115200.0,0.0,230400.0,0,0.0,230400.0,230400.0,26400.0,167616.0,0.13607125185551708,10261248.0,0.0,9.12,3387.6799999999985,0.0,0.0,0.0,115200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,113728.0,6.08,3393.7599999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3554.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",475,161600.0,0.0,323200.0,0,0.0,323200.0,323200.0,26400.0,166166.0,0.13709585285045128,10261248.0,0.0,8.352,3402.1119999999983,0.0,0.0,0.0,161600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,6400.0,18968.0,0.2522863450015768,1623648.0,110272.0,5.952,3408.0639999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50739.0,3446.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",477,147200.0,0.0,294400.0,0,0.0,294400.0,294400.0,26400.0,166616.0,0.13677622580511462,10261248.0,256.0,8.544,3416.6079999999984,0.0,0.0,0.0,147200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320664.0,8.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,39.0,0.0,12832.0,1600.0,4.512,3421.1199999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,401.0,50.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,3424.0639999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",480,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,35.0,0.9481481481481482,1600.0,0.0,5.76,3429.8239999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",481,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,3432.991999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,35.0,0.9481481481481482,1600.0,0.0,6.016,3439.007999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",483,102400.0,0.0,204800.0,0,0.0,204800.0,204800.0,99384.0,26032.0,0.7924347770619379,1660512.0,17344.0,9.216,3448.223999999999,0.0,0.0,0.0,102400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51891.0,542.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,8.416,3456.639999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,804112.0,0.0,1608224.0,0,0.0,1608224.0,1608224.0,0.0,37695.0,0.0,1633248.0,136608.0,6.304,3462.943999999999,0.0,0.0,0.0,804112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,51039.0,4269.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9471.0,0.0,2010304.0,0.0,5.632,3468.575999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,62822.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",487,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,12565.0,0.0,0.0,3216448.0,4.576,3473.151999999999,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,100514.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,12565.0,0.9149479127886119,1608224.0,0.0,6.464,3479.615999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.392,3483.007999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,130470.0,58654.0,0.6898648505742264,5665120.0,3994624.0,17.12,3500.127999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,177035.0,124832.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,28083.0,58545.0,0.3241792492034908,5669984.0,4150208.0,13.696,3513.8239999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,177187.0,129694.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,27978.0,58394.0,0.32392441995091004,5662560.0,4901472.0,15.04,3528.8639999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,176955.0,153171.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,27978.0,58566.0,0.3232806433721575,5661664.0,4290656.0,16.192,3545.0559999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,176927.0,134083.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,12565.0,0.5405682109035065,3216448.0,0.0,5.44,3550.4959999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100514.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.872,3554.3679999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,29664.0,31961.0,0.4813630831643002,3926080.0,2772480.0,11.232,3565.5999999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,122690.0,86640.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",497,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,50260.0,0.0,4859456.0,4824672.0,7.072,3572.6719999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151858.0,150771.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",498,6244080.0,13310088.0,1230592.0,0,0.0,14540680.0,14540680.0,1056.0,13408.0,0.07300884955752213,2150496.0,1484608.0,31.744,3604.415999999999,1650464.0,402056.0,5628784.0,615296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,67203.0,46394.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",499,0.0,2048400.0,0.0,0,0.0,2048400.0,2048400.0,224568.0,25136.0,0.8993368147887099,1608512.0,1170400.0,98.4,3702.815999999999,2048400.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50266.0,36575.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6314.0,0.0,1608224.0,401760.0,3.936,3706.751999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,12555.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.264,3710.015999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,804112.0,0.0,1608224.0,0,0.0,1608224.0,1608224.0,0.0,37695.0,0.0,3618528.0,192832.0,11.648,3721.6639999999993,0.0,0.0,0.0,804112.0,0,0,0,0,0,0,0,0.0,0.0,0.0,113079.0,6026.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",503,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9471.0,0.0,2010304.0,0.0,5.472,3727.1359999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,62822.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",504,6244104.0,13310088.0,1230640.0,0,0.0,14540728.0,14540728.0,1056.0,13408.0,0.07300884955752213,2152128.0,1486496.0,31.904,3759.0399999999995,1650464.0,402056.0,5628784.0,615320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,67254.0,46453.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",505,77312.0,0.0,154624.0,0,0.0,154624.0,154624.0,4012.0,3195.0,0.5566810045788816,1608448.0,1632.0,9.504,3768.5439999999994,0.0,0.0,0.0,77312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,51.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3771.9999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",507,77312.0,0.0,154624.0,0,0.0,154624.0,154624.0,4012.0,3195.0,0.5566810045788816,1608448.0,1632.0,9.888,3781.8879999999995,0.0,0.0,0.0,77312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,51.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,3785.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",509,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,3788.9919999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,3793.4719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",511,8192.0,440456.0,16384.0,0,0.0,456840.0,456840.0,608.0,3164.0,0.16118769883351008,1608448.0,256.0,15.936,3809.4079999999994,440456.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,3812.8959999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",513,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.088,3817.9839999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",514,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3821.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",515,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,3825.7599999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",516,2973696.0,5670160.0,1081344.0,0,0.0,6751504.0,6751504.0,0.0,12565.0,0.0,0.0,1608224.0,7.104,3832.863999999999,0.0,804112.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",517,2512568.0,4020560.0,1004576.0,0,0.0,5025136.0,5025136.0,0.0,9471.0,0.0,3216448.0,0.0,6.016,3838.879999999999,0.0,0.0,2010280.0,502288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,100514.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",518,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,1216.0,3164.0,0.2776255707762557,1608448.0,256.0,22.304,3861.1839999999993,0.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50264.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",519,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.328,3864.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.232,3867.7439999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,64.0,3.904,3871.6479999999992,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,3.456,3875.1039999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,4.0,3879.1039999999994,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,3882.1439999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,3885.0239999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,3888.5439999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",527,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,3891.2319999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,224.0,32.0,3.872,3895.1039999999994,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,7.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",529,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,5.0,0.0,32.0,32.0,7.456,3902.5599999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,3905.9199999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,3909.3119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,3.904,3913.2159999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",533,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,4.8,3918.0159999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",534,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3921.4719999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
