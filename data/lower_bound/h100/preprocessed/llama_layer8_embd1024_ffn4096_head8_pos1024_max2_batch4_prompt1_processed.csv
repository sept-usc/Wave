Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.912,8.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,11.936,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,15.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.936,19.584,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,24.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.376,29.568,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.712,33.28,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,36.0,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,38.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,41.888000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.904,45.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,49.056000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,52.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.128,56.57600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,59.96800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,63.16800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.552,66.72000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,4352.0,16384.0,5.824,72.54400000000001,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,136.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,76.09600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.312,81.40800000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,84.96000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.68,88.64000000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.032,92.67200000000003,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.256,96.92800000000003,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.392,100.32000000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.48,104.80000000000003,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,108.06400000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.456,111.52000000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.304,117.82400000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,121.08800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.584,124.67200000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.8,129.47200000000004,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,133.88800000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19200.0,9.888,143.77600000000004,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,600.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19040.0,9.504,153.28000000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,595.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18944.0,9.952,163.23200000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,592.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,167.93600000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,172.32000000000005,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,177.79200000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.768,182.56000000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,4.128,186.68800000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.8,191.48800000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,195.87200000000007,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,201.44000000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,206.1440000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,209.69600000000008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.488,225.18400000000008,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19232.0,9.408,234.59200000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,601.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,237.98400000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,241.37600000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.632,247.00800000000007,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,250.49600000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,254.11200000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.576,258.6880000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.448,263.1360000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,95136.0,12.928,276.0640000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2973.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.904,279.9680000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93248.0,13.472,293.44000000000005,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2914.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.264,296.70400000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,21152.0,26.016,322.7200000000001,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,661.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,326.1760000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,329.4720000000001,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.632,335.1040000000001,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,338.3360000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,341.6640000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.704,346.3680000000001,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,350.94400000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18496.0,9.536,360.48000000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,578.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18784.0,9.696,370.17600000000016,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,587.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18880.0,9.792,379.96800000000013,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,590.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,384.54400000000015,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.512,389.05600000000015,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.248,394.30400000000014,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,398.72000000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,402.1440000000001,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,5.024,407.1680000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.608,411.7760000000001,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.632,417.40800000000013,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,421.79200000000014,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,425.34400000000016,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.584,440.92800000000017,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18368.0,9.824,450.7520000000002,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,574.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,454.08000000000015,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.424,457.50400000000013,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.112,463.61600000000016,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,467.00800000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,470.27200000000016,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.64,474.91200000000015,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.64,479.55200000000013,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18941568.0,96384.0,13.376,492.9280000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591924.0,3012.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.84,496.7680000000001,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942080.0,96224.0,13.44,510.2080000000001,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591940.0,3007.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.456,513.6640000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19872.0,25.44,539.1040000000002,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,621.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,542.4000000000002,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.424,545.8240000000002,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,551.8080000000002,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,554.9760000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,558.2720000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.768,563.0400000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,567.5200000000003,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19392.0,9.76,577.2800000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,606.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,20000.0,9.888,587.1680000000003,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,625.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19008.0,9.696,596.8640000000004,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,594.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,601.4400000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,605.6640000000004,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,611.1360000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,615.7120000000004,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,619.1680000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,623.5840000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,627.8080000000006,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.28,633.0880000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,637.6000000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,640.8960000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.392,656.2880000000006,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18048.0,9.92,666.2080000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,564.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,669.6320000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,672.9280000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.696,678.6240000000006,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,681.8560000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,685.1840000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,689.5360000000005,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.384,693.9200000000005,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,95136.0,12.864,706.7840000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2973.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.84,710.6240000000006,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94464.0,13.408,724.0320000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2952.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.456,727.4880000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19584.0,26.304,753.7920000000006,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,612.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,757.3440000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,760.6400000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.696,766.3360000000007,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,769.6320000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,773.1520000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,777.4720000000008,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,782.0480000000008,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,20096.0,9.536,791.5840000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,628.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,17536.0,9.472,801.0560000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,548.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19168.0,9.632,810.6880000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,599.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,815.1360000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.48,819.6160000000007,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,825.0240000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,829.4080000000007,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,832.9920000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.8,837.7920000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.512,842.3040000000005,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,847.7760000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,852.3200000000005,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,855.8720000000005,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.616,871.4880000000005,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18848.0,9.504,880.9920000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,589.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,884.2880000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,887.6800000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.304,893.9840000000006,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,897.1520000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,900.4480000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.512,904.9600000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.672,909.6320000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940672.0,93856.0,14.016,923.6480000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591896.0,2933.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.68,927.3280000000005,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940032.0,96192.0,13.856,941.1840000000005,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591876.0,3006.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,944.5760000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19104.0,25.728,970.3040000000005,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,597.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.744,974.0480000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.872,977.9200000000005,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,984.0640000000005,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,987.2960000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,990.7520000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,995.1680000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,999.7760000000005,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18720.0,9.696,1009.4720000000005,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,585.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18528.0,10.08,1019.5520000000006,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,579.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18272.0,9.728,1029.2800000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,571.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,1033.9200000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,1038.1760000000008,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,1043.5520000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,1048.1600000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,1051.5520000000008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1056.0640000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.16,1060.2240000000008,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,1065.6000000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,1070.144000000001,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1073.6000000000008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.456,1089.0560000000007,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19072.0,9.472,1098.5280000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,596.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,1101.9520000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,1105.2480000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.92,1111.1680000000008,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1114.4640000000009,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,1118.0800000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,1122.4640000000009,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.32,1126.7840000000008,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,97504.0,13.568,1140.3520000000008,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,3047.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.616,1143.9680000000008,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18944128.0,95968.0,13.12,1157.0880000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,592004.0,2999.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.552,1160.6400000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19808.0,26.688,1187.3280000000007,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,619.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.808,1191.1360000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.616,1194.7520000000006,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.472,1200.2240000000006,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1203.4560000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1206.7840000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.32,1211.1040000000005,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.736,1215.8400000000006,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18560.0,9.632,1225.4720000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,580.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19456.0,10.016,1235.4880000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,608.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19872.0,9.792,1245.2800000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,621.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.32,1249.6000000000006,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.448,1254.0480000000007,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.28,1259.3280000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,1263.9680000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,1267.2960000000007,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.672,1271.9680000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.608,1276.5760000000007,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,1282.0480000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,1286.4960000000008,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.712,1290.2080000000008,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.584,1305.7920000000008,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19168.0,9.504,1315.2960000000007,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,599.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,1318.7520000000006,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.488,1322.2400000000007,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.24,1328.4800000000007,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1331.6800000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1334.9120000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,1339.3280000000007,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.672,1344.0000000000007,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18943360.0,92384.0,13.216,1357.2160000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591980.0,2887.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.68,1360.8960000000006,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940416.0,93824.0,14.144,1375.0400000000006,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591888.0,2932.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.456,1378.4960000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,21024.0,25.856,1404.3520000000005,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,657.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,1407.7120000000004,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.424,1411.1360000000004,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.888,1417.0240000000003,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,1420.3840000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1423.6480000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,1428.0960000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,1432.5120000000002,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19040.0,9.792,1442.304,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,595.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19456.0,9.536,1451.8400000000001,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,608.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18816.0,9.792,1461.632,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,588.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.448,1466.0800000000002,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.288,1470.3680000000002,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.6,1475.968,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1480.48,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.872,1484.352,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1488.864,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.192,1493.056,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,1498.56,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1503.072,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,1506.656,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.552,1522.2079999999999,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18272.0,9.696,1531.9039999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,571.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.648,1535.5519999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,1538.8479999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.664,1544.5119999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1547.8079999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1551.1039999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,1555.5199999999998,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.416,1559.9359999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,96192.0,13.312,1573.2479999999996,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,3006.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.744,1576.9919999999995,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18943744.0,94464.0,12.96,1589.9519999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591992.0,2952.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,1593.3439999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20960.0,27.072,1620.4159999999995,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,655.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,1623.9359999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,1627.1999999999994,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.568,1632.7679999999993,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1636.0319999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1639.4239999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,1643.8079999999993,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,1648.2879999999993,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19040.0,9.504,1657.7919999999992,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,595.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19392.0,9.728,1667.5199999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,606.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,21216.0,9.664,1677.1839999999993,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,663.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,1681.6959999999992,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.512,1686.2079999999992,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,1691.711999999999,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,1696.319999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.648,1699.967999999999,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,1704.447999999999,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.608,1709.055999999999,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,1714.5279999999989,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,1719.2319999999988,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,1722.7839999999987,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,65536.0,5883904.0,0.0,0,64424509440.0,5883904.0,64430393344.0,33280.0,64.0,0.9980806142034548,49152.0,16384.0,15.648,1738.4319999999987,4960256.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,1536.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,20064.0,9.856,1748.2879999999986,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,627.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.264,1751.5519999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,1754.9439999999986,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,1761.0239999999985,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1764.1919999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,1767.6479999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,1772.0959999999984,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,1776.7039999999984,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94528.0,13.312,1790.0159999999983,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2954.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.584,1793.5999999999983,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942976.0,92736.0,12.928,1806.5279999999984,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591968.0,2898.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.488,1810.0159999999985,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19712.0,25.472,1835.4879999999985,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,616.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,1838.9759999999985,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.616,1842.5919999999985,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.24,1848.8319999999985,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,1851.9679999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1855.3279999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.736,1860.0639999999985,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,1864.6719999999984,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,134144000.0,288768000.0,6144000.0,0,0.0,294912000.0,294912000.0,1936000.0,1600000.0,0.5475113122171946,138246528.0,735616.0,65.312,1929.9839999999983,10240000.0,16384000.0,131072000.0,3072000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4320204.0,22988.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1932.7999999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.384,1937.1839999999984,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1940.5439999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.52,1944.0639999999983,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.232,1947.2959999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33408.0,5.856,1953.1519999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1044.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.656,1959.8079999999982,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33728.0,5.76,1965.5679999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1054.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.72,1972.2879999999982,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33536.0,5.952,1978.2399999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.528,1984.7679999999982,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33664.0,5.696,1990.4639999999981,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1052.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,128.0,6.72,1997.1839999999982,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.0,2001.1839999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,2004.031999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,2009.4719999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,2012.7039999999981,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.888,2018.591999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,21976.0,8408.0,0.7232754081095313,527232.0,7200.0,8.64,2027.2319999999982,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,225.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.48,2035.7119999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42208.0,6.08,2041.791999999998,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1319.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.776,2045.5679999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.808,2049.3759999999984,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.824,2055.1999999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.52,2058.7199999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17654.0,0.7025041286104277,1709952.0,1303712.0,15.264,2073.9839999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53436.0,40741.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17617.0,0.3501420192555978,1705472.0,1560576.0,11.712,2085.6959999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53296.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17594.0,0.38036204832006765,1697152.0,1560576.0,12.928,2098.6239999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53036.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17598.0,0.38030847242763577,1691648.0,1210240.0,12.736,2111.3599999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52864.0,37820.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.832,2116.191999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.616,2119.807999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9389.0,0.5289484246437889,1166848.0,851616.0,9.024,2128.831999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36464.0,26613.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1548928.0,1536000.0,4.832,2133.663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48404.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,23.2,2156.8639999999978,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.296,2220.1599999999976,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.584,2223.7439999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.2,2226.9439999999972,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,61376.0,11.776,2238.719999999997,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1918.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.616,2242.335999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,23.008,2265.343999999997,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.936,2297.279999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2300.639999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.736,2333.375999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,2336.831999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,2340.223999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,2344.831999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,12.032,2356.8639999999973,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,2360.3199999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.928,2365.2479999999973,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2368.6079999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.704,2373.3119999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.088,2378.399999999998,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.184,2383.583999999998,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.896,2400.479999999998,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,2403.807999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2407.199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.712,2410.911999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,2414.239999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.416,2418.655999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2421.471999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2424.223999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,2427.647999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2430.495999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,4.032,2434.527999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.136,2441.663999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,2445.0559999999978,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2448.4479999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.448,2452.8959999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.832,2457.7279999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2461.0559999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,2464.5759999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.512,2469.0879999999975,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.064,2473.1519999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.2,2476.351999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.168,2479.5199999999973,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.328,2482.8479999999972,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,4.064,2486.911999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,384.0,0.0,16640.0,16384.0,7.84,2494.751999999997,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,520.0,512.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.84,2498.5919999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.896,2503.4879999999976,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2506.8799999999974,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.456,2510.3359999999975,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.096,2514.4319999999975,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.288,2518.7199999999975,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.616,2522.3359999999975,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.416,2526.7519999999977,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.488,2530.2399999999975,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,2533.5359999999973,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,2539.5199999999973,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2542.623999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,2545.823999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.512,2550.335999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.736,2555.071999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19296.0,9.728,2564.799999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,603.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18048.0,9.664,2574.463999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,564.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18976.0,9.568,2584.0319999999974,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,593.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,2588.4479999999976,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.576,2593.0239999999976,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,2598.4319999999975,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,2603.0079999999975,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,2606.5599999999977,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,2611.071999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.352,2615.4239999999977,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,2620.8639999999978,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,2625.375999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.744,2629.119999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,2633.791999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.576,2638.367999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,63488.0,5880576.0,0.0,0,64424509440.0,5880576.0,64430390016.0,33306.0,64.0,0.9980821096793527,81920.0,16384.0,15.712,2654.079999999998,4961216.0,792384.0,63488.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18560.0,9.408,2663.487999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,580.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,2666.815999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,2670.207999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.08,2676.2879999999977,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2679.4879999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2682.6559999999977,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,2687.0079999999975,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.512,2691.5199999999977,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94560.0,12.896,2704.415999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2955.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,2708.063999999998,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94272.0,12.896,2720.959999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2946.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.424,2724.383999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19392.0,25.12,2749.503999999998,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,606.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.488,2752.991999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,2756.2879999999977,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,2762.2719999999977,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2765.5039999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2768.8959999999975,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,2773.2479999999973,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.352,2777.599999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19168.0,9.696,2787.295999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,599.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19424.0,9.664,2796.9599999999973,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,607.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18400.0,9.696,2806.655999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,575.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,2811.295999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.736,2816.031999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.696,2821.727999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.352,2826.0799999999967,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.584,2829.6639999999966,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,2834.1439999999966,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.416,2838.5599999999968,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,2843.999999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.832,2848.8319999999967,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.616,2852.4479999999967,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.704,2857.151999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.48,2861.631999999997,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.552,2877.183999999997,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18240.0,9.6,2886.783999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,570.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,2890.0799999999967,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.328,2893.4079999999967,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.016,2899.423999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2902.6239999999966,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2905.7919999999967,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,2910.207999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.544,2914.7519999999968,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18940160.0,95200.0,13.152,2927.903999999997,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591880.0,2975.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.712,2931.615999999997,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93696.0,13.184,2944.799999999997,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2928.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.36,2948.159999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19776.0,25.76,2973.9199999999973,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,618.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,2977.2799999999975,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.328,2980.6079999999974,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,64.0,6.144,2986.751999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2989.855999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2993.215999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.544,2997.759999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.64,3002.399999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18496.0,9.664,3012.063999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,578.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,21760.0,9.888,3021.951999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,680.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,20672.0,9.408,3031.359999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,646.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.672,3036.031999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.352,3040.383999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,3045.951999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,3050.559999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3053.983999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.736,3058.719999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.352,3063.071999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.376,3068.447999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.832,3073.279999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,3076.671999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.64,3081.3119999999967,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.544,3085.8559999999966,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.808,3101.6639999999966,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19200.0,9.952,3111.615999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,600.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,3114.943999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.232,3118.1759999999967,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.272,3124.4479999999967,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3127.5839999999966,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3130.8799999999965,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,3135.1679999999965,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.672,3139.8399999999965,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94272.0,13.088,3152.9279999999967,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2946.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,3156.575999999997,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,94176.0,12.832,3169.4079999999967,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2943.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.328,3172.7359999999967,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20768.0,26.24,3198.9759999999965,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,649.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,3202.3359999999966,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.52,3205.8559999999966,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,3211.8399999999965,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3215.0719999999965,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3218.2719999999963,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,3222.623999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,3227.103999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,17952.0,9.696,3236.799999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,561.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,17888.0,9.792,3246.591999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,559.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19008.0,9.568,3256.159999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,594.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,3260.6399999999962,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.448,3265.087999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.504,3270.591999999996,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,3275.199999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,3278.7519999999963,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.64,3283.391999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,3287.647999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,3293.1199999999963,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.512,3297.6319999999964,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3301.0559999999964,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.576,3305.6319999999964,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,3310.3039999999964,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.712,3326.0159999999964,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18112.0,9.632,3335.6479999999965,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,566.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3338.9439999999963,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,3342.2079999999964,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,3348.351999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3351.6159999999963,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3354.815999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.48,3359.295999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,3363.871999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942336.0,92960.0,13.28,3377.1519999999964,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591948.0,2905.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.84,3380.9919999999966,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18943872.0,93600.0,13.152,3394.1439999999966,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591996.0,2925.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.68,3397.8239999999964,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20576.0,24.704,3422.5279999999966,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,643.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,3425.8879999999967,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,3429.2799999999966,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.272,3435.5519999999965,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3438.6879999999965,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3441.8559999999966,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.576,3446.4319999999966,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,3451.039999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18752.0,9.536,3460.575999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,586.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19200.0,9.44,3470.015999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,600.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18624.0,9.536,3479.551999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,582.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3484.127999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.512,3488.639999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.536,3494.175999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,3498.7839999999974,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.616,3502.3999999999974,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.8,3507.1999999999975,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.48,3511.6799999999976,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.408,3517.0879999999975,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,3521.5679999999975,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,3525.0879999999975,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.608,3529.6959999999976,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.576,3534.2719999999977,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.552,3549.823999999998,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19392.0,9.568,3559.391999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,606.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.328,3562.719999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.392,3566.111999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,3572.0959999999977,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3575.1999999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3578.3999999999974,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.416,3582.8159999999975,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,3587.3919999999976,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93408.0,13.472,3600.8639999999978,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2919.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,3604.511999999998,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942976.0,94080.0,12.896,3617.407999999998,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591968.0,2940.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.328,3620.735999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20416.0,26.592,3647.327999999998,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,638.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.36,3650.6879999999983,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.52,3654.2079999999983,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,3660.383999999998,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3663.615999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3666.943999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,3671.391999999998,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.64,3676.031999999998,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19392.0,9.536,3685.567999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,606.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19712.0,9.504,3695.071999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,616.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19200.0,9.536,3704.607999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,600.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.672,3709.279999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.64,3713.919999999998,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,3719.359999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.416,3723.775999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.552,3727.327999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3731.903999999998,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.16,3736.063999999998,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,3741.503999999998,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.608,3746.1119999999983,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3749.5359999999982,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.544,3754.079999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.768,3758.847999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.68,3774.527999999998,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19072.0,9.472,3783.999999999998,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,596.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3787.423999999998,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,3790.719999999998,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,3796.8639999999978,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3800.0639999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3803.2639999999974,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,3807.6159999999973,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,3812.0959999999973,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93024.0,13.024,3825.119999999997,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2907.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.648,3828.7679999999973,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93664.0,13.376,3842.1439999999975,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2927.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.392,3845.5359999999973,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,19968.0,25.376,3870.9119999999975,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,624.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,3874.2079999999974,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,3877.4719999999975,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,3883.6159999999973,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3886.8799999999974,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3890.079999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.352,3894.431999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.48,3898.911999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19296.0,9.568,3908.4799999999973,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,603.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18112.0,9.6,3918.079999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,566.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19552.0,9.216,3927.295999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,611.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,3931.775999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.384,3936.159999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.6,3941.759999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,3946.303999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,3949.727999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.576,3954.303999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.224,3958.527999999997,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.44,3963.967999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,3968.447999999997,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.456,3971.9039999999973,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.608,3976.5119999999974,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.544,3981.0559999999973,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.712,3996.7679999999973,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18720.0,9.696,4006.463999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,585.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.392,4009.855999999997,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.648,4013.503999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.144,4019.647999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,4022.7519999999968,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,4025.9519999999966,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.448,4030.3999999999965,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.608,4035.0079999999966,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,91968.0,13.248,4048.2559999999967,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2874.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.872,4052.1279999999965,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18949120.0,94176.0,13.696,4065.8239999999964,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,592160.0,2943.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.456,4069.2799999999966,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,20128.0,26.912,4096.191999999996,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,629.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,4099.615999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,4102.911999999997,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.176,4109.087999999997,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4112.319999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4115.647999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,4119.935999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.384,4124.319999999997,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19264.0,9.44,4133.759999999997,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,602.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19104.0,9.664,4143.423999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,597.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,18496.0,9.632,4153.055999999996,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,578.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.48,4157.5359999999955,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.544,4162.079999999995,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.472,4167.551999999995,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.384,4171.935999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.52,4175.455999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.704,4180.159999999995,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,3072.0,2048.0,6144.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,4.256,4184.415999999996,2048.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,5.568,4189.983999999996,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,8192.0,4096.0,16384.0,0,0.0,20480.0,20480.0,0.0,384.0,0.0,24576.0,16384.0,4.544,4194.527999999996,0.0,4096.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,512.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.424,4197.951999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.672,4202.623999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,320.0,0.0,32768.0,32768.0,4.704,4207.327999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,65536.0,5885952.0,0.0,0,64424509440.0,5885952.0,64430395392.0,33280.0,64.0,0.9980806142034548,81920.0,16384.0,15.584,4222.911999999995,4962304.0,792576.0,65536.0,0.0,0,0,0,0,0,0,0,0.0,0.0,251658240.0,2560.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,4292608.0,9240576.0,196608.0,0,0.0,9437184.0,9437184.0,61952.0,51200.0,0.5475113122171946,6291456.0,19424.0,9.632,4232.543999999994,327680.0,524288.0,4194304.0,98304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,196608.0,607.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,4235.839999999995,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.296,4239.135999999995,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,6.048,4245.183999999995,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4248.415999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,4251.743999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.288,4256.031999999995,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.544,4260.575999999995,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18939904.0,93216.0,13.024,4273.599999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591872.0,2913.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,204800.0,393216.0,32768.0,0,0.0,425984.0,425984.0,0.0,256.0,0.0,65536.0,65536.0,3.84,4277.439999999995,16384.0,0.0,188416.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,17170432.0,36962304.0,786432.0,0,0.0,37748736.0,37748736.0,247808.0,204800.0,0.5475113122171946,18942080.0,93664.0,13.824,4291.263999999995,1310720.0,2097152.0,16777216.0,393216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,591940.0,2927.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,384.0,0.0,131072.0,65536.0,3.52,4294.783999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,17072128.0,36765696.0,589824.0,0,0.0,37355520.0,37355520.0,221696.0,198656.0,0.5274056029232643,25165824.0,21248.0,26.336,4321.119999999995,1114112.0,2097152.0,16777216.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,786432.0,664.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,4096.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,96.0,0.0,32768.0,16384.0,3.296,4324.415999999996,0.0,0.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,16384.0,16384.0,3.264,4327.679999999996,0.0,4096.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,8580.0,4096.0,0,0.0,12676.0,12676.0,40.0,36.0,0.5263157894736842,16384.0,32.0,5.984,4333.663999999996,8576.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,4336.7999999999965,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,4339.967999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,16896.0,16384.0,4.384,4344.351999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,528.0,512.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,4096.0,4096.0,8192.0,0,0.0,12288.0,12288.0,0.0,384.0,0.0,32768.0,16384.0,4.576,4348.927999999996,0.0,4096.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,512.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,134144000.0,288768000.0,6144000.0,0,0.0,294912000.0,294912000.0,1936000.0,1600000.0,0.5475113122171946,138212224.0,727392.0,64.704,4413.631999999996,10240000.0,16384000.0,131072000.0,3072000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4319132.0,22731.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,4416.415999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.776,4420.1919999999955,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4423.583999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.744,4427.327999999995,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4430.207999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34496.0,5.952,4436.159999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1078.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.688,4442.847999999995,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35200.0,5.824,4448.671999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1100.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.688,4455.359999999995,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34560.0,5.792,4461.1519999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1080.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,56320.0,0.0,112640.0,0,0.0,112640.0,112640.0,8448.0,34600.0,0.19624605091990335,2109440.0,0.0,6.496,4467.647999999996,0.0,0.0,0.0,56320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34560.0,5.856,4473.503999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1080.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,48128.0,0.0,96256.0,0,0.0,96256.0,96256.0,8448.0,34856.0,0.19508590430445225,2109440.0,128.0,6.528,4480.031999999996,0.0,0.0,0.0,48128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.064,4484.095999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.328,4487.423999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,4492.863999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.816,4495.679999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.728,4501.407999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,29971.0,8426.0,0.7805557725864,527232.0,7424.0,8.8,4510.207999999996,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,232.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.928,4519.135999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,43552.0,6.048,4525.183999999996,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1361.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.552,4528.735999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.616,4532.351999999995,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.76,4538.1119999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,4541.695999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17668.0,0.7023384325089291,1711104.0,1271520.0,15.616,4557.311999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53472.0,39735.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17672.0,0.3494330731850979,1700992.0,1560576.0,11.456,4568.7679999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53156.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17637.0,0.37978689735204135,1696000.0,1560576.0,12.896,4581.663999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53000.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17609.0,0.38016121651589285,1695488.0,1212672.0,12.992,4594.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52984.0,37896.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.736,4599.391999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.616,4603.007999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9372.0,0.529399949786593,1164928.0,857728.0,9.088,4612.095999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36404.0,26804.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549184.0,1536000.0,4.736,4616.831999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48412.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,521216.0,512000.0,23.392,4640.223999999995,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16288.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.808,4704.031999999995,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.584,4707.6159999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.072,4710.687999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,58336.0,11.584,4722.2719999999945,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1823.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.488,4725.759999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,514560.0,512000.0,23.232,4748.991999999995,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16080.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.544,4781.535999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4784.927999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.936,4816.863999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,4820.351999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,4823.8079999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,4828.415999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.424,4839.839999999995,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4843.2319999999945,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.024,4848.255999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4851.583999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,4856.095999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.152,4861.247999999995,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.088,4866.335999999995,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.64,4882.975999999995,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,4886.239999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,4889.599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.936,4893.535999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,4896.863999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,4.032,4900.895999999995,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4903.743999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4906.623999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,4909.887999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,4912.5759999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.968,4916.543999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.912,4923.455999999996,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,4926.751999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,4930.143999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.0,4934.143999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.672,4938.815999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4942.1119999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
