Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,8.192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.2,11.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,17.791999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,20.543999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,23.711999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.032,27.743999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,31.007999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,34.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,37.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.0,41.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,44.768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,48.224000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.52,51.74400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,5.76,57.504000000000005,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,61.056000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,64.41600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),20,32768.0,69632.0,0.0,0,0.0,69632.0,69632.0,364.0,2.0,0.994535519125683,288.0,256.0,5.568,69.98400000000001,0.0,4096.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",21,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,4.512,74.49600000000001,0.0,0.0,0.0,288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",22,1024.0,2304.0,0.0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,4.576,79.072,0.0,256.0,1024.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",23,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.392,82.464,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",24,896.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,8.0,0.0,512.0,512.0,3.872,86.336,0.0,256.0,896.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",25,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.296,89.632,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,93.024,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",27,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,98.144,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",28,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,101.47200000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",29,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,104.83200000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",30,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,109.248,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",31,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,112.70400000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",32,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.432,119.13600000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",33,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.112,125.248,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",34,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6400.0,6.016,131.264,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,200.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.512,135.776,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.416,140.192,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",37,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.408,145.6,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.672,150.272,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",39,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.36,153.632,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,157.792,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,162.336,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",42,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.152,167.488,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,171.808,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.648,175.456,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",45,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.296,190.75199999999998,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",46,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.112,196.86399999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",47,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,200.35199999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,203.74399999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",49,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.504,209.24799999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",50,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,212.35199999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",51,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,215.48799999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",52,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.16,219.64799999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",53,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,223.19999999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",54,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14048.0,8.544,231.74399999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,439.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.744,235.48799999999997,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",56,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14144.0,8.768,244.25599999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,442.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",57,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.552,247.80799999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",58,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3200.0,8.544,256.352,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,100.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",59,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,259.67999999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,263.03999999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",61,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.504,268.544,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",62,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,271.84,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,275.008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",64,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,279.424,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.488,282.912,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",66,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,6.24,289.152,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",67,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.016,295.168,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",68,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,6.016,301.184,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.768,305.952,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.512,310.464,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",71,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.504,315.968,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,320.32,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",73,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.84,324.15999999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,328.57599999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,332.92799999999994,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",76,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,338.27199999999993,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.736,343.0079999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,346.55999999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",79,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.296,361.85599999999994,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",80,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.016,367.87199999999996,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.616,371.48799999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.616,375.1039999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",83,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.344,380.4479999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",84,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,383.5199999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",85,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,386.78399999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.48,391.26399999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",87,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.488,394.75199999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",88,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14432.0,8.576,403.328,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,451.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.744,407.072,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",90,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14272.0,8.896,415.968,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,446.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",91,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,419.392,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",92,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3360.0,8.704,428.096,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,105.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,431.552,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.744,435.29600000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,440.4800000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,443.48800000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,446.7200000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.352,451.07200000000006,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",99,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,454.5280000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",100,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.336,460.8640000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",101,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.016,466.8800000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",102,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.016,472.89600000000013,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,477.2160000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.16,481.37600000000015,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",105,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.216,486.59200000000016,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,490.97600000000017,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",107,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,494.36800000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,498.5600000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.608,503.1680000000002,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,508.44800000000015,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,512.7040000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,516.0960000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",113,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.2,531.2960000000003,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",114,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.888,537.1840000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",115,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,540.7680000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,544.0960000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",117,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.568,549.6640000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",118,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,553.0880000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",119,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,556.2880000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",120,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,560.4160000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",121,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.584,564.0000000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",122,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14208.0,8.512,572.5120000000002,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,444.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.648,576.1600000000002,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",124,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14080.0,8.832,584.9920000000002,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,440.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",125,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.392,588.3840000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",126,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3232.0,8.8,597.1840000000002,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,101.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,600.7040000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.296,604.0000000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",129,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.472,609.4720000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",130,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,612.5760000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",131,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,616.0000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",132,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,620.1280000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",133,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,623.6480000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",134,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,5.952,629.6000000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",135,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,5.984,635.5840000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",136,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,5.92,641.5040000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,645.9520000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.608,650.5600000000002,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",139,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,655.9360000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,660.2560000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",141,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,663.9680000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.768,668.7360000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.256,672.9920000000002,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",144,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,678.3360000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,682.7840000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,686.2720000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",147,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.232,701.5040000000002,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",148,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.048,707.5520000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",149,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,711.0080000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,714.4640000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",151,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,719.6160000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",152,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,722.6560000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",153,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,726.2080000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",154,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.352,730.5600000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",155,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.648,734.2080000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",156,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14080.0,8.576,742.7840000000003,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,440.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.776,746.5600000000003,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",158,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14240.0,8.512,755.0720000000003,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,445.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",159,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.296,758.3680000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",160,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.192,766.5600000000004,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",161,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,770.0480000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,773.4720000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",163,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.088,778.5600000000004,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",164,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,781.6320000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,785.0560000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",166,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.448,789.5040000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,792.9280000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",168,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,5.984,798.9120000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",169,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6496.0,6.144,805.0560000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,203.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",170,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.888,810.9440000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.576,815.5200000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.256,819.7760000000004,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",173,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.312,825.0880000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.736,829.8240000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",175,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,833.2480000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,837.4400000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,841.9840000000004,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",178,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,847.3280000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",179,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,851.5840000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,855.1680000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",181,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.616,870.7840000000003,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",182,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.24,877.0240000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",183,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,880.4480000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,883.7760000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",185,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.76,889.5360000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",186,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,892.8000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",187,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,895.9680000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.192,900.1600000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",189,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.744,903.9040000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",190,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14048.0,8.448,912.3520000000003,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,439.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.52,915.8720000000003,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",192,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14080.0,8.512,924.3840000000002,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,440.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",193,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.552,927.9360000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",194,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3168.0,8.576,936.5120000000003,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,99.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",195,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,939.9360000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,943.3280000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",197,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.696,949.0240000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",198,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,952.2240000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",199,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,955.4240000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,959.5520000000005,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",201,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.712,963.2640000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",202,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,5.92,969.1840000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",203,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.08,975.2640000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",204,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6400.0,6.016,981.2800000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,200.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,985.7280000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.608,990.3360000000004,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",207,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.44,995.7760000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.032,999.8080000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",209,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,1003.3280000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,1007.8080000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.288,1012.0960000000005,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",212,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,1017.4720000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,1021.8240000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.68,1025.5040000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",215,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.008,1040.5120000000004,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",216,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6240.0,6.272,1046.7840000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,195.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",217,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,1050.2720000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.552,1053.8240000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",219,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.408,1059.2320000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",220,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,1062.2720000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",221,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1065.5680000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,1069.9840000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",223,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1073.44,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",224,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14176.0,8.608,1082.048,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,443.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.776,1085.824,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",226,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13728.0,8.832,1094.6560000000002,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,429.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",227,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1098.0800000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",228,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3392.0,8.416,1106.496,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,106.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,1110.016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1113.472,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.344,1118.816,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1122.048,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.584,1125.632,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.512,1130.144,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",235,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1133.696,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",236,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.432,1140.128,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",237,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.08,1146.2079999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",238,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.08,1152.2879999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,1156.7359999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,1160.9599999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",241,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,1166.2079999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.576,1170.7839999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",243,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,1174.176,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,1178.5919999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,1183.136,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",246,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.216,1188.3519999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.224,1192.5759999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,1195.9039999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",249,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.264,1211.1679999999997,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",250,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.048,1217.2159999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",251,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,1220.6399999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,1223.9999999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",253,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.728,1229.7279999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",254,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1232.8959999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",255,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,1236.0639999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",256,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,1240.1919999999993,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",257,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.68,1243.8719999999994,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",258,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13856.0,8.416,1252.2879999999993,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,433.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.488,1255.7759999999994,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",260,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14336.0,8.736,1264.5119999999995,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,448.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",261,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.488,1267.9999999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",262,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3392.0,8.32,1276.3199999999995,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,106.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",263,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1279.7759999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,1283.1359999999993,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",265,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.504,1288.6399999999992,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",266,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,1291.7439999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",267,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,1294.9119999999991,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",268,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.224,1299.135999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",269,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1302.687999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",270,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6240.0,5.984,1308.671999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,195.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",271,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.984,1314.6559999999988,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",272,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,6.08,1320.7359999999987,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,1325.1839999999988,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.512,1329.6959999999988,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",275,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.312,1335.0079999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,1339.3919999999987,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",277,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.744,1343.1359999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,1347.5839999999987,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.256,1351.8399999999988,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",280,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.312,1357.1519999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",281,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,1361.5359999999987,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1364.9919999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",283,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.296,1380.2879999999986,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",284,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.048,1386.3359999999986,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",285,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1389.8879999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1393.3439999999985,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",287,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,1398.5279999999984,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",288,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,1401.5679999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",289,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1404.7999999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",290,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.48,1409.2799999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",291,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,1412.7039999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",292,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14176.0,8.448,1421.1519999999985,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,443.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.808,1424.9599999999984,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",294,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14304.0,9.12,1434.0799999999983,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,447.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",295,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.328,1437.4079999999983,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",296,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3264.0,8.544,1445.9519999999984,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,102.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,1449.5359999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.584,1453.1199999999985,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",299,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,1458.2399999999984,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",300,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,1461.2799999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",301,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1464.5759999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",302,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.96,1469.5359999999985,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",303,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1472.9919999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",304,25088000.0,53728000.0,1024000.0,0,0.0,54752000.0,54752000.0,1024000.0,880000.0,0.5378151260504201,99008000.0,179712.0,37.344,1510.3359999999984,1504000.0,3072000.0,24576000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3094000.0,5616.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,1513.2159999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",306,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,4.416,1517.6319999999985,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,1520.7999999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",308,128.0,32768.0,256.0,0,0.0,33024.0,33024.0,0.0,512.0,0.0,128000.0,128000.0,3.552,1524.3519999999983,0.0,32768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.168,1527.5199999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8256.0,5.536,1533.0559999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,258.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",311,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,6.4,1539.4559999999983,0.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8320.0,5.632,1545.0879999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,260.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",313,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,6.336,1551.4239999999984,0.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,5.344,1556.7679999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,2112.0,8578.0,0.19756782039289056,527360.0,0.0,6.176,1562.9439999999984,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8448.0,5.504,1568.4479999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,264.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,2112.0,8610.0,0.1969781757134863,527360.0,32.0,6.272,1574.7199999999982,0.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,1056.0,128.0,4.064,1578.7839999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,1581.9199999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,11.0,0.9831029185867896,128.0,0.0,5.376,1587.2959999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,1590.3999999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,11.0,0.9831029185867896,128.0,0.0,5.408,1595.8079999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",323,8193.0,0.0,16386.0,0,0.0,16386.0,16386.0,6396.0,2104.0,0.7524705882352941,131808.0,1888.0,7.904,1603.7119999999982,0.0,0.0,0.0,8193.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4119.0,59.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.704,1612.4159999999981,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",325,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,9856.0,5.792,1618.207999999998,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4063.0,308.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,3.648,1621.855999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",327,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,1000.0,0.0,0.0,256000.0,3.52,1625.375999999998,0.0,0.0,0.0,32000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,1000.0,0.9926561306621232,128000.0,0.0,5.664,1631.039999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,1634.527999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,10422.0,4240.0,0.7108170781612331,407552.0,326016.0,13.632,1648.159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12736.0,10188.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,3426.0,4253.0,0.44615184268784996,407552.0,390144.0,11.776,1659.935999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12736.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,4806.0,4224.0,0.5322259136212625,405504.0,390144.0,12.96,1672.8959999999981,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12672.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,4806.0,4224.0,0.5322259136212625,405504.0,350048.0,13.248,1686.1439999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12672.0,10939.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",334,498638.0,1061280.0,101276.0,0,0.0,1162556.0,1162556.0,132.0,1312.0,0.09141274238227147,128000.0,128000.0,23.2,1709.3439999999982,133280.0,32000.0,448000.0,50638.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",335,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,3.136,1712.4799999999982,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",336,15.0,84347.0,30.0,0,0.0,84377.0,84377.0,4417.0,2073.0,0.6805855161787365,136096.0,129024.0,5.312,1717.791999999998,84347.0,0.0,0.0,15.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4253.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,512.0,0.0,128000.0,31808.0,3.68,1721.4719999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,1724.2879999999982,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",339,36096.0,0.0,72192.0,0,0.0,72192.0,72192.0,0.0,3000.0,0.0,288000.0,14528.0,11.488,1735.7759999999982,0.0,0.0,0.0,36096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9000.0,454.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,3.68,1739.4559999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",341,498641.0,1061280.0,101282.0,0,0.0,1162562.0,1162562.0,132.0,1312.0,0.09141274238227147,128512.0,128000.0,22.784,1762.2399999999984,133280.0,32000.0,448000.0,50641.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4016.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",342,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,11.904,1774.1439999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",343,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1777.5359999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",344,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,12.32,1789.8559999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1793.1839999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,1796.7679999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.64,1801.4079999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",348,1024.0,36576.0,2048.0,0,0.0,38624.0,38624.0,62.0,251.0,0.19808306709265175,128000.0,32.0,12.288,1813.6959999999985,36576.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1816.9599999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,1820.5439999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,1825.0559999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",352,352000.0,640000.0,128000.0,0,0.0,768000.0,768000.0,0.0,1000.0,0.0,0.0,128000.0,3.84,1828.8959999999984,0.0,64000.0,288000.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",353,200145.0,320000.0,80290.0,0,0.0,400290.0,400290.0,0.0,768.0,0.0,256000.0,0.0,4.928,1833.8239999999985,0.0,0.0,160000.0,40145.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",354,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,124.0,251.0,0.33066666666666666,128000.0,32.0,16.672,1850.4959999999985,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,1853.8559999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,1856.9919999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.136,1860.1279999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,1863.5519999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",359,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,4.384,1867.9359999999983,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,1870.6559999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1873.4079999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,1876.8959999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,1879.7759999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,1882.9439999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,1886.5279999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,1889.7919999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.872,1893.6639999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.992,1898.6559999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,1901.9839999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1905.3759999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",371,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,4.8,1910.1759999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,1913.2159999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.776,1916.9919999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,1920.3519999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,1923.9359999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.52,1927.4559999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",377,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,4.608,1932.0639999999983,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,1935.5519999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",379,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.632,1941.1839999999984,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,1944.7039999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),381,32768.0,69632.0,0.0,0,0.0,69632.0,69632.0,364.0,2.0,0.994535519125683,288.0,256.0,5.536,1950.2399999999984,0.0,4096.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",382,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,4.416,1954.6559999999984,0.0,0.0,0.0,288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,1024.0,2304.0,0.0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,3.872,1958.5279999999984,0.0,256.0,1024.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.168,1961.6959999999983,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,900.0,2056.0,0.0,0,0.0,2056.0,2056.0,0.0,8.0,0.0,512.0,512.0,4.096,1965.7919999999983,0.0,256.0,900.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",386,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.2,1968.9919999999984,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.552,1972.5439999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",388,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.056,1977.5999999999983,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",389,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1980.7679999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1984.127999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.64,1988.7679999999982,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",392,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.488,1992.2559999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",393,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,5.984,1998.2399999999982,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",394,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,5.984,2004.2239999999981,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",395,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.08,2010.303999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",396,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,2014.5599999999981,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.384,2018.9439999999981,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,2024.2239999999981,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,2028.6719999999982,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2032.0959999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.032,2036.127999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.32,2040.447999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",403,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.152,2045.599999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,2049.791999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",405,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2053.279999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",406,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.8,2058.079999999998,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.64,2062.719999999998,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",408,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.2,2077.919999999998,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",409,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,5.984,2083.9039999999977,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.776,2087.6799999999976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2091.1359999999977,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",412,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.472,2096.607999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",413,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,2099.775999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",414,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2103.167999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,2107.583999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",416,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.36,2110.943999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",417,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14016.0,8.416,2119.3599999999983,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,438.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",418,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.616,2122.9759999999983,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",419,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14144.0,8.576,2131.5519999999983,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,442.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",420,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.264,2134.8159999999984,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3360.0,8.544,2143.3599999999983,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,105.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2146.8799999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2150.3359999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",424,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,2155.5199999999986,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",425,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2158.6239999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2161.9519999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",427,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.384,2166.3359999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",428,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2169.7279999999982,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",429,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,6.208,2175.9359999999983,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",430,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6240.0,5.984,2181.9199999999983,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,195.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",431,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.176,2188.095999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,2192.5119999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,2196.7359999999985,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",434,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,2201.9839999999986,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,2206.4639999999986,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,2210.1759999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.064,2214.2399999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,2218.5919999999983,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",439,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.728,2224.3199999999983,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.128,2228.4479999999985,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,2231.9999999999986,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.608,2236.607999999999,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.512,2241.119999999999,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",444,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.168,2256.287999999999,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",445,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,6.112,2262.399999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2265.919999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",447,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.52,2269.439999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",448,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,2274.6239999999993,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",449,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,2277.9839999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",450,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2281.3119999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.608,2285.9199999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",452,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,2289.3759999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",453,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13984.0,8.576,2297.9519999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,437.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.616,2301.5679999999998,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",455,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14336.0,8.352,2309.9199999999996,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,448.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.36,2313.2799999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3168.0,8.512,2321.792,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,99.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2325.3759999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,2328.7039999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",460,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.28,2333.984,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",461,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2337.0879999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",462,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2340.448,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",463,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.384,2344.832,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",464,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,2348.288,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",465,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.984,2354.272,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",466,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.952,2360.224,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",467,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.92,2366.1440000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,2370.4,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.288,2374.688,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",470,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.216,2379.904,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.896,2384.8,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",472,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2388.224,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,2392.416,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.736,2397.152,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",475,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.088,2402.2400000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",476,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,2406.5600000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",477,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,2409.8880000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",478,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,2414.5920000000006,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.512,2419.1040000000007,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",480,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.2,2434.3040000000005,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",481,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.952,2440.2560000000008,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.36,2443.616000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,2447.0080000000007,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",484,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,2452.1280000000006,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",485,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2455.2640000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",486,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2458.6240000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.448,2463.0720000000006,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",488,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.616,2466.6880000000006,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",489,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14208.0,8.32,2475.0080000000007,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,444.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",490,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.584,2478.5920000000006,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",491,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13664.0,8.576,2487.1680000000006,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,427.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",492,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.264,2490.4320000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3360.0,8.544,2498.9760000000006,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,105.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.872,2502.8480000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,2506.2720000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",496,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,2511.4560000000006,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",497,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2514.5600000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2517.8880000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.192,2522.0800000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",500,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2525.6000000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",501,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.112,2531.7120000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",502,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.016,2537.7280000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",503,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,6.048,2543.7760000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",504,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,2548.1600000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,2552.512,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",506,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.12,2557.632,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,2562.112,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,2565.44,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,2569.824,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.576,2574.4,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",511,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,2579.744,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,2583.84,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",513,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.296,2587.136,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",514,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.64,2591.776,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.544,2596.3199999999997,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",516,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.36,2611.68,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",517,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.176,2617.8559999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2621.4399999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",519,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2624.9279999999994,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",520,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.28,2630.2079999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",521,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2633.3119999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",522,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2636.6399999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.512,2641.1519999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",524,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.68,2644.8319999999994,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",525,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14304.0,8.576,2653.4079999999994,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,447.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",526,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.712,2657.1199999999994,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",527,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13792.0,8.544,2665.6639999999993,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,431.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.52,2669.1839999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3360.0,8.416,2677.5999999999995,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,105.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2681.0879999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,2684.479999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",532,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,2689.631999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",533,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2692.767999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",534,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,2696.3199999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,2700.7359999999994,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",536,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,2704.1919999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",537,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.048,2710.2399999999993,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",538,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.048,2716.287999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",539,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,5.888,2722.175999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,2726.431999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.288,2730.719999999999,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",542,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.504,2736.223999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.864,2741.087999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",544,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2744.511999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.064,2748.5759999999987,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,2752.9279999999985,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",547,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,2758.1119999999987,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,2762.3039999999987,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",549,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2765.7279999999987,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",550,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.576,2770.3039999999987,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.672,2774.9759999999987,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",552,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.392,2790.3679999999986,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",553,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6176.0,5.92,2796.2879999999986,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,193.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2799.7759999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",555,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2803.2639999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",556,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.408,2808.671999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",557,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2811.9359999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",558,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2815.2959999999985,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",559,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,2819.7119999999986,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",560,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2823.2959999999985,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",561,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14336.0,8.352,2831.6479999999983,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,448.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",562,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.616,2835.2639999999983,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",563,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13952.0,8.448,2843.711999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,436.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",564,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.392,2847.103999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",565,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3232.0,8.608,2855.711999999998,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,101.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2859.231999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.648,2862.8799999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",568,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,2868.0639999999985,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",569,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2871.1679999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",570,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2874.4959999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.448,2878.943999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",572,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,2882.3999999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",573,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.048,2888.447999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",574,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,6.016,2894.463999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",575,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6368.0,6.112,2900.575999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,199.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",576,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,2904.8959999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,2909.1199999999985,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",578,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.216,2914.3359999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.576,2918.9119999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2922.3999999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,2926.5919999999983,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.48,2931.0719999999983,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",583,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.152,2936.2239999999983,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",584,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,2940.3199999999983,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",585,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.36,2943.6799999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",586,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.8,2948.4799999999987,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.576,2953.0559999999987,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",588,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.296,2968.3519999999985,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",589,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.984,2974.3359999999984,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2977.8239999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,2981.2799999999984,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",592,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.024,2986.3039999999983,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",593,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,2989.7279999999982,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2993.023999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.544,2997.567999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",596,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3001.087999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",597,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14304.0,8.384,3009.471999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,447.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",598,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.648,3013.119999999998,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",599,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13920.0,8.64,3021.759999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,435.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",600,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.456,3025.215999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",601,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3424.0,8.448,3033.663999999998,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,107.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,3037.119999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,3040.447999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",604,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,3045.599999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",605,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3048.735999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",606,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3052.095999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.48,3056.575999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",608,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,3060.0319999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",609,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,5.984,3066.0159999999983,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",610,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.208,3072.2239999999983,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",611,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6464.0,5.952,3078.1759999999986,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,202.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",612,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,3082.4319999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,3086.7839999999983,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,3092.1599999999985,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,3096.6399999999985,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,3100.0319999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,3104.2239999999983,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,3108.767999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",619,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.088,3113.8559999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,3117.9519999999984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",621,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,3121.2799999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",622,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,3125.9839999999986,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.832,3130.8159999999984,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",624,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.296,3146.1119999999983,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",625,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.92,3152.0319999999983,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3155.5519999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",627,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,3158.9759999999983,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",628,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.408,3164.383999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",629,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3167.519999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",630,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3170.8799999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",631,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.64,3175.519999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",632,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.616,3179.135999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",633,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14176.0,8.288,3187.423999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,443.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",634,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.584,3191.007999999998,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",635,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14496.0,8.48,3199.487999999998,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,453.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",636,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,3202.719999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",637,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3392.0,8.48,3211.199999999998,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,106.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,3214.751999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,3218.143999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",640,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,3223.263999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",641,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3226.399999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",642,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.648,3230.047999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.224,3234.271999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",644,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3237.695999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",645,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6560.0,6.048,3243.743999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,205.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",646,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6304.0,6.048,3249.7919999999976,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,197.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",647,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.08,3255.8719999999976,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,3260.3199999999974,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.32,3264.6399999999976,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",650,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,3269.8879999999976,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.544,3274.4319999999975,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",652,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3277.8559999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,3282.3359999999975,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,3286.8799999999974,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",655,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,3292.0639999999976,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",656,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,3296.3199999999974,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",657,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,3299.8079999999973,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",658,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.576,3304.3839999999973,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.576,3308.9599999999973,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",660,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.2,3324.159999999997,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",661,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.016,3330.175999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3333.695999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,3337.183999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",664,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,3342.303999999997,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",665,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3345.4079999999967,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",666,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,3348.9279999999967,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",667,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.352,3353.2799999999966,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",668,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,3356.8319999999967,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",669,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14144.0,8.704,3365.535999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,442.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.648,3369.183999999997,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",671,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13632.0,8.544,3377.727999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,426.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",672,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3381.087999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",673,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3264.0,8.288,3389.375999999997,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,102.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,3392.863999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,3396.2559999999967,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",676,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.376,3401.631999999997,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",677,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3404.703999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",678,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3408.031999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.352,3412.383999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",680,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.648,3416.031999999997,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",681,25088000.0,53728000.0,1024000.0,0,0.0,54752000.0,54752000.0,1024000.0,880000.0,0.5378151260504201,98974720.0,179776.0,37.44,3453.471999999997,1504000.0,3072000.0,24576000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3092960.0,5618.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3456.287999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.544,3460.8319999999967,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3464.1599999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",685,128.0,32768.0,256.0,0,0.0,33024.0,33024.0,0.0,512.0,0.0,128000.0,128000.0,3.36,3467.519999999997,0.0,32768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,4000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",686,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.136,3470.6559999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8256.0,5.568,3476.223999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,258.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,6.432,3482.6559999999968,0.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,5.696,3488.3519999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,2112.0,8802.0,0.19351291918636612,527360.0,0.0,6.4,3494.7519999999968,0.0,0.0,0.0,9216.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,5.376,3500.127999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,2112.0,8610.0,0.1969781757134863,527360.0,0.0,6.752,3506.879999999997,0.0,0.0,0.0,15360.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,512.0,1512.0,0.25296442687747034,129024.0,8192.0,5.632,3512.511999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4032.0,256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",694,13312.0,0.0,26624.0,0,0.0,26624.0,26624.0,2112.0,8674.0,0.19580938253291302,527360.0,32.0,6.208,3518.719999999997,0.0,0.0,0.0,13312.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16480.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,1056.0,128.0,3.904,3522.623999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33.0,4.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,3525.535999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,11.0,0.9831029185867896,128.0,0.0,5.92,3531.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,3534.495999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,11.0,0.9831029185867896,128.0,0.0,5.472,3539.967999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",700,8193.0,0.0,16386.0,0,0.0,16386.0,16386.0,7298.0,2106.0,0.7760527435133986,131808.0,1728.0,8.096,3548.063999999997,0.0,0.0,0.0,8193.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4119.0,54.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.672,3556.735999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",702,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,3000.0,0.0,130016.0,9536.0,5.888,3562.623999999997,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4063.0,298.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,4.0,3566.623999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5000.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",704,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,1000.0,0.0,0.0,256000.0,3.488,3570.111999999997,0.0,0.0,0.0,32000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,1000.0,0.9926561306621232,128000.0,0.0,5.664,3575.775999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.68,3579.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,10422.0,4248.0,0.7104294478527607,407552.0,320672.0,13.696,3593.151999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12736.0,10021.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,3426.0,4248.0,0.4464425332290852,407552.0,390144.0,11.552,3604.703999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12736.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,4806.0,4226.0,0.5321080602302923,405504.0,390144.0,13.088,3617.791999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12672.0,12192.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,4806.0,4224.0,0.5322259136212625,405504.0,351680.0,14.144,3631.935999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,12672.0,10990.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",711,498638.0,1061280.0,101276.0,0,0.0,1162556.0,1162556.0,132.0,1312.0,0.09141274238227147,128000.0,128000.0,22.88,3654.815999999997,133280.0,32000.0,448000.0,50638.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,4000.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",712,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,0.0,416.0,3.008,3657.823999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,13.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",713,15.0,84347.0,30.0,0,0.0,84377.0,84377.0,4417.0,2071.0,0.6807953144266338,138112.0,129024.0,5.248,3663.071999999997,84347.0,0.0,0.0,15.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4316.0,4032.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,512.0,0.0,128000.0,31808.0,3.584,3666.6559999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,994.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3669.5039999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,36096.0,0.0,72192.0,0,0.0,72192.0,72192.0,0.0,3000.0,0.0,288000.0,13536.0,11.168,3680.671999999997,0.0,0.0,0.0,36096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9000.0,423.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,768.0,0.0,160000.0,0.0,3.776,3684.4479999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",718,498641.0,1061280.0,101282.0,0,0.0,1162562.0,1162562.0,132.0,1312.0,0.09141274238227147,128384.0,128000.0,22.848,3707.2959999999966,133280.0,32000.0,448000.0,50641.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4012.0,4000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",719,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,11.296,3718.5919999999965,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,3721.9839999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",721,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,251.0,0.19808306709265175,128000.0,32.0,11.936,3733.9199999999964,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,3737.2479999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3740.6399999999962,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,3745.183999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",725,1024.0,36576.0,2048.0,0,0.0,38624.0,38624.0,62.0,251.0,0.19808306709265175,128000.0,32.0,11.936,3757.1199999999963,36576.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3760.351999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,3763.775999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,3768.255999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",729,352000.0,640000.0,128000.0,0,0.0,768000.0,768000.0,0.0,1000.0,0.0,0.0,128000.0,3.872,3772.127999999996,0.0,64000.0,288000.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",730,200145.0,320000.0,80290.0,0,0.0,400290.0,400290.0,0.0,768.0,0.0,256000.0,0.0,5.088,3777.2159999999963,0.0,0.0,160000.0,40145.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",731,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,124.0,251.0,0.33066666666666666,128000.0,32.0,16.896,3794.1119999999964,0.0,0.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4000.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,3797.4399999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",733,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3800.8959999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,3804.2559999999967,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3807.6479999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",736,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.384,3812.0319999999965,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,3814.7519999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3817.5999999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,3821.279999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3824.127999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,3827.487999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",742,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,3830.8479999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3834.1119999999964,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",744,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,3838.0799999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,3843.103999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,3846.7519999999963,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
