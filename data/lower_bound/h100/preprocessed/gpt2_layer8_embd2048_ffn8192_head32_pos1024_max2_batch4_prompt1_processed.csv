Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.528,5.311999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,7.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.136,11.104,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,14.591999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.68,18.272,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.128,22.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.088,27.488,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,30.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,33.728,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,36.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.2,39.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.744,43.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,46.528000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,50.016000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.968,53.98400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,57.12000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,60.54400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.328,63.872000000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,8704.0,32768.0,5.536,69.40800000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,272.0,1024.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",21,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,8704.0,32768.0,5.632,75.04000000000002,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,272.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",22,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,78.62400000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,82.01600000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",24,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.96,86.97600000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",25,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.896,95.87200000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",26,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.656,142.52800000000002,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.736,147.264,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",28,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,151.64800000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",29,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.544,156.19200000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",30,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,14.176,170.36800000000002,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",31,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.296,213.66400000000002,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",32,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.808,217.472,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",33,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.864,226.336,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.464,272.8,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",35,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.552,276.35200000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",36,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.456,279.80800000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",37,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.328,283.136,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",38,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,286.656,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",39,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.488,290.144,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",40,191212.0,472536.0,16384.0,0,0.0,488920.0,488920.0,0.0,512.0,0.0,131072.0,131072.0,3.52,293.664,32768.0,73728.0,183020.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",41,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.552,297.216,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",42,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.296,300.512,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",43,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42752.0,3.008,303.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",44,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,850696.0,0.759706143552174,72430080.0,1064096.0,95.584,399.104,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2263440.0,33253.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",45,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.48,403.584,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,407.104,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",47,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.768,415.87199999999996,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",48,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.336,462.20799999999997,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.416,466.62399999999997,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.32,470.94399999999996,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",51,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,475.328,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",52,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.736,488.06399999999996,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",53,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,42.688,530.752,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",54,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,534.304,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",55,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,543.1039999999999,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.56,589.664,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",57,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.328,592.992,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",58,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.552,596.544,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",59,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,599.936,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,603.392,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",61,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.296,606.6880000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",62,191384.0,472880.0,16384.0,0,0.0,489264.0,489264.0,0.0,512.0,0.0,131072.0,131072.0,3.712,610.4000000000001,32768.0,73728.0,183192.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.488,613.8880000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",64,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,617.3440000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",65,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42624.0,2.912,620.2560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1332.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",66,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,846866.0,0.7605289217685094,72547296.0,1064352.0,94.656,714.9120000000003,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2267103.0,33261.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",67,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.16,719.0720000000002,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",68,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,722.4640000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",69,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.768,731.2320000000003,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.464,777.6960000000004,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.416,782.1120000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.416,786.5280000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.32,790.8480000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",74,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.928,803.7760000000005,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",75,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.232,847.0080000000005,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",76,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,850.3360000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",77,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.96,859.2960000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",78,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.656,905.9520000000005,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",79,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,909.3440000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",80,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.264,912.6080000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",81,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,916.0320000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,919.4560000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",83,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,922.8800000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",84,191248.0,472608.0,16384.0,0,0.0,488992.0,488992.0,0.0,512.0,0.0,131072.0,131072.0,3.36,926.2400000000005,32768.0,73728.0,183056.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.488,929.7280000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",86,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.52,933.2480000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",87,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,45056.0,3.04,936.2880000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1408.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",88,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,862397.0,0.757203472024951,72500160.0,1064160.0,94.496,1030.7840000000006,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2265630.0,33255.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",89,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.448,1035.2320000000007,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,1038.6880000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",91,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.544,1047.2320000000007,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,47.104,1094.3360000000007,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",93,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.64,1098.9760000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",94,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.32,1103.2960000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.576,1107.8720000000008,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",96,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.768,1120.6400000000008,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",97,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.52,1164.1600000000008,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,1167.6480000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",99,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.832,1176.480000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",100,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.752,1223.2320000000009,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",101,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.456,1226.6880000000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",102,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.52,1230.2080000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",103,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.616,1233.8240000000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.456,1237.2800000000007,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",105,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,1240.6720000000007,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",106,191448.0,473008.0,16384.0,0,0.0,489392.0,489392.0,0.0,512.0,0.0,131072.0,131072.0,3.584,1244.2560000000008,32768.0,73728.0,183256.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",107,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.424,1247.6800000000007,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",108,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.264,1250.9440000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",109,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42752.0,2.976,1253.9200000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",110,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,876520.0,0.7542046451317647,72445824.0,1064192.0,94.624,1348.5440000000008,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2263932.0,33256.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",111,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.256,1352.8000000000009,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1356.192000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",113,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.832,1365.024000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",114,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.016,1411.040000000001,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,1415.4240000000011,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.416,1419.840000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.736,1424.5760000000012,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",118,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.96,1437.5360000000012,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",119,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,42.4,1479.9360000000013,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",120,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,1483.3600000000013,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",121,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.736,1492.0960000000014,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",122,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.496,1538.5920000000015,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",123,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.232,1541.8240000000014,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",124,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.264,1545.0880000000013,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",125,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.488,1548.5760000000014,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",126,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,1552.0960000000014,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",127,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.296,1555.3920000000014,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,190884.0,471880.0,16384.0,0,0.0,488264.0,488264.0,0.0,512.0,0.0,131072.0,131072.0,3.68,1559.0720000000015,32768.0,73728.0,182692.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",129,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.328,1562.4000000000015,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",130,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.456,1565.8560000000014,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",131,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,43008.0,2.944,1568.8000000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1344.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",132,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,887067.0,0.7519805804558124,72555840.0,1064256.0,93.664,1662.4640000000013,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2267370.0,33258.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",133,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.224,1666.6880000000012,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,1670.0800000000013,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",135,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.896,1678.9760000000012,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,45.696,1724.6720000000012,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,1729.0560000000012,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.224,1733.280000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.416,1737.696000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",140,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.8,1750.496000000001,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.072,1793.5680000000011,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,1796.896000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",143,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.768,1805.6640000000011,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",144,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.432,1852.0960000000011,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",145,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,1855.4880000000012,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",146,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.296,1858.7840000000012,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",147,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,1862.1760000000013,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,1865.6000000000013,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",149,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.648,1869.2480000000012,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,191300.0,472712.0,16384.0,0,0.0,489096.0,489096.0,0.0,512.0,0.0,131072.0,131072.0,3.456,1872.704000000001,32768.0,73728.0,183108.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",151,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.456,1876.160000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",152,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.488,1879.648000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",153,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42752.0,2.912,1882.560000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",154,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,879412.0,0.7535934958985113,72544576.0,1064288.0,94.528,1977.088000000001,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2267018.0,33259.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",155,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.256,1981.3440000000012,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",156,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.36,1984.704000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",157,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,1993.504000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",158,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.976,2040.480000000001,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,2044.864000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",160,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.448,2049.312000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.672,2053.984000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",162,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,12.704,2066.688000000001,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",163,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.136,2109.824000000001,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",164,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,2113.056000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",165,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.832,2121.888000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",166,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.88,2168.768000000001,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",167,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,2172.192000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",168,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.392,2175.5840000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",169,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,2179.0080000000007,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",170,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.488,2182.4960000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",171,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.264,2185.7600000000007,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",172,190916.0,471944.0,16384.0,0,0.0,488328.0,488328.0,0.0,512.0,0.0,131072.0,131072.0,3.584,2189.3440000000005,32768.0,73728.0,182724.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",173,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.264,2192.6080000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",174,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.616,2196.2240000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",175,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,45568.0,3.04,2199.2640000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1424.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",176,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,860497.0,0.7576087320878425,72538624.0,1064256.0,92.992,2292.2560000000008,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2266832.0,33258.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",177,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.416,2296.672000000001,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",178,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2300.1600000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",179,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,9.12,2309.2800000000007,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.624,2355.9040000000005,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.512,2360.4160000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",182,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.32,2364.736000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.288,2369.024000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",184,262144.0,8708096.0,0.0,0,77309411328.0,8708096.0,77318119424.0,68096.0,128.0,0.99812382739212,98304.0,32768.0,13.024,2382.0480000000007,6586368.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,3072.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",185,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.008,2425.0560000000005,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",186,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2428.5440000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",187,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.992,2437.5360000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",188,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.752,2484.2880000000005,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",189,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.616,2487.9040000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",190,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.552,2491.4560000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",191,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.296,2494.7520000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,2498.1760000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",193,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.456,2501.6320000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,191352.0,472816.0,16384.0,0,0.0,489200.0,489200.0,0.0,512.0,0.0,131072.0,131072.0,3.424,2505.0560000000005,32768.0,73728.0,183160.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",195,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.424,2508.4800000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",196,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.424,2511.9040000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",197,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,43136.0,3.04,2514.9440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1348.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",198,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,849834.0,0.759891167072106,72559552.0,1064256.0,94.944,2609.8880000000004,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2267486.0,33258.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",199,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.16,2614.0480000000002,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",200,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.264,2617.3120000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",201,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.608,2625.9200000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,419746576.0,903829056.0,16082464.0,0,0.0,919911520.0,919911520.0,5654076.0,4925476.0,0.5344343503392204,453477376.0,1411360.0,181.664,2807.5840000000007,28948032.0,51470336.0,411705344.0,8041232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14171168.0,44105.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2810.368000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",204,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.84,2814.208000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",205,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,2817.344000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",206,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.808,2821.152000000001,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",207,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,2824.192000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",208,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54720.0,5.856,2830.048000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1710.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",209,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.128,2838.1760000000013,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",210,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55296.0,5.984,2844.160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1728.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",211,70400.0,0.0,140800.0,0,0.0,140800.0,140800.0,13200.0,83408.0,0.1366346472341835,5134848.0,0.0,8.064,2852.224000000001,0.0,0.0,0.0,70400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",212,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54464.0,6.048,2858.272000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1702.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",213,76800.0,0.0,153600.0,0,0.0,153600.0,153600.0,13200.0,83208.0,0.13691809808314662,5134848.0,0.0,8.448,2866.7200000000007,0.0,0.0,0.0,76800.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",214,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54080.0,5.92,2872.640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1690.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",215,70400.0,0.0,140800.0,0,0.0,140800.0,140800.0,13200.0,83408.0,0.1366346472341835,5134848.0,128.0,8.16,2880.8000000000006,0.0,0.0,0.0,70400.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",216,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.872,2884.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",217,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,2887.7440000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",218,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.6,2893.3440000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",219,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,2896.2240000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",220,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.92,2902.1440000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",221,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,33128.0,13012.0,0.717988729952319,831584.0,8736.0,8.576,2910.7200000000007,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,273.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,9.472,2920.192000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,69248.0,6.496,2926.688000000001,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2164.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",224,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.352,2931.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",225,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.096,2935.136000000001,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",226,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.176,2941.312000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",227,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,2944.8960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",228,0.0,0.0,0.0,0,0.0,0.0,0.0,65855.0,28345.0,0.6990976645435244,2741568.0,1972640.0,15.744,2960.640000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85674.0,61645.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",229,0.0,0.0,0.0,0,0.0,0.0,0.0,19826.0,28192.0,0.4128868341038777,2722112.0,1781824.0,12.576,2973.216000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85066.0,55682.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",230,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28227.0,0.3516698056869861,2723392.0,1547328.0,13.152,2986.368000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85106.0,48354.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",231,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28181.0,0.35204175480548144,2723136.0,1794176.0,12.832,2999.2000000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85098.0,56068.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",232,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,5.056,3004.2560000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",233,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.264,3007.520000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15246.0,0.49313474517104955,1870624.0,1336448.0,9.472,3016.992000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58457.0,41764.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",235,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429696.0,2412352.0,5.216,3022.208000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75928.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",236,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1052096.0,753152.0,32.064,3054.272000000001,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32878.0,23536.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",237,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804288.0,620992.0,98.496,3152.768000000001,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25134.0,19406.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",238,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.712,3156.480000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,3159.712000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,94944.0,11.424,3171.136000000001,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2967.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",241,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.096,3175.232000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",242,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1058720.0,752320.0,31.68,3206.9120000000007,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33085.0,23510.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",243,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.504,3216.4160000000006,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",244,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,3220.0640000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",245,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.664,3229.728000000001,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3232.992000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",247,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,3236.576000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",248,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.736,3241.312000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",249,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,15.488,3256.8000000000006,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",250,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3260.0000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",251,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.152,3265.1520000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,3268.7040000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",253,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,3273.312000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",254,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,6.016,3279.328000000001,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.408,3284.736000000001,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",256,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.656,3307.3920000000007,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",257,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,3310.6880000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",258,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,3313.8560000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",259,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.808,3317.6640000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",260,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3321.0560000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",261,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,3.84,3324.8960000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",262,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,3327.5840000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",263,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,3330.4000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",264,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,3333.8240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",265,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,3336.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",266,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.648,3340.3200000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",267,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.104,3347.4240000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,3350.8160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,3354.0800000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",270,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.808,3357.8880000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.248,3363.1360000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",272,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,3366.2400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3369.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",274,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.992,3374.5280000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",275,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.84,3378.3680000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",276,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.072,3381.4400000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",277,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,3384.7360000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",278,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.2,3387.936,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.328,3391.264,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",280,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,33280.0,32768.0,7.808,3399.072,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1040.0,1024.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",281,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,768.0,0.0,8704.0,32768.0,5.376,3404.4480000000003,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,272.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,3407.9040000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",283,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.264,3411.1680000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",284,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.864,3416.0320000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",285,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.832,3424.8640000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,45.856,3470.7200000000007,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",287,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.856,3476.576000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",288,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.92,3482.496000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.384,3486.880000000001,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",290,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,14.208,3501.088000000001,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",291,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.808,3544.896000000001,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,3548.128000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",293,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.64,3556.768000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",294,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.784,3603.552000000001,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",295,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.264,3606.816000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",296,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.488,3610.304000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",297,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.328,3613.632000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.584,3617.216000000001,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",299,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.52,3620.736000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",300,191348.0,472808.0,16384.0,0,0.0,489192.0,489192.0,0.0,512.0,0.0,131072.0,131072.0,3.392,3624.1280000000006,32768.0,73728.0,183156.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.264,3627.3920000000007,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",302,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.744,3631.136000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",303,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42880.0,2.912,3634.0480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1340.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",304,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,869496.0,0.7556931210508925,72595072.0,1064224.0,96.672,3730.7200000000007,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2268596.0,33257.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",305,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.384,3735.1040000000007,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",306,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.552,3738.656000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",307,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.64,3747.2960000000007,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.656,3793.9520000000007,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",309,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.464,3800.4160000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.08,3806.4960000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.32,3810.8160000000007,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",312,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,12.896,3823.712000000001,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",313,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,42.912,3866.6240000000007,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",314,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.584,3870.2080000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",315,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.704,3878.9120000000007,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",316,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,45.792,3924.7040000000006,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",317,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.36,3928.0640000000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",318,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.264,3931.328000000001,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",319,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.488,3934.8160000000007,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",320,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.296,3938.1120000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",321,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.328,3941.4400000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",322,191154.0,472420.0,16384.0,0,0.0,488804.0,488804.0,0.0,512.0,0.0,131072.0,131072.0,3.584,3945.0240000000003,32768.0,73728.0,182962.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",323,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.36,3948.3840000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",324,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.552,3951.9360000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42752.0,2.976,3954.9120000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",326,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,860956.0,0.7575107900538854,72447392.0,1064320.0,94.176,4049.0880000000006,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2263981.0,33260.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",327,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.32,4053.408000000001,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",328,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.264,4056.672000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",329,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.928,4065.600000000001,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",330,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,45.888,4111.488000000001,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",331,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.792,4117.280000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",332,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.792,4123.072000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",333,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.256,4127.328000000002,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",334,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,13.088,4140.416000000002,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",335,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.136,4183.552000000002,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",336,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.296,4186.848000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",337,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.928,4195.776000000003,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",338,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.528,4242.304000000003,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",339,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.616,4245.920000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",340,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.392,4249.312000000003,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",341,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,4252.736000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",342,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.52,4256.256000000003,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",343,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.296,4259.552000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,191258.0,472628.0,16384.0,0,0.0,489012.0,489012.0,0.0,512.0,0.0,131072.0,131072.0,3.488,4263.040000000004,32768.0,73728.0,183066.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",345,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.328,4266.368000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",346,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.392,4269.760000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,43520.0,2.944,4272.704000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1360.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",348,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,886654.0,0.7520674237107089,72541824.0,1064256.0,96.736,4369.440000000004,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2266932.0,33258.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",349,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.064,4373.504000000004,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",350,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4376.896000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",351,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.992,4385.8880000000045,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",352,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.752,4432.640000000005,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",353,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.208,4438.8480000000045,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",354,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.24,4445.088000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",355,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.864,4449.952000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",356,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,12.992,4462.944000000004,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",357,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.04,4505.984000000004,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",358,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.488,4509.472000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",359,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,4518.2720000000045,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",360,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,47.168,4565.440000000004,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",361,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.488,4568.928000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",362,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.456,4572.384000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",363,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,4575.8080000000045,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",364,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.424,4579.2320000000045,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.36,4582.592000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,191039.0,472190.0,16384.0,0,0.0,488574.0,488574.0,0.0,512.0,0.0,131072.0,131072.0,3.456,4586.048000000004,32768.0,73728.0,182847.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",367,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.328,4589.376000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",368,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.488,4592.864000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,43904.0,3.008,4595.872000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1372.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",370,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,838465.0,0.762339919971678,72668896.0,1064128.0,97.024,4692.896000000005,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2270903.0,33254.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",371,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.352,4697.248000000005,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",372,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,4700.5760000000055,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",373,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.896,4709.472000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",374,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,47.136,4756.608000000006,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",375,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.696,4762.3040000000055,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.856,4768.160000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.48,4772.640000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",378,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,12.96,4785.600000000005,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",379,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,42.56,4828.160000000005,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",380,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,4831.360000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",381,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,9.056,4840.416000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",382,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,47.296,4887.712000000005,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.552,4891.264000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",384,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.328,4894.592000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",385,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.584,4898.176000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",386,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.552,4901.728000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",387,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.456,4905.184000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,191072.0,472256.0,16384.0,0,0.0,488640.0,488640.0,0.0,512.0,0.0,131072.0,131072.0,3.776,4908.960000000005,32768.0,73728.0,182880.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",389,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.232,4912.192000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",390,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.488,4915.680000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42112.0,2.912,4918.592000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1316.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",392,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,870676.0,0.7554426534150214,72455264.0,1064224.0,95.264,5013.856000000005,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2264227.0,33257.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",393,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.192,5018.048000000005,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",394,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.456,5021.504000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",395,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.768,5030.272000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",396,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.656,5076.928000000005,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",397,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.336,5083.264000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",398,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.208,5089.472000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.224,5093.696000000005,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",400,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,12.864,5106.560000000005,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",401,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.36,5149.920000000005,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",402,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5153.344000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",403,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,5162.144000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.208,5208.352000000004,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",405,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.52,5211.872000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",406,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.36,5215.2320000000045,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",407,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.488,5218.720000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.616,5222.336000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",409,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.456,5225.792000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",410,191207.0,472526.0,16384.0,0,0.0,488910.0,488910.0,0.0,512.0,0.0,131072.0,131072.0,3.584,5229.376000000005,32768.0,73728.0,183015.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.424,5232.800000000005,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",412,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.392,5236.192000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",413,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42624.0,2.976,5239.168000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1332.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",414,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,867544.0,0.7561078187727012,72529504.0,1064000.0,94.496,5333.664000000004,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2266547.0,33250.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",415,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.096,5337.760000000004,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",416,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.424,5341.184000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",417,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,5349.984000000004,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.4,5396.384000000004,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",419,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.6,5401.984000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,5.696,5407.680000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.224,5411.904000000004,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",422,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,12.896,5424.800000000004,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",423,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,42.912,5467.712000000004,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",424,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.232,5470.944000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",425,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.896,5479.840000000004,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,47.136,5526.976000000004,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",427,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.52,5530.496000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",428,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.424,5533.920000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",429,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,5537.344000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",430,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.36,5540.704000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",431,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,5544.128000000004,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,190825.0,471762.0,16384.0,0,0.0,488146.0,488146.0,0.0,512.0,0.0,131072.0,131072.0,3.584,5547.712000000004,32768.0,73728.0,182633.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",433,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.456,5551.168000000004,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",434,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.52,5554.688000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",435,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,42752.0,2.944,5557.632000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1336.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",436,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,888321.0,0.7517170194337001,72526080.0,1064256.0,96.128,5653.760000000005,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2266440.0,33258.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",437,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.096,5657.856000000004,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.52,5661.376000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",439,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.8,5670.176000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,50552832.0,101941248.0,442368.0,0,0.0,102383616.0,102383616.0,446208.0,419328.0,0.515527950310559,53501952.0,98304.0,46.368,5716.544000000005,491520.0,786432.0,50331648.0,221184.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1671936.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.336,5722.880000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,6.272,5729.1520000000055,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,8192.0,0.0,16384.0,0,0.0,16384.0,16384.0,0.0,512.0,0.0,32768.0,32768.0,4.448,5733.600000000006,0.0,0.0,0.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 64, 64, 1, 1>::Params)",444,262144.0,8716288.0,0.0,0,77309411328.0,8716288.0,77318127616.0,68096.0,128.0,0.99812382739212,163840.0,32768.0,13.088,5746.688000000006,6594560.0,1597440.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,301989888.0,5120.0,1024.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",445,16850944.0,33980416.0,147456.0,0,0.0,34127872.0,34127872.0,148736.0,139776.0,0.515527950310559,17833984.0,32768.0,43.264,5789.952000000006,163840.0,262144.0,16777216.0,73728.0,0,0,0,0,0,0,0,0.0,0.0,0.0,557312.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.328,5793.280000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",447,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.704,5801.984000000006,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_NN_kernel<float, 256, 4, 2, 8, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",448,67403776.0,135921664.0,589824.0,0,0.0,136511488.0,136511488.0,594944.0,559104.0,0.515527950310559,71335936.0,131072.0,46.272,5848.256000000006,655360.0,1048576.0,67108864.0,294912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2229248.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",449,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.424,5851.680000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 2)], std::array<char *, 2>>(int, T2, T3)",450,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.456,5855.136000000006,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",451,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.36,5858.496000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,768.0,0.0,262144.0,131072.0,3.328,5861.824000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",453,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,131072.0,131072.0,3.392,5865.216000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::tanh_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",454,191229.0,472570.0,16384.0,0,0.0,488954.0,488954.0,0.0,512.0,0.0,131072.0,131072.0,3.488,5868.704000000006,32768.0,73728.0,183037.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",455,32768.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,512.0,0.0,131072.0,131072.0,3.232,5871.936000000006,0.0,0.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",456,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,3.552,5875.488000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,4096.0
"void scal_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",457,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2048.0,0.0,0.0,44032.0,3.04,5878.528000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1376.0
"void sgemm_largek_lds64<0, 0, 6, 3, 4, 5, 2, 64>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",458,134742528.0,269221888.0,525312.0,0,0.0,269747200.0,269747200.0,2689536.0,883642.0,0.7527013767576091,72552800.0,1064320.0,95.328,5973.856000000006,0.0,262144.0,134479872.0,262656.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2267275.0,33260.0
"void cublasLt::globalKernel<8, 32, float, float, float, 1, 1, 1>(int, int, long, T3 *, cublasLtEpilogue_t, int, T4 *, long, void *, long, long, long, T5 *, long, int *)",459,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,2560.0,0.0,40960.0,0.0,4.16,5978.016000000006,8192.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1280.0,0.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,3.2,5981.216000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
"void native::<unnamed>::vectorized_layer_norm_kernel<float, float>(int, T2, const T1 *, const T1 *, const T1 *, T2 *, T2 *, T1 *)",461,55364.0,175348.0,8192.0,0,0.0,183540.0,183540.0,80.0,712.0,0.10101010101010101,98304.0,33024.0,8.864,5990.080000000005,51760.0,21052.0,51268.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1032.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,419746576.0,903829056.0,16082464.0,0,0.0,919911520.0,919911520.0,5654076.0,4925476.0,0.5344343503392204,453351936.0,1413344.0,183.232,6173.312000000005,28948032.0,51470336.0,411705344.0,8041232.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14167248.0,44167.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",463,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,6176.0000000000055,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",464,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,6179.872000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",465,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6183.200000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",466,128.0,201728.0,256.0,0,0.0,201984.0,201984.0,0.0,3158.0,0.0,804128.0,804128.0,3.616,6186.816000000006,0.0,201728.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,25129.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",467,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.072,6189.888000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",468,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54144.0,5.76,6195.6480000000065,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1692.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",469,96000.0,0.0,192000.0,0,0.0,192000.0,192000.0,13200.0,82608.0,0.1377755511022044,5134848.0,0.0,8.064,6203.712000000007,0.0,0.0,0.0,96000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",470,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,55936.0,5.888,6209.600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1748.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",471,75200.0,0.0,150400.0,0,0.0,150400.0,150400.0,13200.0,83258.0,0.13684712517365072,5134848.0,0.0,8.384,6217.984000000007,0.0,0.0,0.0,75200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,54336.0,5.824,6223.808000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1698.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",473,73600.0,0.0,147200.0,0,0.0,147200.0,147200.0,13200.0,83308.0,0.13677622580511462,5134848.0,0.0,8.032,6231.8400000000065,0.0,0.0,0.0,73600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",474,0.0,0.0,0.0,0,0.0,0.0,0.0,3200.0,9484.0,0.2522863450015768,813152.0,53888.0,5.76,6237.600000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25411.0,1684.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",475,72000.0,0.0,144000.0,0,0.0,144000.0,144000.0,13200.0,83358.0,0.1367053998632946,5134848.0,128.0,8.0,6245.600000000007,0.0,0.0,0.0,72000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160464.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",476,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,21.0,0.0,6432.0,800.0,3.84,6249.440000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,201.0,25.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",477,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.296,6252.736000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",478,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.632,6258.368000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",479,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,6261.312000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",480,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,23.0,0.9653092006033183,800.0,0.0,5.92,6267.232000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",481,51200.0,0.0,102400.0,0,0.0,102400.0,102400.0,51578.0,13012.0,0.7985446663570213,831584.0,8512.0,8.928,6276.160000000007,0.0,0.0,0.0,51200.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25987.0,266.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",482,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.384,6284.544000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,816544.0,69216.0,6.08,6290.624000000007,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25517.0,2163.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,3.968,6294.592000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",485,201028.0,0.0,402056.0,0,0.0,402056.0,402056.0,0.0,6283.0,0.0,0.0,1608224.0,4.032,6298.624000000007,0.0,0.0,0.0,201028.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,50257.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",486,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,6283.0,0.9555817915744674,804128.0,0.0,6.144,6304.768000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",487,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.616,6308.384000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",488,0.0,0.0,0.0,0,0.0,0.0,0.0,64451.0,28146.0,0.6960376686069744,2720832.0,1974816.0,15.232,6323.616000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85026.0,61713.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",489,0.0,0.0,0.0,0,0.0,0.0,0.0,14210.0,28347.0,0.33390511549216345,2736192.0,2451264.0,11.744,6335.360000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85506.0,76602.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",490,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28184.0,0.35201747327279,2719424.0,2269216.0,12.832,6348.192000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,84982.0,70913.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",491,0.0,0.0,0.0,0,0.0,0.0,0.0,15311.0,28275.0,0.35128252191070525,2730688.0,2427040.0,13.024,6361.216000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85334.0,75845.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",492,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,6283.0,0.7017610480846822,1608224.0,0.0,4.864,6366.080000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50257.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",493,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,6369.504000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",494,0.0,0.0,0.0,0,0.0,0.0,0.0,14833.0,15191.0,0.4940381028510525,1865632.0,1337536.0,9.344,6378.848000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,58301.0,41798.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",495,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,25132.0,0.0,2429120.0,2412352.0,5.184,6384.032000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75910.0,75386.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",496,3122040.0,6655044.0,615296.0,0,0.0,7270340.0,7270340.0,528.0,6704.0,0.07300884955752213,1067936.0,752960.0,32.064,6416.096000000008,825232.0,201028.0,2814392.0,307648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33373.0,23530.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",497,0.0,1024200.0,0.0,0,0.0,1024200.0,1024200.0,112284.0,12568.0,0.8993368147887099,804224.0,614400.0,98.016,6514.112000000007,1024200.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,19200.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",498,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3158.0,0.0,804128.0,200800.0,3.616,6517.728000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25129.0,6275.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,6520.960000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,402056.0,0.0,804112.0,0,0.0,804112.0,804112.0,0.0,18849.0,0.0,1809280.0,90048.0,11.616,6532.576000000007,0.0,0.0,0.0,402056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56540.0,2814.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",501,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4737.0,0.0,1005184.0,0.0,4.224,6536.8000000000075,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,31412.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",502,3122052.0,6655044.0,615320.0,0,0.0,7270364.0,7270364.0,528.0,6704.0,0.07300884955752213,1046848.0,752768.0,31.904,6568.704000000008,825232.0,201028.0,2814392.0,307660.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32714.0,23524.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",503,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.44,6578.1440000000075,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6581.472000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",505,38912.0,0.0,77824.0,0,0.0,77824.0,77824.0,2037.0,1598.0,0.560385144429161,804256.0,832.0,9.504,6590.976000000008,0.0,0.0,0.0,38912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25133.0,26.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",506,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6594.3360000000075,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",507,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,6597.824000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,6602.432000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",509,4096.0,220484.0,8192.0,0,0.0,228676.0,228676.0,320.0,1582.0,0.16824395373291273,804224.0,128.0,16.032,6618.464000000008,220484.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",510,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6621.792000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",511,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,6627.040000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,6630.304000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",513,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,6634.752000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",514,2213376.0,4023944.0,804864.0,0,0.0,4828808.0,4828808.0,0.0,6283.0,0.0,0.0,804128.0,5.984,6640.736000000009,0.0,402056.0,1810944.0,402432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,25129.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",515,1256412.0,2010280.0,502544.0,0,0.0,2512824.0,2512824.0,0.0,4737.0,0.0,1608256.0,0.0,5.376,6646.112000000009,0.0,0.0,1005140.0,251272.0,0,0,0,0,0,0,0,0.0,0.0,0.0,50258.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",516,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1582.0,0.28802880288028804,804224.0,128.0,22.528,6668.640000000009,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25132.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",517,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,6671.93600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",518,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,6675.3280000000095,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.776,6679.104000000009,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,6682.40000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,6686.24000000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",522,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,6689.024000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",523,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,6691.840000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",524,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,6695.16800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",525,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,6697.92000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.936,6701.85600000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",527,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.976,6708.832000000009,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",528,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,6712.16000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6715.48800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",530,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.84,6719.32800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",531,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.736,6724.06400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,6727.360000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
