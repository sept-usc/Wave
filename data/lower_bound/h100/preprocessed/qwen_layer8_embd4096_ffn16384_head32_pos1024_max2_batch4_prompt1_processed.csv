Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002816,0.002816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002592,0.005408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003936,0.009344,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004384,0.013728,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.004928,0.018656,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003456,0.022112,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002656,0.024768,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002944,0.027711999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003136,0.030847999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003808,0.034656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,0.037952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00384,0.041792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.003904,0.045696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,0.048864,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003424,0.052288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,0.00384,0.056128000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,17408.0,65536.0,0.006016,0.062144000000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003456,0.0656,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005536,0.071136,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003616,0.074752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003456,0.078208,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.004576,0.082784,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004384,0.087168,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003424,0.09059199999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,0.004352,0.09494399999999999,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003552,0.09849599999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,0.10207999999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008608,0.110688,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003136,0.113824,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003392,0.117216,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004768,0.121984,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,0.12639999999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75842048.0,83968.0,0.038368,0.16476799999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370064.0,2624.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75796864.0,87808.0,0.035712,0.20047999999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368652.0,2744.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75842304.0,85120.0,0.03648,0.23695999999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370072.0,2660.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004864,0.24182399999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004608,0.24643199999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006336,0.25276799999999994,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,0.2574079999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,0.26092799999999994,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,0.26566399999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004512,0.27017599999999997,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006272,0.27644799999999997,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,0.281248,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003648,0.284896,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015808,0.30070399999999997,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75773184.0,96768.0,0.03824,0.33894399999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367912.0,3024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,0.342336,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00336,0.34569599999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008768,0.35446399999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,0.35772799999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,0.36102399999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,0.36556799999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004768,0.37033599999999994,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298184064.0,377312.0,0.134016,0.5043519999999999,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9318252.0,11791.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00384,0.5081919999999999,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298355968.0,370560.0,0.136832,0.6450239999999998,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9323624.0,11580.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.00352,0.6485439999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303283584.0,99680.0,0.122144,0.7706879999999998,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9477612.0,3115.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,0.7742399999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,0.7776959999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,0.7862719999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,0.7894719999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,0.7926719999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,0.7972479999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004704,0.8019519999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75831296.0,85216.0,0.036384,0.8383359999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369728.0,2663.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75810304.0,85312.0,0.036672,0.8750079999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369072.0,2666.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75805312.0,85728.0,0.036224,0.9112319999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368916.0,2679.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,0.9159039999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,0.920288,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,0.92624,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,0.9309759999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003616,0.9345919999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,0.9393599999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,0.9436799999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006112,0.9497919999999999,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,0.9546239999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,0.9580159999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015936,0.9739519999999997,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75769984.0,95488.0,0.036992,1.0109439999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367812.0,2984.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,1.0143679999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003648,1.0180159999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00816,1.0261759999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,1.0292799999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,1.0325759999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004608,1.0371839999999997,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,1.0418239999999996,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297781632.0,376032.0,0.134432,1.1762559999999995,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9305676.0,11751.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.004384,1.1806399999999995,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297178880.0,378112.0,0.134592,1.3152319999999995,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9286840.0,11816.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003488,1.3187199999999994,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303206400.0,99296.0,0.121664,1.4403839999999994,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9475200.0,3103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,1.4438399999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,1.4471039999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008288,1.4553919999999994,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,1.4585599999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.00336,1.4619199999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,1.4664959999999994,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,1.4711359999999993,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75790464.0,81248.0,0.037536,1.5086719999999993,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368452.0,2539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75805824.0,83232.0,0.036224,1.5448959999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368932.0,2601.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75810816.0,85856.0,0.036032,1.5809279999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369088.0,2683.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,1.5855359999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,1.5898239999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006016,1.5958399999999995,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,1.6006399999999994,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,1.6040639999999995,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,1.6086079999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,1.6129919999999995,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,1.6189439999999995,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,1.6234559999999996,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,1.6268479999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015968,1.6428159999999996,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75779840.0,92768.0,0.037728,1.6805439999999996,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368120.0,2899.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,1.6840959999999996,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,1.6873599999999995,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,1.6958079999999995,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,1.6990079999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,1.7022399999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004864,1.7071039999999995,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004704,1.7118079999999996,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298006144.0,371040.0,0.139904,1.8517119999999996,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9312692.0,11595.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00384,1.8555519999999996,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297923968.0,380192.0,0.134848,1.9903999999999997,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9310124.0,11881.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003424,1.9938239999999998,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303191296.0,95520.0,0.130176,2.1239999999999997,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474728.0,2985.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.0032,2.1271999999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,2.130464,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008832,2.139296,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003296,2.142592,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,2.145856,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,2.1504320000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,2.1550720000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75820928.0,81792.0,0.03536,2.1904320000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369404.0,2556.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75825792.0,82720.0,0.036352,2.2267840000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369556.0,2585.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75852672.0,83680.0,0.036128,2.2629120000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370396.0,2615.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004864,2.2677760000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,2.2722240000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00576,2.2779840000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,2.2825280000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,2.2860160000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,2.2907200000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004576,2.2952960000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.0056,2.3008960000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,2.305632,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,2.309184,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.016096,2.3252800000000002,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75776512.0,94464.0,0.03552,2.3608000000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368016.0,2952.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,2.364224,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,2.3674880000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008192,2.3756800000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003136,2.3788160000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,2.3821440000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004672,2.3868160000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,2.3914560000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297917056.0,373888.0,0.13728,2.5287360000000008,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309908.0,11684.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003776,2.5325120000000005,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297828736.0,379584.0,0.135392,2.6679040000000005,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9307148.0,11862.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003552,2.6714560000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303122176.0,95744.0,0.13136,2.8028160000000004,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9472568.0,2992.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,2.8063360000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00352,2.8098560000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008192,2.8180480000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003104,2.8211520000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003328,2.8244800000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004672,2.8291520000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,2.8336960000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75815680.0,84480.0,0.036704,2.8704000000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369240.0,2640.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75849856.0,84736.0,0.037408,2.9078080000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370308.0,2648.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75831552.0,82592.0,0.036384,2.9441920000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369736.0,2581.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,2.9489600000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,2.9534400000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00544,2.9588800000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,2.9635840000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,2.9669440000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,2.971776,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,2.976224,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005664,2.981888,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,2.9864960000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,2.98992,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.01584,3.00576,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75771392.0,96672.0,0.036256,3.042016,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367856.0,3021.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,3.0454079999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003488,3.0488959999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,3.0574399999999997,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,3.060704,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,3.063968,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,3.068544,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,3.07296,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297740544.0,377184.0,0.133248,3.206208,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9304392.0,11787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003744,3.2099520000000004,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298144000.0,374048.0,0.136096,3.3460480000000006,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9317000.0,11689.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003456,3.3495040000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303162368.0,93312.0,0.123232,3.4727360000000003,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473824.0,2916.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,3.4762880000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003232,3.4795200000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,3.4880640000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,3.4912640000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,3.4944960000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,3.499008000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004608,3.503616000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75829888.0,83168.0,0.03664,3.5402560000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369684.0,2599.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75848832.0,81216.0,0.038272,3.578528000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370276.0,2538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75806336.0,83328.0,0.035872,3.6144000000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368948.0,2604.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,3.619040000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004576,3.623616000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00544,3.629056000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,3.6336000000000013,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,3.636960000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,3.641696000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004544,3.646240000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005504,3.651744000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,3.656448000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,3.659872000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015936,3.675808000000001,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75771776.0,97600.0,0.035648,3.711456000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2367868.0,3050.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,3.714880000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003328,3.718208000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008256,3.726464000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00304,3.729504000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,3.732704000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004608,3.737312000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004928,3.742240000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297640576.0,378432.0,0.133056,3.875296000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9301268.0,11826.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00384,3.879136000000001,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297356160.0,374240.0,0.133888,4.013024000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9292380.0,11695.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003488,4.0165120000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303168384.0,97408.0,0.126624,4.143136,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474012.0,3044.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,4.14656,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,4.150016,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008096,4.158112,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003328,4.16144,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,4.1647039999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,4.169344,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,4.173888,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75849216.0,83200.0,0.035776,4.209664,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370288.0,2600.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75844480.0,85184.0,0.036224,4.245888,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370140.0,2662.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75819520.0,82880.0,0.037312,4.2832,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369360.0,2590.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,4.287712,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004608,4.29232,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.0056,4.29792,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,4.302752000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,4.306144000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004544,4.310688000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004352,4.315040000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005536,4.320576000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,4.325152000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,4.328576000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015936,4.344512000000001,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75793664.0,96640.0,0.0352,4.3797120000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368552.0,3020.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,4.3832,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,4.386592,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008416,4.395008000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003328,4.3983360000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,4.401504,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,4.406144,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004736,4.410880000000001,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297901440.0,370976.0,0.135296,4.546176000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309420.0,11593.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00384,4.550016000000001,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298420352.0,372896.0,0.136128,4.686144000000001,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9325636.0,11653.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003616,4.6897600000000015,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303172096.0,93216.0,0.128928,4.818688000000002,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9474128.0,2913.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003232,4.821920000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003328,4.825248000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008512,4.833760000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,4.83696,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003392,4.840352,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,4.844896,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,4.849376,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75824768.0,81952.0,0.036352,4.885728,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369524.0,2561.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75824128.0,83328.0,0.035488,4.921216,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369504.0,2604.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75841792.0,84096.0,0.035328,4.956544,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370056.0,2628.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,4.961152,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,4.965568,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,4.971488,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,4.976192,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,4.979584,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,4.984224,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,4.988672,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00592,4.994592,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,4.999424,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003808,5.003232000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,262144.0,23535616.0,0.0,0,257698037760.0,23535616.0,257721573376.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.015904,5.0191360000000005,19841024.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75778304.0,94240.0,0.0368,5.055936000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368072.0,2945.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,5.059232000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00336,5.062592,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008512,5.071104,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003072,5.0741760000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,5.077472,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004512,5.081984,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004704,5.0866880000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298108928.0,374336.0,0.134592,5.22128,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9315904.0,11698.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00368,5.22496,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298299776.0,370112.0,0.139552,5.364512,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9321868.0,11566.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003424,5.367936,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303283072.0,96384.0,0.127616,5.495552,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9477596.0,3012.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003584,5.499136,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003296,5.502432,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00832,5.510752,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,5.513984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,5.5172159999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004704,5.52192,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004544,5.526464,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,2741441664.0,3497472.0,1.025632,6.552096,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85670052.0,109296.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002848,6.554944,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.004416,6.55936,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,6.5625599999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004608,6.567168,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002976,6.570144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172224.0,0.006336,6.57648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5382.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,37968640.0,0.0,0.014944,6.591424,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1186520.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174464.0,0.00656,6.597984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5452.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,37985856.0,0.0,0.015104,6.613088,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1187058.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171968.0,0.006368,6.6194560000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5374.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38000064.0,0.0,0.014528,6.633984000000001,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1187502.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169856.0,0.006176,6.640160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5308.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,37973024.0,128.0,0.014784,6.654944,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1186657.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.005184,6.660128,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003072,6.663200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.006144,6.669344000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002912,6.672256000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.005824,6.6780800000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,98564.0,38400.0,0.7196343564732338,2488224.0,11136.0,0.008768,6.686848,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77757.0,348.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.00912,6.695968000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,200896.0,0.006528,6.702496000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6278.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005504,6.708000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005568,6.713568000000001,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.00688,6.720448000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.00352,6.723968000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,170394.0,84382.0,0.6687992589568876,8757120.0,5977088.0,0.01712,6.741088000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,273660.0,186784.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91596.0,0.30301785143587634,8847616.0,7409664.0,0.01424,6.755328000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276488.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,90740.0,0.30982551683222537,8859520.0,5724800.0,0.01424,6.769568000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276860.0,178900.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,91032.0,0.30169834767800435,8853248.0,7409664.0,0.014752,6.784320000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276664.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.006208,6.790528000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.003616,6.794144000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51085.0,0.43050957047144467,6182528.0,4012736.0,0.01248,6.806624000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,193204.0,125398.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7332096.0,7292928.0,0.00832,6.8149440000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229128.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.087424,6.902368000000002,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.284608,7.186976000000002,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607488.0,0.004256,7.191232000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003392,7.194624000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,282912.0,0.011808,7.206432000000002,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8841.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005088,7.211520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9424712.0,20076672.0,1832592.0,0,0.0,21909264.0,21909264.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.087488,7.2990080000000015,2452096.0,607744.0,8508416.0,916296.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009344,7.308352000000001,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003424,7.311776000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.0096,7.321376000000001,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003296,7.3246720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003392,7.328064,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.0048,7.332864000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009632,7.342496000000001,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,7.345664,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00496,7.350624,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,7.3538879999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004608,7.358496,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.0072,7.365696,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3798344.0,6077440.0,1519248.0,0,0.0,7596688.0,7596688.0,0.0,14280.0,0.0,4861952.0,0.0,0.006912,7.372608,0.0,0.0,3038720.0,759624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,0.012864,7.385472,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,0.004352,7.389824,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002688,7.392512,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002752,7.395264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003616,7.39888,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003392,7.402272,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003936,7.406208,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.004672,7.410880000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003456,7.4143360000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00352,7.4178560000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,0.004384,7.42224,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.003872,7.426112000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.00336,7.4294720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.00336,7.432832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,0.00336,7.436192,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.00384,7.440032,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,1536.0,0.0,66560.0,65536.0,0.008128,7.448160000000001,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2080.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,0.003232,7.451392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.004928,7.45632,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003584,7.459904,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.00368,7.463584,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.004096,7.46768,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,0.004224,7.471903999999999,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.00336,7.475263999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,0.004224,7.479487999999999,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,0.003264,7.482751999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003424,7.486175999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008608,7.494783999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,7.498047999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,7.501279999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004448,7.505727999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00464,7.510367999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75805568.0,84736.0,0.03536,7.545727999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368924.0,2648.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75804032.0,85312.0,0.037312,7.583039999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368876.0,2666.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75811456.0,83200.0,0.036192,7.619231999999998,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369108.0,2600.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,7.624031999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004544,7.628575999999998,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005888,7.634463999999998,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,7.639039999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,7.642527999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,7.647263999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,7.651583999999998,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006016,7.657599999999998,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,7.662399999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,7.665855999999998,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004672,7.670527999999998,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004736,7.6752639999999985,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,261376.0,23541792.0,0.0,0,257698037760.0,23541792.0,257721579552.0,133153.0,256.0,0.9980810889820028,327680.0,65536.0,0.016032,7.691295999999999,19848808.0,3170232.0,261376.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75826048.0,96128.0,0.035936,7.727231999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369564.0,3004.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,7.730687999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003424,7.734111999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008928,7.743039999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,7.7463039999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,7.749567999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004608,7.754175999999998,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004672,7.758847999999999,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297919104.0,371360.0,0.134848,7.8936959999999985,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309972.0,11605.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003776,7.897471999999999,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297416576.0,371136.0,0.140704,8.038175999999998,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9294268.0,11598.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003552,8.041727999999999,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303148672.0,93312.0,0.137472,8.1792,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473396.0,2916.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,8.182688,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,8.186144,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008512,8.194656,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,8.197824,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,8.200992000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.0048,8.205792,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004576,8.210368,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75794816.0,83872.0,0.035904,8.246272000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368588.0,2621.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75799040.0,83008.0,0.035424,8.281696000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368720.0,2594.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75803904.0,85408.0,0.036672,8.318368000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368872.0,2669.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,8.322880000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,8.327264000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,8.333216000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,8.337920000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,8.341408000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,8.346048000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,8.350496000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,8.356448000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,8.361216000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,8.364768000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004608,8.369376000000004,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.00464,8.374016000000005,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,261760.0,23542800.0,0.0,0,257698037760.0,23542800.0,257721580560.0,133144.0,256.0,0.9980809595202399,327680.0,65536.0,0.016096,8.390112000000004,19849012.0,3170268.0,261760.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75815808.0,95104.0,0.036288,8.426400000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369244.0,2972.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003584,8.429984000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003232,8.433216000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00864,8.441856000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,8.445056000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,8.448352000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004672,8.453024000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004576,8.457600000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298334848.0,375712.0,0.13264,8.590240000000005,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9322964.0,11741.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00368,8.593920000000004,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298249856.0,374528.0,0.133024,8.726944000000005,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9320308.0,11704.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003776,8.730720000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303164800.0,94688.0,0.132704,8.863424000000006,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473900.0,2959.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,8.866752000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00352,8.870272000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,8.878816000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,8.882080000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,8.885312000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,8.889792000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004416,8.894208000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75822080.0,83040.0,0.034848,8.929056000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369440.0,2595.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75850624.0,83776.0,0.035008,8.964064000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370332.0,2618.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75851136.0,82400.0,0.034208,8.998272000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370348.0,2575.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004608,9.002880000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,9.007360000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005952,9.013312000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,9.018048000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,9.021472000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,9.026176000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,9.030464000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.00608,9.036544000000006,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,9.041248000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,9.044768000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.0048,9.049568000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.00464,9.054208000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,261952.0,23543304.0,0.0,0,257698037760.0,23543304.0,257721581064.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,0.016096,9.070304000000005,19849114.0,3170286.0,261952.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75785216.0,95776.0,0.035872,9.106176000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368288.0,2993.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,9.109664000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,9.112928000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008416,9.121344000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.124608000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,9.127840000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004576,9.132416000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004512,9.136928000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297678464.0,375264.0,0.136832,9.273760000000006,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9302452.0,11727.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003968,9.277728000000007,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298236416.0,373056.0,0.133216,9.410944000000008,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9319888.0,11658.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.00352,9.414464000000008,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303154176.0,95616.0,0.132032,9.546496000000008,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473568.0,2988.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003424,9.549920000000009,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,9.553376000000009,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,9.561952000000009,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,9.565216000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,9.568416000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004704,9.573120000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004832,9.577952000000009,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75800704.0,85312.0,0.034816,9.612768000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368772.0,2666.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75809024.0,85792.0,0.035168,9.647936000000009,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369032.0,2681.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75836544.0,84864.0,0.034816,9.682752000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369892.0,2652.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,9.687456000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,9.691840000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005536,9.697376000000007,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00496,9.702336000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003552,9.705888000000009,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,9.710528000000009,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004448,9.714976000000009,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005536,9.720512000000008,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,9.725152000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,9.728480000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004608,9.733088000000008,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004736,9.737824000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,261952.0,23543304.0,0.0,0,257698037760.0,23543304.0,257721581064.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,0.016,9.753824000000007,19849114.0,3170286.0,261952.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75805056.0,93504.0,0.036896,9.790720000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368908.0,2922.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003264,9.793984000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,9.797248000000007,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008608,9.805856000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,9.809024000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.0032,9.812224000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004608,9.816832000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004736,9.821568000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298011008.0,370592.0,0.13568,9.957248000000007,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9312844.0,11581.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.00384,9.961088000000007,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298173952.0,374432.0,0.13504,10.096128000000007,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9317936.0,11701.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003648,10.099776000000007,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303125376.0,98816.0,0.121248,10.221024000000007,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9472668.0,3088.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,10.224320000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003296,10.227616000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008576,10.236192000000008,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003264,10.239456000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,10.242720000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,10.247360000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004512,10.251872000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75823616.0,85344.0,0.034912,10.286784000000008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369488.0,2667.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75817984.0,83296.0,0.035072,10.321856000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369312.0,2603.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75813760.0,82976.0,0.036928,10.358784000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369180.0,2593.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,10.363552000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00464,10.368192000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005792,10.373984000000007,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,10.378560000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003584,10.382144000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004768,10.386912000000008,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,10.391232000000008,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005792,10.397024000000007,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004736,10.401760000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,10.405152000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004768,10.409920000000007,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004736,10.414656000000006,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,261952.0,23543304.0,0.0,0,257698037760.0,23543304.0,257721581064.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,0.016,10.430656000000006,19849114.0,3170286.0,261952.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75819392.0,98496.0,0.034208,10.464864000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369356.0,3078.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,10.468256000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003264,10.471520000000005,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008448,10.479968000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003488,10.483456000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,10.486720000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,10.491264000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.0048,10.496064000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298435328.0,369184.0,0.135072,10.631136000000003,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9326104.0,11537.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003808,10.634944000000003,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297896064.0,375296.0,0.136704,10.771648000000003,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9309252.0,11728.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003616,10.775264000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303147264.0,98912.0,0.129056,10.904320000000002,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9473352.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,10.907840000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003392,10.911232000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008224,10.919456000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,10.922624000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003392,10.926016000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004704,10.930720000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004576,10.935296000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75824640.0,85824.0,0.034048,10.969344000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369520.0,2682.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75841408.0,84256.0,0.034944,11.004288000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370044.0,2633.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75815040.0,84064.0,0.035808,11.040096000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369220.0,2627.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004448,11.044544000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,11.048800000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.0056,11.054400000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,11.059040000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00352,11.062560000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,11.067264000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,11.071680000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005664,11.077344000000002,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004832,11.082176000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,11.085536000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004672,11.090208000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004608,11.094816000000002,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,261952.0,23543304.0,0.0,0,257698037760.0,23543304.0,257721581064.0,133132.0,256.0,0.9980807868773802,327680.0,65536.0,0.015904,11.110720000000002,19849114.0,3170286.0,261952.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75802624.0,95680.0,0.034784,11.145504000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368832.0,2990.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,11.148960000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003296,11.152256000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008768,11.161024000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.0032,11.164224000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003168,11.167392000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,11.172032000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004672,11.176704000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297759232.0,376256.0,0.133504,11.310208000000003,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9304976.0,11758.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003744,11.313952000000002,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297410048.0,376128.0,0.134656,11.448608000000002,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9294064.0,11754.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003456,11.452064000000002,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303238400.0,94816.0,0.13232,11.584384000000002,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9476200.0,2963.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,11.587712000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003488,11.591200000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,11.599744000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.00336,11.603104000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,11.606336000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00448,11.610816000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004448,11.615264000000003,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75817600.0,83232.0,0.037824,11.653088000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369300.0,2601.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75841920.0,83200.0,0.03408,11.687168000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2370060.0,2600.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75801984.0,83328.0,0.037152,11.724320000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368812.0,2604.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,11.728960000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,11.733280000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005984,11.739264000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,11.744064000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,11.747520000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.00464,11.752160000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,11.756640000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.006112,11.762752000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004576,11.767328000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,11.770720000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004832,11.775552000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004576,11.780128000000003,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.015904,11.796032000000004,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75791360.0,95520.0,0.03536,11.831392000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2368480.0,2985.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003328,11.834720000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,11.838304000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008544,11.846848000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003328,11.850176000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003264,11.853440000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.004544,11.857984000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004768,11.862752000000004,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298136832.0,375040.0,0.13728,12.000032000000004,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9316776.0,11720.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003776,12.003808000000005,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,298636160.0,371072.0,0.137312,12.141120000000004,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9332380.0,11596.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003616,12.144736000000004,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303289984.0,98688.0,0.12512,12.269856000000004,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9477812.0,3084.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003392,12.273248000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003584,12.276832000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008672,12.285504000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,12.288672000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,12.291904000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,12.296544000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004768,12.301312000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75821696.0,83776.0,0.035552,12.336864000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369428.0,2618.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75814528.0,84800.0,0.036384,12.373248000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369204.0,2650.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,75832192.0,85376.0,0.035136,12.408384000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369756.0,2668.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004512,12.412896000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,12.417280000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005856,12.423136000000005,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004704,12.427840000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003488,12.431328000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.004672,12.436000000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,12.440320000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,0.0,1024.0,0.0,65536.0,65536.0,0.005536,12.445856000000004,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,98304.0,65536.0,0.0048,12.450656000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,12.454112000000004,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004704,12.458816000000004,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,0.0,1280.0,0.0,131072.0,131072.0,0.004704,12.463520000000004,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,262144.0,23543808.0,0.0,0,257698037760.0,23543808.0,257721581568.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.016,12.479520000000004,19849216.0,3170304.0,262144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,1006632960.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,75816576.0,98592.0,0.035104,12.514624000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2369268.0,3081.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003456,12.518080000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003488,12.521568000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00864,12.530208000000005,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003168,12.533376000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003296,12.536672000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.0048,12.541472000000006,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.004736,12.546208000000005,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297543168.0,378912.0,0.131232,12.677440000000006,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9298224.0,11841.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,819200.0,1572864.0,131072.0,0,0.0,1703936.0,1703936.0,0.0,1024.0,0.0,262144.0,262144.0,0.003744,12.681184000000005,65536.0,0.0,753664.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,273154048.0,588251136.0,9437184.0,0,0.0,597688320.0,597688320.0,3547136.0,3178496.0,0.5274056029232643,297752320.0,376192.0,0.132,12.813184000000005,17825792.0,33554432.0,268435456.0,4718592.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9304760.0,11756.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,65536.0,0.0,0,0.0,65536.0,65536.0,0.0,1536.0,0.0,524288.0,262144.0,0.003456,12.816640000000005,0.0,65536.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16384.0,8192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,272760832.0,587464704.0,8650752.0,0,0.0,596115456.0,596115456.0,3442688.0,3153920.0,0.5218876125426886,303279360.0,96224.0,0.123008,12.939648000000005,17039360.0,33554432.0,268435456.0,4325376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9477480.0,3007.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00336,12.943008000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003456,12.946464000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.008672,12.955136000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,0.003232,12.958368000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,0.003232,12.961600000000008,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,67584.0,65536.0,0.00464,12.966240000000008,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,16384.0,16384.0,32768.0,0,0.0,49152.0,49152.0,0.0,1536.0,0.0,131072.0,65536.0,0.00448,12.970720000000007,0.0,16384.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,2742583424.0,3495744.0,1.009376,13.980096000000007,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0,0,0.0,0.0,0.0,85705732.0,109242.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002752,13.982848000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.00384,13.986688000000006,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,13.989920000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.004512,13.994432000000007,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00304,13.997472000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172224.0,0.006336,14.003808000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5382.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38120000.0,0.0,0.014656,14.018464000000007,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191250.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174592.0,0.0064,14.024864000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5456.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,267008.0,0.0,534016.0,0,0.0,534016.0,534016.0,39336.0,718784.0,0.05188624492164829,38128448.0,32.0,0.015136,14.040000000000006,0.0,0.0,0.0,267008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191514.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172352.0,0.006272,14.046272000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5386.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,243168.0,0.0,486336.0,0,0.0,486336.0,486336.0,39336.0,719529.0,0.051835306675100314,38148320.0,0.0,0.014912,14.061184000000006,0.0,0.0,0.0,243168.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192135.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170944.0,0.006112,14.067296000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5342.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38147360.0,128.0,0.01536,14.082656000000005,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192105.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,0.005216,14.087872000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.00288,14.090752000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.00608,14.096832000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.003232,14.100064000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,0.005984,14.106048000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,156333.0,38398.0,0.8028151655360471,2488288.0,10912.0,0.009696,14.115744000000007,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,341.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.00848,14.124224000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,202496.0,0.00624,14.130464000000007,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6328.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.00576,14.136224000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,0.005536,14.141760000000007,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,0.00688,14.148640000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.00352,14.152160000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,167586.0,83816.0,0.6666056753725109,8697216.0,5999392.0,0.01744,14.169600000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,271788.0,187481.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91528.0,0.30317472401979445,8839040.0,7409664.0,0.0144,14.184000000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276220.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91063.0,0.3090662154677269,8866944.0,5718688.0,0.015168,14.199168000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277092.0,178709.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,39330.0,91058.0,0.3016381875632727,8884992.0,7409664.0,0.015136,14.214304000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277656.0,231552.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,0.006176,14.220480000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.00336,14.223840000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51145.0,0.4302218063121776,6210432.0,3999776.0,0.012768,14.236608000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194076.0,124993.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7331968.0,7292928.0,0.008224,14.244832000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229124.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.08704,14.331872000000008,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.28768,14.619552000000008,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,0.004288,14.623840000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.003232,14.627072000000009,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,284672.0,0.011808,14.63888000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8896.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,0.005536,14.644416000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9424709.0,20076672.0,1832586.0,0,0.0,21909258.0,21909258.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.086848,14.731264000000008,2452096.0,607744.0,8508416.0,916293.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009984,14.741248000000008,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.0032,14.744448000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.009888,14.754336000000007,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003328,14.757664000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003488,14.761152000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004448,14.765600000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.009664,14.775264000000009,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,14.77843200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.005024,14.78345600000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003168,14.78662400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.004416,14.791040000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,0.007264,14.79830400000001,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3798341.0,6077440.0,1519242.0,0,0.0,7596682.0,7596682.0,0.0,14280.0,0.0,4861952.0,1536.0,0.006784,14.80508800000001,0.0,0.0,3038720.0,759621.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,48.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,0.013024,14.81811200000001,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,0.004032,14.82214400000001,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002752,14.82489600000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002816,14.827712000000009,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003168,14.83088000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003232,14.83411200000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,0.003968,14.83808000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00512,14.84320000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003264,14.84646400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
