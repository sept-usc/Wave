Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.656,5.4719999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,32.0,3.744,9.216,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,64.0,4.48,13.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,4.736,18.432,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,21.791999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.752,24.543999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,27.423999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.2,30.623999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.616,34.239999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,37.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,40.992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,64.0,32.0,3.936,44.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.136,48.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.392,51.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.328,54.784000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,3456.0,24576.0,7.104,61.888000000000005,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.488,65.376,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.536,70.912,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.52,74.432,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,4.032,78.464,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,4.832,83.29599999999999,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,8192.0,18432.0,0.0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,4.032,87.32799999999999,0.0,2048.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.168,90.496,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,7168.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,16.0,0.0,4096.0,4096.0,4.096,94.592,0.0,2048.0,7168.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.36,97.952,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.808,101.75999999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.24,107.99999999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.744,111.74399999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.68,115.42399999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.512,119.93599999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,124.288,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26304.0,12.416,136.704,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,822.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26176.0,11.872,148.57600000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,818.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26080.0,11.904,160.48000000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,815.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,164.89600000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,169.40800000000002,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,174.78400000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,179.36,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,182.68800000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,187.104,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,191.616,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.632,197.24800000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,201.79200000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,205.24800000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.68,220.92800000000003,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,47,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1104384.0,8.0,228.92800000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34512.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,48,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.048,238.97600000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",49,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,242.49600000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",50,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.584,246.08000000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",51,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.88,252.96000000000004,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",52,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,256.35200000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,259.84000000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.352,264.192,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",55,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,268.704,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149088.0,12.992,281.696,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4659.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",57,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.712,285.408,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,148640.0,13.568,298.976,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4645.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",59,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,302.432,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,60,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3063680.0,12.672,315.10400000000004,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95740.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,61,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.28,336.384,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,339.968,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,343.488,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",64,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.112,349.6,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,352.76800000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,356.192,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,360.672,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,365.24800000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,27808.0,12.768,378.0160000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,869.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26720.0,11.872,389.8880000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,835.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26720.0,12.032,401.9200000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,835.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,406.4320000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.64,411.07200000000006,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",74,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,416.4800000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.64,421.12000000000006,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",76,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,424.41600000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,428.86400000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.416,433.28000000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",79,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,438.624,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,443.00800000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,446.46400000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",82,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.712,462.17600000000004,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,83,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102976.0,7.872,470.04800000000006,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34468.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,84,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,480.28800000000007,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,483.61600000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,487.10400000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.784,493.88800000000003,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,497.088,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,500.416,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.64,505.056,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,509.568,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149440.0,13.472,523.04,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4670.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.584,526.6239999999999,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,154240.0,13.44,540.064,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4820.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.296,543.36,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,96,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3052640.0,12.672,556.032,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95395.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,97,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.44,577.4720000000001,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,581.0240000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",99,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.616,584.6400000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",100,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,5.984,590.6240000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",101,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,593.7600000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,597.1520000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.704,601.8560000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.32,606.1760000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26240.0,11.872,618.0480000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,820.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26624.0,12.0,630.0480000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,832.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25312.0,12.192,642.2400000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,791.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,646.7840000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.32,651.1040000000002,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,656.5760000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,661.0240000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,664.4480000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,669.0240000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.544,673.5680000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",115,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.6,679.1680000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,683.7440000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",117,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,687.0080000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",118,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.648,702.6560000000002,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,119,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1104480.0,7.68,710.3360000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34515.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,120,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.368,720.7040000000002,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,724.0320000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,727.4240000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",123,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.592,734.0160000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",124,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.616,737.6320000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,740.8960000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.384,745.2800000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,749.6640000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,147552.0,13.184,762.8480000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4611.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.744,766.5920000000002,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681472.0,149760.0,13.312,779.9040000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396296.0,4680.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.648,783.5520000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,132,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3059936.0,12.672,796.2240000000003,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95623.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,133,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.152,817.3760000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,820.9600000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,824.2880000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.112,830.4000000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,833.6000000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,836.9920000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,841.4080000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,845.7920000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26560.0,11.616,857.4080000000004,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,830.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26208.0,12.0,869.4080000000004,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,819.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",143,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25696.0,11.808,881.2160000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,803.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,885.6320000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,889.9840000000004,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",146,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,895.3920000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,899.9680000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,903.3280000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,907.8080000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",150,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,912.2560000000004,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",151,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.28,917.5360000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.8,922.3360000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,925.8880000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",154,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.648,941.5360000000004,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,155,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105984.0,7.936,949.4720000000004,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34562.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,156,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.24,959.7120000000004,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",157,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,963.1680000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,966.5280000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",159,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.496,973.0240000000005,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",160,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,976.4480000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,979.7440000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.672,984.4160000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.64,989.0560000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,144704.0,13.088,1002.1440000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4522.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.776,1005.9200000000004,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",166,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681728.0,147296.0,13.088,1019.0080000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396304.0,4603.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.488,1022.4960000000004,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,168,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3069120.0,12.672,1035.1680000000003,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95910.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,169,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.6,1056.7680000000003,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",170,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,1060.1920000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",171,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.648,1063.8400000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",172,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,5.952,1069.7920000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",173,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1073.0880000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",174,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1076.4800000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,1081.0240000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,1085.4080000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",177,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26592.0,12.064,1097.4720000000004,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,831.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25696.0,12.608,1110.0800000000004,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,803.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26080.0,13.088,1123.1680000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,815.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,1127.6480000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,1132.1600000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.536,1137.6960000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,1142.3680000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,1145.6640000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",185,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.64,1150.3040000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",186,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.672,1154.9760000000006,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",187,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,1160.3840000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.704,1165.0880000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",189,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1168.5440000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",190,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.584,1184.1280000000004,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,191,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1107968.0,7.968,1192.0960000000005,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34624.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,192,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,1202.6880000000006,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,1206.0160000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,1209.3760000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",195,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.4,1215.7760000000005,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1219.0720000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1222.3680000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.576,1226.9440000000006,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,1231.3280000000007,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",200,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,150272.0,13.088,1244.4160000000006,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4696.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",201,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.84,1248.2560000000005,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,143584.0,13.056,1261.3120000000006,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4487.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",203,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,1264.7680000000005,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,204,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3069504.0,12.672,1277.4400000000005,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95922.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,205,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.344,1298.7840000000006,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",206,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,1302.3680000000006,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",207,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,1305.7280000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",208,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.016,1311.7440000000006,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",209,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,1315.2000000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,1318.6240000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,1323.0720000000006,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,1327.4240000000007,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",213,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26624.0,11.776,1339.2000000000007,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,832.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",214,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26208.0,12.032,1351.2320000000007,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,819.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",215,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26944.0,11.744,1362.9760000000006,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,842.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,1367.3920000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,1371.9040000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",218,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,1377.3120000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.736,1382.0480000000005,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",220,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1385.5360000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",221,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.32,1389.8560000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.544,1394.4000000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",223,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,1399.7120000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.512,1404.2240000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",225,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,1407.7440000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",226,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.616,1423.3600000000004,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,227,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106848.0,7.872,1431.2320000000004,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34589.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,228,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,1441.8240000000005,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,1445.2480000000005,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.648,1448.8960000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.624,1455.5200000000004,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1458.7200000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1462.1120000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,1466.5280000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.64,1471.1680000000006,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",236,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,146784.0,13.024,1484.1920000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4587.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.552,1487.7440000000004,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149248.0,13.12,1500.8640000000003,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4664.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",239,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,1504.3200000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,240,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3061344.0,12.672,1516.9920000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95667.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,241,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.6,1538.592,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",242,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,1542.208,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",243,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,1545.632,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",244,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.176,1551.808,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",245,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,1554.944,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,1558.336,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,1562.88,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,1567.3280000000002,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",249,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26752.0,11.744,1579.0720000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,836.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",250,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25792.0,11.872,1590.9440000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,806.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26368.0,12.096,1603.0400000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,824.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,1607.5200000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.32,1611.8400000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,1617.3120000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,1621.728,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",256,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1625.184,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,1629.728,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.416,1634.144,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",259,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.44,1639.584,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,1644.1280000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",261,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,1647.584,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",262,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.552,1663.136,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,263,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1108544.0,7.776,1670.912,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34642.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,264,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.112,1681.0240000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",265,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,1684.288,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.744,1688.032,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",267,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.592,1694.624,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",268,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1697.792,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,1701.312,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.896,1706.2079999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,1710.56,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681472.0,144544.0,13.056,1723.616,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396296.0,4517.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.616,1727.232,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,143040.0,13.792,1741.024,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4470.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",275,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.488,1744.512,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,276,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3068672.0,12.672,1757.184,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95896.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,277,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.28,1778.464,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.744,1782.2079999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",279,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,1785.7279999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",280,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,5.92,1791.648,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",281,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1794.848,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,1798.272,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,1802.752,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.608,1807.36,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25248.0,12.768,1820.128,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,789.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25632.0,12.0,1832.128,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,801.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26880.0,12.064,1844.192,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,840.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,1848.8,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.608,1853.408,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",290,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.632,1859.04,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,1863.712,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,1867.2,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,1871.68,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.768,1876.448,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.28,1881.728,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,1886.1760000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,1889.5040000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",298,98304.0,8825856.0,0.0,0,96636764160.0,8825856.0,96645590016.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,15.68,1905.1840000000002,7440384.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,2304.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,299,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1109696.0,7.776,1912.9600000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34678.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,300,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.528,1923.4880000000003,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,1926.7520000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,1930.2400000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.496,1936.7360000000003,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1939.9360000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1943.2320000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,1947.7760000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.416,1952.1920000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,145632.0,13.504,1965.6960000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4551.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",309,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.744,1969.4400000000003,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",310,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,147648.0,13.504,1982.9440000000002,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4614.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",311,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,1986.3360000000002,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,312,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3064512.0,12.704,1999.0400000000002,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95766.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,313,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.536,2020.5760000000002,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",314,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2024.0320000000002,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",315,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,2027.488,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",316,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.08,2033.568,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",317,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,2036.7359999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",318,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2040.128,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,2044.576,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.544,2049.12,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,65536.0,0.0,0.0,2455936.0,4.416,2053.536,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,76748.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,98304.0,0.0,0.0,3405376.0,4.352,2057.888,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,106418.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,31328.0,0.0,0.0,950368.0,3.456,2061.344,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,29699.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",324,938361484.0,1874282496.0,4871448.0,0,0.0,1879153944.0,1879153944.0,18711868.0,4263704.0,0.8144244678652615,503695680.0,19598912.0,253.92,2315.264,0.0,2430976.0,935925760.0,2435724.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15740490.0,612466.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.816,2318.08,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",326,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,4.448,2322.528,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2325.888,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",328,0.0,1215488.0,0.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,5.76,2331.648,0.0,1215488.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.168,2334.8160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,230592.0,8.128,2342.9440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7206.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",331,380160.0,0.0,760320.0,0,0.0,760320.0,760320.0,52272.0,637576.0,0.07577321380941889,39662848.0,64.0,13.28,2356.2240000000006,0.0,0.0,0.0,380160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1239464.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,231616.0,7.68,2363.9040000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7238.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",333,228096.0,0.0,456192.0,0,0.0,456192.0,456192.0,52272.0,642328.0,0.075254822919666,39770464.0,0.0,13.536,2377.4400000000005,0.0,0.0,0.0,228096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1242827.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,230144.0,7.584,2385.0240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7192.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",335,430848.0,0.0,861696.0,0,0.0,861696.0,861696.0,52272.0,635992.0,0.07594760150174933,39621120.0,64.0,13.472,2398.4960000000005,0.0,0.0,0.0,430848.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1238160.0,2.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,229632.0,7.648,2406.1440000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7176.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",337,253440.0,0.0,506880.0,0,0.0,506880.0,506880.0,52272.0,641536.0,0.07534072827064549,39758464.0,192.0,13.76,2419.904000000001,0.0,0.0,0.0,253440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1242452.0,6.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75.0,0.0,25376.0,3168.0,5.824,2425.728000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,793.0,99.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,2428.608000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3168.0,0.0,6.016,2434.624000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,2437.856000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",342,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3168.0,0.0,5.824,2443.680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",343,202752.0,0.0,405504.0,0,0.0,405504.0,405504.0,368344.0,64000.0,0.851969727809337,4940416.0,18848.0,12.96,2456.6400000000012,0.0,0.0,0.0,202752.0,0,0,0,0,0,0,0,0.0,0.0,0.0,154388.0,589.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,8.8,2465.4400000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,4894976.0,386240.0,8.64,2474.0800000000013,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152968.0,12070.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,1920.0,6.144,2480.224000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,189920.0,60.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",347,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,0.0,9723904.0,7.776,2488.000000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",348,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,37984.0,0.7806320458325633,4861952.0,0.0,7.872,2495.8720000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.488,2499.3600000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,316583.0,169666.0,0.6510717759830869,17128960.0,11973504.0,28.064,2527.4240000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,535280.0,374172.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,77903.0,180741.0,0.30119778537294506,17206784.0,14818304.0,22.56,2549.9840000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,537712.0,463072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,78843.0,181527.0,0.30281138379997696,17192192.0,14818304.0,23.936,2573.9200000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,537256.0,463072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,78843.0,180329.0,0.30421110305125554,17198464.0,12963136.0,23.744,2597.6640000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,537452.0,405098.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,37984.0,0.2801697998787144,9723904.0,0.0,7.872,2605.5360000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.36,2608.8960000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,78004.0,161850.0,0.32521450549084024,13395328.0,8491456.0,17.952,2626.848000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,418604.0,265358.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,151936.0,0.0,14668000.0,14585856.0,12.32,2639.168000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,458375.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",358,18849392.0,40153344.0,3665120.0,0,0.0,43818464.0,43818464.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,87.424,2726.592000000001,4904192.0,1215488.0,17016832.0,1832560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",359,0.0,6104232.0,0.0,0,0.0,6104232.0,6104232.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,287.328,3013.920000000001,6104232.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,5.152,3019.072000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",361,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.36,3022.432000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",362,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,10939392.0,616192.0,12.256,3034.688000000001,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,341856.0,19256.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,4608.0,6.208,3040.896000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,189920.0,144.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",364,18849408.0,40153344.0,3665152.0,0,0.0,43818496.0,43818496.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,87.296,3128.192000000001,4904192.0,1215488.0,17016832.0,1832576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",365,229376.0,0.0,458752.0,0,0.0,458752.0,458752.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.272,3138.464000000001,0.0,0.0,0.0,229376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3141.920000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",367,229376.0,0.0,458752.0,0,0.0,458752.0,458752.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,9.92,3151.840000000001,0.0,0.0,0.0,229376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3155.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,3158.496000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,3163.104000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",371,238784.0,1971352.0,477568.0,0,0.0,2448920.0,2448920.0,14744.0,9664.0,0.6040642412323828,4862784.0,4992.0,10.464,3173.568000000001,1971352.0,0.0,0.0,238784.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151962.0,156.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,3176.768000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.088,3181.856000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3185.3120000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,3189.7280000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",376,4325376.0,9459712.0,1622016.0,0,0.0,11081728.0,11081728.0,0.0,37984.0,0.0,0.0,4861952.0,9.376,3199.1040000000016,0.0,2430976.0,3514368.0,811008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",377,7596416.0,12154880.0,3037952.0,0,0.0,15192832.0,15192832.0,0.0,28488.0,0.0,9723904.0,17408.0,8.96,3208.0640000000017,0.0,0.0,6077440.0,1518976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,544.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",378,169472.0,0.0,338944.0,0,0.0,338944.0,338944.0,26904.0,9824.0,0.7325201481158788,4864512.0,5248.0,13.6,3221.6640000000016,0.0,0.0,0.0,169472.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152016.0,164.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",379,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,128.0,256.0,3.904,3225.5680000000016,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,3228.2880000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,3231.2640000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,3234.8480000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,3238.144000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,4.032,3242.1760000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",385,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,5.024,3247.200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3250.432000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,3253.8880000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",388,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,160.0,64.0,4.448,3258.336000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,96.0,8.0,0.9230769230769231,128.0,32.0,4.0,3262.336000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,3.296,3265.632000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.168,3268.800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,160.0,0.0,3.392,3272.192000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",393,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,128.0,64.0,4.096,3276.288000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",394,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,576.0,0.0,24960.0,24576.0,10.912,3287.2000000000007,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,780.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",395,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,32.0,3.648,3290.848000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",396,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,5.408,3296.2560000000008,0.0,0.0,0.0,16.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",397,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.552,3299.808000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",398,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,3.488,3303.2960000000007,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,4.128,3307.424000000001,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,8192.0,18432.0,0.0,0,0.0,18432.0,18432.0,0.0,16.0,0.0,4096.0,4096.0,4.064,3311.4880000000007,0.0,2048.0,8192.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",401,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.104,3314.5920000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",402,7200.0,16448.0,0.0,0,0.0,16448.0,16448.0,0.0,16.0,0.0,4096.0,4096.0,3.936,3318.5280000000007,0.0,2048.0,7200.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",403,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,3.168,3321.696000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,3325.120000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",405,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.784,3331.904000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",406,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3335.136000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",407,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3338.368000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,3342.784000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,3347.136000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",410,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,28032.0,12.16,3359.2960000000007,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,876.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",411,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25856.0,11.968,3371.2640000000006,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,808.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",412,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26272.0,12.448,3383.7120000000004,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,821.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,3388.3200000000006,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.384,3392.7040000000006,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,3398.176000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",416,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,3402.6240000000007,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",417,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3405.984000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",418,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.704,3410.688000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",419,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.288,3414.976000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.568,3420.5440000000012,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",421,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,3425.1520000000014,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",422,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,3428.4480000000012,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.64,3433.088000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.832,3437.920000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",425,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,16.096,3454.016000000001,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,426,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105152.0,7.712,3461.728000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34536.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,427,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3472.0640000000008,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",428,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3475.4880000000007,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",429,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.392,3478.8800000000006,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",430,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.24,3485.1200000000003,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",431,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3488.1920000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3491.5840000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,3496.0640000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",434,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,3500.5440000000003,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",435,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,147648.0,13.184,3513.7280000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4614.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.84,3517.5680000000007,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",437,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,151104.0,13.248,3530.8160000000007,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4722.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",438,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,3534.176000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,439,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3065824.0,12.928,3547.1040000000007,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95807.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,440,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.088,3568.192000000001,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",441,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,3571.744000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",442,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.328,3575.072000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",443,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.272,3581.344000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",444,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3584.640000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.68,3588.3200000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,3592.8000000000006,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.448,3597.2480000000005,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",448,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25504.0,11.776,3609.0240000000003,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,797.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",449,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25408.0,11.936,3620.9600000000005,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,794.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",450,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26880.0,11.904,3632.8640000000005,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,840.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,3637.3120000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",452,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,3641.8240000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.6,3647.4240000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.704,3652.1280000000006,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,3655.4240000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,3659.8080000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",457,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.384,3664.1920000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,3669.5360000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,3674.0800000000004,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",460,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,3677.6000000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",461,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.64,3682.2400000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",462,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.736,3686.976,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",463,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,16.128,3703.1040000000003,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,464,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1102592.0,7.808,3710.9120000000003,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34456.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,465,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.464,3721.376,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",466,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,3724.8320000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,3728.2560000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",468,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.272,3734.5280000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",469,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3737.824,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",470,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3741.088,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.512,3745.6000000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,3750.0800000000004,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",473,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,144544.0,13.344,3763.4240000000004,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4517.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",474,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.616,3767.0400000000004,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,146944.0,13.504,3780.5440000000003,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4592.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",476,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.392,3783.936,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,477,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3068224.0,12.832,3796.768,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95882.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,478,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.312,3818.08,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",479,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,3821.536,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.616,3825.152,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",481,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.624,3831.776,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",482,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3835.104,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",483,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3838.432,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,3842.848,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,3847.36,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",486,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,24896.0,12.0,3859.36,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,778.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25248.0,12.0,3871.36,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,789.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",488,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26176.0,11.808,3883.168,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,818.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,3887.744,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",490,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.64,3892.384,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.6,3897.984,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,3902.656,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",493,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3906.08,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.736,3910.816,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,3915.2639999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,3920.5759999999996,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,3924.9919999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.296,3928.2879999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",499,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.704,3932.9919999999997,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",500,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.864,3937.8559999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",501,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.808,3953.6639999999998,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,502,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1105728.0,7.776,3961.4399999999996,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34554.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,503,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,3971.7759999999994,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.584,3975.359999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,3978.8159999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.048,3984.863999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3988.0319999999992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3991.423999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,3995.871999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,4000.351999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,145984.0,13.088,4013.439999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4562.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.808,4017.247999999999,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,144128.0,13.28,4030.5279999999993,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4504.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.552,4034.0799999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,515,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3051424.0,12.736,4046.8159999999993,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95357.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,516,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.344,4068.1599999999994,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,4071.6799999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,4075.0399999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",519,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.112,4081.1519999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",520,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,4084.6079999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,4088.1279999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.352,4092.4799999999996,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.544,4097.023999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",524,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25984.0,12.032,4109.056,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,812.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25760.0,11.872,4120.928,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,805.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25664.0,11.872,4132.8,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,802.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,4137.28,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.576,4141.856,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",529,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,4147.168,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.384,4151.552,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",531,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.424,4154.976,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,4159.5199999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.608,4164.128,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,4169.536,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4173.952,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",536,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,4177.344,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.608,4181.952,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",538,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.672,4186.624,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",539,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.648,4202.272,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,540,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1111808.0,7.808,4210.08,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34744.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,541,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,4220.672,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,4224.16,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,4227.36,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",544,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.496,4233.856,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",545,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4237.12,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",546,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,4240.64,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",547,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,4245.088000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",548,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.576,4249.664000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,148960.0,13.216,4262.880000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4655.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",550,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.968,4266.848000000001,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,147616.0,13.056,4279.904,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4613.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",552,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.296,4283.200000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,553,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3070656.0,12.704,4295.904,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95958.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,554,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.44,4317.344,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",555,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,4320.8,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.488,4324.2880000000005,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",557,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.464,4330.752,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",558,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,4333.888000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",559,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4337.152000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,4341.568000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,4346.048000000001,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25792.0,12.032,4358.080000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,806.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26784.0,12.0,4370.080000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,837.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",564,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26688.0,12.352,4382.432000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,834.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.576,4387.008000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.384,4391.392000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",567,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.696,4397.088000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4401.696000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,4405.312000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4409.920000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.544,4414.464000000001,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",572,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.408,4419.872000000001,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",573,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,4424.544000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",574,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,4427.872000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",575,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.512,4432.384000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.576,4436.960000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",577,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.616,4452.576000000001,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,578,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1104544.0,7.648,4460.224000000001,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34517.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,579,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.464,4470.688000000001,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.456,4474.144000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.552,4477.696000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.016,4483.712,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,4486.816000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,4490.2080000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.736,4494.944,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,4499.328,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681344.0,150592.0,13.344,4512.6720000000005,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396292.0,4706.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.744,4516.416,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",589,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,149600.0,13.28,4529.696,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4675.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.584,4533.28,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,591,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3066752.0,12.672,4545.951999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95836.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,592,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.6,4567.552,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",593,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,4570.9439999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,4574.24,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",595,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.016,4580.255999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",596,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,4583.5199999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",597,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.616,4587.1359999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",598,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.544,4591.679999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",599,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.768,4596.447999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",600,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26816.0,11.936,4608.383999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,838.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",601,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26016.0,12.096,4620.479999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,813.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",602,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,25856.0,12.0,4632.479999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,808.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.544,4637.0239999999985,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,4641.471999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",605,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.536,4647.007999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4651.615999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",607,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.264,4654.879999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,4659.487999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",609,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.352,4663.839999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",610,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.376,4669.215999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.448,4673.664,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,4677.28,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",613,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.832,4682.112,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",614,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.512,4686.624,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",615,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.616,4702.24,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,616,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106656.0,7.776,4710.016,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34583.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,617,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.592,4720.607999999999,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",618,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,4724.096,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",619,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.456,4727.552,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",620,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.464,4734.016,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",621,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,4737.312,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",622,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,4740.864,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.448,4745.312,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,4749.664,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",625,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,146208.0,13.088,4762.7519999999995,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4569.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",626,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.712,4766.464,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",627,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,143552.0,13.44,4779.9039999999995,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4486.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",628,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.456,4783.36,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,629,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3064896.0,12.736,4796.096,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95778.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,630,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.536,4817.632,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.232,4820.864,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.52,4824.384,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",633,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.688,4831.072,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",634,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4834.272,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",635,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4837.568,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",636,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.416,4841.984,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",637,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.544,4846.528,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",638,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26336.0,12.0,4858.528,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,823.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",639,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,24896.0,12.096,4870.624,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,778.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",640,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26464.0,12.128,4882.7519999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,827.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.768,4887.5199999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.384,4891.9039999999995,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",643,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,4897.375999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.64,4902.016,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",645,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.616,4905.632,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4910.048,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.256,4914.304,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.344,4919.648,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.416,4924.064,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,4927.616,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",651,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.544,4932.16,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",652,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.864,4937.023999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",653,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.648,4952.672,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,654,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1100448.0,7.776,4960.447999999999,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34389.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,655,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.336,4970.784,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",656,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.552,4974.335999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",657,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.424,4977.759999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",658,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.112,4983.871999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",659,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,4987.008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,4990.5599999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.704,4995.263999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.352,4999.615999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",663,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,150400.0,13.024,5012.639999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4700.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.808,5016.447999999999,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",665,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681472.0,149216.0,13.088,5029.535999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396296.0,4663.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",666,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.328,5032.864,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,667,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3065248.0,12.704,5045.567999999999,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95789.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,668,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.312,5066.879999999999,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",669,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.648,5070.527999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.296,5073.824,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",671,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,5.856,5079.679999999999,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",672,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,5083.071999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,5086.4,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",674,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,5090.879999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",675,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.512,5095.391999999999,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",676,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26464.0,12.0,5107.391999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,827.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",677,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,24672.0,12.16,5119.551999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,771.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,40320.0,0.8330683624801272,4721664.0,26976.0,12.064,5131.615999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,147552.0,843.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.608,5136.223999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.448,5140.672,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.312,5145.9839999999995,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.672,5150.655999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.488,5154.143999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.64,5158.784,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",685,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,4.512,5163.295999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",686,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,5.472,5168.767999999999,0.0,0.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",687,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,36864.0,24576.0,4.48,5173.247999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",688,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.392,5176.6399999999985,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",689,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.736,5181.375999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,480.0,0.0,49152.0,49152.0,4.48,5185.855999999998,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",691,98304.0,8828928.0,0.0,0,96636764160.0,8828928.0,96645593088.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,15.552,5201.407999999998,7443456.0,1188864.0,98304.0,0.0,0,0,0,0,0,0,0,0.0,0.0,377487360.0,3840.0,768.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,692,18892800.0,37748736.0,36864.0,0,0.0,37785600.0,37785600.0,74880.0,2304.0,0.9701492537313433,2949120.0,1106272.0,7.84,5209.247999999998,0.0,0.0,18874368.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,92160.0,34571.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,693,24576.0,344064.0,0.0,0,0.0,344064.0,344064.0,960.0,2496.0,0.2777777777777778,1179648.0,24576.0,10.56,5219.807999999998,294912.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36864.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",694,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.328,5223.135999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",695,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.2,5226.335999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",696,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,64.0,6.4,5232.735999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",697,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,5235.903999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",698,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,5239.295999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",699,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.48,5243.775999999997,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.48,5248.255999999997,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",701,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,152320.0,13.088,5261.343999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4760.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",702,307200.0,589824.0,49152.0,0,0.0,638976.0,638976.0,0.0,384.0,0.0,98304.0,98304.0,3.712,5265.055999999997,24576.0,0.0,282624.0,24576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",703,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12681216.0,148288.0,13.28,5278.335999999997,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396288.0,4634.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",704,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,3.36,5281.695999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6144.0,3072.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_kernel__5x_cublas,705,77907456.0,155713536.0,101376.0,0,0.0,155814912.0,155814912.0,307296.0,6336.0,0.9797979797979798,11796480.0,3067712.0,12.544,5294.239999999996,0.0,0.0,77856768.0,50688.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,95866.0
sm80_xmma_gemm_f32f32_f32f32_f32_tn_n_tilesize32x32x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4_execute_split_k_kernel__5x_cublas,706,24576.0,860160.0,0.0,0,0.0,860160.0,860160.0,960.0,6528.0,0.1282051282051282,3244032.0,24576.0,21.184,5315.423999999996,811008.0,0.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,101376.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",707,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,3.52,5318.943999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",708,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,3.36,5322.303999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",709,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,6.432,5328.735999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",710,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,5331.8399999999965,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",711,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,5335.039999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",712,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,25344.0,24576.0,4.384,5339.423999999996,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,6144.0,6144.0,12288.0,0,0.0,18432.0,18432.0,0.0,576.0,0.0,49152.0,24576.0,4.384,5343.807999999996,0.0,6144.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,65536.0,0.0,0.0,3450624.0,4.448,5348.255999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,107832.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,98304.0,0.0,0.0,3388864.0,4.224,5352.479999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,105902.0
"void scal_64addr_kernel<float, float, 1, 1, 6, 5, 5, 3>(cublasTransposeParams<T2>, const T1 *, T1 *, const T2 *)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,31328.0,0.0,0.0,953696.0,3.392,5355.871999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,29803.0
"void sgemm_largek_lds64<1, 0, 6, 3, 4, 5, 2, 66>(float *, const float *, const float *, int, int, int, int, int, int, const float *, const float *, float, float, int, int, int *, int *)",717,938361484.0,1874282496.0,4871448.0,0,0.0,1879153944.0,1879153944.0,18711868.0,4263704.0,0.8144244678652615,503771904.0,19598624.0,253.632,5609.503999999996,0.0,2430976.0,935925760.0,2435724.0,0,0,0,0,0,0,0,0.0,0.0,0.0,15742872.0,612457.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.72,5612.2239999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",719,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,4.256,5616.479999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,5619.775999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",721,0.0,1215488.0,0.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,4861952.0,4861952.0,5.792,5625.5679999999975,0.0,1215488.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,151936.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.104,5628.671999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,232704.0,8.0,5636.671999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7272.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",724,380160.0,0.0,760320.0,0,0.0,760320.0,760320.0,52272.0,637576.0,0.07577321380941889,39814528.0,0.0,13.44,5650.111999999997,0.0,0.0,0.0,380160.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1244204.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,230464.0,7.616,5657.727999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7202.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",726,228096.0,0.0,456192.0,0,0.0,456192.0,456192.0,52272.0,642328.0,0.075254822919666,39923808.0,32.0,13.472,5671.199999999997,0.0,0.0,0.0,228096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1247619.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,230208.0,7.68,5678.879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7194.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",728,342144.0,0.0,684288.0,0,0.0,684288.0,684288.0,52272.0,638764.0,0.07564294769013481,39842368.0,0.0,13.632,5692.511999999997,0.0,0.0,0.0,342144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1245074.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,12672.0,50656.0,0.20010106114199092,4866176.0,230080.0,7.648,5700.159999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152068.0,7190.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",730,326304.0,0.0,652608.0,0,0.0,652608.0,652608.0,52272.0,639259.0,0.07558880223735451,39852288.0,224.0,13.152,5713.311999999997,0.0,0.0,0.0,326304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1245384.0,7.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",731,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75.0,0.0,25376.0,3168.0,5.44,5718.751999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,793.0,99.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,5721.663999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",733,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3168.0,0.0,5.888,5727.551999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.072,5730.623999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,59.0,0.9155937052932761,3168.0,0.0,5.92,5736.543999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",736,202752.0,0.0,405504.0,0,0.0,405504.0,405504.0,317586.0,64000.0,0.8322789620164261,4940544.0,20832.0,12.544,5749.087999999997,0.0,0.0,0.0,202752.0,0,0,0,0,0,0,0,0.0,0.0,0.0,154392.0,651.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,8.576,5757.663999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",738,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,4895104.0,376832.0,8.64,5766.303999999997,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152972.0,11776.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,3072.0,6.176,5772.479999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,189920.0,96.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",740,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,37984.0,0.0,0.0,9723904.0,7.744,5780.223999999997,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,303872.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,37984.0,0.7806320458325633,4861952.0,0.0,8.384,5788.607999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",742,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.392,5791.999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,341855.0,169009.0,0.6691702684080303,17063296.0,12039232.0,28.16,5820.159999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,533228.0,376226.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",744,0.0,0.0,0.0,0,0.0,0.0,0.0,77903.0,180391.0,0.3016059219339203,17212416.0,14818304.0,22.592,5842.751999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,537888.0,463072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,78843.0,180905.0,0.3035365046121626,17202688.0,14818304.0,23.52,5866.271999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,537584.0,463072.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,78843.0,180392.0,0.30413717283545816,17166336.0,12974144.0,23.424,5889.695999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,536448.0,405442.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,37984.0,0.2801697998787144,9723904.0,0.0,7.456,5897.151999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.616,5900.767999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",749,0.0,0.0,0.0,0,0.0,0.0,0.0,78004.0,149612.0,0.34269998594123435,13627904.0,8490688.0,18.336,5919.1039999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,425872.0,265334.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,151936.0,0.0,14664160.0,14585856.0,12.384,5931.487999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,458255.0,455808.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",751,18849392.0,40153344.0,3665120.0,0,0.0,43818464.0,43818464.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,87.296,6018.783999999998,4904192.0,1215488.0,17016832.0,1832560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,455808.0,151936.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",752,0.0,6104232.0,0.0,0,0.0,6104232.0,6104232.0,669744.0,75968.0,0.8981268908103933,4861952.0,4861952.0,286.272,6305.055999999998,6104232.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,151936.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,18992.0,0.0,4861952.0,1215488.0,5.216,6310.271999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,37984.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,3.232,6313.503999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",755,2430976.0,0.0,4861952.0,0,0.0,4861952.0,4861952.0,0.0,113952.0,0.0,10939392.0,595136.0,12.16,6325.663999999998,0.0,0.0,0.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,341856.0,18598.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,28488.0,0.0,6077440.0,1408.0,6.208,6331.871999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,189920.0,44.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",757,18849410.0,40153344.0,3665156.0,0,0.0,43818500.0,43818500.0,1056.0,38272.0,0.026851098454027666,14585856.0,4861952.0,87.2,6419.071999999997,4904192.0,1215488.0,17016832.0,1832578.0,0,0,0,0,0,0,0,0.0,0.0,0.0,455808.0,151936.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",758,229376.0,0.0,458752.0,0,0.0,458752.0,458752.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.112,6429.1839999999975,0.0,0.0,0.0,229376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6432.543999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",760,229376.0,0.0,458752.0,0,0.0,458752.0,458752.0,11833.0,9651.0,0.5507819772854217,4862560.0,4800.0,10.048,6442.591999999997,0.0,0.0,0.0,229376.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151955.0,150.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",761,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,6445.855999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",762,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.168,6449.023999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",763,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,6453.599999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",764,238784.0,1971352.0,477568.0,0,0.0,2448920.0,2448920.0,14744.0,9664.0,0.6040642412323828,4862784.0,4992.0,10.112,6463.711999999997,1971352.0,0.0,0.0,238784.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151962.0,156.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",765,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,6466.911999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",766,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.896,6471.807999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",767,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6475.135999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",768,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,6479.711999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",769,4325376.0,9459712.0,1622016.0,0,0.0,11081728.0,11081728.0,0.0,37984.0,0.0,0.0,4861952.0,9.312,6489.023999999997,0.0,2430976.0,3514368.0,811008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",770,7596418.0,12154880.0,3037956.0,0,0.0,15192836.0,15192836.0,0.0,28488.0,0.0,9723904.0,0.0,9.12,6498.143999999997,0.0,0.0,6077440.0,1518978.0,0,0,0,0,0,0,0,0.0,0.0,0.0,303872.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",771,169472.0,0.0,338944.0,0,0.0,338944.0,338944.0,26904.0,9824.0,0.7325201481158788,4864512.0,5184.0,13.376,6511.519999999997,0.0,0.0,0.0,169472.0,0,0,0,0,0,0,0,0.0,0.0,0.0,152016.0,162.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",772,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,192.0,320.0,4.256,6515.775999999997,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",773,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,6518.5279999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",774,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,6521.279999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",775,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.584,6524.863999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",776,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,6528.191999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",777,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,64.0,4.224,6532.415999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",778,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,4.544,6536.959999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",779,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,6540.319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
