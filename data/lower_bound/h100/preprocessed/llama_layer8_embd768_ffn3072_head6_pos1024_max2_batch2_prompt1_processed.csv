Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.04,3.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.592,5.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,8.448,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.2,11.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,15.296,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.744,19.04,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.192,23.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.992,28.224,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,31.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,34.496,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,37.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,40.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.712,44.096000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,47.29600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,50.81600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.0,54.81600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.104,57.92000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,61.24800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.584,64.83200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,5.088,69.92,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,73.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.376,78.88000000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,82.24000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.584,85.82400000000001,0.0,256.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,4.0,89.82400000000001,0.0,0.0,0.0,320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,2048.0,4608.0,0.0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,4.224,94.04800000000002,0.0,512.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.424,97.47200000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,1792.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,16.0,0.0,1024.0,1024.0,3.968,101.44000000000003,0.0,512.0,1792.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.328,104.76800000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.84,108.60800000000003,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.824,114.43200000000003,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,117.63200000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,121.08800000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.544,125.63200000000003,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,130.36800000000002,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),36,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,12.0,142.36800000000002,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",37,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,147.20000000000002,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),38,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.456,158.656,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",39,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.248,163.904,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),40,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.52,175.424,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",41,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.576,180.0,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.672,184.672,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",43,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.736,189.408,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",44,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.472,194.88,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.416,199.296,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",46,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,202.75199999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.672,207.42399999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",48,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.032,211.456,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",49,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.44,216.896,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",50,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.576,221.47199999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,224.95999999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",52,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.36,240.32,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),53,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,251.68,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",54,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.928,256.608,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",55,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,260.128,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,263.55199999999996,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",57,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.376,268.92799999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",58,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,272.15999999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,275.424,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",60,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.32,279.74399999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,284.128,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35008.0,9.216,293.344,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1094.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,4.192,297.536,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",64,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34624.0,9.696,307.232,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1082.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",65,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,310.59200000000004,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",66,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,7072.0,19.712,330.30400000000003,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,221.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",67,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,333.79200000000003,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",68,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,337.184,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",69,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.664,342.848,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",70,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,346.272,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",71,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,349.824,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,354.08000000000004,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.576,358.65600000000006,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),74,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.776,370.4320000000001,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",75,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.928,375.36000000000007,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),76,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,386.68800000000005,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",77,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,391.52000000000004,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),78,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,402.944,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",79,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.024,407.968,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,412.48,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.256,416.736,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",82,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,422.01599999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,426.62399999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",84,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,429.95199999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",85,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,434.27199999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",86,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.576,438.84799999999996,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",87,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,444.22399999999993,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,448.5759999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",89,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,452.0319999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",90,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.552,467.58399999999995,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),91,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,478.9119999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",92,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.608,483.5199999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",93,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,486.9439999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.712,490.6559999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",95,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.792,496.44799999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",96,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,499.7119999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",97,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,503.10399999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",98,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.608,507.7119999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,512.2559999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",100,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34944.0,9.344,521.5999999999999,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1092.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.872,525.4719999999999,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35040.0,9.536,535.0079999999998,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1095.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",103,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.488,538.4959999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6784.0,19.136,557.6319999999998,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,212.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",105,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,561.3119999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",106,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,564.7679999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",107,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.696,570.4639999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",108,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,573.8559999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",109,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,577.1199999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.768,581.8879999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.608,586.4959999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),112,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.68,598.1759999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",113,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,602.9439999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),114,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,614.2399999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",115,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.12,619.3599999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),116,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,630.7839999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",117,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,635.5839999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",118,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,640.0639999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",119,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.48,644.5439999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",120,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.696,650.2399999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.256,654.4959999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",122,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,658.0159999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",123,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.704,662.7199999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.256,666.9759999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",125,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,672.3519999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,676.9919999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",127,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.68,680.6719999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",128,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.552,696.2239999999997,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),129,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,707.5839999999997,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",130,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.704,712.2879999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.744,716.0319999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,719.4879999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,725.0239999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,728.5119999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,732.0639999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,736.5119999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.256,740.7679999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35680.0,9.248,750.0159999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1115.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",139,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,4.096,754.1119999999997,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35552.0,9.152,763.2639999999998,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1111.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",141,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.296,766.5599999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6688.0,19.648,786.2079999999999,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,209.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,789.7279999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",144,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.488,793.2159999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",145,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.312,798.5279999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",146,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,801.7919999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,805.0239999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",148,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,809.4079999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.384,813.7919999999999,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),150,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.584,825.3759999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",151,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.152,830.5279999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),152,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,841.9519999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",153,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,846.7519999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),154,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,858.0799999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",155,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,862.8799999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,867.3599999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",157,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.288,871.6479999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",158,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,877.0559999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.736,881.7919999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",160,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,885.4079999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",161,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,889.7599999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.48,894.2399999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",163,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.248,899.4879999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",164,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,903.9999999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,907.5199999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",166,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.52,923.0399999999997,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),167,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,934.3999999999997,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",168,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.928,939.3279999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",169,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,942.6879999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",170,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,946.1439999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",171,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,951.6799999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",172,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,954.8799999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",173,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,958.1119999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.8,962.9119999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,967.4559999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",176,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35136.0,9.504,976.9599999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1098.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",177,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.68,980.6399999999996,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34368.0,9.216,989.8559999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1074.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",179,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,993.2479999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",180,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6464.0,19.68,1012.9279999999997,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,202.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,1016.3519999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",182,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.552,1019.9039999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",183,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,6.112,1026.0159999999996,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",184,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,1029.2479999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1032.4479999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",186,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.48,1036.9279999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",187,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.672,1041.5999999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),188,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,1052.9599999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",189,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,1057.7279999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),190,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,1069.0879999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",191,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,1073.9199999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),192,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,1085.3119999999997,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",193,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.576,1089.8879999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",194,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,1094.4959999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",195,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.672,1099.1679999999997,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",196,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.472,1104.6399999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,1108.9919999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",198,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,1112.3839999999998,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.672,1117.0559999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",200,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.256,1121.312,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",201,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,1126.6239999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,1131.1039999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",203,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,1134.5599999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",204,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.488,1150.0479999999998,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),205,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.488,1161.5359999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",206,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,1166.4959999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",207,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,1170.08,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",208,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.616,1173.696,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",209,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.216,1178.9119999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",210,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1182.1759999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",211,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1185.4399999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,1189.8879999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",213,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.32,1194.2079999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",214,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34496.0,9.76,1203.9679999999996,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1078.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.872,1207.8399999999997,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",216,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34336.0,9.504,1217.3439999999996,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1073.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",217,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.2,1220.5439999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",218,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,7072.0,19.616,1240.1599999999996,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,221.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",219,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.456,1243.6159999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",220,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.552,1247.1679999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",221,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,1252.7039999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",222,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1255.9679999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",223,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1259.3279999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.544,1263.8719999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",225,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.48,1268.3519999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),226,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,1279.7439999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",227,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.64,1284.3839999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),228,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,1295.6799999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",229,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,1300.5759999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),230,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.456,1312.0319999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",231,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,1316.9279999999994,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",232,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,1321.3119999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",233,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.288,1325.5999999999995,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",234,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.312,1330.9119999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,1335.5519999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",236,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.328,1338.8799999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,1343.2639999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.416,1347.6799999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",239,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,1353.0559999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,1357.5999999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",241,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,1360.9919999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",242,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.552,1376.5439999999994,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),243,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.232,1387.7759999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",244,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,1392.5759999999993,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",245,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,1396.0959999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.616,1399.7119999999993,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",247,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.728,1405.4399999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",248,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,1408.8639999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",249,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1412.0639999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",250,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.768,1416.8319999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,1421.5679999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",252,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34592.0,9.472,1431.0399999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1081.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.936,1434.9759999999994,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,33408.0,9.312,1444.2879999999993,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1044.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",255,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.584,1447.8719999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",256,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6304.0,19.424,1467.2959999999994,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,197.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",257,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,1470.8159999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",258,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,1474.1759999999992,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",259,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.952,1480.1279999999992,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",260,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1483.3279999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1486.5599999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",262,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.512,1491.0719999999992,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",263,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,1495.8079999999993,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),264,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,1507.2319999999993,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",265,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.736,1511.9679999999994,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),266,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.488,1523.4559999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",267,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,1528.2239999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),268,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,1539.5839999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",269,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,1544.3839999999993,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,1549.0239999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.672,1553.6959999999995,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",272,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.44,1559.1359999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.448,1563.5839999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,1567.1039999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,1571.7119999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.224,1575.9359999999995,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,1581.3439999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.8,1586.1439999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",279,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.712,1589.8559999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",280,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.68,1605.5359999999994,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),281,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,1616.9279999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",282,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,1621.7599999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,1625.2479999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",284,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,1628.6399999999996,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",285,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.536,1634.1759999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",286,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,1637.5039999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.584,1641.0879999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.512,1645.5999999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.256,1649.8559999999998,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",290,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35392.0,9.312,1659.1679999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1106.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",291,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.968,1663.1359999999997,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",292,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36480.0,9.472,1672.6079999999997,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1140.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",293,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.232,1675.8399999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",294,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,7072.0,20.0,1695.8399999999997,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,221.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",295,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,1699.3599999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",296,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.584,1702.9439999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",297,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.344,1708.2879999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",298,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,1711.7439999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1715.0079999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",300,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.288,1719.2959999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",301,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.352,1723.6479999999997,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),302,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,1735.0399999999997,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",303,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,1739.9999999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),304,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.488,1751.4879999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",305,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,1756.2559999999999,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),306,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.424,1767.6799999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",307,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,1772.4799999999998,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",308,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,1776.8639999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",309,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.288,1781.1519999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,1786.5599999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",311,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.672,1791.2319999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",312,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,1794.6559999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",313,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.48,1799.1359999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",314,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.352,1803.4879999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",315,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,1808.8959999999997,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",316,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,1813.2479999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",317,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,1816.6399999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",318,24576.0,2206464.0,0.0,0,24159191040.0,2206464.0,24161397504.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,15.712,1832.3519999999999,1860096.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,576.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),319,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.552,1843.9039999999998,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",320,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,1848.7999999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",321,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,1852.4479999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",322,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,1855.9039999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",323,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.504,1861.4079999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",324,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1864.6079999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",325,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1867.8399999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.768,1872.6079999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",327,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.608,1877.2159999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",328,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34336.0,9.184,1886.3999999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1073.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",329,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.744,1890.1439999999993,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",330,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34784.0,9.056,1899.1999999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1087.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",331,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.52,1902.7199999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",332,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6720.0,18.88,1921.5999999999995,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,210.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",333,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,1925.1519999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,1928.5439999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",335,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.696,1934.2399999999993,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",336,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1937.4399999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",337,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1940.6719999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",338,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.704,1945.3759999999993,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",339,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.8,1950.1759999999992,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",340,49664000.0,108544000.0,1024000.0,0,0.0,109568000.0,109568000.0,1200000.0,992000.0,0.5474452554744526,99431296.0,374592.0,41.12,1991.2959999999991,4096000.0,6144000.0,49152000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3107228.0,11706.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1994.047999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",342,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.448,1998.4959999999992,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",343,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2001.6959999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",344,128.0,64512.0,256.0,0,0.0,64768.0,64768.0,0.0,1024.0,0.0,256000.0,256000.0,3.424,2005.1199999999992,0.0,64512.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.104,2008.2239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16896.0,5.76,2013.9839999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,528.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",347,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,4224.0,17220.0,0.1969781757134863,1054720.0,0.0,6.272,2020.2559999999992,0.0,0.0,0.0,30720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",348,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16768.0,5.728,2025.9839999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,524.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",349,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,4224.0,17604.0,0.19351291918636612,1054720.0,0.0,6.24,2032.2239999999993,0.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16832.0,5.856,2038.0799999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,526.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",351,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,4224.0,17156.0,0.19756782039289056,1054720.0,0.0,6.336,2044.4159999999993,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16960.0,5.632,2050.0479999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,530.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",353,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,4224.0,17220.0,0.1969781757134863,1054720.0,64.0,6.464,2056.5119999999993,0.0,0.0,0.0,30720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6.0,0.0,2080.0,256.0,3.776,2060.287999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,2063.167999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,256.0,0.0,5.152,2068.3199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,2071.423999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,256.0,0.0,5.504,2076.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",359,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,12792.0,4208.0,0.7524705882352941,263616.0,3776.0,8.352,2085.279999999999,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8238.0,118.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,8.864,2094.143999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",361,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,260032.0,20128.0,6.016,2100.159999999999,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8126.0,629.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,4.768,2104.927999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",363,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,0.0,512000.0,3.552,2108.479999999999,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,2000.0,0.9854193397877056,256000.0,0.0,5.792,2114.271999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.712,2117.983999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,20844.0,8635.0,0.707079615997829,828800.0,625536.0,14.176,2132.159999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25900.0,19548.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,5448.0,8662.0,0.3861091424521616,829440.0,780288.0,11.52,2143.679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25920.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,6804.0,8597.0,0.44178949418868907,828672.0,780288.0,12.928,2156.607999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25896.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,6804.0,8600.0,0.441703453648403,824576.0,709504.0,13.024,2169.6319999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25768.0,22172.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,2000.0,0.880838894184938,512000.0,0.0,4.672,2174.3039999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.328,2177.6319999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,5260.0,4592.0,0.5339017458384084,565248.0,453696.0,9.344,2186.9759999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,17664.0,14178.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",373,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,774720.0,768000.0,4.48,2191.4559999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24210.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",374,997276.0,2122560.0,202552.0,0,0.0,2325112.0,2325112.0,264.0,2624.0,0.09141274238227147,256512.0,256000.0,22.976,2214.431999999999,266560.0,64000.0,896000.0,101276.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8016.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",375,0.0,327744.0,0.0,0,0.0,327744.0,327744.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,63.04,2277.471999999999,327744.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1024.0,0.0,256000.0,63616.0,3.616,2281.087999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",377,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.232,2284.319999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",378,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,576000.0,29248.0,11.936,2296.255999999999,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18000.0,914.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,4.768,2301.023999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",380,997282.0,2122560.0,202564.0,0,0.0,2325124.0,2325124.0,264.0,2624.0,0.09141274238227147,256000.0,256000.0,22.592,2323.615999999999,266560.0,64000.0,896000.0,101282.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",381,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,18.272,2341.887999999999,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2345.183999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",383,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,18.624,2363.8079999999986,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2367.1999999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",385,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2370.4959999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,2375.039999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",387,2048.0,73600.0,4096.0,0,0.0,77696.0,77696.0,152.0,502.0,0.2324159021406728,256000.0,64.0,12.32,2387.3599999999983,73600.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2390.6239999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,4.768,2395.3919999999985,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",390,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,2398.6239999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",391,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.672,2403.2959999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",392,704000.0,1280000.0,256000.0,0,0.0,1536000.0,1536000.0,0.0,2000.0,0.0,0.0,256000.0,4.16,2407.4559999999983,0.0,128000.0,576000.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",393,400034.0,640000.0,160068.0,0,0.0,800068.0,800068.0,0.0,1536.0,0.0,512000.0,0.0,5.024,2412.479999999998,0.0,0.0,320000.0,80034.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",394,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,304.0,502.0,0.3771712158808933,256000.0,64.0,16.8,2429.2799999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",395,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2432.6399999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",396,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2435.9999999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.584,2439.5839999999985,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",398,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.2,2442.7839999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",399,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.384,2447.1679999999983,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2449.9519999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",401,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2452.7039999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",402,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,2455.999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",403,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2458.847999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",404,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.096,2462.943999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",405,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,32.0,32.0,5.632,2468.575999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",406,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,2471.8399999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",407,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2475.327999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",408,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,2479.295999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",409,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.8,2484.095999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",410,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2487.391999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",411,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,2490.847999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",412,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,4.672,2495.519999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",413,0.0,0.0,0.0,0,0.0,0.0,0.0,36.0,2.0,0.9473684210526315,32.0,32.0,4.064,2499.583999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",414,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,2502.751999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",415,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2506.047999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",416,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.328,2509.375999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",417,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,3.84,2513.215999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",418,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,144.0,0.0,3264.0,6144.0,5.184,2518.3999999999983,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",419,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,2521.9519999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",420,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.832,2526.7839999999983,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",421,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2530.0479999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",422,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.456,2533.5039999999985,0.0,256.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",423,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,4.352,2537.8559999999984,0.0,0.0,0.0,320.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,2048.0,4608.0,0.0,0,0.0,4608.0,4608.0,0.0,16.0,0.0,1024.0,1024.0,4.128,2541.9839999999986,0.0,512.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",425,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.328,2545.3119999999985,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,1800.0,4112.0,0.0,0,0.0,4112.0,4112.0,0.0,16.0,0.0,1024.0,1024.0,4.384,2549.6959999999985,0.0,512.0,1800.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",427,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,16.0,0.0,1024.0,1024.0,3.36,2553.0559999999987,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,2556.4479999999985,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",429,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.76,2562.2079999999987,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",430,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2565.3119999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",431,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,2568.4159999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",432,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.224,2572.6399999999985,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,2577.3759999999984,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),434,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,2588.7359999999985,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",435,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,2593.6319999999987,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),436,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,2604.9599999999987,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",437,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,2609.8239999999987,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),438,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.264,2621.087999999999,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",439,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.736,2625.8239999999987,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",440,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,2630.2079999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.544,2634.7519999999986,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",442,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,2640.127999999999,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,2644.4799999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,2647.839999999999,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,2652.3839999999987,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.352,2656.7359999999985,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",447,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,2662.1439999999984,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,2666.6879999999983,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",449,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,2670.2079999999983,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.608,2674.8159999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.192,2679.0079999999984,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",452,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.328,2694.3359999999984,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),453,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,2705.6959999999985,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",454,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,2710.4959999999987,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,2713.8879999999986,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.52,2717.4079999999985,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.792,2723.1999999999985,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2726.3999999999983,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,2729.5359999999982,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,2733.791999999998,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,2738.335999999998,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34528.0,9.312,2747.647999999998,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1079.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.904,2751.551999999998,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35840.0,9.312,2760.8639999999978,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1120.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.392,2764.2559999999976,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6656.0,19.168,2783.4239999999977,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,208.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,2786.8479999999977,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,2790.1759999999977,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,2796.0639999999976,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2799.1999999999975,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2802.4639999999977,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,2806.8479999999977,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,2811.3919999999976,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),474,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,2822.6879999999974,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.704,2827.3919999999976,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),476,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,2838.7839999999974,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",477,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,2843.6159999999973,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),478,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.264,2854.8799999999974,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",479,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,2859.6799999999976,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.576,2864.2559999999976,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.512,2868.7679999999978,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",482,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.536,2874.303999999998,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.576,2878.879999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",484,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,2882.2719999999977,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.864,2887.1359999999977,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.384,2891.5199999999977,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.536,2897.0559999999978,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",488,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,2901.5999999999976,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",489,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,2905.1839999999975,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",490,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.768,2909.9519999999975,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",491,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.16,2914.1119999999974,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",492,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.296,2929.407999999997,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),493,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,2940.703999999997,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",494,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,2945.471999999997,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",495,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,2949.055999999997,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,2952.415999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",497,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.696,2958.111999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",498,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2961.343999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,2964.479999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.16,2968.6399999999967,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",501,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,2973.3759999999966,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34912.0,9.312,2982.6879999999965,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1091.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",503,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.904,2986.5919999999965,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",504,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34432.0,9.312,2995.9039999999964,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1076.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",505,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.456,2999.3599999999965,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",506,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6720.0,20.0,3019.3599999999965,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,210.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",507,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,3022.8799999999965,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,3026.2399999999966,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",509,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.824,3032.0639999999967,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",510,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3035.3599999999965,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",511,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3038.6879999999965,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",512,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.32,3043.0079999999966,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.576,3047.5839999999966,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),514,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3058.9119999999966,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",515,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.928,3063.8399999999965,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),516,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,3075.2319999999963,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",517,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,3080.0959999999964,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),518,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.232,3091.3279999999963,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",519,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.736,3096.063999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3100.703999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.704,3105.4079999999963,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",522,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.248,3110.6559999999963,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",523,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.512,3115.1679999999965,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",524,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,3118.5279999999966,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.672,3123.1999999999966,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",526,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.544,3127.7439999999965,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",527,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,3133.1519999999964,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",528,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3137.7919999999963,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",529,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,3141.279999999996,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",530,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.64,3145.919999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.256,3150.175999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",532,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.328,3165.503999999996,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),533,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3176.831999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",534,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,3181.6639999999957,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",535,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,3185.2479999999955,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,3188.6399999999953,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",537,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.76,3194.3999999999955,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",538,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3197.5999999999954,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",539,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3200.895999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",540,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.288,3205.183999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.672,3209.855999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",542,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36448.0,9.056,3218.9119999999953,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1139.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.712,3222.6239999999952,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",544,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35456.0,9.44,3232.0639999999953,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1108.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",545,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.424,3235.4879999999953,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6976.0,19.136,3254.6239999999952,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,218.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3258.047999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",548,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.52,3261.567999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",549,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.824,3267.3919999999953,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",550,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3270.5279999999952,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",551,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3273.663999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,3278.111999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.672,3282.783999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),554,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3294.111999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",555,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,3298.879999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),556,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3310.207999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",557,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,3315.1039999999953,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),558,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.808,3326.9119999999953,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",559,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,3331.7759999999953,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",560,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3336.127999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.512,3340.6399999999953,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",562,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.504,3346.1439999999952,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.32,3350.4639999999954,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,3354.0159999999955,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,3358.6239999999957,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.384,3363.0079999999957,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",567,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,3368.3519999999958,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3372.7039999999956,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",569,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,3376.3519999999958,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",570,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.608,3380.959999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",571,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.16,3385.119999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",572,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.776,3400.8959999999956,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),573,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,3412.1919999999955,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",574,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,3417.0879999999956,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,3420.6719999999955,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,3424.0639999999953,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.984,3430.047999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3433.2159999999953,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3436.3519999999953,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,3440.607999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,3445.151999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35040.0,9.216,3454.367999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1095.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",583,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.712,3458.079999999995,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34816.0,9.216,3467.295999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1088.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",585,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.52,3470.815999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",586,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6432.0,19.264,3490.079999999995,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,201.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",587,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.584,3493.6639999999948,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.456,3497.119999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",589,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.856,3502.975999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",590,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3506.111999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3509.215999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.48,3513.695999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.608,3518.303999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),594,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,3529.599999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",595,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.64,3534.239999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),596,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,3545.599999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",597,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.12,3550.719999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),598,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.232,3561.9519999999948,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",599,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,3566.815999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",600,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,3571.3599999999947,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.416,3575.775999999995,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",602,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,3581.1839999999947,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.64,3585.8239999999946,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",604,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3589.2159999999944,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,3593.7599999999943,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.448,3598.207999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",607,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.344,3603.551999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.384,3607.9359999999942,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",609,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.712,3611.647999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",610,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.768,3616.4159999999943,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",611,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.16,3620.575999999994,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",612,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.552,3636.1279999999942,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),613,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3647.455999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",614,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,3652.3199999999943,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",615,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,3655.7439999999942,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.264,3659.0079999999944,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",617,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.856,3664.8639999999946,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",618,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3668.1599999999944,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",619,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3671.263999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.064,3675.327999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.704,3680.0319999999942,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",622,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35072.0,9.216,3689.247999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",623,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.84,3693.0879999999943,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",624,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35456.0,9.216,3702.303999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1108.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",625,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,3705.6639999999943,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",626,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6400.0,19.456,3725.1199999999944,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,200.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",627,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.488,3728.6079999999943,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.36,3731.9679999999944,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",629,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.792,3737.7599999999943,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",630,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,3740.9919999999943,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",631,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,3744.095999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",632,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.256,3748.351999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.736,3753.087999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),634,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3764.415999999994,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",635,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,3769.375999999994,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),636,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,3780.7679999999937,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",637,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,3785.7279999999937,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),638,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.232,3796.9599999999937,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",639,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.8,3801.759999999994,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,3806.047999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.48,3810.527999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",642,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.408,3815.935999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3820.2879999999936,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",644,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,3823.6479999999938,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",645,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.864,3828.511999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.576,3833.087999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",647,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,3838.463999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",648,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,3842.815999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",649,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.616,3846.431999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",650,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.832,3851.2639999999938,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",651,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.096,3855.3599999999938,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",652,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.52,3870.8799999999937,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),653,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,3882.2079999999937,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",654,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.864,3887.0719999999937,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3890.4639999999936,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",656,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.392,3893.8559999999934,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",657,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.824,3899.6799999999935,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",658,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3902.8479999999936,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",659,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,3905.9839999999936,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.352,3910.3359999999934,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,3914.8799999999933,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",662,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,35744.0,9.056,3923.9359999999933,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1117.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",663,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.808,3927.7439999999933,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",664,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36160.0,9.152,3936.8959999999934,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1130.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",665,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.488,3940.383999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",666,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6944.0,19.744,3960.1279999999933,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,217.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,3963.519999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,3966.943999999993,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",669,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.856,3972.7999999999934,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",670,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3975.9679999999935,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",671,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.072,3979.0399999999936,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.352,3983.3919999999935,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",673,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.576,3987.9679999999935,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),674,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,3999.3279999999936,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",675,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.056,4004.3839999999936,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),676,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,4015.7119999999936,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",677,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,4020.6719999999937,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),678,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.296,4031.9679999999935,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",679,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,4036.7999999999934,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",680,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,4041.0879999999934,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.448,4045.5359999999932,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",682,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.216,4050.751999999993,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",683,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,4055.103999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.36,4058.463999999993,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",685,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.608,4063.0719999999933,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",686,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.224,4067.2959999999935,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",687,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.504,4072.7999999999934,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.416,4077.2159999999935,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",689,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.648,4080.8639999999937,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",690,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.672,4085.5359999999937,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",691,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.352,4089.8879999999936,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",692,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.424,4105.3119999999935,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),693,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.2,4116.511999999993,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",694,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.768,4121.279999999993,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",695,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.52,4124.799999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",696,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.616,4128.415999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",697,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.728,4134.143999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",698,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4137.343999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,4140.479999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.448,4144.927999999994,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",701,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.448,4149.375999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",702,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34336.0,9.632,4159.007999999994,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1073.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",703,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.872,4162.879999999995,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",704,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34240.0,9.344,4172.223999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1070.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",705,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,4175.583999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",706,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6720.0,19.808,4195.391999999994,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,210.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",707,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,4198.815999999994,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",708,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,4202.143999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",709,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.76,4207.903999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",710,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,4211.199999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",711,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,4214.3039999999955,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",712,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.384,4218.687999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,4223.231999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),714,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.36,4234.591999999995,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",715,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.832,4239.423999999995,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),716,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,4250.751999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",717,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.896,4255.647999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),718,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.328,4266.975999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",719,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,4.96,4271.935999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",720,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.352,4276.287999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",721,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.448,4280.735999999996,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.28,4286.015999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",723,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.288,4290.3039999999955,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",724,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,4293.7279999999955,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",725,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.576,4298.3039999999955,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",726,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,4.32,4302.623999999995,768.0,0.0,0.0,1152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",727,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,5.376,4307.999999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,9216.0,6144.0,4.544,4312.543999999995,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",729,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.424,4315.967999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",730,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.8,4320.7679999999955,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,120.0,0.0,12288.0,12288.0,4.256,4325.023999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",732,24576.0,2207232.0,0.0,0,24159191040.0,2207232.0,24161398272.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,15.424,4340.447999999996,1860864.0,297216.0,24576.0,0.0,0,0,0,0,0,0,0,0.0,0.0,94371840.0,960.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),733,18874368.0,38338560.0,0.0,0,0.0,38338560.0,38338560.0,93888.0,1152.0,0.9878787878787879,2396160.0,147456.0,11.392,4351.839999999996,0.0,589824.0,18874368.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,74880.0,4608.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",734,1536.0,38400.0,3072.0,0,0.0,41472.0,41472.0,0.0,1200.0,0.0,147456.0,6144.0,5.152,4356.991999999996,36864.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4608.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",735,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.392,4360.3839999999955,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.424,4363.807999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",737,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,4369.695999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",738,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4372.927999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",739,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,4376.031999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",740,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.608,4380.639999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",741,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.544,4385.183999999996,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",742,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,36736.0,9.152,4394.335999999996,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1148.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",743,76800.0,147456.0,12288.0,0,0.0,159744.0,159744.0,0.0,96.0,0.0,24576.0,24576.0,3.744,4398.079999999995,6144.0,0.0,70656.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",744,4767744.0,10420224.0,98304.0,0,0.0,10518528.0,10518528.0,115200.0,95232.0,0.5474452554744526,10248192.0,34368.0,9.248,4407.327999999995,393216.0,589824.0,4718592.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,320256.0,1074.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,3.36,4410.687999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",746,4730880.0,10346496.0,24576.0,0,0.0,10371072.0,10371072.0,104832.0,92928.0,0.5300970873786408,11796480.0,6624.0,20.064,4430.751999999995,319488.0,589824.0,4718592.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,368640.0,207.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",747,2176.0,4096.0,256.0,0,0.0,4352.0,4352.0,0.0,72.0,0.0,12288.0,6144.0,3.552,4434.303999999995,0.0,0.0,2048.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",748,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,3.328,4437.631999999995,0.0,1536.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",749,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,5.888,4443.519999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",750,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,4446.591999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",751,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,4449.695999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",752,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.16,4453.855999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",753,1536.0,1536.0,3072.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,12288.0,6144.0,4.768,4458.623999999995,0.0,1536.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",754,49664000.0,108544000.0,1024000.0,0,0.0,109568000.0,109568000.0,1200000.0,992000.0,0.5474452554744526,99447168.0,370560.0,39.488,4498.1119999999955,4096000.0,6144000.0,49152000.0,512000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3107724.0,11580.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",755,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4500.831999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",756,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,3.968,4504.799999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,4507.967999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",758,128.0,64512.0,256.0,0,0.0,64768.0,64768.0,0.0,1024.0,0.0,256000.0,256000.0,3.52,4511.487999999996,0.0,64512.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4514.367999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16832.0,5.728,4520.095999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,526.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",761,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,4224.0,17220.0,0.1969781757134863,1054720.0,0.0,6.432,4526.527999999996,0.0,0.0,0.0,30720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",762,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16832.0,5.824,4532.351999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,526.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",763,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,4224.0,17604.0,0.19351291918636612,1054720.0,0.0,6.304,4538.655999999995,0.0,0.0,0.0,18432.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",764,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16640.0,5.664,4544.319999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,520.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",765,30720.0,0.0,61440.0,0,0.0,61440.0,61440.0,4224.0,17220.0,0.1969781757134863,1054720.0,0.0,6.336,4550.655999999995,0.0,0.0,0.0,30720.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",766,0.0,0.0,0.0,0,0.0,0.0,0.0,1024.0,3024.0,0.25296442687747034,258048.0,16896.0,5.824,4556.479999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8064.0,528.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",767,26624.0,0.0,53248.0,0,0.0,53248.0,53248.0,4224.0,17348.0,0.19580938253291302,1054720.0,64.0,6.272,4562.751999999995,0.0,0.0,0.0,26624.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",768,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,6.0,0.0,2080.0,256.0,3.904,4566.655999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",769,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,4569.759999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",770,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,256.0,0.0,5.376,4575.135999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",771,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.848,4577.983999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",772,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,13.0,0.9800918836140888,256.0,0.0,5.44,4583.423999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",773,16384.0,0.0,32768.0,0,0.0,32768.0,32768.0,14596.0,4212.0,0.7760527435133986,263616.0,3264.0,8.704,4592.127999999995,0.0,0.0,0.0,16384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8238.0,102.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",774,0.0,0.0,0.0,0,0.0,0.0,0.0,916.0,16.0,0.9828326180257511,1280.0,0.0,8.576,4600.703999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",775,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,260032.0,20032.0,6.08,4606.783999999995,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8126.0,626.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",776,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,4.768,4611.551999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",777,64000.0,0.0,128000.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,0.0,512000.0,3.52,4615.071999999996,0.0,0.0,0.0,64000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",778,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,2000.0,0.9854193397877056,256000.0,0.0,5.6,4620.671999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",779,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,4624.255999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",780,0.0,0.0,0.0,0,0.0,0.0,0.0,20844.0,8666.0,0.7063368349711963,830976.0,637568.0,14.272,4638.527999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25968.0,19924.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",781,0.0,0.0,0.0,0,0.0,0.0,0.0,5448.0,8648.0,0.38649262202043133,829824.0,780288.0,11.872,4650.399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25932.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",782,0.0,0.0,0.0,0,0.0,0.0,0.0,6804.0,8606.0,0.4415314730694354,826368.0,780288.0,12.864,4663.263999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25824.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",783,0.0,0.0,0.0,0,0.0,0.0,0.0,6804.0,8593.0,0.4419042670650127,824320.0,716224.0,12.992,4676.255999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,25760.0,22382.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",784,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,2000.0,0.880838894184938,512000.0,0.0,4.896,4681.1519999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",785,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,4684.5759999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",786,0.0,0.0,0.0,0,0.0,0.0,0.0,5260.0,4576.0,0.5347702318015454,567296.0,457952.0,8.992,4693.567999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,17728.0,14311.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",787,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,8000.0,0.0,774656.0,768000.0,4.512,4698.079999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,24208.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",788,997276.0,2122560.0,202552.0,0,0.0,2325112.0,2325112.0,264.0,2624.0,0.09141274238227147,257024.0,256000.0,22.88,4720.9599999999955,266560.0,64000.0,896000.0,101276.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8032.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",789,0.0,327744.0,0.0,0,0.0,327744.0,327744.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,62.592,4783.551999999995,327744.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",790,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1024.0,0.0,256000.0,63616.0,3.648,4787.199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",791,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,3.104,4790.3039999999955,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",792,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,576000.0,28736.0,11.68,4801.983999999996,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18000.0,898.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",793,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1536.0,0.0,320000.0,0.0,4.832,4806.815999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",794,997282.0,2122560.0,202564.0,0,0.0,2325124.0,2325124.0,264.0,2624.0,0.09141274238227147,256000.0,256000.0,22.656,4829.471999999996,266560.0,64000.0,896000.0,101282.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",795,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,18.752,4848.2239999999965,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",796,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4851.6479999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",797,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,18.528,4870.175999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",798,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,4873.791999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",799,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,4877.215999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",800,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,4881.695999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",801,2048.0,73600.0,4096.0,0,0.0,77696.0,77696.0,152.0,502.0,0.2324159021406728,256000.0,64.0,11.648,4893.343999999996,73600.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",802,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4896.671999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",803,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.184,4901.855999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",804,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4905.1839999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",805,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.48,4909.663999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",806,704000.0,1280000.0,256000.0,0,0.0,1536000.0,1536000.0,0.0,2000.0,0.0,0.0,256000.0,4.16,4913.823999999997,0.0,128000.0,576000.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",807,400034.0,640000.0,160068.0,0,0.0,800068.0,800068.0,0.0,1536.0,0.0,512000.0,0.0,4.896,4918.719999999997,0.0,0.0,320000.0,80034.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",808,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,304.0,502.0,0.3771712158808933,256000.0,64.0,17.152,4935.871999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",809,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.232,4939.103999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",810,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4942.431999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",811,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,3.968,4946.399999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",812,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,4949.695999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",813,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,64.0,4.064,4953.7599999999975,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",814,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4956.607999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",815,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4959.455999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",816,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,4962.751999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",817,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4965.471999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",818,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,96.0,32.0,3.744,4969.215999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",819,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,32.0,32.0,6.048,4975.263999999997,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",820,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.264,4978.5279999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",821,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4981.9519999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",822,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.224,4986.175999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",823,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,4991.199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",824,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,4994.335999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
