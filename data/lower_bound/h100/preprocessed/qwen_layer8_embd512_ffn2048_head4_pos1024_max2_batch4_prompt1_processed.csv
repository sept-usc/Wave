Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.624,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.68,9.12,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.288,13.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.992,18.4,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,21.823999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,24.543999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,27.327999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,30.495999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.744,34.239999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,37.76,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,41.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.224,45.632000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.168,48.800000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,52.25600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.456,55.71200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,2176.0,8192.0,5.76,61.47200000000001,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,68.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,65.21600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,70.49600000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.968,74.46400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.424,77.88800000000002,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.64,82.52800000000002,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.352,86.88000000000002,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,90.20800000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.48,94.68800000000003,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.584,98.27200000000003,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.648,101.92000000000003,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.024,106.94400000000003,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,110.04800000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,113.44000000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.416,117.85600000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,122.11200000000002,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.848,128.96000000000004,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.752,135.71200000000005,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.464,142.17600000000004,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,146.68800000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,151.20000000000005,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.28,156.48000000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,161.05600000000004,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.52,164.57600000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.352,168.92800000000005,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.64,173.56800000000004,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.472,179.04000000000005,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,183.48800000000006,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,186.78400000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.264,202.04800000000006,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),47,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,209.69600000000005,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",48,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,214.01600000000005,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",49,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,217.44000000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",50,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,220.83200000000005,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",51,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,226.17600000000004,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",52,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,229.24800000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",53,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,232.48000000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.64,237.12000000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",55,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.512,241.63200000000003,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",56,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43680.0,7.264,248.89600000000004,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1365.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",57,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.808,252.70400000000004,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45888.0,7.296,260.00000000000006,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1434.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",59,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.488,263.48800000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),60,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,273.66400000000004,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",61,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.472,279.136,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",62,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,282.49600000000004,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",63,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.52,286.016,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",64,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.088,291.10400000000004,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",65,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,294.208,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",66,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,297.536,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.736,302.272,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,306.71999999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.464,313.18399999999997,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,319.58399999999995,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.464,326.04799999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,330.4959999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,335.0079999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",74,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,340.4479999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.832,345.2799999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",76,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,348.6719999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",77,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,353.0559999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.704,357.75999999999993,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",79,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,363.16799999999995,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",80,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,367.55199999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",81,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,370.816,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",82,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.296,386.11199999999997,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),83,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.68,393.792,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",84,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,398.176,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,401.408,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,404.8,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,410.144,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,413.184,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,416.44800000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,420.992,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.768,425.76,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43968.0,7.2,432.96,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1374.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,436.64,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44832.0,7.2,443.84,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1401.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.744,447.584,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),96,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,457.76,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",97,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.888,463.64799999999997,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",98,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,467.07199999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",99,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.616,470.68799999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",100,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.184,475.87199999999996,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",101,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,478.912,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",102,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,482.20799999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.48,486.688,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,491.13599999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,497.53599999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.496,504.0319999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",107,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,510.4319999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,514.752,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.288,519.04,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",110,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.248,524.288,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",111,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.8,529.088,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.584,532.6719999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,537.1839999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",114,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.736,541.9199999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",115,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,547.3599999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",116,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.352,551.7119999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",117,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,554.9759999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",118,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.232,570.2079999999999,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),119,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.616,577.8239999999998,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",120,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.352,582.1759999999998,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",121,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.488,585.6639999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",122,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,589.0559999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",123,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.472,594.5279999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",124,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,597.632,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,600.8639999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",126,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.48,605.3439999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",127,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,609.9519999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44128.0,7.52,617.4719999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1379.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.872,621.3439999999998,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45024.0,7.264,628.6079999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1407.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",131,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.488,632.0959999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),132,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.336,642.4319999999999,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",133,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.248,647.68,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",134,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,651.04,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,654.3679999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",136,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,659.68,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",137,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,662.784,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",138,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,665.984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.608,670.592,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,674.848,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",141,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,681.2479999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",142,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.592,687.8399999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",143,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.368,694.208,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,698.7199999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",145,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.224,702.944,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",146,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.568,708.512,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.736,713.2479999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",148,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,716.6719999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,720.9599999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",150,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,725.4719999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",151,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.184,730.6559999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",152,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,735.0399999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,738.3359999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",154,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.296,753.632,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),155,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.52,761.1519999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",156,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.384,765.536,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",157,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.616,769.1519999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.552,772.704,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",159,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,778.016,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",160,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,781.2479999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,784.3839999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",162,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,788.8959999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.768,793.6639999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45504.0,7.264,800.9279999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1422.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",165,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.808,804.7359999999999,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",166,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43904.0,7.616,812.3519999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1372.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",167,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.552,815.9039999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),168,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.24,826.1439999999999,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",169,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.184,831.3279999999999,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",170,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.584,834.9119999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",171,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.424,838.3359999999998,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",172,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,843.6479999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",173,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,846.6559999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",174,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,849.9199999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.736,854.6559999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.416,859.0719999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",177,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.496,865.5679999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",178,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.688,872.2559999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",179,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.56,878.8159999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,883.1039999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,887.4239999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.44,892.8639999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,897.5679999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,900.8319999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",185,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,905.4399999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",186,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,909.9519999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",187,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,915.4559999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",188,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,919.9679999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",189,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,923.3599999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",190,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.488,938.8479999999997,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),191,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,946.3999999999997,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",192,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.256,950.6559999999997,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",193,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,953.9839999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",194,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,957.3759999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",195,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.472,962.8479999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",196,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,966.1439999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,969.3119999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",198,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,973.8239999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",199,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.544,978.3679999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",200,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45984.0,7.264,985.6319999999997,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1437.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",201,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.648,989.2799999999997,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",202,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44768.0,7.328,996.6079999999997,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1399.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",203,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,1000.1279999999997,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),204,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,1010.3359999999997,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",205,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.504,1015.8399999999997,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",206,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,1019.2319999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",207,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,1022.5599999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",208,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.056,1027.6159999999998,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",209,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,1030.8159999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",210,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1034.0799999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.608,1038.6879999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,1043.1359999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",213,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.592,1049.7279999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",214,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.528,1056.2559999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",215,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.528,1062.7839999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",216,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,1067.1039999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.48,1071.5839999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",218,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,1076.9279999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,1081.5359999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",220,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,1084.9279999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",221,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.64,1089.568,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",222,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.64,1094.208,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",223,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.216,1099.424,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.352,1103.776,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",225,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,1107.0720000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",226,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.296,1122.3680000000002,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),227,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.616,1129.9840000000002,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",228,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.192,1134.1760000000002,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",229,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,1137.5680000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,1140.8960000000002,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",231,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.408,1146.304,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",232,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1149.376,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",233,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.104,1152.48,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",234,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.48,1156.96,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.736,1161.6960000000001,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",236,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45344.0,7.552,1169.248,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1417.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.648,1172.896,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44352.0,7.168,1180.0639999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1386.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",239,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.68,1183.744,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),240,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,1193.952,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",241,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.824,1199.776,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",242,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,1203.2,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",243,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.616,1206.816,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",244,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,1212.128,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",245,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1215.3919999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",246,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1218.7199999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",247,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.416,1223.1359999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,1227.5839999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",249,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.464,1234.0479999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",250,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.72,1240.7679999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.528,1247.2959999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",252,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.48,1251.7759999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,1256.224,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",254,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.248,1261.472,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",255,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,1266.176,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",256,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,1269.6,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,1274.048,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.608,1278.656,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",259,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.344,1284.0,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,1288.32,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",261,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,1291.616,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",262,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.2,1306.816,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),263,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,1314.368,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",264,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,1318.6879999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",265,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,1322.0159999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",266,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,1325.3759999999997,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",267,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.408,1330.7839999999997,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",268,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1334.0479999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",269,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.008,1337.0559999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.48,1341.5359999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,1346.1439999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44960.0,7.232,1353.3759999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1405.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",273,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.648,1357.0239999999994,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47104.0,7.392,1364.4159999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1472.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",275,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.456,1367.8719999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),276,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.368,1378.2399999999993,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",277,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.344,1383.5839999999994,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1386.9439999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",279,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,1390.2719999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",280,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.024,1395.2959999999991,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",281,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1398.367999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",282,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,1401.791999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,1406.335999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",284,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.544,1410.8799999999992,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.496,1417.3759999999993,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",286,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.496,1423.8719999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",287,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.432,1430.3039999999994,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",288,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,1434.6239999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",289,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.256,1438.8799999999994,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",290,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.6,1444.4799999999993,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,1449.0239999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",292,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.584,1452.6079999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",293,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,1456.8959999999995,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.48,1461.3759999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",295,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.248,1466.6239999999996,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",296,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.48,1471.1039999999996,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",297,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.52,1474.6239999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",298,32768.0,2941952.0,0.0,0,32212254720.0,2941952.0,32215196672.0,16640.0,32.0,0.9980806142034548,24576.0,8192.0,15.328,1489.9519999999995,2480128.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,768.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),299,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.776,1497.7279999999996,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",300,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,1501.9519999999995,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,1505.3119999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,1508.6719999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,1513.9839999999992,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,1516.9919999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.072,1520.0639999999992,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.64,1524.7039999999993,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.544,1529.2479999999994,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47008.0,7.328,1536.5759999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1469.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",309,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.872,1540.4479999999994,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",310,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46240.0,7.296,1547.7439999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1445.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",311,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.456,1551.1999999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),312,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,1561.3759999999993,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",313,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.184,1566.5599999999993,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",314,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.648,1570.2079999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",315,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.552,1573.759999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",316,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.056,1578.8159999999991,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",317,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,1581.855999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",318,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,1584.991999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",319,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.576,1589.567999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",320,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.256,1593.8239999999992,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",321,320888832.0,690397184.0,19447808.0,0,0.0,709844992.0,709844992.0,5241792.0,3950336.0,0.5702479338842975,315134720.0,3399776.0,144.128,1737.951999999999,29171712.0,38895616.0,311164928.0,9723904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9847960.0,106243.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,1740.9279999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",323,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.32,1745.2479999999991,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,1748.6399999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",325,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.544,1753.1839999999993,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.008,1756.1919999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173184.0,6.464,1762.6559999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5412.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",328,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38120832.0,32.0,15.04,1777.6959999999992,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1191276.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,173952.0,6.464,1784.1599999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5436.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",330,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38101696.0,0.0,14.912,1799.0719999999992,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190678.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",331,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,170112.0,6.144,1805.2159999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5316.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",332,247936.0,0.0,495872.0,0,0.0,495872.0,495872.0,39336.0,719380.0,0.05184548632162759,38147328.0,0.0,15.36,1820.575999999999,0.0,0.0,0.0,247936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1192104.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171136.0,6.176,1826.751999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5348.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",334,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38102048.0,128.0,14.912,1841.663999999999,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190689.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,4.864,1846.527999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,1849.6319999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.336,1855.9679999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.976,1858.9439999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.112,1865.0559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",340,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,113980.0,38400.0,0.7479984249901562,2488288.0,10720.0,9.664,1874.7199999999993,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77759.0,335.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.864,1883.5839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,199712.0,6.304,1889.8879999999995,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6241.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",343,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.6,1895.4879999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",344,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,1901.0559999999994,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.912,1907.9679999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.36,1911.3279999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,164778.0,84769.0,0.6603084789638826,8593664.0,6031200.0,16.864,1928.1919999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,268552.0,188475.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",348,0.0,0.0,0.0,0,0.0,0.0,0.0,39822.0,91544.0,0.3031377982126273,8870656.0,7409664.0,14.56,1942.7519999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,277208.0,231552.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",349,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91983.0,0.3069237550577545,8845312.0,5355328.0,14.464,1957.2159999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276416.0,167354.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91637.0,0.307726012495184,8849152.0,4575808.0,15.2,1972.4159999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276536.0,142994.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,6.144,1978.5599999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.488,1982.0479999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51313.0,0.42941810943945913,6172032.0,4011936.0,12.192,1994.2399999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192876.0,125373.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7327040.0,7292928.0,8.256,2002.4959999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,228970.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",355,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.104,2089.5999999999995,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",356,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,286.88,2376.4799999999996,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.288,2380.7679999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",358,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.296,2384.0639999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",359,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,289952.0,12.128,2396.1919999999996,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,9061.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.472,2401.6639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",361,9424704.0,20076672.0,1832576.0,0,0.0,21909248.0,21909248.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.688,2488.352,2452096.0,607744.0,8508416.0,916288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",362,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.312,2497.6639999999998,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,2501.216,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",364,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.888,2511.104,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2514.464,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.328,2517.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,2522.4,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",368,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.792,2532.192,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,2535.52,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.992,2540.512,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2543.904,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",372,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.576,2548.48,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",373,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.232,2555.712,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",374,3798336.0,6077440.0,1519232.0,0,0.0,7596672.0,7596672.0,0.0,14280.0,0.0,4861952.0,0.0,6.944,2562.656,0.0,0.0,3038720.0,759616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",375,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,13.024,2575.68,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",376,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.576,2580.256,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,2582.9759999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2585.7599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.488,2589.2479999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2592.6399999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.904,2596.5439999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,2601.5679999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.808,2605.3759999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,2608.9279999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",385,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.704,2613.6319999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",386,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,4.032,2617.6639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.328,2620.9919999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.296,2624.2879999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.296,2627.5839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.744,2631.3279999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",391,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,192.0,0.0,8320.0,8192.0,8.128,2639.4559999999997,0.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,260.0,256.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",392,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.456,2642.912,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",393,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.216,2648.1279999999997,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",394,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.744,2651.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",395,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.648,2655.52,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.128,2659.648,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.16,2663.808,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",398,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.52,2667.328,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.128,2671.456,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",400,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.296,2674.752,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",401,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.52,2678.272,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",402,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.408,2683.68,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",403,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2686.9759999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2690.2079999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.288,2694.4959999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.512,2699.008,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.304,2705.312,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",408,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.56,2711.872,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",409,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.656,2718.528,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.544,2723.0719999999997,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.544,2727.6159999999995,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,2733.1199999999994,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.256,2737.3759999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,2740.767999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",415,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,2745.2799999999993,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",416,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.288,2749.5679999999993,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.312,2754.879999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",418,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,2759.5839999999994,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.616,2763.1999999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",420,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.192,2767.3919999999994,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",421,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.128,2771.5199999999995,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",422,29408.0,2934156.0,0.0,0,32212254720.0,2934156.0,32215188876.0,16715.0,32.0,0.9980892100077626,40960.0,8192.0,15.776,2787.2959999999994,2479367.0,395973.0,29408.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),423,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.648,2794.9439999999995,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",424,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.16,2799.1039999999994,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",425,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,2802.4639999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",426,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.584,2806.0479999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",427,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.568,2811.6159999999995,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",428,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,2814.7519999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",429,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,2817.9199999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.64,2822.5599999999995,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.416,2826.9759999999997,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",432,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,47872.0,7.392,2834.3679999999995,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1496.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.776,2838.1439999999993,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",434,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45472.0,7.328,2845.4719999999993,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1421.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",435,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.488,2848.959999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),436,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.24,2859.199999999999,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",437,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.504,2864.703999999999,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",438,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,2868.127999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",439,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,2871.4559999999988,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",440,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.088,2876.543999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",441,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,2879.711999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",442,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2883.039999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.672,2887.711999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.608,2892.3199999999993,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",445,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.464,2898.783999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",446,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.528,2905.311999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",447,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.624,2911.935999999999,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.576,2916.511999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.288,2920.799999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",450,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,2926.3039999999987,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",451,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.704,2931.007999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",452,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,2934.3039999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,2938.623999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",454,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.288,2942.911999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",455,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.536,2948.447999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",456,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,2952.735999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",457,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,2956.063999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",458,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.768,2960.831999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",459,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.832,2965.663999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",460,32672.0,2942724.0,0.0,0,32212254720.0,2942724.0,32215197444.0,16649.0,32.0,0.9980816497811882,40960.0,8192.0,15.456,2981.119999999999,2481101.0,396279.0,32672.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),461,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,2988.671999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",462,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.48,2993.151999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",463,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,2996.479999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,2999.775999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",465,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.992,3004.767999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",466,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3008.063999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",467,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3011.391999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",468,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.544,3015.935999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.16,3020.0959999999986,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",470,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44128.0,7.168,3027.2639999999988,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1379.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.776,3031.0399999999986,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",472,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44512.0,7.2,3038.2399999999984,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1391.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",473,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.328,3041.5679999999984,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),474,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.272,3051.8399999999983,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",475,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.536,3057.3759999999984,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",476,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.648,3061.0239999999985,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",477,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.232,3064.2559999999985,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",478,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.312,3069.5679999999984,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",479,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,3072.8319999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3076.2239999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.16,3080.383999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.48,3084.863999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",483,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.336,3091.199999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",484,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,3097.599999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",485,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.624,3104.223999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.768,3108.991999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",487,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.448,3113.439999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.472,3118.911999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,3123.199999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",490,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.488,3126.687999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",491,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,3131.295999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",492,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.224,3135.519999999998,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",493,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.472,3140.9919999999984,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.736,3145.7279999999982,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",495,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3149.0879999999984,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.288,3153.3759999999984,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",497,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.256,3157.6319999999982,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",498,32704.0,2942808.0,0.0,0,32212254720.0,2942808.0,32215197528.0,16646.0,32.0,0.9980813047127953,40960.0,8192.0,15.328,3172.959999999998,2481118.0,396282.0,32704.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),499,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3180.5119999999984,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",500,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.512,3185.0239999999985,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",501,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,3188.3199999999983,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",502,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,3191.7759999999985,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",503,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,3197.1199999999985,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",504,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,3200.6079999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3203.807999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",506,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.672,3208.479999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.8,3213.2799999999984,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",508,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45696.0,7.264,3220.5439999999985,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1428.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.776,3224.3199999999983,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44224.0,7.104,3231.423999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1382.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",511,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.392,3234.815999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),512,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.208,3245.023999999998,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",513,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.376,3250.3999999999983,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",514,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.52,3253.9199999999983,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",515,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.552,3257.4719999999984,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",516,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.96,3262.4319999999984,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",517,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3265.5679999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",518,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3268.9919999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.608,3273.5999999999985,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.48,3278.0799999999986,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",521,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.4,3284.4799999999987,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",522,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.56,3291.0399999999986,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.336,3297.3759999999984,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",524,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.48,3301.8559999999984,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.352,3306.2079999999983,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",526,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,3311.615999999998,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",527,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.672,3316.287999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,3319.711999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",529,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.32,3324.0319999999983,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.512,3328.5439999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",531,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,3333.9519999999984,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.384,3338.3359999999984,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",533,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3341.6959999999985,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",534,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.832,3346.5279999999984,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",535,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.576,3351.1039999999985,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",536,32704.0,2942808.0,0.0,0,32212254720.0,2942808.0,32215197528.0,16646.0,32.0,0.9980813047127953,40960.0,8192.0,15.52,3366.6239999999984,2481118.0,396282.0,32704.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),537,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.744,3374.3679999999986,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",538,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.48,3378.8479999999986,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.648,3382.4959999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,3385.759999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,4.896,3390.655999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3393.951999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3397.183999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.352,3401.5359999999987,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.384,3405.9199999999987,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43712.0,7.232,3413.1519999999987,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1366.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",547,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.808,3416.9599999999987,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46592.0,7.328,3424.2879999999986,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1456.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",549,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.392,3427.6799999999985,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),550,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.112,3437.7919999999986,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",551,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.248,3443.0399999999986,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,3446.3359999999984,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,3449.6319999999982,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.568,3455.1999999999985,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,3458.7199999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,3461.9199999999983,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.32,3466.2399999999984,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.448,3470.6879999999983,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.528,3477.215999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",560,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.336,3483.551999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,7.04,3490.591999999998,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",562,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.768,3495.359999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",563,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.64,3499.9999999999977,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",564,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.6,3505.5999999999976,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",565,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,3510.111999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",566,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3513.471999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,3517.983999999998,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,3522.3039999999983,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",569,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.472,3527.7759999999985,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.512,3532.2879999999986,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",571,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,3535.7119999999986,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",572,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.32,3540.031999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.192,3544.223999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",574,32704.0,2942808.0,0.0,0,32212254720.0,2942808.0,32215197528.0,16646.0,32.0,0.9980813047127953,40960.0,8192.0,15.232,3559.4559999999988,2481118.0,396282.0,32704.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),575,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.488,3566.9439999999986,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",576,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.48,3571.4239999999986,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",577,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.328,3574.7519999999986,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",578,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.36,3578.1119999999987,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",579,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.472,3583.583999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",580,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,3586.943999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3590.111999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.672,3594.783999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",583,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.544,3599.327999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44672.0,7.232,3606.559999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1396.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",585,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,3610.239999999999,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",586,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46336.0,7.264,3617.503999999999,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1448.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",587,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.52,3621.023999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),588,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.368,3631.391999999999,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",589,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.312,3636.703999999999,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,3640.159999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",591,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.456,3643.615999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",592,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.184,3648.7999999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",593,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3651.999999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",594,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3655.423999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",595,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.64,3660.063999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",596,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.48,3664.543999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.816,3671.3599999999988,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.656,3678.0159999999987,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.432,3684.4479999999985,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",600,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.352,3688.7999999999984,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",601,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.416,3693.2159999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",602,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.536,3698.7519999999986,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.896,3703.647999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",604,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.68,3707.3279999999986,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.736,3712.0639999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.576,3716.6399999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",607,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.28,3721.9199999999987,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.48,3726.3999999999987,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",609,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.424,3729.8239999999987,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",610,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.576,3734.3999999999987,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",611,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.672,3739.0719999999988,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",612,32704.0,2942808.0,0.0,0,32212254720.0,2942808.0,32215197528.0,16646.0,32.0,0.9980813047127953,40960.0,8192.0,15.36,3754.431999999999,2481118.0,396282.0,32704.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),613,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.776,3762.2079999999987,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",614,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.224,3766.431999999999,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",615,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.36,3769.791999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.264,3773.055999999999,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",617,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.344,3778.399999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",618,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,3781.791999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",619,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3785.119999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",620,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.256,3789.375999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.16,3793.5359999999987,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",622,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,43872.0,7.328,3800.8639999999987,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1371.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",623,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.68,3804.5439999999985,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",624,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44672.0,7.264,3811.8079999999986,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1396.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",625,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.424,3815.2319999999986,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),626,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.176,3825.4079999999985,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",627,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.568,3830.9759999999987,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,3834.2719999999986,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.296,3837.5679999999984,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",630,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.376,3842.9439999999986,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",631,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3846.2399999999984,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,3849.4719999999984,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.32,3853.7919999999986,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",634,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.512,3858.3039999999987,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.368,3864.6719999999987,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",636,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.624,3871.2959999999985,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",637,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.368,3877.6639999999984,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",638,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.8,3882.4639999999986,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.736,3887.1999999999985,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",640,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.376,3892.5759999999987,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,3896.8639999999987,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",642,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.392,3900.2559999999985,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.864,3905.1199999999985,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.416,3909.5359999999987,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",645,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.568,3915.103999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.608,3919.711999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,3923.167999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.192,3927.359999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.256,3931.615999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",650,32704.0,2942808.0,0.0,0,32212254720.0,2942808.0,32215197528.0,16646.0,32.0,0.9980813047127953,40960.0,8192.0,15.328,3946.943999999999,2481118.0,396282.0,32704.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),651,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.552,3954.495999999999,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",652,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.32,3958.8159999999993,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",653,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.232,3962.0479999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",654,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,3965.3759999999993,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",655,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.44,3970.8159999999993,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",656,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3974.1439999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",657,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,3977.3119999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.704,3982.0159999999996,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.8,3986.816,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",660,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45440.0,7.488,3994.3039999999996,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1420.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.936,3998.24,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",662,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,46336.0,7.136,4005.3759999999997,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1448.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",663,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.584,4008.9599999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),664,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.4,4019.3599999999997,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",665,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,6.016,4025.3759999999997,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,4028.832,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",667,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.552,4032.384,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",668,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.248,4037.632,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",669,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,4040.992,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",670,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,4044.288,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",671,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.512,4048.8,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",672,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.096,4052.896,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",673,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.56,4059.456,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",674,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.56,4066.016,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",675,1081344.0,2326528.0,65536.0,0,0.0,2392064.0,2392064.0,17664.0,13568.0,0.5655737704918032,1574912.0,8192.0,6.592,4072.608,98304.0,131072.0,1048576.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,49216.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,4076.896,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.256,4081.152,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",678,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.408,4086.56,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",679,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.672,4091.232,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",680,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.296,4094.528,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",681,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.448,4098.976,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",682,1536.0,1024.0,3072.0,0,0.0,4096.0,4096.0,0.0,64.0,0.0,4096.0,4096.0,4.32,4103.295999999999,1024.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,128.0,128.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",683,4096.0,0.0,8192.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,8192.0,8192.0,5.504,4108.799999999999,0.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",684,4096.0,2048.0,8192.0,0,0.0,10240.0,10240.0,0.0,192.0,0.0,12288.0,8192.0,4.288,4113.087999999999,0.0,2048.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",685,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.264,4116.351999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",686,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.736,4121.087999999999,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",687,2048.0,0.0,4096.0,0,0.0,4096.0,4096.0,0.0,160.0,0.0,16384.0,16384.0,4.864,4125.951999999998,0.0,0.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,512.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",688,32768.0,2942976.0,0.0,0,32212254720.0,2942976.0,32215197696.0,16640.0,32.0,0.9980806142034548,40960.0,8192.0,15.424,4141.375999999998,2481152.0,396288.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,125829120.0,1280.0,256.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),689,8388608.0,17039360.0,0.0,0,0.0,17039360.0,17039360.0,41728.0,1024.0,0.9760479041916168,1081344.0,131072.0,7.584,4148.959999999998,0.0,262144.0,8388608.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,33792.0,4096.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",690,2048.0,34816.0,4096.0,0,0.0,38912.0,38912.0,0.0,1088.0,0.0,131072.0,8192.0,4.448,4153.4079999999985,32768.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4096.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",691,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.456,4156.863999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",692,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.392,4160.2559999999985,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",693,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.024,4165.279999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",694,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,4168.479999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",695,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,4171.743999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",696,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.384,4176.127999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",697,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.288,4180.415999999998,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",698,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,44992.0,7.392,4187.807999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1406.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",699,102400.0,196608.0,16384.0,0,0.0,212992.0,212992.0,0.0,128.0,0.0,32768.0,32768.0,3.968,4191.775999999998,8192.0,0.0,94208.0,8192.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1024.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",700,4325376.0,9306112.0,262144.0,0,0.0,9568256.0,9568256.0,70656.0,53248.0,0.5702479338842975,5275648.0,45856.0,7.424,4199.199999999998,393216.0,524288.0,4194304.0,131072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,164864.0,1433.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",701,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,192.0,0.0,65536.0,32768.0,3.392,4202.591999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2048.0,1024.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),702,33554432.0,67633152.0,0.0,0,0.0,67633152.0,67633152.0,132608.0,2048.0,0.9847908745247148,4325376.0,262144.0,10.144,4212.735999999998,0.0,524288.0,33554432.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,135168.0,8192.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",703,2048.0,67584.0,4096.0,0,0.0,71680.0,71680.0,0.0,2112.0,0.0,262144.0,8192.0,5.472,4218.207999999998,65536.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,8192.0,256.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",704,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,48.0,0.0,16384.0,8192.0,3.488,4221.695999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",705,0.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,32.0,0.0,8192.0,8192.0,3.328,4225.0239999999985,0.0,2048.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,256.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",706,2048.0,6532.0,4096.0,0,0.0,10628.0,10628.0,40.0,20.0,0.6666666666666666,8192.0,32.0,5.536,4230.559999999999,6528.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",707,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,4233.887999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",708,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,4237.087999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",709,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,8448.0,8192.0,4.416,4241.503999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,264.0,256.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",710,2048.0,2048.0,4096.0,0,0.0,6144.0,6144.0,0.0,192.0,0.0,16384.0,8192.0,4.512,4246.015999999999,0.0,2048.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,512.0,256.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",711,320888832.0,690397184.0,19447808.0,0,0.0,709844992.0,709844992.0,5241792.0,3950336.0,0.5702479338842975,315295488.0,3404288.0,142.912,4388.927999999999,29171712.0,38895616.0,311164928.0,9723904.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9852984.0,106384.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.88,4391.807999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",713,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,4395.679999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4398.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",715,128.0,608256.0,256.0,0,0.0,608512.0,608512.0,0.0,9520.0,0.0,2430976.0,2430976.0,4.736,4403.7119999999995,0.0,608256.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.104,4406.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,174400.0,6.272,4413.088,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5450.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",718,286080.0,0.0,572160.0,0,0.0,572160.0,572160.0,39336.0,718188.0,0.05192706765726234,38044672.0,0.0,14.72,4427.808,0.0,0.0,0.0,286080.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188896.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,171712.0,6.464,4434.272,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5366.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",720,305152.0,0.0,610304.0,0,0.0,610304.0,610304.0,39336.0,717592.0,0.051967954679969564,38025248.0,96.0,14.304,4448.576,0.0,0.0,0.0,305152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1188289.0,3.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,169536.0,6.176,4454.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5298.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",722,219328.0,0.0,438656.0,0,0.0,438656.0,438656.0,39336.0,720274.0,0.0517844683455984,38085696.0,0.0,14.624,4469.376,0.0,0.0,0.0,219328.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190178.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,9536.0,28528.0,0.2505254308532997,2435200.0,172416.0,6.08,4475.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76100.0,5388.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",724,228864.0,0.0,457728.0,0,0.0,457728.0,457728.0,39336.0,719976.0,0.05180479170617612,38091360.0,128.0,14.56,4490.0160000000005,0.0,0.0,0.0,228864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1190355.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,57.0,0.0,19104.0,2400.0,5.024,4495.040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,597.0,75.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.88,4497.920000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.048,4503.968000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,4507.072000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,47.0,0.9315866084425036,2400.0,0.0,6.016,4513.088000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",730,152576.0,0.0,305152.0,0,0.0,305152.0,305152.0,149773.0,38398.0,0.7959409260725616,2488256.0,11040.0,9.824,4522.912,0.0,0.0,0.0,152576.0,0,0,0,0,0,0,0,0.0,0.0,0.0,77758.0,345.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",731,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.48,4531.392,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",732,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2447872.0,198304.0,6.304,4537.696,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76496.0,6197.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",733,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.344,4543.04,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",734,607744.0,0.0,1215488.0,0,0.0,1215488.0,1215488.0,0.0,18992.0,0.0,0.0,4861952.0,5.568,4548.608,0.0,0.0,0.0,607744.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,18992.0,0.8768033212247016,2430976.0,0.0,6.944,4555.552000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.552,4559.104,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",737,0.0,0.0,0.0,0,0.0,0.0,0.0,176010.0,85607.0,0.6727773806748032,8831104.0,5938688.0,17.792,4576.896000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275972.0,185584.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,41226.0,90947.0,0.31190939147934904,8811520.0,5113184.0,14.816,4591.712,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275360.0,159787.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",739,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91978.0,0.30693531858460427,8814848.0,5172608.0,14.432,4606.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,275464.0,161644.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,40734.0,91792.0,0.3073661017460725,8855040.0,5412704.0,14.688,4620.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,276720.0,169147.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,18992.0,0.43770724774988157,4861952.0,0.0,5.92,4626.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",742,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.456,4630.2080000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,38618.0,51493.0,0.42856033114714076,6211456.0,4039392.0,12.576,4642.784000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,194108.0,126231.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",744,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,75968.0,0.0,7330912.0,7292928.0,8.352,4651.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,229091.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",745,9424696.0,20076672.0,1832560.0,0,0.0,21909232.0,21909232.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,86.816,4737.952,2452096.0,607744.0,8508416.0,916280.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",746,0.0,3052116.0,0.0,0,0.0,3052116.0,3052116.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,285.6,5023.552000000001,3052116.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,9520.0,0.0,2430976.0,607360.0,4.224,5027.776000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",748,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.232,5031.008000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,5469696.0,287744.0,12.032,5043.040000000001,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0,0,0.0,0.0,0.0,170928.0,8992.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,14280.0,0.0,3038720.0,0.0,5.632,5048.6720000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,94960.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",751,9424704.0,20076672.0,1832576.0,0,0.0,21909248.0,21909248.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,87.52,5136.192000000001,2452096.0,607744.0,8508416.0,916288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",752,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.6,5145.792000000001,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.872,5149.664000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",754,115712.0,0.0,231424.0,0,0.0,231424.0,231424.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,9.376,5159.040000000002,0.0,0.0,0.0,115712.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",755,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,5162.528000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,5166.144000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,5170.560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",758,119088.0,990796.0,238176.0,0,0.0,1228972.0,1228972.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,9.664,5180.224000000002,990796.0,0.0,0.0,119088.0,0,0,0,0,0,0,0,0.0,0.0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,5183.552000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",760,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,5188.832000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",761,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,5192.096000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",762,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,5196.512000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",763,2973696.0,6081536.0,1081344.0,0,0.0,7162880.0,7162880.0,0.0,18992.0,0.0,0.0,2430976.0,7.168,5203.680000000002,0.0,1215488.0,2433024.0,540672.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",764,3798336.0,6077440.0,1519232.0,0,0.0,7596672.0,7596672.0,0.0,14280.0,0.0,4861952.0,0.0,6.752,5210.4320000000025,0.0,0.0,3038720.0,759616.0,0,0,0,0,0,0,0,0.0,0.0,0.0,151936.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",765,89600.0,0.0,179200.0,0,0.0,179200.0,179200.0,14092.0,4912.0,0.7415280993475057,2432256.0,2560.0,13.024,5223.456000000003,0.0,0.0,0.0,89600.0,0,0,0,0,0,0,0,0.0,0.0,0.0,76008.0,80.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",766,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.84,5227.296000000003,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",767,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,5230.112000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",768,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,5232.928000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",769,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,5236.352000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",770,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,5239.808000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",771,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.16,5243.968000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",772,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.184,5249.152000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",773,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,5252.640000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
