Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,5.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,8.256,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.296,11.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.68,15.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.744,18.976,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.288,23.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,5.28,28.544,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,32.096000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,34.848000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,37.66400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.232,40.89600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.712,44.60800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,47.84000000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,51.23200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,32.0,32.0,4.0,55.23200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,58.496000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,62.048000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.552,65.60000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,3264.0,12288.0,5.76,71.36000000000003,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.616,74.97600000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.28,80.25600000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,83.68000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,4.032,87.71200000000003,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,91.71200000000003,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.448,96.16000000000003,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.52,99.68000000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,3584.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,32.0,0.0,2048.0,2048.0,4.256,103.93600000000002,0.0,1024.0,3584.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.456,107.39200000000002,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.488,110.88000000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,116.96000000000002,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.648,120.60800000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,123.90400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,128.288,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.352,132.64000000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13088.0,8.288,140.92800000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,409.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13600.0,7.872,148.8,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,425.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13920.0,8.256,157.056,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,435.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,161.696,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.32,166.016,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,171.552,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,175.968,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,179.328,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,183.84,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,188.224,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,193.696,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,198.272,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,201.536,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.296,216.832,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13664.0,7.968,224.79999999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,427.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,228.19199999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,231.35999999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.664,237.02399999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,240.44799999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,243.83999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,248.28799999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,252.79999999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,68896.0,9.824,262.62399999999997,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2153.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,4.096,266.71999999999997,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72160.0,10.528,277.248,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2255.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.328,280.57599999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14368.0,21.248,301.82399999999996,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,449.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,305.15199999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,308.38399999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.76,314.14399999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,317.50399999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,320.79999999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.48,325.28,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.32,329.59999999999997,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,8.544,338.14399999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13568.0,7.808,345.95199999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,424.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13888.0,8.096,354.04799999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,434.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,358.46399999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,362.8159999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.312,368.12799999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,372.63999999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,375.9359999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,380.7039999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.544,385.2479999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,390.8479999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,395.2639999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,398.5599999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.776,414.3359999999999,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13632.0,8.0,422.3359999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,426.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,425.6959999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,428.9919999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.272,435.2639999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,438.5279999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,441.75999999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,446.2079999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.288,450.4959999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70944.0,9.696,460.19199999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2217.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.584,463.77599999999995,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72768.0,10.048,473.82399999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2274.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,477.34399999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14432.0,20.704,498.04799999999994,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,451.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,501.43999999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.68,505.11999999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.048,511.16799999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,514.4,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,517.664,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.704,522.3679999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.544,526.9119999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14272.0,8.128,535.04,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,446.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13696.0,8.192,543.232,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,428.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14336.0,7.904,551.136,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,448.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,555.6479999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.256,559.9039999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,565.3439999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,569.9839999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,573.3439999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,577.8879999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.128,582.016,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,587.36,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,591.808,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,595.04,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.584,610.6239999999999,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13984.0,8.032,618.656,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,437.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,622.016,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,625.216,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.696,630.912,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,634.432,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,637.7280000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.224,641.9520000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.48,646.4320000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71520.0,9.696,656.1280000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2235.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.872,660.0000000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72384.0,9.76,669.7600000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2262.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.264,673.0240000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14464.0,20.704,693.7280000000001,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,452.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,697.2160000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,700.4160000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.632,706.0480000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,709.4080000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,712.8000000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.512,717.3120000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.256,721.5680000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14272.0,7.84,729.4080000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,446.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13696.0,7.904,737.3120000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,428.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14592.0,7.872,745.1840000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,456.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,749.7280000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.768,754.4960000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,759.9040000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,764.6080000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,767.9680000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,772.3840000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,776.7680000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,782.2080000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,786.8160000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,790.2080000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.616,805.8240000000002,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14208.0,8.16,813.9840000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,444.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.168,817.1520000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,820.4160000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.888,826.3040000000002,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,829.6960000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,832.9280000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,837.3120000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,841.8240000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73024.0,9.856,851.6800000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2282.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.552,855.2320000000002,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69248.0,9.632,864.8640000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2164.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.488,868.3520000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14080.0,21.056,889.4080000000002,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,440.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,892.7040000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,896.0960000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.984,902.0800000000004,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,905.3440000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,908.7040000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.352,913.0560000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.384,917.4400000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14368.0,7.872,925.3120000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,449.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13728.0,8.128,933.4400000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,429.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13472.0,7.84,941.2800000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,421.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,945.7280000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.192,949.9200000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,955.2640000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,959.6800000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,963.1040000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.672,967.7760000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.256,972.0320000000005,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,977.4400000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.704,982.1440000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,985.4720000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.264,1000.7360000000004,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13984.0,8.224,1008.9600000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,437.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,1012.3200000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,1015.5200000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.824,1021.3440000000005,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.488,1024.8320000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.488,1028.3200000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.48,1032.8000000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.608,1037.4080000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73024.0,9.664,1047.0720000000006,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2282.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.616,1050.6880000000006,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70720.0,9.664,1060.3520000000005,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2210.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,1063.8720000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14752.0,20.672,1084.5440000000006,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,461.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1087.8400000000006,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1091.2000000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.632,1096.8320000000006,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,1100.1280000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1103.4240000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.608,1108.0320000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,1112.5440000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13792.0,7.744,1120.2880000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,431.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13472.0,8.064,1128.3520000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,421.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13696.0,7.776,1136.1280000000006,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,428.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,1140.7680000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,1145.1200000000008,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,1150.6560000000009,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,1155.0400000000009,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,1158.432000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,1162.8480000000009,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.576,1167.424000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.504,1172.9280000000008,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,1177.568000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1180.864000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.424,1196.288000000001,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14144.0,8.096,1204.384000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,442.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,1207.680000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,1211.072000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.208,1217.280000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,1220.544000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1223.776000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,1228.192000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.704,1232.8960000000009,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69472.0,10.304,1243.200000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2171.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.616,1246.816000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72640.0,10.016,1256.832000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2270.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1260.192000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14272.0,20.992,1281.1840000000009,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,446.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.168,1284.3520000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,1287.6480000000008,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,1293.7280000000007,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1297.1200000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,1300.4800000000007,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,1304.8960000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.416,1309.3120000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14816.0,7.936,1317.2480000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,463.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13728.0,8.096,1325.3440000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,429.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13856.0,8.0,1333.3440000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,433.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,1337.7600000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.256,1342.0160000000005,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,1347.3600000000006,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,1352.1280000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,1355.6160000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.32,1359.9360000000006,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,1364.3200000000006,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,1369.6640000000007,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,1374.0480000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,1377.2800000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.552,1392.8320000000006,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13312.0,7.936,1400.7680000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,416.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,1404.1920000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,1407.3920000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.6,1412.9920000000004,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,1416.3200000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1419.6480000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,1423.9360000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.608,1428.5440000000003,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72256.0,9.888,1438.4320000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2258.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.872,1442.3040000000003,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71008.0,10.016,1452.3200000000004,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2219.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,1455.7760000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14048.0,20.576,1476.3520000000003,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,439.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,1479.8400000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,1483.0080000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,1488.8640000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,1492.2880000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.456,1495.7440000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,1500.0320000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.384,1504.4160000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13504.0,8.096,1512.5120000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,422.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,7.808,1520.3200000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,7.936,1528.256,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,1532.768,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,1537.152,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.6,1542.752,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,1547.296,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.2,1550.496,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,1554.912,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.512,1559.424,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,1564.96,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,1569.4080000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,1572.736,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,49152.0,4412928.0,0.0,0,48318382080.0,4412928.0,48322795008.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,15.424,1588.16,3720192.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14208.0,8.0,1596.16,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,444.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,1599.52,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,1602.816,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.76,1608.576,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,1612.032,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,1615.2959999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.544,1619.84,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.8,1624.6399999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72512.0,9.568,1634.2079999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2266.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.712,1637.9199999999998,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69664.0,10.24,1648.1599999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2177.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.36,1651.5199999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,13888.0,20.8,1672.3199999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.2,1675.5199999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.36,1678.8799999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.208,1685.0879999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.392,1688.4799999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.2,1691.6799999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,1695.9679999999998,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.384,1700.3519999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",308,100864000.0,217088000.0,5120000.0,0,0.0,222208000.0,222208000.0,1520000.0,1216000.0,0.5555555555555556,101721728.0,718528.0,49.408,1749.7599999999998,8192000.0,12288000.0,98304000.0,2560000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3178804.0,22454.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,1752.5119999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",310,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.544,1757.0559999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1760.3519999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",312,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.68,1764.032,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.2,1767.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33280.0,5.728,1772.96,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1040.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",315,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.432,1779.392,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33856.0,5.792,1785.184,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1058.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",317,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.496,1791.68,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33600.0,5.952,1797.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1050.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",319,65536.0,0.0,131072.0,0,0.0,131072.0,131072.0,8448.0,34312.0,0.19756782039289056,2109440.0,0.0,6.496,1804.1280000000002,0.0,0.0,0.0,65536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,33280.0,5.952,1810.0800000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1040.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",321,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,128.0,6.912,1816.9920000000002,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,3.808,1820.8000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.944,1823.7440000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.472,1829.2160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,1832.352,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.536,1837.8880000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",327,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,25584.0,8416.0,0.7524705882352941,527232.0,7584.0,8.736,1846.6240000000003,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,237.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.48,1855.1040000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",329,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,42752.0,6.048,1861.1520000000003,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1336.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.68,1864.8320000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",331,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.712,1868.5440000000003,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",332,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.824,1874.3680000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",333,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.456,1877.8240000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17697.0,0.7019954533973226,1704320.0,1264352.0,15.008,1892.8320000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53260.0,39511.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17708.0,0.34897058823529414,1705216.0,1560576.0,11.36,1904.1920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53288.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17594.0,0.38036204832006765,1699840.0,1560576.0,12.992,1917.1840000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53120.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17646.0,0.37966673697532166,1694336.0,1213024.0,12.768,1929.9520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,52948.0,37907.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",338,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.864,1934.8160000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",339,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.424,1938.2400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9395.0,0.5287892466646604,1158400.0,855360.0,9.344,1947.5840000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36200.0,26730.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",341,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549440.0,1536000.0,4.832,1952.4160000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48420.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",342,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,23.232,1975.6480000000004,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",343,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.488,2039.1360000000004,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.552,2042.6880000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",345,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.264,2045.9520000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,58624.0,11.872,2057.824,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1832.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.584,2061.408,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",348,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,512000.0,512000.0,22.848,2084.256,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",349,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.928,2117.1839999999997,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",350,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2120.544,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",351,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.384,2152.928,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",352,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,2156.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,2159.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,2164.2560000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",355,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,12.384,2176.6400000000003,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2180.0000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",357,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,4.832,2184.8320000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2188.0960000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.544,2192.6400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",360,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.056,2197.6960000000004,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",361,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.28,2202.9760000000006,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",362,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,17.12,2220.0960000000005,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,2223.4880000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2226.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",365,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.584,2230.464,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.52,2233.984,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",367,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,64.0,128.0,4.352,2238.336,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2241.1519999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.752,2243.9039999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,2247.5199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,2250.3679999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,3.936,2254.3039999999996,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",373,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,7.008,2261.3119999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",374,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.648,2264.9599999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2268.2559999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.256,2272.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",377,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.704,2277.2159999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",378,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,2280.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",379,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,2284.0319999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,96.0,32.0,4.768,2288.7999999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",381,0.0,0.0,0.0,0,0.0,0.0,0.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.936,2292.7359999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",382,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,3.36,2296.0959999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.488,2299.5839999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",384,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,96.0,0.0,3.52,2303.1039999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,3.744,2306.8479999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",386,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,288.0,0.0,9408.0,12288.0,6.912,2313.7599999999993,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,294.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",387,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,32.0,3.616,2317.3759999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.8,2322.1759999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",389,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2325.5679999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",390,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,3.712,2329.2799999999993,0.0,512.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",391,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,4.0,2333.2799999999993,0.0,0.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",392,4096.0,9216.0,0.0,0,0.0,9216.0,9216.0,0.0,32.0,0.0,2048.0,2048.0,4.16,2337.439999999999,0.0,1024.0,4096.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",393,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.264,2340.7039999999993,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",394,3600.0,8224.0,0.0,0,0.0,8224.0,8224.0,0.0,32.0,0.0,2048.0,2048.0,4.256,2344.959999999999,0.0,1024.0,3600.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",395,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,32.0,0.0,2048.0,2048.0,3.328,2348.287999999999,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",396,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.136,2351.423999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",397,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.952,2357.3759999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",398,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,2360.575999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",399,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2363.807999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,2368.255999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.32,2372.575999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",402,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13440.0,8.096,2380.671999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,420.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13824.0,7.904,2388.575999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,432.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13664.0,8.064,2396.639999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,427.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,2401.023999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,2405.375999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",407,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.664,2411.039999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",408,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,2415.583999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",409,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.488,2419.0719999999988,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",410,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,2423.5519999999988,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,2427.9039999999986,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",412,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.28,2433.183999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.352,2437.5359999999987,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",414,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,2440.9279999999985,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",415,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.512,2445.4399999999987,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.48,2449.9199999999987,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",417,47008.0,4408836.0,0.0,0,48318382080.0,4408836.0,48322790916.0,24989.0,48.0,0.9980828374006471,61440.0,12288.0,15.552,2465.471999999999,3720589.0,594231.0,47008.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",418,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13504.0,8.0,2473.471999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,422.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",419,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,2476.703999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",420,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.328,2480.031999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",421,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,2485.887999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",422,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2489.151999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",423,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2492.4159999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",424,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,2496.863999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,2501.311999999999,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",426,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,68992.0,9.984,2511.295999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2156.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",427,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.552,2514.847999999999,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73728.0,9.888,2524.735999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2304.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",429,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.648,2528.383999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",430,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,15040.0,20.96,2549.343999999999,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,470.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,2552.735999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",432,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,2556.031999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",433,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.24,2562.2719999999986,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",434,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,2565.5999999999985,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",435,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2568.8639999999987,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.256,2573.1199999999985,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.32,2577.4399999999987,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",438,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13888.0,7.936,2585.375999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,434.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13952.0,7.904,2593.279999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,436.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13568.0,8.064,2601.3439999999987,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,424.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.672,2606.0159999999987,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.416,2610.431999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",443,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.408,2615.839999999999,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",444,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.672,2620.511999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",445,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2623.935999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",446,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,2628.351999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.224,2632.575999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",448,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.568,2638.1439999999993,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,2642.5599999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",450,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.616,2646.1759999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",451,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.576,2650.7519999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.448,2655.1999999999994,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",453,48544.0,4412868.0,0.0,0,48318382080.0,4412868.0,48322794948.0,24993.0,48.0,0.9980831436444232,61440.0,12288.0,15.648,2670.8479999999995,3721405.0,594375.0,48544.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",454,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14400.0,8.0,2678.8479999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,450.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",455,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,2682.1759999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",456,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.296,2685.4719999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",457,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.824,2691.2959999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",458,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,2694.591999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",459,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,2697.823999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",460,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.608,2702.4319999999993,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.48,2706.9119999999994,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",462,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70816.0,9.696,2716.6079999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2213.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",463,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.584,2720.191999999999,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73344.0,9.76,2729.9519999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2292.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",465,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.488,2733.439999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",466,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14688.0,20.928,2754.367999999999,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,459.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,2757.791999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",468,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,2760.959999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",469,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.76,2766.7199999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",470,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,2770.1759999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",471,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2773.4399999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,2777.8879999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,2782.3359999999993,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",474,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14496.0,7.808,2790.1439999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,453.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14272.0,8.544,2798.687999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,446.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14176.0,8.096,2806.783999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,443.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,2811.167999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.416,2815.5839999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",479,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,2821.1199999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",480,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.64,2825.7599999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",481,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,2829.055999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",482,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,2833.5679999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,2837.919999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",484,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,2843.3919999999994,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,2847.8079999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",486,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,2851.2639999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",487,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.448,2855.7119999999995,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.672,2860.3839999999996,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",489,48832.0,4413624.0,0.0,0,48318382080.0,4413624.0,48322795704.0,24978.0,48.0,0.9980819947254855,61440.0,12288.0,15.552,2875.9359999999997,3721558.0,594402.0,48832.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",490,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13728.0,8.128,2884.064,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,429.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",491,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,2887.328,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",492,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,2890.496,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",493,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.984,2896.48,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",494,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2899.744,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",495,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,2903.136,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",496,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.64,2907.776,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.544,2912.3199999999997,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",498,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72800.0,9.728,2922.048,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2275.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",499,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.776,2925.8239999999996,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72032.0,9.824,2935.6479999999997,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2251.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",501,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.424,2939.0719999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",502,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14240.0,20.96,2960.0319999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,445.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,2963.2639999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",504,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,2966.4639999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",505,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.856,2972.3199999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",506,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.36,2975.68,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",507,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2978.944,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,2983.232,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.64,2987.872,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",510,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13760.0,7.84,2995.712,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,430.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13600.0,7.84,3003.552,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,425.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14848.0,7.872,3011.424,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,464.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,3016.032,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.544,3020.576,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",515,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,3026.0480000000002,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",516,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.768,3030.8160000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",517,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3034.112,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",518,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,3038.688,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.16,3042.848,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",520,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,3048.32,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,3052.864,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",522,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.712,3056.576,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",523,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.512,3061.088,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.64,3065.728,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",525,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.584,3081.312,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",526,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13504.0,8.032,3089.344,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,422.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",527,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.168,3092.512,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",528,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,3095.712,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",529,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.048,3101.7599999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",530,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3105.0879999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",531,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3108.352,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",532,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.544,3112.8959999999997,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,3117.408,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",534,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72416.0,9.568,3126.976,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2263.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",535,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.552,3130.5280000000002,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,74688.0,9.952,3140.4800000000005,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2334.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",537,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.456,3143.9360000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",538,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14048.0,20.896,3164.832000000001,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,439.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,3168.2560000000008,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",540,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,3171.6480000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",541,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,3177.7280000000005,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",542,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,3181.0240000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",543,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3184.2880000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.288,3188.5760000000005,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.576,3193.1520000000005,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",546,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14208.0,7.904,3201.0560000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,444.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13920.0,7.968,3209.0240000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,435.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14080.0,7.808,3216.8320000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,440.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,3221.2480000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.448,3225.6960000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",551,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.472,3231.1680000000006,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",552,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,3235.7120000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",553,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.392,3239.1040000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",554,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.512,3243.6160000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.352,3247.9680000000003,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",556,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.376,3253.3440000000005,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.352,3257.6960000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",558,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3261.0560000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",559,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.416,3265.4720000000007,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.448,3269.9200000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",561,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.776,3285.6960000000004,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",562,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14208.0,7.808,3293.5040000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,444.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",563,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,3296.7360000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",564,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.2,3299.936,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",565,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.92,3305.856,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",566,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.456,3309.3120000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",567,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,3312.7360000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",568,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,3317.1520000000005,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.64,3321.7920000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",570,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,72160.0,10.112,3331.9040000000005,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2255.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",571,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,4.064,3335.9680000000003,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,67488.0,9.92,3345.8880000000004,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2109.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",573,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.296,3349.184,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",574,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,13792.0,21.12,3370.304,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,431.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.232,3373.536,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",576,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,3376.768,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",577,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.08,3382.848,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",578,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,3386.368,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",579,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3389.632,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,3394.0480000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.32,3398.3680000000004,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",582,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14048.0,8.064,3406.4320000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,439.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14016.0,7.808,3414.2400000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,438.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13440.0,7.872,3422.112,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,420.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.672,3426.784,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.64,3431.424,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",587,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,3436.864,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",588,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.352,3441.216,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",589,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3444.576,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",590,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.384,3448.96,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.256,3453.216,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",592,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,3458.56,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,3463.04,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",594,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3466.4,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",595,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.48,3470.88,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.448,3475.328,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",597,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.68,3491.008,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",598,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13952.0,7.84,3498.848,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,436.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",599,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,3502.272,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",600,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.392,3505.6639999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",601,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,64.0,6.144,3511.8079999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,2.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",602,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.648,3515.4559999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",603,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3518.7519999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",604,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.448,3523.1999999999994,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.416,3527.6159999999995,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",606,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70944.0,10.176,3537.7919999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2217.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",607,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.552,3541.3439999999996,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,74400.0,9.664,3551.008,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2325.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",609,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.52,3554.528,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",610,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14624.0,21.152,3575.68,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,457.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.424,3579.104,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",612,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.264,3582.368,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",613,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.952,3588.32,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",614,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.424,3591.744,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",615,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3595.136,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.608,3599.744,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.352,3604.096,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",618,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14272.0,8.128,3612.224,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,446.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13248.0,7.712,3619.936,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,414.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13728.0,8.128,3628.0640000000003,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,429.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.48,3632.5440000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.384,3636.9280000000003,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",623,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.344,3642.2720000000004,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",624,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,3646.8160000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",625,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,3650.1440000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",626,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.544,3654.688,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.256,3658.944,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",628,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.28,3664.224,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,3668.8320000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",630,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.264,3672.0960000000005,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",631,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.544,3676.6400000000003,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.512,3681.1520000000005,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",633,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.648,3696.8000000000006,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",634,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13888.0,7.936,3704.736000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,434.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",635,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3708.0320000000006,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",636,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,3711.2000000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",637,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.952,3717.152000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",638,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.2,3720.3520000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",639,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3723.7440000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",640,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,3728.1600000000008,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,3732.672000000001,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",642,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,70784.0,9.792,3742.464000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2212.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",643,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.616,3746.080000000001,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,71616.0,9.6,3755.6800000000007,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2238.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",645,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.712,3759.3920000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",646,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14496.0,20.64,3780.0320000000006,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,453.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3783.3920000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",648,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.424,3786.8160000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",649,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.496,3793.312000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",650,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,3796.640000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",651,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3799.9360000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.48,3804.4160000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.288,3808.7040000000006,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",654,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,13888.0,7.808,3816.5120000000006,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,434.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14208.0,7.84,3824.3520000000008,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,444.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14112.0,7.84,3832.192000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,441.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.576,3836.768000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.608,3841.376000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",659,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.536,3846.912000000001,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",660,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.416,3851.3280000000013,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",661,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,3854.7840000000015,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",662,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.448,3859.2320000000013,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,4.416,3863.6480000000015,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",664,6144.0,0.0,12288.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,5.44,3869.0880000000016,0.0,0.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,18432.0,12288.0,4.608,3873.6960000000017,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0,0,0.0,0.0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",666,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.456,3877.152000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",667,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.544,3881.6960000000017,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,3072.0,0.0,6144.0,0,0.0,6144.0,6144.0,0.0,240.0,0.0,24576.0,24576.0,4.384,3886.0800000000017,0.0,0.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",669,49152.0,4414464.0,0.0,0,48318382080.0,4414464.0,48322796544.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,15.584,3901.6640000000016,3721728.0,594432.0,49152.0,0.0,0,0,0,0,0,0,0,0.0,0.0,188743680.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",670,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3538944.0,14624.0,7.904,3909.5680000000016,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,110592.0,457.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",671,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.36,3912.9280000000017,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",672,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.232,3916.1600000000017,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",673,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,5.984,3922.1440000000016,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",674,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.52,3925.6640000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",675,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3928.9600000000014,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",676,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.416,3933.3760000000016,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.512,3937.8880000000017,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",678,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,69952.0,9.568,3947.456000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2186.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",679,153600.0,294912.0,24576.0,0,0.0,319488.0,319488.0,0.0,192.0,0.0,49152.0,49152.0,3.744,3951.200000000002,12288.0,0.0,141312.0,12288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",680,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,11059200.0,73216.0,9.824,3961.024000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0,0,0.0,0.0,0.0,345600.0,2288.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",681,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,3.424,3964.448000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",682,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,14155776.0,14688.0,21.216,3985.664000000002,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,442368.0,459.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",683,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,3.328,3988.992000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",684,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,3.168,3992.160000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",685,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,6.176,3998.336000000002,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",686,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,4001.568000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",687,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,4004.800000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",688,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,12672.0,12288.0,4.384,4009.184000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,3072.0,3072.0,6144.0,0,0.0,9216.0,9216.0,0.0,288.0,0.0,24576.0,12288.0,4.448,4013.632000000002,0.0,3072.0,0.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",690,100864000.0,217088000.0,5120000.0,0,0.0,222208000.0,222208000.0,1520000.0,1216000.0,0.5555555555555556,101622912.0,718112.0,48.16,4061.7920000000017,8192000.0,12288000.0,98304000.0,2560000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3175716.0,22441.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,4064.576000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",692,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.872,4068.4480000000017,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4071.7440000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",694,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.456,4075.2000000000016,0.0,128000.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,4078.1760000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34688.0,6.144,4084.3200000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1084.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",697,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,8448.0,34440.0,0.1969781757134863,2109440.0,0.0,6.624,4090.9440000000013,0.0,0.0,0.0,61440.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35072.0,5.792,4096.736000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1096.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,36864.0,0.0,73728.0,0,0.0,73728.0,73728.0,8448.0,35208.0,0.19351291918636612,2109440.0,0.0,6.688,4103.424000000002,0.0,0.0,0.0,36864.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,34048.0,5.664,4109.088000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1064.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,53248.0,0.0,106496.0,0,0.0,106496.0,106496.0,8448.0,34696.0,0.19580938253291302,2109440.0,0.0,6.912,4116.000000000002,0.0,0.0,0.0,53248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,0.0,0.0,0.0,0,0.0,0.0,0.0,2048.0,6048.0,0.25296442687747034,516096.0,35008.0,5.696,4121.696000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16128.0,1094.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,53248.0,0.0,106496.0,0,0.0,106496.0,106496.0,8448.0,34696.0,0.19580938253291302,2109440.0,128.0,6.816,4128.5120000000015,0.0,0.0,0.0,53248.0,0,0,0,0,0,0,0,0.0,0.0,0.0,65920.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,12.0,0.0,4128.0,512.0,4.0,4132.5120000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.168,4135.680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",706,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.44,4141.120000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.04,4144.160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,17.0,0.974124809741248,512.0,0.0,5.408,4149.568000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",709,32768.0,0.0,65536.0,0,0.0,65536.0,65536.0,32636.0,8422.0,0.7948755419163135,527232.0,6560.0,8.8,4158.368000000001,0.0,0.0,0.0,32768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16476.0,205.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,8.48,4166.848000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",711,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,44768.0,6.144,4172.992000000001,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16252.0,1399.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.744,4176.736000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,0.0,1024000.0,3.776,4180.512000000001,0.0,0.0,0.0,128000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4000.0,0.9712577604046907,512000.0,0.0,5.632,4186.144,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",715,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.68,4189.8240000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,41688.0,17709.0,0.7018536289711602,1703168.0,1257856.0,14.816,4204.64,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53224.0,39308.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,9492.0,17673.0,0.3494202098288239,1704704.0,1560576.0,11.296,4215.936000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53272.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17592.0,0.3803888419273035,1699968.0,1560576.0,12.896,4228.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53124.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,0.0,0.0,0.0,0,0.0,0.0,0.0,10800.0,17595.0,0.3803486529318542,1702016.0,1208160.0,13.12,4241.952,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,53188.0,37755.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",720,0.0,0.0,0.0,0,0.0,0.0,0.0,14784.0,4000.0,0.787052810902896,1024000.0,0.0,4.864,4246.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",721,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,3.68,4250.496,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",722,0.0,0.0,0.0,0,0.0,0.0,0.0,10543.0,9416.0,0.5282328773986673,1165312.0,851360.0,9.152,4259.648,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36416.0,26605.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,16000.0,0.0,1549120.0,1536000.0,4.672,4264.32,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48410.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",724,1994552.0,4245120.0,405104.0,0,0.0,4650224.0,4650224.0,528.0,5248.0,0.09141274238227147,518144.0,512000.0,22.944,4287.264,533120.0,128000.0,1792000.0,202552.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16192.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",725,0.0,655488.0,0.0,0,0.0,655488.0,655488.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,63.456,4350.72,655488.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.584,4354.304,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",727,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,3.264,4357.568,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",728,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1152000.0,59328.0,11.712,4369.280000000001,0.0,0.0,0.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,36000.0,1854.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3000.0,0.0,640000.0,0.0,3.552,4372.832,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",730,1994564.0,4245120.0,405128.0,0,0.0,4650248.0,4650248.0,528.0,5248.0,0.09141274238227147,520192.0,512000.0,23.008,4395.84,533120.0,128000.0,1792000.0,202564.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16256.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",731,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,32.608,4428.448,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",732,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,4431.904,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,31.744,4463.648,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4467.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",735,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.616,4470.688,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",736,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.448,4475.136,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",737,4096.0,147456.0,8192.0,0,0.0,155648.0,155648.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,11.552,4486.688,147456.0,0.0,0.0,4096.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,4490.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",739,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,5.248,4495.295999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",740,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,4498.432,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",741,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.416,4502.848,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",742,1408000.0,2560000.0,512000.0,0,0.0,3072000.0,3072000.0,0.0,4000.0,0.0,0.0,512000.0,5.12,4507.968,0.0,256000.0,1152000.0,256000.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",743,799812.0,1280000.0,319624.0,0,0.0,1599624.0,1599624.0,0.0,3000.0,0.0,1024000.0,0.0,5.088,4513.056,0.0,0.0,640000.0,159812.0,0,0,0,0,0,0,0,0.0,0.0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",744,2560.0,0.0,5120.0,0,0.0,5120.0,5120.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,16.768,4529.824,0.0,0.0,0.0,2560.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",745,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,4533.215999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",746,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.328,4536.544,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",747,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,4.0,4540.544,0.0,0.0,0.0,4.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,4543.968,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",749,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,6.0,0.0,96.0,160.0,3.968,4547.936,0.0,0.0,0.0,256.0,0,0,0,0,0,0,0,0.0,0.0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4550.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",751,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4553.632,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",752,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.36,4556.991999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4559.7119999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,3.84,4563.552,0.0,0.0,0.0,8.0,0,0,0,0,0,0,0,0.0,0.0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,5.0,0.0,32.0,32.0,6.816,4570.3679999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",756,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.424,4573.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",757,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.584,4577.375999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",758,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.224,4581.599999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",759,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.024,4586.624,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",760,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4590.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
