Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,2.784,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.656,5.4399999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",3,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,8.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",4,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.688,10.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",5,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,14.112000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",6,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.68,17.792,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.072,20.864,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,24.288,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.296,27.584,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.872,31.456,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,34.816,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,38.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",13,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,3.36,41.6,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",14,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,5.6,47.2,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",15,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,50.752,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",16,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.52,54.272000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),17,32768.0,69632.0,0.0,0,0.0,69632.0,69632.0,364.0,2.0,0.994535519125683,288.0,256.0,5.792,60.06400000000001,0.0,4096.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",18,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,4.544,64.608,0.0,0.0,0.0,288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",19,1024.0,2304.0,0.0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,3.872,68.48,0.0,256.0,1024.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",20,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.264,71.744,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",21,896.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,8.0,0.0,512.0,512.0,4.096,75.84,0.0,256.0,896.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",22,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.168,79.00800000000001,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,82.43200000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",24,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.696,88.12800000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",25,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,91.36000000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,94.78400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",27,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.0,98.78400000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",28,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,102.24000000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",29,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.464,108.70400000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",30,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,114.94400000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",31,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.432,121.37600000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,125.66400000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",33,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.48,130.144,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",34,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,135.328,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,139.584,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",36,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,142.976,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,147.36,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",38,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,151.584,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",39,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.472,157.056,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,161.472,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",41,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,164.96,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",42,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.232,180.192,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",43,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.176,186.368,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",44,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,189.888,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",45,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,193.376,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",46,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.824,199.20000000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",47,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,202.27200000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",48,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,205.50400000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",49,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.608,210.11200000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",50,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,213.63200000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",51,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14528.0,8.512,222.14400000000003,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,454.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.52,225.66400000000004,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",53,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14080.0,8.896,234.56000000000006,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,440.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",54,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.424,237.98400000000007,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",55,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3424.0,8.352,246.33600000000007,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,107.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",56,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,249.76000000000008,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",57,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,253.21600000000007,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",58,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.824,259.0400000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",59,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,262.14400000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",60,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,265.47200000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",61,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.256,269.72800000000007,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",62,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,273.2800000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",63,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.848,280.1280000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",64,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.432,286.5600000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",65,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.112,292.67200000000014,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,297.08800000000014,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",67,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,301.28000000000014,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",68,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.12,306.40000000000015,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,310.6560000000002,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",70,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,314.0480000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.128,318.17600000000016,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",72,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,322.36800000000017,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",73,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,327.64800000000014,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,332.0000000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",75,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,335.45600000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",76,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.104,350.5600000000001,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",77,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.888,356.4480000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",78,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,359.8400000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",79,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,363.2960000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",80,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.696,368.99200000000013,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",81,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,372.2880000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",82,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,375.6160000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",83,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,379.7440000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",84,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.36,383.1040000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",85,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14368.0,8.544,391.6480000000001,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,449.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.68,395.3280000000001,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",87,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14272.0,8.768,404.0960000000001,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,446.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",88,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.296,407.3920000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",89,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.32,415.7120000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",90,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,419.2960000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",91,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.52,422.8160000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",92,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.28,428.09600000000006,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",93,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,431.20000000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",94,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,434.624,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",95,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.0,438.624,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",96,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.488,442.112,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",97,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.464,448.576,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",98,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.4,454.976,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",99,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.304,461.28,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,465.76,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",101,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.384,470.144,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",102,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.056,475.2,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,479.55199999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",104,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,482.97599999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.672,487.64799999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",106,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.448,492.09599999999995,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",107,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.408,497.50399999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,501.59999999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",109,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,505.08799999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",110,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.072,520.16,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",111,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6240.0,5.984,526.144,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,195.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",112,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,529.728,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",113,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.776,533.5039999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",114,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.696,539.1999999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",115,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.296,542.496,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",116,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.136,545.632,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",117,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.32,549.952,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",118,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,553.376,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",119,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13952.0,8.608,561.9839999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,436.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.936,565.92,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",121,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14272.0,8.608,574.5279999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,446.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",122,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.328,577.8559999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",123,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.32,586.1759999999999,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",124,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,589.5999999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",125,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.584,593.1839999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",126,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.824,599.0079999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",127,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.328,602.3359999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",128,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,605.5999999999998,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",129,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.384,609.9839999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",130,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.68,613.6639999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",131,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,619.8719999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",132,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.144,626.0159999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",133,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.112,632.1279999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,636.5119999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",135,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.32,640.8319999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",136,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.216,646.0479999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,650.5279999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",138,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,653.9839999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,658.0799999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",140,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.0,662.0799999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",141,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,667.2639999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,671.5839999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",143,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,675.0399999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",144,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.36,690.3999999999999,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",145,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.984,696.3839999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",146,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,699.9359999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",147,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,703.424,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",148,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,708.608,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",149,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,711.7439999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",150,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.424,715.1679999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",151,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.224,719.3919999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",152,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.68,723.0719999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",153,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13760.0,8.576,731.6479999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,430.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.904,735.5519999999999,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",155,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14208.0,8.352,743.9039999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,444.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",156,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.392,747.2959999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",157,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3232.0,8.352,755.6479999999999,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,101.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",158,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,759.3599999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",159,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,762.848,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",160,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.504,768.352,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",161,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,771.52,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",162,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,774.912,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",163,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,3.904,778.816,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",164,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,782.272,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",165,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.176,788.4480000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",166,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,794.6560000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",167,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,800.8960000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,805.344,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",169,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.416,809.7600000000001,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",170,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,814.9440000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,819.1360000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",172,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,822.5600000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.544,827.104,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",174,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.128,831.2320000000001,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",175,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,836.6080000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,840.768,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",177,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.68,844.448,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",178,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.104,859.552,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",179,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6560.0,6.048,865.6,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,205.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",180,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,869.056,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",181,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.584,872.64,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",182,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.76,878.4,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",183,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,881.504,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",184,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,884.768,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",185,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.8,889.568,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",186,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.712,893.28,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",187,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13920.0,8.512,901.7919999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,435.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.584,905.3759999999999,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",189,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13312.0,8.416,913.7919999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,416.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",190,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.392,917.184,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",191,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3392.0,8.384,925.568,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,106.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",192,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,929.024,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",193,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,932.448,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",194,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.728,938.1759999999999,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",195,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,941.4079999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",196,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,944.6399999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",197,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.288,948.9279999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",198,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,952.3839999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",199,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,958.6239999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",200,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.336,964.9599999999999,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",201,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.272,971.232,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,975.68,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",203,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,979.872,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",204,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,985.12,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,989.504,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",206,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,992.9920000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,997.152,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",208,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,1001.344,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",209,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.312,1006.6560000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,1011.104,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",211,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.328,1014.432,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",212,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.136,1029.568,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",213,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,6.016,1035.584,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",214,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1039.04,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",215,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1042.4959999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",216,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.376,1047.8719999999998,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",217,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1051.0399999999997,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",218,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,1054.3679999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",219,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.192,1058.5599999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",220,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1062.0159999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",221,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13952.0,8.544,1070.5599999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,436.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.552,1074.1119999999996,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",223,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13888.0,8.352,1082.4639999999997,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,434.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",224,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.328,1085.7919999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",225,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3264.0,8.8,1094.5919999999996,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,102.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",226,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1098.1439999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",227,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,1101.4719999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",228,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.536,1107.0079999999996,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",229,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,1110.1439999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",230,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1113.3759999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",231,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.16,1117.5359999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",232,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,1121.0559999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",233,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.304,1127.3599999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",234,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,1133.5679999999998,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",235,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.464,1140.0319999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,1144.2879999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",237,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,1148.6399999999999,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",238,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.088,1153.7279999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,1157.984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",240,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1161.4399999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,1165.9199999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",242,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,1170.1439999999998,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",243,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,1175.4879999999998,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,1179.6799999999998,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",245,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.616,1183.2959999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",246,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,14.912,1198.2079999999999,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",247,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6400.0,6.016,1204.224,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,200.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",248,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1207.7759999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",249,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.712,1211.4879999999998,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",250,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.824,1217.312,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",251,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1220.3839999999998,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",252,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.168,1223.5519999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",253,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.32,1227.8719999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",254,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,1231.2959999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",255,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13824.0,8.384,1239.6799999999996,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,432.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.744,1243.4239999999995,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",257,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13984.0,8.48,1251.9039999999995,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,437.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",258,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.68,1255.5839999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",259,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3136.0,8.704,1264.2879999999996,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,98.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",260,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.712,1267.9999999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",261,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,1271.3919999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",262,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.792,1277.1839999999995,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",263,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,1280.2559999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",264,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1283.4879999999994,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",265,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.448,1287.9359999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",266,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.68,1291.6159999999995,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",267,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.336,1297.9519999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",268,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.144,1304.0959999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",269,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.08,1310.1759999999995,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.576,1314.7519999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",271,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.16,1318.9119999999996,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",272,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,1324.0959999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.64,1328.7359999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",274,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1332.1919999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,1336.4799999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",276,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.096,1340.5759999999996,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",277,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.12,1345.6959999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,1349.9839999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",279,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1353.5359999999994,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",280,12288.0,1103232.0,0.0,0,12079595520.0,1103232.0,12080698752.0,6240.0,12.0,0.9980806142034548,9216.0,3072.0,15.36,1368.8959999999993,930048.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,288.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",281,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.112,1375.0079999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",282,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1378.4639999999993,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",283,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.456,1381.9199999999992,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",284,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.376,1387.2959999999991,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",285,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,1390.463999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",286,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.232,1393.695999999999,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",287,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.32,1398.015999999999,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",288,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,1401.407999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",289,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14272.0,8.768,1410.175999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,446.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.648,1413.823999999999,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",291,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13824.0,8.736,1422.559999999999,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,432.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",292,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.168,1425.727999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",293,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.352,1434.079999999999,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",294,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,1437.535999999999,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",295,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,1440.863999999999,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",296,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.376,1446.2399999999989,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",297,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.552,1449.7919999999988,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",298,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,1453.0879999999988,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",299,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.032,1457.1199999999988,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",300,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,1460.6719999999987,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",301,119117824.0,255100544.0,4861952.0,0,0.0,259962496.0,259962496.0,4861952.0,4178240.0,0.5378151260504201,468537472.0,874720.0,153.216,1613.8879999999986,7140992.0,14585856.0,116686848.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14641796.0,27335.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,1616.6719999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",303,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,4.0,1620.6719999999987,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",304,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,1623.9679999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",305,128.0,152576.0,256.0,0,0.0,152832.0,152832.0,0.0,2392.0,0.0,607744.0,607744.0,3.808,1627.7759999999987,0.0,152576.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.976,1630.7519999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",307,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40384.0,5.888,1636.6399999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1262.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",308,71520.0,0.0,143040.0,0,0.0,143040.0,143040.0,9834.0,179547.0,0.05192706765726234,10083232.0,0.0,14.848,1651.4879999999987,0.0,0.0,0.0,71520.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",309,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40000.0,5.728,1657.2159999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1250.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",310,42912.0,0.0,85824.0,0,0.0,85824.0,85824.0,9834.0,180441.0,0.051683090264091444,10083232.0,0.0,13.984,1671.1999999999987,0.0,0.0,0.0,42912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40000.0,5.728,1676.9279999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1250.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,81056.0,0.0,162112.0,0,0.0,162112.0,162112.0,9834.0,179249.0,0.052008906141747274,10083232.0,0.0,14.56,1691.4879999999987,0.0,0.0,0.0,81056.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40448.0,5.792,1697.2799999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1264.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,47680.0,0.0,95360.0,0,0.0,95360.0,95360.0,9834.0,180292.0,0.051723593827251405,10083232.0,32.0,14.016,1711.2959999999987,0.0,0.0,0.0,47680.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",315,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,15.0,0.0,4800.0,608.0,3.808,1715.1039999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",316,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.136,1718.2399999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",317,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,19.0,0.9711684370257967,608.0,0.0,5.312,1723.5519999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",318,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,1726.4639999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",319,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,19.0,0.9711684370257967,608.0,0.0,5.376,1731.8399999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",320,38145.0,0.0,76290.0,0,0.0,76290.0,76290.0,46043.0,9600.0,0.82747155976493,625536.0,2560.0,8.8,1740.6399999999985,0.0,0.0,0.0,38145.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19548.0,80.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",321,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.576,1749.2159999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",322,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,14244.0,0.0,611968.0,52704.0,6.016,1755.2319999999986,0.0,0.0,0.0,303872.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1647.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",323,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,4.064,1759.2959999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",324,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,4748.0,0.0,0.0,1215488.0,4.032,1763.3279999999986,0.0,0.0,0.0,151936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",325,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4748.0,0.966065353497813,607744.0,0.0,5.728,1769.0559999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.68,1772.7359999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",327,0.0,0.0,0.0,0,0.0,0.0,0.0,41693.0,20721.0,0.6680071778767585,2043904.0,1502496.0,14.368,1787.1039999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63872.0,46953.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",328,0.0,0.0,0.0,0,0.0,0.0,0.0,11177.0,21141.0,0.34584442106566,2036864.0,1852928.0,11.296,1798.3999999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63652.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",329,0.0,0.0,0.0,0,0.0,0.0,0.0,12209.0,21094.0,0.36660360928444885,2039936.0,1852928.0,12.768,1811.1679999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63748.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,12209.0,21095.0,0.3665926014893106,2036096.0,1649504.0,12.192,1823.3599999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63628.0,51547.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",331,2356174.0,5019168.0,458140.0,0,0.0,5477308.0,5477308.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,85.792,1909.1519999999987,613024.0,151936.0,2127104.0,229070.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",332,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,4.0,0.0,0.0,896.0,2.848,1911.9999999999986,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",333,78.0,407579.0,156.0,0,0.0,407735.0,407735.0,20797.0,9870.0,0.6781556722209541,669952.0,612704.0,6.048,1918.0479999999986,407579.0,0.0,0.0,78.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20936.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2392.0,0.0,607744.0,151648.0,3.744,1921.7919999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,4739.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",335,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,1924.5759999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",336,171008.0,0.0,342016.0,0,0.0,342016.0,342016.0,0.0,14244.0,0.0,1367424.0,67776.0,11.52,1936.0959999999986,0.0,0.0,0.0,171008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42732.0,2118.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",337,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,4.352,1940.4479999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",338,2356176.0,5019168.0,458144.0,0,0.0,5477312.0,5477312.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,86.784,2027.2319999999988,613024.0,151936.0,2127104.0,229072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",339,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.568,2036.7999999999988,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,2040.2879999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",341,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.6,2049.887999999999,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",342,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.456,2053.343999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",343,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.744,2057.0879999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",344,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.96,2062.0479999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",345,19987.0,241939.0,39974.0,0,0.0,281913.0,281913.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.6,2071.6479999999992,241939.0,0.0,0.0,19987.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",346,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.2,2074.847999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,2078.111999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",348,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.512,2082.6239999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",349,1672704.0,3041024.0,608256.0,0,0.0,3649280.0,3649280.0,0.0,4748.0,0.0,0.0,607744.0,5.536,2088.1599999999994,0.0,303872.0,1368576.0,304128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",350,949712.0,1519360.0,380064.0,0,0.0,1899424.0,1899424.0,0.0,3588.0,0.0,1215488.0,0.0,5.44,2093.5999999999995,0.0,0.0,759680.0,190032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",351,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,2803.0,1228.0,0.6953609526172165,608064.0,640.0,12.832,2106.4319999999993,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19002.0,20.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",352,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,4.0,0.0,64.0,64.0,4.48,2110.9119999999994,0.0,0.0,0.0,258.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",353,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2113.727999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",354,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.816,2116.543999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.68,2120.223999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.648,2123.871999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",357,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.968,2127.839999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",358,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,5.568,2133.407999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",359,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.936,2137.343999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,2140.8959999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",361,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,3.0,0.0,64.0,32.0,4.672,2145.5679999999993,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",362,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.456,2149.0239999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",363,0.0,0.0,0.0,0,0.0,0.0,0.0,129.0,6.0,0.9555555555555556,32.0,32.0,4.032,2153.0559999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.392,2156.4479999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.36,2159.8079999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",366,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,0.0,4.128,2163.9359999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(detail::TensorInfo<T1, T3>, detail::TensorInfo<const T1, T3>, detail::TensorInfo<const T2, T3>, int, int, T3, long)",367,768.0,0.0,1536.0,0,0.0,1536.0,1536.0,0.0,72.0,0.0,3264.0,3072.0,4.576,2168.5119999999997,0.0,0.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,102.0,96.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",368,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.872,2172.3839999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",369,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,5.184,2177.5679999999998,0.0,0.0,0.0,2.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",370,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,2180.9919999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),371,32768.0,69632.0,0.0,0,0.0,69632.0,69632.0,364.0,2.0,0.994535519125683,288.0,256.0,5.536,2186.528,0.0,4096.0,32768.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,9.0,8.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",372,288.0,0.0,576.0,0,0.0,576.0,576.0,0.0,10.0,0.0,512.0,512.0,4.384,2190.912,0.0,0.0,0.0,288.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",373,1024.0,2304.0,0.0,0,0.0,2304.0,2304.0,0.0,8.0,0.0,512.0,512.0,4.064,2194.9759999999997,0.0,256.0,1024.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",374,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.648,2198.624,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",375,900.0,2056.0,0.0,0,0.0,2056.0,2056.0,0.0,8.0,0.0,512.0,512.0,4.064,2202.6879999999996,0.0,256.0,900.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",376,128.0,1024.0,256.0,0,0.0,1280.0,1280.0,0.0,8.0,0.0,512.0,512.0,3.2,2205.8879999999995,0.0,1024.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,16.0,16.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",377,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,2209.2479999999996,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",378,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.856,2215.104,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",379,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,2218.176,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2221.504,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",381,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.48,2225.984,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",382,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2229.408,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",383,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.528,2235.9359999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",384,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.176,2242.1119999999996,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",385,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,2248.3519999999994,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,2252.5439999999994,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",387,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,2256.7359999999994,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",388,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,2262.0159999999996,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.64,2266.6559999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",390,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2270.1759999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",391,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.032,2274.2079999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",392,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.16,2278.3679999999995,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",393,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.152,2283.5199999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.224,2287.7439999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",395,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2291.2319999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,2295.9359999999997,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",397,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,2300.64,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",398,12064.0,1103028.0,0.0,0,12079595520.0,1103028.0,12080698548.0,6246.0,12.0,0.9980824544582934,15360.0,3072.0,15.808,2316.448,930313.0,148587.0,12064.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",399,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6336.0,5.952,2322.4,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,198.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",400,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2325.92,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",401,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.328,2329.248,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",402,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.376,2334.6240000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",403,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,2337.728,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",404,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,2341.056,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",405,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.224,2345.28,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",406,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.36,2348.6400000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",407,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14432.0,8.544,2357.184,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,451.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",408,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.648,2360.8320000000003,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",409,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14176.0,8.512,2369.3440000000005,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,443.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",410,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,2372.5760000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",411,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3424.0,8.608,2381.1840000000007,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,107.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",412,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2384.7680000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",413,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.552,2388.3200000000006,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",414,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,2393.4720000000007,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",415,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,2396.5120000000006,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2399.8080000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",417,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.288,2404.0960000000005,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.264,2407.3600000000006,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",419,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.464,2413.8240000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",420,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.272,2420.0960000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",421,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.176,2426.2720000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",422,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,2430.3680000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",423,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.064,2434.4320000000002,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",424,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.408,2439.84,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,2444.1600000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",426,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2447.5840000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",427,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.224,2451.8080000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",428,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.512,2456.3200000000006,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",429,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,2461.696000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.128,2465.824000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",431,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2469.216000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.64,2473.8560000000007,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",433,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.768,2478.6240000000007,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",434,11904.0,1102608.0,0.0,0,12079595520.0,1102608.0,12080698128.0,6255.0,12.0,0.9980852082336046,15360.0,3072.0,15.232,2493.8560000000007,930228.0,148572.0,11904.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",435,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6464.0,6.048,2499.9040000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,202.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",436,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,2503.4240000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",437,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.68,2507.1040000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",438,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,2512.2880000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",439,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,2515.3280000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",440,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.52,2518.8480000000004,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",441,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.128,2522.9760000000006,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",442,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.552,2526.5280000000007,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",443,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13632.0,8.384,2534.9120000000007,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,426.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",444,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.616,2538.5280000000007,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",445,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13856.0,8.64,2547.1680000000006,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,433.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",446,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.2,2550.3680000000004,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",447,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3200.0,8.544,2558.9120000000003,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,100.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",448,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2562.3360000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",449,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,2565.824,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",450,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,2570.976,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",451,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.232,2574.208,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,2577.76,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",453,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.32,2582.0800000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2585.472,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",455,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.176,2591.648,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",456,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.432,2598.08,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",457,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,2604.3199999999997,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",458,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,2608.4799999999996,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",459,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.032,2612.5119999999997,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",460,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,2617.792,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.544,2622.336,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",462,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2625.9199999999996,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",463,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,2630.0799999999995,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",464,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,2634.4319999999993,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",465,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,2639.6159999999995,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.224,2643.8399999999997,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",467,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2647.2319999999995,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.928,2652.1599999999994,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",469,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.896,2657.0559999999996,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",470,12000.0,1102860.0,0.0,0,12079595520.0,1102860.0,12080698380.0,6252.0,12.0,0.9980842911877394,15360.0,3072.0,14.976,2672.0319999999997,930279.0,148581.0,12000.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",471,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6528.0,5.952,2677.984,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,204.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",472,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.648,2681.632,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",473,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,2684.992,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",474,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,2690.1440000000002,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",475,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,2693.2160000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",476,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,2696.5760000000005,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",477,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,2700.9920000000006,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",478,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2704.3840000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",479,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13536.0,8.32,2712.7040000000006,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,423.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",480,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.584,2716.2880000000005,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",481,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13920.0,8.48,2724.7680000000005,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,435.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",482,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,2728.0000000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",483,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.544,2736.5440000000003,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",484,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2739.9680000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",485,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.552,2743.5200000000004,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",486,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,2748.6400000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",487,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.264,2751.9040000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2755.1680000000006,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",489,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.288,2759.4560000000006,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.264,2762.7200000000007,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",491,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.336,2769.0560000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",492,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,2775.2640000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",493,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,2781.5040000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",494,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.384,2785.8880000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",495,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,3.936,2789.8240000000005,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",496,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.408,2795.2320000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,2799.5840000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",498,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,2803.072,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",499,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.512,2807.5840000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",500,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.384,2811.9680000000003,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",501,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,2817.2160000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.352,2821.568,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",503,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2825.152,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.672,2829.824,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",505,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,2834.5280000000002,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",506,12000.0,1102860.0,0.0,0,12079595520.0,1102860.0,12080698380.0,6252.0,12.0,0.9980842911877394,15360.0,3072.0,15.36,2849.8880000000004,930279.0,148581.0,12000.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",507,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6432.0,6.144,2856.032,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,201.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",508,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.584,2859.616,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",509,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.552,2863.168,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",510,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.088,2868.2560000000003,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",511,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.008,2871.264,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",512,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,2874.5280000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",513,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.544,2879.072,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",514,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,2882.464,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",515,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14272.0,8.32,2890.784,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,446.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",516,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.744,2894.5280000000002,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",517,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14176.0,8.384,2902.9120000000003,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,443.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",518,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,2906.1440000000002,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",519,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3328.0,8.32,2914.4640000000004,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,104.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",520,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2917.8880000000004,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",521,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.648,2921.5360000000005,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",522,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.12,2926.6560000000004,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",523,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,2929.7280000000005,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,2933.0240000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",525,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.288,2937.3120000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,2940.7360000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",527,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.592,2947.3280000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",528,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.272,2953.6000000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",529,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.176,2959.7760000000003,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",530,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.128,2963.9040000000005,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",531,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.0,2967.9040000000005,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",532,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,2973.2480000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.896,2978.1440000000007,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",534,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.648,2981.792000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",535,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,2986.080000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",536,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.544,2990.6240000000007,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",537,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.088,2995.712000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.32,3000.032000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",539,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.616,3003.648000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,3008.352000000001,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",541,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.768,3013.1200000000013,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",542,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.104,3028.224000000001,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",543,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6400.0,6.016,3034.240000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,200.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",544,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3037.760000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",545,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,3041.152000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",546,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.216,3046.368000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",547,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3049.4720000000007,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",548,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.552,3053.024000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",549,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.16,3057.1840000000007,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",550,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3060.7040000000006,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",551,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14080.0,8.48,3069.1840000000007,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,440.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",552,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.776,3072.9600000000005,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",553,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13568.0,8.896,3081.8560000000007,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,424.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",554,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.296,3085.1520000000005,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",555,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3264.0,8.352,3093.5040000000004,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,102.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",556,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3097.0240000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",557,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.616,3100.6400000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",558,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,3105.8240000000005,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",559,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.104,3108.9280000000003,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3112.224,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",561,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.32,3116.5440000000003,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.616,3120.1600000000003,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",563,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.4,3126.5600000000004,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",564,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,3132.7680000000005,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",565,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.4,3139.1680000000006,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",566,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.544,3143.7120000000004,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",567,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,3.936,3147.6480000000006,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",568,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.184,3152.832000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.48,3157.312000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",570,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,3160.864000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",571,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,3165.152000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",572,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.192,3169.344000000001,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",573,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.248,3174.592000000001,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.256,3178.848000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",575,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3182.272000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.736,3187.0080000000007,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",577,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.672,3191.6800000000007,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",578,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.232,3206.9120000000007,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",579,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6272.0,6.016,3212.928000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,196.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",580,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.744,3216.672000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",581,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.616,3220.288000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",582,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.44,3225.728000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",583,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.04,3228.768000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",584,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3232.032000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",585,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.096,3236.128000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",586,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,3239.520000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",587,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13920.0,8.928,3248.448000000001,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,435.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",588,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,4.0,3252.448000000001,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",589,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13888.0,8.64,3261.0880000000006,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,434.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",590,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,3264.3200000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",591,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3296.0,8.512,3272.832000000001,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,103.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",592,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,3276.384000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",593,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.488,3279.8720000000008,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",594,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.184,3285.056000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",595,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3288.128000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.264,3291.392000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",597,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.416,3295.8080000000014,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.616,3299.4240000000013,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",599,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.464,3305.8880000000013,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",600,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.112,3312.0000000000014,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",601,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,3318.240000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",602,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.16,3322.400000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",603,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.128,3326.528000000001,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",604,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.28,3331.8080000000014,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.448,3336.256000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",606,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3339.680000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",607,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.192,3343.872000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",608,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.352,3348.224000000001,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",609,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.376,3353.6000000000013,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.512,3358.1120000000014,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",611,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.456,3361.5680000000016,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.704,3366.2720000000018,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",613,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.768,3371.040000000002,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",614,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.072,3386.112000000002,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",615,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6240.0,6.08,3392.192000000002,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,195.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",616,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,3395.6800000000017,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",617,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.36,3399.040000000002,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",618,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.216,3404.2560000000017,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",619,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.168,3407.424000000002,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",620,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.392,3410.8160000000016,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",621,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.256,3415.0720000000015,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",622,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.776,3418.8480000000013,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",623,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14208.0,8.544,3427.392000000001,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,444.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",624,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.616,3431.008000000001,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",625,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13984.0,8.32,3439.3280000000013,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,437.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",626,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.2,3442.528000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",627,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3104.0,8.992,3451.5200000000013,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,97.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",628,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.52,3455.0400000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",629,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.584,3458.624000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",630,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.248,3463.872000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",631,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3467.008000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.36,3470.3680000000013,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",633,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.544,3474.912000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3478.336000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",635,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.24,3484.576000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",636,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.208,3490.784000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",637,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,38400.0,0.2537313432835821,2770944.0,6144.0,6.496,3497.280000000001,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86592.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",638,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.096,3501.376000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",639,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,3.936,3505.3120000000013,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",640,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.344,3510.6560000000013,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,3514.9440000000013,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",642,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3518.3680000000013,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",643,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.288,3522.6560000000013,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",644,512.0,384.0,1024.0,0,0.0,1408.0,1408.0,0.0,24.0,0.0,1536.0,1536.0,4.224,3526.8800000000015,384.0,0.0,0.0,512.0,0,0,0,0,0,0,0,0.0,0.0,0.0,48.0,48.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",645,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,5.312,3532.1920000000014,0.0,0.0,0.0,1536.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,4608.0,3072.0,4.416,3536.6080000000015,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,144.0,96.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",647,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.392,3540.0000000000014,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.608,3544.6080000000015,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",649,896.0,0.0,1792.0,0,0.0,1792.0,1792.0,0.0,60.0,0.0,6144.0,6144.0,4.864,3549.4720000000016,0.0,0.0,0.0,896.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",650,12288.0,1103616.0,0.0,0,12079595520.0,1103616.0,12080699136.0,6240.0,12.0,0.9980806142034548,15360.0,3072.0,15.232,3564.7040000000015,930432.0,148608.0,12288.0,0.0,0,0,0,0,0,0,0,0.0,0.0,47185920.0,480.0,96.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 7, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",651,640512.0,1205760.0,99840.0,0,0.0,1305600.0,1305600.0,13056.0,37632.0,0.25757575757575757,2764800.0,6208.0,6.048,3570.7520000000013,24576.0,0.0,590592.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,86400.0,194.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",652,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.552,3574.3040000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",653,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.424,3577.7280000000014,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",654,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.44,3583.1680000000015,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",655,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.136,3586.3040000000015,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",656,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.328,3589.6320000000014,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",657,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.096,3593.7280000000014,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",658,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.392,3597.1200000000013,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",659,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,14304.0,8.608,3605.7280000000014,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,447.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",660,38400.0,73728.0,6144.0,0,0.0,79872.0,79872.0,0.0,48.0,0.0,12288.0,12288.0,3.552,3609.2800000000016,3072.0,0.0,35328.0,3072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,384.0,384.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",661,2408448.0,5157888.0,98304.0,0,0.0,5256192.0,5256192.0,98304.0,84480.0,0.5378151260504201,9842688.0,13920.0,8.736,3618.0160000000014,144384.0,294912.0,2359296.0,49152.0,0,0,0,0,0,0,0,0.0,0.0,0.0,307584.0,435.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",662,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,72.0,0.0,24576.0,12288.0,3.232,3621.2480000000014,0.0,3072.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,768.0,384.0
"std::enable_if<!T7, void>::type internal::kernel<int, int, float, float, float, float, 0, 1, 1, 0, 8, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)",663,2409984.0,4744704.0,99840.0,0,0.0,4844544.0,4844544.0,13056.0,148224.0,0.08095238095238096,10616832.0,3328.0,8.256,3629.5040000000013,24576.0,0.0,2360064.0,49920.0,0,0,0,0,0,0,0,0.0,0.0,0.0,331776.0,104.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",664,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,6144.0,3072.0,3.488,3632.992000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",665,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,48.0,0.0,3072.0,3072.0,3.392,3636.384000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,96.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",666,384.0,1889.0,768.0,0,0.0,2657.0,2657.0,10.0,7.0,0.5882352941176471,3072.0,32.0,5.152,3641.536000000001,1888.0,1.0,0.0,384.0,0,0,0,0,0,0,0,0.0,0.0,0.0,96.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",667,1152.0,2048.0,256.0,0,0.0,2304.0,2304.0,0.0,2.0,0.0,32.0,32.0,3.072,3644.608000000001,0.0,0.0,1024.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,2.0,0.0,32.0,32.0,3.296,3647.904000000001,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",669,768.0,768.0,1536.0,0,0.0,2304.0,2304.0,0.0,72.0,0.0,3168.0,3072.0,4.576,3652.480000000001,0.0,768.0,0.0,768.0,0,0,0,0,0,0,0,0.0,0.0,0.0,99.0,96.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,128.0,768.0,256.0,0,0.0,1024.0,1024.0,0.0,72.0,0.0,6144.0,3072.0,3.424,3655.904000000001,0.0,768.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,192.0,96.0
"void gemv2T_kernel_val<int, int, float, float, float, float, 128, 16, 4, 4, 0, 0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)",671,119117824.0,255100544.0,4861952.0,0,0.0,259962496.0,259962496.0,4861952.0,4178240.0,0.5378151260504201,468561792.0,869696.0,152.992,3808.896000000001,7140992.0,14585856.0,116686848.0,2430976.0,0,0,0,0,0,0,0,0.0,0.0,0.0,14642556.0,27178.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",672,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.784,3811.680000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",673,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.384,3816.064000000001,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",674,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.232,3819.296000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",675,128.0,152576.0,256.0,0,0.0,152832.0,152832.0,0.0,2392.0,0.0,607744.0,607744.0,3.712,3823.008000000001,0.0,152576.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,18992.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,3.456,3826.4640000000013,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",677,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,39872.0,5.824,3832.2880000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1246.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",678,71520.0,0.0,143040.0,0,0.0,143040.0,143040.0,9834.0,179547.0,0.05192706765726234,10083232.0,0.0,13.184,3845.4720000000016,0.0,0.0,0.0,71520.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",679,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40192.0,5.792,3851.2640000000015,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1256.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",680,42912.0,0.0,85824.0,0,0.0,85824.0,85824.0,9834.0,180441.0,0.051683090264091444,10083232.0,0.0,13.344,3864.6080000000015,0.0,0.0,0.0,42912.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",681,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,39808.0,5.824,3870.4320000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1244.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",682,52448.0,0.0,104896.0,0,0.0,104896.0,104896.0,9834.0,180143.0,0.05176416092474352,10083232.0,0.0,13.472,3883.904000000002,0.0,0.0,0.0,52448.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 1>(detail::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",683,0.0,0.0,0.0,0,0.0,0.0,0.0,2384.0,7132.0,0.2505254308532997,611968.0,40320.0,5.728,3889.632000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1260.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",684,52448.0,0.0,104896.0,0,0.0,104896.0,104896.0,9834.0,180143.0,0.05176416092474352,10083232.0,32.0,14.464,3904.096000000002,0.0,0.0,0.0,52448.0,0,0,0,0,0,0,0,0.0,0.0,0.0,315101.0,1.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",685,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,15.0,0.0,4800.0,608.0,3.712,3907.808000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,150.0,19.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",686,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.912,3910.7200000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",687,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,19.0,0.9711684370257967,608.0,0.0,5.376,3916.096000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,3.104,3919.2000000000016,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",689,0.0,0.0,0.0,0,0.0,0.0,0.0,640.0,19.0,0.9711684370257967,608.0,0.0,5.376,3924.576000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 1>(detail::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, detail::TensorInfo<T1, T2>, T2, detail::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",690,38145.0,0.0,76290.0,0,0.0,76290.0,76290.0,38581.0,9600.0,0.8007513335132106,625536.0,2592.0,8.608,3933.184000000002,0.0,0.0,0.0,38145.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19548.0,81.0
"void native::radixSortKVInPlace<(int)-2, (int)-1, 32, 4, float, long, unsigned int>(detail::TensorInfo<T5, T7>, T7, T7, T7, detail::TensorInfo<T6, T7>, T7, bool)",691,0.0,0.0,0.0,0,0.0,0.0,0.0,458.0,8.0,0.9828326180257511,640.0,0.0,8.224,3941.408000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",692,303872.0,0.0,607744.0,0,0.0,607744.0,607744.0,0.0,14244.0,0.0,611968.0,50784.0,6.304,3947.7120000000023,0.0,0.0,0.0,303872.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19124.0,1587.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,4.256,3951.968000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,23740.0,0.0
"native::<unnamed>::fill_reverse_indices_kernel(long *, int, detail::IntDivider<unsigned int>)",694,151936.0,0.0,303872.0,0,0.0,303872.0,303872.0,0.0,4748.0,0.0,0.0,1215488.0,3.968,3955.936000000002,0.0,0.0,0.0,151936.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,37984.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,135168.0,4748.0,0.966065353497813,607744.0,0.0,5.856,3961.792000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.584,3965.376000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,42065.0,20835.0,0.6687599364069953,2021376.0,1508672.0,13.792,3979.168000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63168.0,47146.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",698,0.0,0.0,0.0,0,0.0,0.0,0.0,11177.0,21199.0,0.3452248579194465,2038272.0,1852928.0,11.392,3990.5600000000018,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63696.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",699,0.0,0.0,0.0,0,0.0,0.0,0.0,12209.0,21099.0,0.36654857691845805,2041472.0,1852928.0,12.896,4003.456000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63796.0,57904.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, detail::OpaqueType<8>, unsigned long long>::Policy900, 0, float, detail::OpaqueType<8>, unsigned long long, int, int, detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",700,0.0,0.0,0.0,0,0.0,0.0,0.0,12209.0,21085.0,0.3667027091968523,2026368.0,1645728.0,13.088,4016.544000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,63324.0,51429.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",701,2356174.0,5019168.0,458140.0,0,0.0,5477308.0,5477308.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,86.88,4103.424000000002,613024.0,151936.0,2127104.0,229070.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56976.0,18992.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<float, 1>>(T1, int)",702,128.0,0.0,256.0,0,0.0,256.0,256.0,0.0,4.0,0.0,0.0,896.0,2.912,4106.336000000002,0.0,0.0,0.0,128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,28.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<float, std::plus<float>>::Policy900, const float *, float *, at_cuda_detail::ScanTileState<float, 1>, std::plus<float>, at_cuda_detail::NullType, unsigned int, float, 0>(T2, T3, T4, int, T5, T6, T7)",703,78.0,407579.0,156.0,0,0.0,407735.0,407735.0,20797.0,9851.0,0.6785760897937875,658496.0,612704.0,6.08,4112.416000000002,407579.0,0.0,0.0,78.0,0,0,0,0,0,0,0,0.0,0.0,0.0,20578.0,19147.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2392.0,0.0,607744.0,151648.0,3.616,4116.032000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18992.0,4739.0
"void native::unrolled_elementwise_kernel<native::FillFunctor<bool>, std::array<char *, 1>, 16, TrivialOffsetCalculator<0, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithoutCast, memory::StoreWithoutCast>(int, T1, T2, T4, T5, T6, T7)",705,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.848,4118.880000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",706,171008.0,0.0,342016.0,0,0.0,342016.0,342016.0,0.0,14244.0,0.0,1367424.0,67360.0,11.616,4130.496000000002,0.0,0.0,0.0,171008.0,0,0,0,0,0,0,0,0.0,0.0,0.0,42732.0,2105.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3588.0,0.0,759680.0,0.0,4.32,4134.816000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,23740.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",708,2356176.0,5019168.0,458144.0,0,0.0,5477312.0,5477312.0,132.0,4784.0,0.026851098454027666,1823232.0,607744.0,86.176,4220.992000000002,613024.0,151936.0,2127104.0,229072.0,0,0,0,0,0,0,0,0.0,0.0,0.0,56976.0,18992.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",709,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.44,4230.432000000002,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.552,4233.984000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",711,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.344,4243.328000000001,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",712,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.488,4246.816000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",713,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.456,4250.272000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",714,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.864,4255.136000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",715,19987.0,241939.0,39974.0,0,0.0,281913.0,281913.0,1563.0,1208.0,0.564056297365572,607840.0,640.0,9.344,4264.480000000001,241939.0,0.0,0.0,19987.0,0,0,0,0,0,0,0,0.0,0.0,0.0,18995.0,20.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",716,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.136,4267.616000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.424,4271.040000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",718,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,4.608,4275.648000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",719,1672704.0,3041024.0,608256.0,0,0.0,3649280.0,3649280.0,0.0,4748.0,0.0,0.0,607744.0,5.504,4281.152000000002,0.0,303872.0,1368576.0,304128.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,18992.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",720,949712.0,1519360.0,380064.0,0,0.0,1899424.0,1899424.0,0.0,3588.0,0.0,1215488.0,0.0,5.248,4286.4000000000015,0.0,0.0,759680.0,190032.0,0,0,0,0,0,0,0,0.0,0.0,0.0,37984.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",721,29696.0,0.0,59392.0,0,0.0,59392.0,59392.0,2803.0,1228.0,0.6953609526172165,608064.0,640.0,13.088,4299.488000000001,0.0,0.0,0.0,29696.0,0,0,0,0,0,0,0,0.0,0.0,0.0,19002.0,20.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",722,257.0,0.0,514.0,0,0.0,514.0,514.0,0.0,5.0,0.0,64.0,64.0,4.352,4303.840000000001,0.0,0.0,0.0,257.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4306.560000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",724,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.72,4309.280000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,3.392,4312.672000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",726,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.296,4315.968000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",727,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,4.032,4320.000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,4.608,4324.608000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",729,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.264,4327.872000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0.0,0.0,0.0,1.0,1.0
