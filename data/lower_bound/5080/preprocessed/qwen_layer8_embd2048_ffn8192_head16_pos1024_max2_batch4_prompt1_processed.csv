Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002048,0.002048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001888,0.003936,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.002624,0.00656,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003776,0.010336,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003232,0.013568,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002432,0.016,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002048,0.018048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.0024,0.020448,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002464,0.022912000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003232,0.026144,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,0.028992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002816,0.031808,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.00336,0.035168000000000005,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.03808,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.00272,0.0408,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,0.00288,0.043680000000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,8704.0,32768.0,0.004704,0.048384,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,272.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.051296,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.00384,0.055136000000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002944,0.05808000000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.003232,0.061312000000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.003008,0.06432,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,0.003488,0.06780800000000001,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002848,0.07065600000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.003648,0.07430400000000001,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.003008,0.077312,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.00288,0.080192,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005344,0.085536,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,0.08832,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,0.091264,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,0.094624,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,0.097984,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19761920.0,32768.0,0.025664,0.12364800000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617560.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19780352.0,32768.0,0.025056,0.148704,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618136.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19716992.0,32768.0,0.025472,0.174176,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616156.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003584,0.17776,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003552,0.181312,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,0.1856,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,0.189024,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,0.191904,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003584,0.195488,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003616,0.199104,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,0.20339200000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,0.20678400000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,0.20972800000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020448,0.23017600000000002,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19794688.0,32800.0,0.024576,0.25475200000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618584.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002976,0.257728,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,0.260544,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005408,0.265952,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,0.26864000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,0.27152000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003616,0.27513600000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003456,0.27859200000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83698688.0,137056.0,0.07984,0.3584320000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2615584.0,4283.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003328,0.3617600000000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84871040.0,137376.0,0.079776,0.4415360000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2652220.0,4293.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003008,0.4445440000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78728448.0,32768.0,0.092672,0.5372160000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2460264.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,0.5401600000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,0.5429760000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005504,0.5484800000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,0.5511680000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,0.5540160000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003616,0.557632,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003648,0.56128,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19902208.0,32832.0,0.024224,0.585504,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,621944.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19624064.0,32768.0,0.026816,0.61232,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613252.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19794816.0,32768.0,0.02512,0.63744,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618588.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,0.640928,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003456,0.6443840000000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,0.6488640000000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,0.6522880000000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,0.6551680000000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,0.6586560000000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003584,0.6622400000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,0.6664960000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,0.6699200000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,0.6728320000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020384,0.6932160000000002,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19778176.0,32768.0,0.025696,0.7189120000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618068.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,0.7217920000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002976,0.7247680000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005184,0.7299520000000002,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,0.7326400000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,0.7355200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003424,0.7389440000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003328,0.7422720000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84823168.0,139008.0,0.079648,0.8219200000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2650724.0,4344.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003296,0.8252160000000002,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84733312.0,137312.0,0.079872,0.9050880000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2647916.0,4291.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003168,0.9082560000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78283264.0,32832.0,0.094752,1.0030080000000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446352.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003008,1.006016,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,1.008864,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005312,1.014176,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,1.0169599999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,1.0198079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003424,1.023232,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,1.026656,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19702400.0,32800.0,0.025856,1.0525120000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615700.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19812864.0,32768.0,0.025472,1.077984,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619152.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19598208.0,32800.0,0.026528,1.1045120000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612444.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,1.1080320000000001,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,1.111552,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,1.1158720000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,1.1192640000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,1.1221760000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,1.1256960000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00368,1.1293760000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004192,1.1335680000000001,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,1.137024,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,1.139904,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.02048,1.160384,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19716864.0,32800.0,0.02592,1.186304,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616152.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,1.189184,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,1.192032,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005312,1.197344,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,1.200032,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,1.20288,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,1.206272,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,1.209664,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84171264.0,136992.0,0.082176,1.29184,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2630352.0,4281.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003296,1.295136,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83488768.0,136320.0,0.079264,1.3744,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2609024.0,4260.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003104,1.377504,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78271872.0,32800.0,0.096128,1.473632,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2445996.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,1.476544,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002784,1.479328,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005184,1.484512,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,1.487328,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,1.4903359999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,1.493696,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,1.497056,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19658112.0,32800.0,0.02656,1.5236159999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614316.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19697920.0,32768.0,0.026336,1.5499519999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615560.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19592704.0,32768.0,0.026752,1.5767039999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612272.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,1.5802239999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003488,1.5837119999999998,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,1.5879679999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,1.5914239999999997,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003136,1.5945599999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,1.5980799999999997,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003712,1.6017919999999997,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004192,1.6059839999999996,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,1.6093759999999997,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002976,1.6123519999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020416,1.6327679999999998,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19685632.0,32832.0,0.026592,1.6593599999999997,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615176.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00304,1.6623999999999997,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.00288,1.6652799999999996,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005184,1.6704639999999997,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002656,1.6731199999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,1.6760319999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003488,1.6795199999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003296,1.6828159999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84413568.0,139296.0,0.079776,1.7625919999999997,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2637924.0,4353.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003616,1.7662079999999998,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83158784.0,136480.0,0.080032,1.8462399999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2598712.0,4265.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003232,1.8494719999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78300160.0,32832.0,0.096224,1.9456959999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446880.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003136,1.948832,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,1.9516479999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005152,1.9567999999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,1.9595839999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,1.9625279999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003616,1.966144,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,1.969504,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19806976.0,32768.0,0.025472,1.9949759999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618968.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19674624.0,32768.0,0.0264,2.021376,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614832.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19636736.0,32768.0,0.026592,2.047968,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613648.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,2.051488,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,2.055008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,2.0592639999999998,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,2.0626559999999996,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00304,2.0656959999999995,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003616,2.0693119999999996,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003488,2.0727999999999995,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004192,2.0769919999999997,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,2.0803839999999996,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003168,2.0835519999999996,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020416,2.1039679999999996,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19852160.0,32864.0,0.024832,2.1287999999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,620380.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003072,2.1318719999999995,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002944,2.1348159999999994,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005184,2.1399999999999992,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,2.1426879999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,2.145695999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003552,2.149247999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,2.152671999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84173056.0,137248.0,0.080192,2.232863999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2630408.0,4289.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.00336,2.2362239999999987,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83675648.0,137408.0,0.080096,2.316319999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2614864.0,4294.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003104,2.319423999999999,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78296832.0,32864.0,0.096928,2.416351999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446776.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,2.419295999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,2.422143999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00544,2.427583999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,2.430271999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,2.4331519999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,2.436543999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,2.439935999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19745408.0,32768.0,0.02608,2.466015999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617044.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19760000.0,32768.0,0.025792,2.491807999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617500.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19607424.0,32800.0,0.02672,2.518527999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612732.0,1025.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003648,2.522175999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003488,2.525663999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,2.530047999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,2.533535999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,2.5364479999999987,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00368,2.540127999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003584,2.543711999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004352,2.5480639999999988,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,2.5515839999999987,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002976,2.5545599999999986,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020512,2.5750719999999987,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19719936.0,32896.0,0.026144,2.6012159999999986,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616248.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,2.604095999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,2.606911999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005184,2.612095999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,2.614815999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,2.617695999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,2.621055999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003328,2.624383999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84391296.0,136960.0,0.080704,2.705087999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2637228.0,4280.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003264,2.708351999999999,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84510592.0,137120.0,0.079648,2.7879999999999994,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2640956.0,4285.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003072,2.7910719999999993,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78401024.0,32896.0,0.095712,2.886783999999999,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450032.0,1028.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003168,2.889951999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002784,2.8927359999999993,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005216,2.897951999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,2.9007039999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,2.9035519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003328,2.9068799999999997,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,2.9103039999999996,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19657600.0,32768.0,0.026272,2.9365759999999996,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614300.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19735552.0,32768.0,0.025984,2.9625599999999994,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616736.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19631360.0,32768.0,0.026624,2.9891839999999994,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613480.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,2.9926719999999993,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,2.9961919999999993,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,3.000479999999999,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,3.003935999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,3.006847999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,3.0103039999999988,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003584,3.013887999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,3.0183039999999988,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,3.0217279999999986,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,3.024607999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020352,3.044959999999999,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19685760.0,32864.0,0.02608,3.0710399999999987,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615180.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,3.0739839999999985,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,3.0768319999999987,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005312,3.0821439999999987,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,3.0848319999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,3.087679999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,3.0910719999999987,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003648,3.094719999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84101504.0,136736.0,0.080384,3.175103999999999,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2628172.0,4273.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003488,3.1785919999999988,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83035008.0,137056.0,0.080256,3.2588479999999986,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2594844.0,4283.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003072,3.2619199999999986,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78467584.0,32800.0,0.095104,3.3570239999999987,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2452112.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,3.359903999999999,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,3.362751999999999,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005216,3.367967999999999,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,3.370655999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,3.373535999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,3.376895999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003648,3.380543999999999,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19794048.0,32832.0,0.025216,3.405759999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618564.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19769344.0,32768.0,0.02576,3.431519999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617792.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19576320.0,32768.0,0.02752,3.459039999999999,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611760.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,3.462431999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003648,3.466079999999999,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,3.4703039999999987,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00368,3.473983999999999,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,3.4769279999999987,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,3.4804479999999987,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,3.4839679999999986,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,3.4881919999999984,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,3.4916479999999983,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003008,3.494655999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,131072.0,12029952.0,0.0,0,0.0,12029952.0,12029952.0,66560.0,128.0,0.9980806142034548,98304.0,32768.0,0.020416,3.515071999999998,10182656.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19707904.0,32832.0,0.025312,3.540383999999998,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615872.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,3.543327999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,3.546175999999998,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005216,3.551391999999998,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002656,3.554047999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,3.5568959999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,3.560255999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003648,3.563903999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84999936.0,137920.0,0.07968,3.6435839999999984,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2656248.0,4310.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.00336,3.646943999999998,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83859456.0,137088.0,0.08,3.7269439999999983,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2620608.0,4284.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003456,3.730399999999998,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78290176.0,32768.0,0.096448,3.8268479999999983,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446568.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003072,3.829919999999998,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,3.8327679999999984,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00528,3.8380479999999983,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,3.8408319999999985,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,3.8438079999999983,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003456,3.8472639999999982,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,3.850623999999998,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,1268969472.0,2732417024.0,48619520.0,0,0.0,2781036544.0,2781036544.0,17092800.0,14889728.0,0.5344418052256532,1780958208.0,2754176.0,1.374592,5.225215999999998,87515136.0,155582464.0,1244659712.0,24309760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,55654944.0,86068.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002336,5.2275519999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.002912,5.230463999999998,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002752,5.233215999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.005536,5.238751999999998,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00256,5.241311999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006368,5.247679999999998,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20575296.0,0.0,0.012992,5.260671999999998,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,642978.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,266932.0,0.0,533864.0,0,0.0,533864.0,533864.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006176,5.266847999999998,0.0,0.0,0.0,266932.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,456960.0,0.0,913920.0,0,0.0,913920.0,913920.0,31416.0,460776.0,0.06382874975619271,20691392.0,0.0,0.012608,5.279455999999998,0.0,0.0,0.0,456960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646606.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243728.0,0.0,487456.0,0,0.0,487456.0,487456.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006496,5.285951999999998,0.0,0.0,0.0,243728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,426496.0,0.0,852992.0,0,0.0,852992.0,852992.0,31416.0,459824.0,0.06395244686914746,20655392.0,32.0,0.012864,5.298815999999999,0.0,0.0,0.0,426496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645481.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.00624,5.305055999999999,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,472192.0,0.0,944384.0,0,0.0,944384.0,944384.0,31416.0,461252.0,0.06376708046798249,20746976.0,128.0,0.012544,5.317599999999999,0.0,0.0,0.0,472192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,648343.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.003872,5.321471999999999,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002336,5.323807999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.005024,5.3288319999999985,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002368,5.331199999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004928,5.336127999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,97744.0,34560.0,0.7387834079090579,2473696.0,9856.0,0.007392,5.343519999999998,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,308.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006624,5.3501439999999985,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006816,5.356959999999998,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,5376.0,0.007232,5.364191999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,168.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.00704,5.371231999999998,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388641.0,0.0,777282.0,0,0.0,777282.0,777282.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.006784,5.378015999999998,0.0,0.0,0.0,388641.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.002912,5.380927999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,475392.0,0.0,950784.0,0,0.0,950784.0,950784.0,159930.0,84015.0,0.6555985980446412,8304256.0,5709248.0,0.027584,5.408511999999998,0.0,0.0,0.0,475392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,259508.0,178414.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,95468.0,0.2943037506837569,8433536.0,7410688.0,0.023648,5.432159999999998,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263548.0,231584.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,101524.0,0.2856157732524593,8411520.0,6221504.0,0.0232,5.455359999999998,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262860.0,194422.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,92993.0,0.30385602958460284,8411648.0,4576448.0,0.0232,5.478559999999998,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262864.0,143014.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.00912,5.487679999999998,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.002912,5.490591999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,50073.0,0.4355236903513815,5936896.0,3840864.0,0.015392,5.505983999999999,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185528.0,120027.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7329888.0,7292928.0,0.012192,5.518175999999999,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229059.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.065984,5.584159999999999,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.230048,5.814207999999999,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.005408,5.819615999999999,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002624,5.822239999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,215744.0,0.01136,5.833599999999999,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6742.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,5248.0,0.006912,5.840511999999999,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,164.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9884996.0,20076672.0,2753160.0,0,0.0,22829832.0,22829832.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066144,5.906655999999999,2452096.0,607744.0,8508416.0,1376580.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008512,5.915167999999999,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002784,5.917951999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00832,5.926271999999999,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002752,5.929023999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.00288,5.931903999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.00368,5.9355839999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.008544,5.944127999999999,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.002752,5.946879999999999,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003808,5.9506879999999995,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.002656,5.9533439999999995,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003456,5.956799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.0056,5.9624,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649732.0,6082560.0,1216904.0,0,0.0,7299464.0,7299464.0,0.0,14280.0,0.0,4861952.0,116736.0,0.009376,5.971775999999999,0.0,0.0,3041280.0,608452.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,3648.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,0.010048,5.981824,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.00288,5.984704,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002432,5.987136,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002304,5.989439999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.00288,5.992319999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.002688,5.9950079999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003104,5.998112,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00352,6.001632,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.00272,6.004352,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002816,6.007168,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,0.00368,6.010848,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.003264,6.014112,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.002784,6.016896,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,0.00272,6.019616,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,0.002784,6.0224,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.003008,6.0254080000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,10240.0,0.0,20480.0,0,0.0,20480.0,20480.0,0.0,768.0,0.0,33280.0,32768.0,0.006752,6.03216,0.0,0.0,0.0,10240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1040.0,1024.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,0.003072,6.035232000000001,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,0.003872,6.039104000000001,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002976,6.042080000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.002656,6.044736000000001,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.002944,6.0476800000000015,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,0.00368,6.051360000000002,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.00288,6.054240000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.003584,6.057824000000002,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002816,6.060640000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.00288,6.063520000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005376,6.068896000000002,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,6.071584000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,6.074496000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,6.077856000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,6.081248000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19726976.0,32768.0,0.025664,6.106912000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616468.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19820160.0,32768.0,0.0248,6.131712000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619380.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19769728.0,32768.0,0.025728,6.157440000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617804.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,6.160896000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00368,6.164576000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,6.168832000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,6.172320000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,6.175264000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003584,6.178848000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003552,6.182400000000002,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,6.186656000000002,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,6.190080000000002,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,6.192960000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002976,6.195936000000002,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.003072,6.199008000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020672,6.219680000000003,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19996288.0,32864.0,0.024192,6.243872000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,624884.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002976,6.2468480000000035,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,6.249664000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00528,6.254944000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,6.257664000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,6.260576000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003456,6.264032000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003488,6.267520000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,82632832.0,135584.0,0.079552,6.347072000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2582276.0,4237.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003392,6.350464000000003,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84670592.0,137152.0,0.078752,6.429216000000003,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2645956.0,4286.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003104,6.432320000000003,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78719872.0,32960.0,0.09216,6.524480000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2459996.0,1030.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00304,6.5275200000000035,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,6.530368000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00544,6.535808000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,6.538528000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,6.541504000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003424,6.544928000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,6.548320000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19714176.0,32768.0,0.024832,6.573152000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616068.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19693952.0,32768.0,0.026304,6.5994560000000035,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615436.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19816320.0,32768.0,0.024544,6.624000000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619260.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,6.627488000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,6.631008000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004384,6.635392000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,6.638880000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,6.641824000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003584,6.645408000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003552,6.648960000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,6.653216000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,6.656672000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,6.659584000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002912,6.6624960000000035,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002976,6.665472000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020768,6.686240000000004,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19754240.0,32768.0,0.024864,6.711104000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617320.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,6.714016000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,6.716864000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00528,6.722144000000005,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,6.724864000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,6.727712000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003328,6.731040000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,6.734400000000004,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84739968.0,136960.0,0.07936,6.813760000000005,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2648124.0,4280.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003328,6.8170880000000045,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,85066112.0,138368.0,0.079008,6.8960960000000044,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2658316.0,4324.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003104,6.899200000000005,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78403712.0,32800.0,0.092704,6.991904000000005,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450116.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,6.994784000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002944,6.997728000000006,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005312,7.003040000000006,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,7.005760000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,7.008640000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,7.012000000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003616,7.015616000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19698176.0,32832.0,0.026208,7.041824000000005,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615568.0,1026.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19703296.0,32768.0,0.026112,7.067936000000006,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615728.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19560704.0,32768.0,0.026976,7.094912000000006,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611272.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,7.098400000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003712,7.102112000000006,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,7.106336000000006,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,7.109760000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00304,7.112800000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,7.116320000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00368,7.120000000000006,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,7.124224000000006,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,7.127744000000006,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002976,7.130720000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.003072,7.133792000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002944,7.136736000000007,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.02064,7.157376000000007,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19754752.0,32864.0,0.0256,7.182976000000007,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617336.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,7.185888000000007,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,7.1887040000000075,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005152,7.193856000000007,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,7.196576000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,7.199488000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,7.2028800000000075,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,7.206272000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84748288.0,139008.0,0.080128,7.2864000000000075,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2648384.0,4344.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.00336,7.289760000000007,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,83450112.0,136096.0,0.078944,7.368704000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2607816.0,4253.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.00304,7.371744000000008,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78412288.0,32768.0,0.094272,7.466016000000008,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450384.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003008,7.469024000000008,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,7.471840000000008,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,7.477088000000008,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,7.479776000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,7.482624000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,7.486016000000008,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003488,7.489504000000008,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19672064.0,32768.0,0.025856,7.515360000000008,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614752.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19714176.0,32768.0,0.025952,7.5413120000000085,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616068.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19600128.0,32768.0,0.027296,7.568608000000008,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612504.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,7.572064000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003776,7.575840000000008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,7.580096000000008,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00368,7.583776000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,7.5866560000000085,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,7.590112000000008,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003552,7.593664000000008,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.00448,7.5981440000000084,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003552,7.6016960000000084,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,7.604608000000009,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.00304,7.607648000000009,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002976,7.610624000000009,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.02064,7.63126400000001,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19669376.0,32768.0,0.026176,7.65744000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614668.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,7.66038400000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002912,7.6632960000000105,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,7.6685440000000105,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,7.6712960000000106,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,7.674208000000011,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003296,7.6775040000000105,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,7.68092800000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84320256.0,136640.0,0.0824,7.76332800000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2635008.0,4270.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.00336,7.76668800000001,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84450304.0,137664.0,0.079616,7.84630400000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2639072.0,4302.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003168,7.849472000000009,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78353280.0,32864.0,0.094432,7.94390400000001,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2448540.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002848,7.94675200000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,7.94956800000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,7.95481600000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,7.95753600000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,7.96044800000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,7.96384000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,7.96726400000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19835392.0,32768.0,0.025248,7.99251200000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,619856.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19702912.0,32768.0,0.025888,8.01840000000001,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,615716.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19619712.0,32768.0,0.026592,8.044992000000011,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613116.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,8.048448000000011,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00368,8.05212800000001,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004416,8.056544000000011,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,8.059968000000012,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,8.062880000000012,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,8.066336000000012,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,8.069856000000012,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004192,8.074048000000012,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,8.077536000000013,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,8.080416000000012,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.0032,8.083616000000012,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.0032,8.086816000000011,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020608,8.10742400000001,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19771520.0,32768.0,0.0256,8.133024000000011,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617860.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,8.13590400000001,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,8.13872000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005344,8.144064000000009,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,8.146816000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,8.149696000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003328,8.153024000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,8.156416000000007,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84434944.0,137472.0,0.079232,8.235648000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2638592.0,4296.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003296,8.238944000000007,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84300672.0,139168.0,0.078752,8.317696000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2634396.0,4349.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003072,8.320768000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78240384.0,32768.0,0.096096,8.416864000000006,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2445012.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003072,8.419936000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,8.422752000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005472,8.428224000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,8.431040000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,8.433920000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003392,8.437312000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,8.440672000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19759616.0,32768.0,0.025408,8.466080000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,617488.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19777152.0,32768.0,0.025408,8.491488000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618036.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19602688.0,32768.0,0.02672,8.518208000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612584.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003584,8.521792000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003584,8.525376000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.00432,8.529696000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,8.533120000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002848,8.535968000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003424,8.539392000000005,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,8.542912000000005,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,8.547136000000005,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,8.550656000000005,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,8.553568000000006,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002944,8.556512000000005,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002944,8.559456000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020736,8.580192000000004,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19797120.0,32864.0,0.024992,8.605184000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618660.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,8.608064000000002,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.00288,8.610944000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,8.616192000000002,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,8.618912000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,8.621888000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003584,8.625472000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,8.628864000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84533504.0,136672.0,0.08192,8.710784000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2641672.0,4271.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003328,8.714112000000002,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84872576.0,138112.0,0.079136,8.793248000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2652268.0,4316.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003104,8.796352000000002,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78329856.0,32832.0,0.095584,8.891936000000003,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2447808.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002848,8.894784000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002816,8.897600000000002,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005216,8.902816000000003,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,8.905504000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,8.908416000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.00336,8.911776000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,8.915168000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19625600.0,32800.0,0.026336,8.941504000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,613300.0,1025.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19665280.0,32768.0,0.02592,8.967424000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614540.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19586176.0,32768.0,0.02672,8.994144000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,612068.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,8.997632000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,9.001152000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004288,9.005440000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003392,9.008832000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,9.011744000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,9.015264000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,9.018784000000004,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004224,9.023008000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,9.026464000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,9.029344000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.003232,9.032576000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002944,9.035520000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020576,9.056096000000004,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19780864.0,32864.0,0.02464,9.080736000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618152.0,1027.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,9.083648000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002784,9.086432000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,9.091680000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,9.094368000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,9.097312000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003424,9.100736000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003392,9.104128000000003,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84553216.0,138208.0,0.079968,9.184096000000002,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2642288.0,4319.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003328,9.187424000000002,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84130432.0,137472.0,0.079424,9.266848000000001,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2629076.0,4296.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003136,9.269984000000001,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78267776.0,32768.0,0.094432,9.364416,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2445868.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.003104,9.36752,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,9.370368000000001,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00544,9.375808000000001,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,9.378624,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,9.381536,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003552,9.385088000000001,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003424,9.388512000000002,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19801472.0,32768.0,0.025504,9.414016000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,618796.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19736576.0,32768.0,0.025632,9.439648000000002,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,616768.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,201728.0,0.533175355450237,19574400.0,32768.0,0.027328,9.466976000000003,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,611700.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003488,9.470464000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.00352,9.473984000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.00416,9.478144000000004,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003552,9.481696000000005,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.00288,9.484576000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.00352,9.488096000000004,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,6144.0,4096.0,12288.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,16384.0,16384.0,0.003616,9.491712000000003,4096.0,0.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,512.0,512.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,188416.0,0.0,376832.0,0,0.0,376832.0,376832.0,0.0,512.0,0.0,32768.0,32768.0,0.004256,9.495968000000003,0.0,0.0,0.0,188416.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,24576.0,8192.0,49152.0,0,0.0,57344.0,57344.0,0.0,768.0,0.0,49152.0,32768.0,0.003456,9.499424000000003,0.0,8192.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1024.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,9.502336000000003,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.002912,9.505248000000003,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,12288.0,0.0,24576.0,0,0.0,24576.0,24576.0,0.0,640.0,0.0,65536.0,65536.0,0.003104,9.508352000000004,0.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,131072.0,12034048.0,0.0,0,0.0,12034048.0,12034048.0,66560.0,128.0,0.9980806142034548,163840.0,32768.0,0.020736,9.529088000000003,10186752.0,1585152.0,131072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5120.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,17104896.0,36831232.0,655360.0,0,0.0,37486592.0,37486592.0,230400.0,200704.0,0.5344418052256532,19677824.0,32800.0,0.025536,9.554624000000004,1179648.0,2097152.0,16777216.0,327680.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,614932.0,1025.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002912,9.557536000000004,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002848,9.560384000000004,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.005248,9.565632000000004,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,9.568352000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,9.571328000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003488,9.574816000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.00336,9.578176000000006,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84407680.0,137856.0,0.079904,9.658080000000007,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2637740.0,4308.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,360448.0,688128.0,65536.0,0,0.0,753664.0,753664.0,0.0,512.0,0.0,131072.0,131072.0,0.003328,9.661408000000007,32768.0,0.0,327680.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,68419584.0,147324928.0,2621440.0,0,0.0,149946368.0,149946368.0,921600.0,802816.0,0.5344418052256532,84732160.0,137280.0,0.079424,9.740832000000006,4718592.0,8388608.0,67108864.0,1310720.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2647880.0,4290.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,768.0,0.0,262144.0,131072.0,0.003072,9.743904000000006,0.0,32768.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8192.0,4096.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,68222976.0,146931712.0,2228224.0,0,0.0,149159936.0,149159936.0,869376.0,790528.0,0.5237507711289328,78285440.0,32832.0,0.09616,9.840064000000005,4325376.0,8388608.0,67108864.0,1114112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2446420.0,1026.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,8192.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,192.0,0.0,65536.0,32768.0,0.002944,9.843008000000005,0.0,0.0,8192.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,8192.0,0.0,0,0.0,8192.0,8192.0,0.0,128.0,0.0,32768.0,32768.0,0.002912,9.845920000000005,0.0,8192.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,12676.0,4096.0,0,0.0,16772.0,16772.0,40.0,68.0,0.37037037037037035,32768.0,32.0,0.00528,9.851200000000006,12672.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002784,9.853984000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,9.856864000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,33792.0,32768.0,0.003456,9.860320000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1056.0,1024.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,16384.0,8192.0,32768.0,0,0.0,40960.0,40960.0,0.0,768.0,0.0,65536.0,32768.0,0.003456,9.863776000000005,0.0,8192.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1024.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,1268969472.0,2732417024.0,48619520.0,0,0.0,2781036544.0,2781036544.0,17092800.0,14889728.0,0.5344418052256532,1802019840.0,2826176.0,1.374176,11.237952000000005,87515136.0,155582464.0,1244659712.0,24309760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,56313120.0,88318.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002464,11.240416000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.002912,11.243328000000005,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002688,11.246016000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.005664,11.251680000000004,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002432,11.254112000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006272,11.260384000000004,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20503296.0,0.0,0.013472,11.273856000000004,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,640728.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,267231.0,0.0,534462.0,0,0.0,534462.0,534462.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006368,11.280224000000004,0.0,0.0,0.0,267231.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,456960.0,0.0,913920.0,0,0.0,913920.0,913920.0,31416.0,460776.0,0.06382874975619271,20601088.0,0.0,0.013152,11.293376000000004,0.0,0.0,0.0,456960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,643784.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243729.0,0.0,487458.0,0,0.0,487458.0,487458.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.00608,11.299456000000005,0.0,0.0,0.0,243729.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,449344.0,0.0,898688.0,0,0.0,898688.0,898688.0,31416.0,460538.0,0.06385962915231912,20676096.0,0.0,0.013152,11.312608000000004,0.0,0.0,0.0,449344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,646128.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243717.0,0.0,487434.0,0,0.0,487434.0,487434.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006304,11.318912000000005,0.0,0.0,0.0,243717.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,449344.0,0.0,898688.0,0,0.0,898688.0,898688.0,31416.0,460538.0,0.06385962915231912,20589376.0,128.0,0.013568,11.332480000000004,0.0,0.0,0.0,449344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,643418.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.003904,11.336384000000004,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.00224,11.338624000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004768,11.343392000000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002336,11.345728000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004864,11.350592000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,130134.0,34556.0,0.7901754812071164,2473696.0,10656.0,0.008128,11.358720000000003,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,333.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006592,11.365312000000003,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006688,11.372000000000003,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,0.0,0.006848,11.378848000000003,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.006912,11.385760000000003,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388607.0,0.0,777214.0,0,0.0,777214.0,777214.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.006816,11.392576000000004,0.0,0.0,0.0,388607.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.002912,11.395488000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,496128.0,0.0,992256.0,0,0.0,992256.0,992256.0,168982.0,83903.0,0.6682167783775234,8359680.0,5694112.0,0.027456,11.422944000000005,0.0,0.0,0.0,496128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261240.0,177941.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,97479.0,0.28999293481823546,8429696.0,7410560.0,0.023392,11.446336000000004,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263428.0,231580.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,96655.0,0.2957484789974134,8437888.0,6710912.0,0.02368,11.470016000000005,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263684.0,209716.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,89612.0,0.311746363343113,8443904.0,7078912.0,0.024384,11.494400000000004,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263872.0,221216.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.008768,11.503168000000004,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.00288,11.506048000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,51216.0,0.42998330550918196,5930240.0,3841024.0,0.014912,11.520960000000004,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185320.0,120032.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7333920.0,7292928.0,0.01232,11.533280000000005,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229185.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066144,11.599424000000004,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.229376,11.828800000000005,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.005632,11.834432000000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002752,11.837184000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,218464.0,0.011744,11.848928000000004,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6827.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2560.0,0.007008,11.855936000000005,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,80.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884996.0,20076672.0,2753160.0,0,0.0,22829832.0,22829832.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066624,11.922560000000004,2452096.0,607744.0,8508416.0,1376580.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008224,11.930784000000004,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002752,11.933536000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008352,11.941888000000004,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002784,11.944672000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.00288,11.947552000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.00352,11.951072000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.00896,11.960032000000004,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.002816,11.962848000000003,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003808,11.966656000000002,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.002688,11.969344000000001,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003488,11.972832000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.005536,11.978368000000001,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649732.0,6082560.0,1216904.0,0,0.0,7299464.0,7299464.0,0.0,14280.0,0.0,4861952.0,81920.0,0.009248,11.987616000000001,0.0,0.0,3041280.0,608452.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,2560.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2592.0,0.009728,11.997344000000002,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,81.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.002912,12.000256000000002,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002368,12.002624000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002368,12.004992000000003,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.002912,12.007904000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00272,12.010624000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003072,12.013696000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00352,12.017216000000003,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002848,12.020064000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
