Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.664,1.664,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,1.568,3.232,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.664,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.048,6.944,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.624,9.568,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,32.0,2.496,12.064,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,64.0,3.776,15.84,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.36,19.2,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.944,22.144,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.144,24.287999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,26.336,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.208,28.543999999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.912,31.455999999999996,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,33.983999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,36.44799999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,96.0,8.0,0.9230769230769231,64.0,32.0,3.008,39.455999999999996,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,41.888,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.4,44.288,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.592,46.879999999999995,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,6912.0,0.0,13824.0,0,0.0,13824.0,13824.0,0.0,576.0,0.0,3456.0,24576.0,5.344,52.224,0.0,0.0,0.0,6912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,108.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.136,55.36,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.424,58.784,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,536.0,0.0,1072.0,0,0.0,1072.0,1072.0,0.0,2.0,0.0,64.0,32.0,2.784,61.568,0.0,0.0,0.0,536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.656,64.224,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,2.624,66.848,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,8448.0,18432.0,512.0,0,0.0,18944.0,18944.0,0.0,16.0,0.0,4096.0,4096.0,3.424,70.272,0.0,2048.0,8192.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,72.896,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,8320.0,18432.0,256.0,0,0.0,18688.0,18688.0,0.0,16.0,0.0,4096.0,4096.0,3.456,76.352,0.0,2048.0,8192.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.528,78.88000000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,81.53600000000002,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.448,85.98400000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,88.51200000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,91.23200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,94.30400000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,97.40800000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24608.0,11.712,109.12000000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.264,120.38400000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424064.0,24576.0,11.136,131.52,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138252.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,134.68800000000002,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.136,137.824,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.616,141.44000000000003,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,144.60800000000003,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,147.23200000000003,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,150.33600000000004,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,153.44000000000005,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,157.08800000000005,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,160.25600000000006,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,162.84800000000007,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.16,183.00800000000007,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.072,194.08000000000007,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,196.80000000000007,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,199.36000000000007,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,203.64800000000008,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,206.0480000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,208.67200000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,211.7760000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,214.8160000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11959808.0,99424.0,16.704,231.5200000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373744.0,3107.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.04,234.5600000000001,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11969408.0,99200.0,17.472,252.0320000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374044.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,254.72000000000008,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695616.0,24576.0,34.112,288.8320000000001,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552988.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,291.4240000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,293.9840000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,298.2080000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,300.6720000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,303.2960000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.008,306.3040000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,309.3440000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.424,320.7680000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,331.7120000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.232,342.9440000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,346.04800000000006,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,349.05600000000004,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,352.73600000000005,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,355.84000000000003,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,358.49600000000004,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,361.696,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,364.76800000000003,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,368.41600000000005,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,371.6480000000001,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.688,374.33600000000007,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.192,394.5280000000001,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.04,405.5680000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,408.1600000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,410.6880000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,414.9120000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,417.4400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,420.0320000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.008,423.0400000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,426.1760000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11757440.0,99040.0,17.024,443.2000000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,367420.0,3095.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,446.1440000000001,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11913344.0,99008.0,17.44,463.5840000000001,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372292.0,3094.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,466.2720000000001,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695232.0,24576.0,34.08,500.3520000000001,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552976.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,502.9440000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,505.4720000000001,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,509.6960000000001,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,512.0960000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,514.7200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,517.7600000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,520.8320000000001,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.36,532.1920000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24608.0,10.656,542.8480000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,553.8240000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,556.9920000000001,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,560.032,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,563.712,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,566.848,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.88,569.728,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,572.8639999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,575.9039999999999,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,579.5839999999998,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,582.7839999999999,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,585.3439999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.192,605.5359999999998,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24608.0,10.944,616.4799999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,619.0399999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,621.5999999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,625.8559999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,628.4159999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,631.0399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,634.1119999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,637.1839999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12035840.0,99136.0,16.8,653.9839999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,376120.0,3098.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.976,656.9599999999996,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12023296.0,98912.0,17.952,674.9119999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,375728.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,677.5679999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17704448.0,24576.0,33.856,711.4239999999995,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553264.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,713.9839999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,716.5119999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.384,720.8959999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,723.3279999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,725.9199999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,728.9599999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,731.9999999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.88,742.8799999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,753.8239999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24608.0,10.976,764.7999999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,769.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.072,767.8719999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,770.8799999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,774.5599999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,777.6639999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,780.2559999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,783.4239999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,786.4639999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,790.1119999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.296,793.4079999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,795.9679999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.128,816.0959999999994,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.072,827.1679999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.752,829.9199999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,832.4479999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,836.6719999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,839.0719999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,841.6639999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,844.7039999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,2.976,847.6799999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11972096.0,99200.0,17.216,864.8959999999994,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374128.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.04,867.9359999999994,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11812224.0,98848.0,17.088,885.0239999999993,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,369132.0,3089.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.72,887.7439999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695616.0,24576.0,34.4,922.1439999999993,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552988.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,924.7359999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.592,927.3279999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.32,931.6479999999993,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,934.0799999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,936.6719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,939.7439999999993,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.296,943.0399999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24608.0,10.976,954.0159999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,10.976,964.9919999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.88,975.8719999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,978.9759999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,982.0159999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.616,985.6319999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.264,988.8959999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,991.5519999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,994.6879999999993,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,997.7279999999993,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.84,1001.5679999999993,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,1004.7999999999993,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1007.4239999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.224,1027.6479999999992,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.88,1038.5279999999993,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1041.1519999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,1043.6799999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,1047.9359999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1050.3679999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1052.9919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.008,1055.9999999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,1059.1039999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11855232.0,98912.0,16.96,1076.0639999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370476.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,1079.0719999999997,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11779456.0,99104.0,16.896,1095.9679999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,368108.0,3097.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,1098.6559999999997,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696000.0,24608.0,33.952,1132.6079999999997,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553000.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1135.1999999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1137.7599999999998,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.384,1142.1439999999998,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1144.5759999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1147.1999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,1150.2399999999998,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,1153.3119999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.912,1164.2239999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24608.0,10.752,1174.9759999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,769.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.784,1185.7599999999998,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1188.9279999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.168,1192.0959999999995,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,1195.7439999999995,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1198.8799999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1201.4719999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1204.6079999999995,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,1207.6799999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,1211.3279999999993,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1214.4639999999993,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1217.0879999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.256,1237.3439999999994,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.88,1248.2239999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,1250.9439999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1253.5039999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,1257.7919999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1260.2239999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1262.8159999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,1265.9199999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.168,1269.0879999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11877888.0,99264.0,17.376,1286.4639999999995,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371184.0,3102.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,1289.4719999999995,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12034560.0,99008.0,17.216,1306.6879999999994,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,376080.0,3094.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.816,1309.5039999999995,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17698432.0,24576.0,33.952,1343.4559999999994,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553076.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1346.0799999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1348.6399999999994,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,1352.8959999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1355.4559999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1358.1119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.2,1361.3119999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,1364.4479999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,1375.4239999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.104,1386.5279999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,1397.5039999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1400.6399999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,1403.6479999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,1407.3279999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,1410.5279999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.752,1413.2799999999997,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,1416.3839999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,1419.4239999999998,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.84,1423.2639999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,1426.4639999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1429.0559999999998,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.352,1449.408,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,1460.3519999999999,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,1462.9759999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.688,1465.664,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1469.856,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,1472.416,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1475.072,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,1478.2079999999999,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,1481.2799999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11922048.0,99168.0,17.056,1498.3359999999998,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372564.0,3099.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,1501.3439999999998,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11855232.0,98944.0,17.248,1518.5919999999999,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370476.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.784,1521.376,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695104.0,24576.0,33.92,1555.296,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552972.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1557.8880000000001,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1560.448,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.448,1564.8960000000002,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1567.3280000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1569.9520000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,1573.0560000000003,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,1576.0960000000002,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,10.752,1586.8480000000002,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,11.04,1597.8880000000001,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.752,1608.64,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,1611.776,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,1614.784,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,1618.432,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,1621.6,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,1624.1599999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,1627.3919999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,1630.4639999999997,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.808,1634.2719999999997,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,1637.4719999999998,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1640.0639999999999,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,98304.0,9022464.0,0.0,0,0.0,9022464.0,9022464.0,49920.0,96.0,0.9980806142034548,73728.0,24576.0,20.416,1660.4799999999998,7636992.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.168,1671.6479999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.656,1674.3039999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,1676.8639999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1681.0559999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1683.5199999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1686.1439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,1689.1839999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,1692.2559999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11913088.0,98944.0,17.376,1709.6319999999994,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372284.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,1712.5759999999993,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11840384.0,98912.0,17.376,1729.9519999999993,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370012.0,3091.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,1732.6399999999994,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695360.0,24576.0,34.368,1767.0079999999994,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552980.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1769.5999999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,1772.1279999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,1776.3199999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1778.7839999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1781.4079999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,1784.4479999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.232,1787.6799999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,40000.0,0.9850690556177678,104389120.0,5120000.0,168.256,1955.9359999999995,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3262160.0,160000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,256000.0,1536000.0,512000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,5120000.0,1024000.0,12.288,1968.2239999999995,1280000.0,256000.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160000.0,32000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.016,1970.2399999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,264.0,0.0,528.0,0,0.0,528.0,528.0,0.0,6.0,0.0,128.0,256.0,2.528,1972.7679999999996,0.0,0.0,0.0,264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,1975.1679999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,256000.0,0.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.712,1978.8799999999997,0.0,256000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1980.9279999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,385024.0,0.0,770048.0,0,0.0,770048.0,770048.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.288,1985.2159999999997,0.0,0.0,0.0,385024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,16896.0,68880.0,0.1969781757134863,4207872.0,0.0,5.12,1990.3359999999996,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,129536.0,0.0,259072.0,0,0.0,259072.0,259072.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.192,1994.5279999999996,0.0,0.0,0.0,129536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,270336.0,0.0,540672.0,0,0.0,540672.0,540672.0,16896.0,70416.0,0.19351291918636612,4207872.0,0.0,4.992,1999.5199999999995,0.0,0.0,0.0,270336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,129040.0,0.0,258080.0,0,0.0,258080.0,258080.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.192,2003.7119999999995,0.0,0.0,0.0,129040.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,229376.0,0.0,458752.0,0,0.0,458752.0,458752.0,16896.0,69136.0,0.19639204017109912,4207872.0,0.0,5.024,2008.7359999999994,0.0,0.0,0.0,229376.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,129032.0,0.0,258064.0,0,0.0,258064.0,258064.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.224,2012.9599999999994,0.0,0.0,0.0,129032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,270336.0,0.0,540672.0,0,0.0,540672.0,540672.0,16896.0,70416.0,0.19351291918636612,4207872.0,256.0,5.216,2018.1759999999992,0.0,0.0,0.0,270336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,8.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8224.0,1024.0,3.168,2021.3439999999991,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,2023.3599999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,25.0,0.962178517397882,1024.0,0.0,4.576,2027.9359999999992,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,2029.9839999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,25.0,0.962178517397882,1024.0,0.0,4.384,2034.3679999999993,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,322336.0,0.0,644672.0,0,0.0,644672.0,644672.0,53136.0,16832.0,0.7594328836039332,1048960.0,14784.0,6.208,2040.5759999999993,0.0,0.0,0.0,322336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32780.0,462.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,6.272,2046.8479999999993,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,1040128.0,64000.0,4.416,2051.263999999999,0.0,0.0,0.0,512000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32504.0,2000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,6000.0,0.0,1280000.0,0.0,3.872,2055.135999999999,0.0,0.0,0.0,32000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,8000.0,0.0,0.0,2048000.0,3.904,2059.039999999999,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,388365.0,0.0,776730.0,0,0.0,776730.0,776730.0,64512.0,8000.0,0.8896734333627537,1024000.0,0.0,4.992,2064.0319999999992,0.0,0.0,0.0,388365.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.688,2066.7199999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,239232.0,0.0,478464.0,0,0.0,478464.0,478464.0,83316.0,36841.0,0.6933928110721805,3513472.0,2379712.0,17.056,2083.7759999999994,0.0,0.0,0.0,239232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109796.0,74366.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,78144.0,0.0,156288.0,0,0.0,156288.0,156288.0,17572.0,36530.0,0.32479390780377804,3516416.0,3121280.0,14.4,2098.1759999999995,0.0,0.0,0.0,78144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109888.0,97540.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,80256.0,0.0,160512.0,0,0.0,160512.0,160512.0,18732.0,36380.0,0.3398896791987226,3494784.0,3122432.0,15.584,2113.7599999999993,0.0,0.0,0.0,80256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109212.0,97576.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,80256.0,0.0,160512.0,0,0.0,160512.0,160512.0,18732.0,36346.0,0.3400994952612658,3512320.0,2625664.0,15.808,2129.5679999999993,0.0,0.0,0.0,80256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109760.0,82052.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,8000.0,0.5404411764705882,2048000.0,0.0,5.408,2134.975999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.72,2137.695999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,62637.0,0.0,125274.0,0,0.0,125274.0,125274.0,21125.0,19847.0,0.5155960167919554,2406272.0,1717280.0,9.632,2147.327999999999,0.0,0.0,0.0,62637.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75196.0,53665.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,32000.0,0.0,3097888.0,3072000.0,6.848,2154.175999999999,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96809.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,4195952.0,8490240.0,1223904.0,0,0.0,9714144.0,9714144.0,1056.0,10496.0,0.09141274238227147,2026112.0,1024000.0,18.592,2172.767999999999,1066240.0,256000.0,3584000.0,611952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63316.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,274432.0,1310976.0,548864.0,0,0.0,1859840.0,1859840.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,51.104,2223.871999999999,1310976.0,0.0,0.0,274432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.712,2227.583999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,2.144,2229.7279999999987,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,24000.0,0.0,2304000.0,100512.0,9.312,2239.0399999999986,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,72000.0,3141.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,6000.0,0.0,1280000.0,0.0,4.224,2243.2639999999988,0.0,0.0,0.0,32000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,4195976.0,8490240.0,1223952.0,0,0.0,9714192.0,9714192.0,1056.0,10496.0,0.09141274238227147,2022016.0,1024000.0,18.688,2261.951999999999,1066240.0,256000.0,3584000.0,611976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,63188.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,50688.0,0.0,101376.0,0,0.0,101376.0,101376.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.88,2268.831999999999,0.0,0.0,0.0,50688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,2271.295999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,50688.0,0.0,101376.0,0,0.0,101376.0,101376.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.464,2277.759999999999,0.0,0.0,0.0,50688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.56,2280.319999999999,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.592,2282.911999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2286.175999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,16384.0,294400.0,32768.0,0,0.0,327168.0,327168.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,9.472,2295.6479999999992,294400.0,0.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,2.0,0.0,32.0,32.0,2.432,2298.079999999999,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.296,2301.375999999999,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2303.8079999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2307.0399999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1806336.0,2834432.0,1290240.0,0,0.0,4124672.0,4124672.0,0.0,8000.0,0.0,0.0,1024000.0,4.128,2311.1679999999988,0.0,512000.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,1535624.0,2560000.0,511248.0,0,0.0,3071248.0,3071248.0,0.0,6000.0,0.0,2048000.0,0.0,5.984,2317.1519999999987,0.0,0.0,1280000.0,255624.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,148480.0,0.0,296960.0,0,0.0,296960.0,296960.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,12.768,2329.9199999999987,0.0,0.0,0.0,148480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.432,2332.3519999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.464,2334.8159999999984,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,2.688,2337.5039999999985,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.496,2339.9999999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,264.0,0.0,528.0,0,0.0,528.0,528.0,0.0,6.0,0.0,128.0,256.0,2.72,2342.7199999999984,0.0,0.0,0.0,264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,8.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.176,2344.8959999999984,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.08,2346.9759999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.528,2349.503999999998,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.176,2351.679999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,32.0,2.56,2354.239999999998,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,10.0,0.0,20.0,0,0.0,20.0,20.0,0.0,5.0,0.0,32.0,32.0,5.696,2359.935999999998,0.0,0.0,0.0,10.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.528,2362.4639999999977,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,2.432,2364.8959999999975,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,3.104,2367.9999999999973,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.264,2371.2639999999974,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2373.6639999999975,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2376.0639999999976,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,144.0,0.0,288.0,0,0.0,288.0,288.0,0.0,3.0,0.0,160.0,64.0,3.328,2379.3919999999976,0.0,0.0,0.0,144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,2.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1280.0,0.0,2560.0,0,0.0,2560.0,2560.0,96.0,8.0,0.9230769230769231,128.0,32.0,3.04,2382.4319999999975,0.0,0.0,0.0,1280.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,128.0,128.0,2.4,2384.8319999999976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,128.0,32.0,2.4,2387.2319999999977,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,160.0,0.0,2.56,2389.7919999999976,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,128.0,64.0,2.4,2392.1919999999977,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,6912.0,0.0,13824.0,0,0.0,13824.0,13824.0,0.0,576.0,0.0,21888.0,24576.0,7.36,2399.551999999998,0.0,0.0,0.0,6912.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,684.0,768.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,32.0,0.0,64.0,0,0.0,64.0,64.0,0.0,2.0,0.0,128.0,32.0,2.752,2402.303999999998,0.0,0.0,0.0,32.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,48.0,0.0,96.0,0,0.0,96.0,96.0,0.0,2.0,0.0,32.0,32.0,3.392,2405.6959999999976,0.0,0.0,0.0,48.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,536.0,0.0,1072.0,0,0.0,1072.0,1072.0,0.0,2.0,0.0,64.0,32.0,2.784,2408.4799999999977,0.0,0.0,0.0,536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,64.0,48.0,0.5714285714285714,2560.0,2048.0,2.592,2411.071999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,64.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,0.0,40.0,0.0,4096.0,4096.0,2.624,2413.6959999999976,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,8448.0,18464.0,512.0,0,0.0,18976.0,18976.0,0.0,16.0,0.0,4096.0,4096.0,3.776,2417.4719999999975,32.0,2048.0,8192.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2420.0959999999973,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,8320.0,18432.0,256.0,0,0.0,18688.0,18688.0,0.0,16.0,0.0,4096.0,4096.0,3.52,2423.6159999999973,0.0,2048.0,8192.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,4096.0,4096.0,2.624,2426.239999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,128.0,128.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2428.799999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,2433.055999999997,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2435.455999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2438.143999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,2441.183999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,2444.287999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.072,2455.359999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,2466.303999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,11.072,2477.375999999997,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,2480.575999999997,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,2483.5839999999966,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.68,2487.2639999999965,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,2490.3999999999965,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,2493.0239999999962,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,2496.159999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,2499.167999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,2502.815999999996,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,2506.015999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2508.607999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2511.199999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2513.7919999999963,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.352,2534.143999999996,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.784,2544.9279999999962,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2547.5199999999963,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2550.0799999999963,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,2554.2719999999963,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,2556.799999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2559.455999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,2562.495999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,2565.567999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11873024.0,99008.0,17.184,2582.7519999999963,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371032.0,3094.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,2585.6959999999963,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11882496.0,99072.0,17.056,2602.7519999999963,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371328.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,2605.4079999999963,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696512.0,24576.0,34.688,2640.0959999999964,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553016.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,2642.719999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.624,2645.343999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.416,2649.759999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2652.127999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2654.719999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.2,2657.919999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,2661.055999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.656,2671.711999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,2682.687999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,2693.663999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,2696.767999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,2699.8719999999958,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.616,2703.4879999999957,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,2706.5919999999956,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.688,2709.2799999999957,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,2712.4159999999956,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,2715.4559999999956,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.744,2719.1999999999957,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,2722.367999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2724.959999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2727.551999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,2730.143999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.448,2750.591999999996,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.04,2761.631999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2764.223999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2766.783999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,2771.039999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2773.407999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.688,2776.095999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.168,2779.263999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.008,2782.271999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11976576.0,99072.0,16.896,2799.167999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,374268.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.072,2802.239999999996,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11938432.0,99200.0,17.152,2819.391999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373076.0,3100.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,2822.047999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695488.0,24576.0,34.784,2856.8319999999962,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552984.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.752,2859.583999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,2862.143999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,2866.335999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2868.7359999999962,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,2871.455999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,2874.559999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.168,2877.727999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.072,2888.799999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424064.0,24576.0,10.784,2899.583999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138252.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.072,2910.6559999999963,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,2913.8879999999963,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,2916.895999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.744,2920.6399999999962,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,2923.775999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2926.3679999999963,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,2929.471999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,2.976,2932.4479999999962,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.904,2936.351999999996,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,2939.455999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2942.047999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2944.7359999999962,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.688,2947.4239999999963,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.672,2968.0959999999964,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.36,2979.4559999999965,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,2982.0159999999964,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.592,2984.6079999999965,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.192,2988.7999999999965,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2991.2639999999965,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2993.8559999999966,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.104,2996.9599999999964,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.296,3000.255999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11928960.0,98880.0,17.024,3017.279999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372780.0,3090.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.04,3020.319999999996,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,12035968.0,99264.0,17.312,3037.631999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,376124.0,3102.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,3040.319999999996,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17706496.0,24576.0,33.76,3074.0799999999963,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553328.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3076.6719999999964,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3079.2319999999963,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,3083.5199999999963,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3085.9199999999964,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3088.5119999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,3091.5519999999965,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,3094.6239999999966,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,10.88,3105.5039999999967,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.848,3116.3519999999967,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.656,3127.0079999999966,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3130.1439999999966,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3133.1519999999964,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.616,3136.7679999999964,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.36,3140.1279999999965,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.848,3142.9759999999965,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,3146.1759999999963,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,3149.279999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,3152.9279999999962,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,3156.159999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3158.783999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.688,3161.471999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.944,3164.415999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.448,3184.863999999996,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.936,3196.799999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3199.391999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.688,3202.0799999999963,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,3206.335999999996,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3208.703999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3211.359999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.168,3214.527999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.2,3217.727999999996,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11875584.0,99392.0,17.088,3234.815999999996,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,371112.0,3106.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.944,3237.759999999996,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11954560.0,99104.0,17.184,3254.9439999999963,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373580.0,3097.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,3257.6319999999964,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695616.0,24576.0,34.272,3291.9039999999964,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552988.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3294.4959999999965,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.656,3297.1519999999964,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3301.3759999999966,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3303.7759999999967,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3306.3679999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,3309.439999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,3312.479999999997,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.816,3323.2959999999966,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.624,3333.9199999999964,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.976,3344.8959999999965,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,3347.9999999999964,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3351.007999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.584,3354.591999999996,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3357.759999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3360.383999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.072,3363.455999999996,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.008,3366.463999999996,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.872,3370.3359999999957,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3373.4719999999957,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3376.0639999999958,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.688,3378.751999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.56,3381.311999999996,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.48,3401.791999999996,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.264,3413.055999999996,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3415.647999999996,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3418.175999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.448,3422.6239999999957,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3425.023999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3427.6799999999957,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,3430.7199999999957,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.04,3433.7599999999957,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11935232.0,99328.0,17.024,3450.7839999999956,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372976.0,3104.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,3453.7919999999954,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11935616.0,98848.0,17.056,3470.8479999999954,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372988.0,3089.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.688,3473.5359999999955,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17701376.0,24576.0,34.144,3507.6799999999953,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553168.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,3510.399999999995,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,3512.927999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.384,3517.311999999995,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3519.7439999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3522.335999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,3525.407999999995,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.008,3528.4159999999947,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,10.944,3539.3599999999947,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,10.88,3550.239999999995,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423808.0,24576.0,11.2,3561.4399999999946,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138244.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.232,3564.6719999999946,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,3567.7119999999945,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.616,3571.3279999999945,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3574.4639999999945,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3577.0879999999943,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3580.2559999999944,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,3583.359999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.712,3587.071999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.328,3590.399999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3593.023999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,3595.615999999994,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.624,3598.239999999994,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.416,3618.655999999994,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4424192.0,24576.0,11.296,3629.951999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138256.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3632.5759999999937,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3635.1359999999936,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.256,3639.3919999999935,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3641.7919999999935,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3644.3839999999936,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.232,3647.6159999999936,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.136,3650.7519999999936,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11943552.0,99072.0,16.896,3667.6479999999938,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373236.0,3096.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.008,3670.6559999999936,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11864320.0,98848.0,17.088,3687.743999999994,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,370760.0,3089.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,3690.3999999999937,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17697152.0,24608.0,34.336,3724.7359999999935,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553036.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3727.3279999999936,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3729.8879999999936,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.32,3734.2079999999937,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3736.607999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3739.199999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.136,3742.335999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,3745.407999999994,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.136,3756.543999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423936.0,24576.0,11.04,3767.583999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138248.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.944,3778.527999999994,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3781.663999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.04,3784.703999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.744,3788.447999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,3791.615999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3794.207999999994,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.2,3797.407999999994,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.104,3800.511999999994,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,3804.159999999994,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,3807.2639999999938,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.56,3809.8239999999937,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.656,3812.4799999999937,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.72,3815.1999999999935,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.576,3835.7759999999935,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.2,3846.9759999999933,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.816,3849.791999999993,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3852.351999999993,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,3856.575999999993,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3858.9759999999933,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3861.599999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.04,3864.639999999993,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,3867.743999999993,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11940480.0,99424.0,17.248,3884.991999999993,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,373140.0,3107.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,2.912,3887.9039999999927,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11914240.0,98944.0,17.568,3905.471999999993,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372320.0,3092.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.656,3908.127999999993,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17695232.0,24608.0,33.888,3942.015999999993,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,552976.0,769.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.72,3944.7359999999926,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,3947.2959999999925,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.288,3951.5839999999926,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3953.9839999999926,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,3956.7039999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.2,3959.9039999999923,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.104,3963.007999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.136,3974.143999999992,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.008,3985.151999999992,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,10.912,3996.0639999999917,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,3999.1999999999916,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.072,4002.2719999999917,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,4005.919999999992,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.104,4009.0239999999917,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4011.615999999992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.168,4014.783999999992,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,4608.0,3072.0,9216.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,12288.0,12288.0,3.136,4017.919999999992,3072.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,184320.0,0.0,368640.0,0,0.0,368640.0,368640.0,0.0,384.0,0.0,24576.0,24576.0,3.648,4021.567999999992,0.0,0.0,0.0,184320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,18432.0,6144.0,36864.0,0,0.0,43008.0,43008.0,0.0,576.0,0.0,36864.0,24576.0,3.136,4024.703999999992,0.0,6144.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.592,4027.295999999992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.72,4030.015999999992,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,9216.0,0.0,18432.0,0,0.0,18432.0,18432.0,0.0,480.0,0.0,49152.0,49152.0,2.592,4032.607999999992,0.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,98304.0,9025536.0,0.0,0,0.0,9025536.0,9025536.0,49920.0,96.0,0.9980806142034548,122880.0,24576.0,20.448,4053.055999999992,7640064.0,1188864.0,98304.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3840.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,4780032.0,10420224.0,122880.0,0,0.0,10543104.0,10543104.0,201216.0,39936.0,0.8343949044585988,4423680.0,24576.0,11.744,4064.799999999992,393216.0,589824.0,4718592.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,138240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.848,4067.647999999992,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.56,4070.207999999992,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.224,4074.431999999992,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,4076.863999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4079.455999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.168,4082.623999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.2,4085.823999999992,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11935616.0,99104.0,17.344,4103.1679999999915,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,372988.0,3097.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,270336.0,516096.0,49152.0,0,0.0,565248.0,565248.0,0.0,384.0,0.0,98304.0,98304.0,3.072,4106.239999999992,24576.0,0.0,245760.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,19120128.0,41680896.0,491520.0,0,0.0,42172416.0,42172416.0,804864.0,159744.0,0.8343949044585988,11765120.0,99488.0,17.664,4123.903999999991,1572864.0,2359296.0,18874368.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,367660.0,3109.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,576.0,0.0,196608.0,98304.0,2.912,4126.815999999992,0.0,24576.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,3072.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 8, 9, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,19046400.0,41385984.0,344064.0,0,0.0,41730048.0,41730048.0,754176.0,150528.0,0.833616298811545,17696128.0,24576.0,34.08,4160.895999999992,1277952.0,2359296.0,18874368.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,553004.0,768.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,6144.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,144.0,0.0,49152.0,24576.0,2.624,4163.519999999991,0.0,0.0,6144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,24576.0,24576.0,2.528,4166.047999999992,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,10504.0,4096.0,0,0.0,14600.0,14600.0,32.0,56.0,0.36363636363636365,24576.0,32.0,4.384,4170.431999999992,10496.0,8.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4172.831999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4175.423999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,25344.0,24576.0,3.072,4178.495999999991,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,792.0,768.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,12288.0,6144.0,24576.0,0,0.0,30720.0,30720.0,0.0,576.0,0.0,49152.0,24576.0,3.072,4181.567999999991,0.0,6144.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,40000.0,0.9850690556177678,104372704.0,5120000.0,167.136,4348.7039999999915,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3261647.0,160000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,256000.0,1536000.0,512000.0,0,0.0,2048000.0,2048000.0,0.0,48000.0,0.0,5120000.0,1024000.0,12.128,4360.831999999991,1280000.0,256000.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160000.0,32000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,64.0,2.048,4362.879999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,268.0,0.0,536.0,0,0.0,536.0,536.0,0.0,6.0,0.0,192.0,320.0,2.592,4365.471999999991,0.0,0.0,0.0,268.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,4367.87199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,256000.0,0.0,0,0.0,256000.0,256000.0,0.0,4000.0,0.0,1024000.0,1024000.0,3.552,4371.42399999999,0.0,256000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,32000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.016,4373.43999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,385024.0,0.0,770048.0,0,0.0,770048.0,770048.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.288,4377.727999999989,0.0,0.0,0.0,385024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,221184.0,0.0,442368.0,0,0.0,442368.0,442368.0,16896.0,68880.0,0.1969781757134863,4207872.0,0.0,4.96,4382.687999999989,0.0,0.0,0.0,221184.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,129543.0,0.0,259086.0,0,0.0,259086.0,259086.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.192,4386.879999999989,0.0,0.0,0.0,129543.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,270336.0,0.0,540672.0,0,0.0,540672.0,540672.0,16896.0,70416.0,0.19351291918636612,4207872.0,0.0,5.216,4392.0959999999895,0.0,0.0,0.0,270336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,129061.0,0.0,258122.0,0,0.0,258122.0,258122.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.32,4396.415999999989,0.0,0.0,0.0,129061.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,244736.0,0.0,489472.0,0,0.0,489472.0,489472.0,16896.0,69616.0,0.19530238579619014,4207872.0,0.0,5.088,4401.503999999989,0.0,0.0,0.0,244736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,129032.0,0.0,258064.0,0,0.0,258064.0,258064.0,4096.0,12096.0,0.25296442687747034,1026688.0,65536.0,4.448,4405.951999999989,0.0,0.0,0.0,129032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32084.0,2048.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,242688.0,0.0,485376.0,0,0.0,485376.0,485376.0,16896.0,69552.0,0.195446973903387,4207872.0,256.0,4.928,4410.879999999989,0.0,0.0,0.0,242688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,131496.0,8.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,0.0,24.0,0.0,8224.0,1024.0,3.232,4414.111999999989,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,257.0,32.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.984,4416.0959999999895,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,25.0,0.962178517397882,1024.0,0.0,4.48,4420.575999999989,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,4422.623999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,25.0,0.962178517397882,1024.0,0.0,4.416,4427.039999999989,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,322336.0,0.0,644672.0,0,0.0,644672.0,644672.0,64165.0,16848.0,0.7920333773591892,1048960.0,13952.0,6.496,4433.535999999989,0.0,0.0,0.0,322336.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32780.0,436.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,1024.0,0.0,2048.0,0,0.0,2048.0,2048.0,3664.0,64.0,0.9828326180257511,5120.0,0.0,6.272,4439.807999999989,0.0,0.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,160.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,512000.0,0.0,1024000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,1040128.0,64000.0,4.288,4444.095999999989,0.0,0.0,0.0,512000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32504.0,2000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,6000.0,0.0,1280000.0,0.0,3.872,4447.967999999989,0.0,0.0,0.0,32000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,8000.0,0.0,0.0,2048000.0,3.84,4451.807999999989,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,64000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,388348.0,0.0,776696.0,0,0.0,776696.0,776696.0,64512.0,8000.0,0.8896734333627537,1024000.0,0.0,4.832,4456.639999999989,0.0,0.0,0.0,388348.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.656,4459.295999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,239232.0,0.0,478464.0,0,0.0,478464.0,478464.0,83316.0,36571.0,0.6949544154078424,3510912.0,2401632.0,17.28,4476.575999999989,0.0,0.0,0.0,239232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109716.0,75051.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,81600.0,0.0,163200.0,0,0.0,163200.0,163200.0,18976.0,36462.0,0.3422922904866698,3513856.0,2488640.0,14.4,4490.975999999989,0.0,0.0,0.0,81600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109808.0,77770.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,80256.0,0.0,160512.0,0,0.0,160512.0,160512.0,18732.0,36334.0,0.34017360984999817,3503232.0,3122048.0,15.456,4506.431999999989,0.0,0.0,0.0,80256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109476.0,97564.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,80256.0,0.0,160512.0,0,0.0,160512.0,160512.0,18732.0,36471.0,0.3393293842725939,3513728.0,2626752.0,15.328,4521.759999999989,0.0,0.0,0.0,80256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,109804.0,82086.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,8000.0,0.5404411764705882,2048000.0,0.0,5.248,4527.007999999989,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,4529.5999999999885,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,62637.0,0.0,125274.0,0,0.0,125274.0,125274.0,21125.0,19685.0,0.5176427346238667,2409472.0,1718176.0,9.632,4539.231999999988,0.0,0.0,0.0,62637.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75296.0,53693.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,32000.0,0.0,3098304.0,3072000.0,6.592,4545.823999999988,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96822.0,96000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,4195952.0,8490240.0,1223904.0,0,0.0,9714144.0,9714144.0,1056.0,10496.0,0.09141274238227147,2094464.0,1024000.0,18.208,4564.031999999987,1066240.0,256000.0,3584000.0,611952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65452.0,32000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,274432.0,1310976.0,548864.0,0,0.0,1859840.0,1859840.0,143680.0,16000.0,0.8997995991983968,1024000.0,1024000.0,51.104,4615.135999999988,1310976.0,0.0,0.0,274432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,32000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,4000.0,0.0,1024000.0,256000.0,3.552,4618.687999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,256.0,2.272,4620.959999999987,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,768000.0,0.0,1536000.0,0,0.0,1536000.0,1536000.0,0.0,24000.0,0.0,2304000.0,99328.0,9.12,4630.079999999987,0.0,0.0,0.0,768000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,72000.0,3104.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,32000.0,0.0,64000.0,0,0.0,64000.0,64000.0,0.0,6000.0,0.0,1280000.0,0.0,3.904,4633.983999999988,0.0,0.0,0.0,32000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,4195975.0,8490240.0,1223950.0,0,0.0,9714190.0,9714190.0,1056.0,10496.0,0.09141274238227147,2054016.0,1024000.0,18.752,4652.735999999988,1066240.0,256000.0,3584000.0,611975.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64188.0,32000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,50688.0,0.0,101376.0,0,0.0,101376.0,101376.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.336,4659.071999999988,0.0,0.0,0.0,50688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,4661.535999999988,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,50688.0,0.0,101376.0,0,0.0,101376.0,101376.0,2590.0,2034.0,0.5601211072664359,1024128.0,1056.0,6.592,4668.127999999988,0.0,0.0,0.0,50688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32004.0,33.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,4670.5279999999875,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.464,4672.9919999999875,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.456,4676.447999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,16384.0,294400.0,32768.0,0,0.0,327168.0,327168.0,608.0,2008.0,0.2324159021406728,1024000.0,256.0,9.632,4686.079999999987,294400.0,0.0,0.0,16384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,2.0,0.0,32.0,32.0,2.4,4688.479999999987,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.264,4691.743999999987,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4694.175999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4697.375999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1806336.0,2834432.0,1290240.0,0,0.0,4124672.0,4124672.0,0.0,8000.0,0.0,0.0,1024000.0,4.288,4701.663999999986,0.0,512000.0,1161216.0,645120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,1535623.0,2560000.0,511246.0,0,0.0,3071246.0,3071246.0,0.0,6000.0,0.0,2048000.0,0.0,5.728,4707.391999999986,0.0,0.0,1280000.0,255623.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,148480.0,0.0,296960.0,0,0.0,296960.0,296960.0,1216.0,2008.0,0.3771712158808933,1024000.0,256.0,12.8,4720.191999999986,0.0,0.0,0.0,148480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,8.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.432,4722.623999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,4725.055999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,2.464,4727.519999999986,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,128.0,64.0,2.464,4729.983999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,2.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,268.0,0.0,536.0,0,0.0,536.0,536.0,0.0,6.0,0.0,192.0,320.0,2.56,4732.543999999986,0.0,0.0,0.0,268.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6.0,10.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.048,4734.591999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.112,4736.703999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.56,4739.2639999999865,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,1.0,0.0,0.0,32.0,2.048,4741.311999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,224.0,32.0,2.496,4743.807999999986,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,10.0,0.0,20.0,0,0.0,20.0,20.0,0.0,5.0,0.0,32.0,32.0,5.696,4749.503999999986,0.0,0.0,0.0,10.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,64.0,32.0,2.528,4752.0319999999865,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,32.0,32.0,2.432,4754.463999999986,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,3.0,0.0,96.0,64.0,3.168,4757.631999999986,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,2.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,3.264,4760.895999999986,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,4763.327999999986,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
