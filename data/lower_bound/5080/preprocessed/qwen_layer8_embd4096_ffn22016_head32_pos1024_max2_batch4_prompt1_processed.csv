Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002048,0.002048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.001856,0.003904,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.002752,0.0066560000000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003712,0.010368,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003136,0.013504,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002464,0.015968,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002048,0.018016,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002368,0.020384,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002496,0.022879999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,0.003264,0.026143999999999997,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002784,0.028927999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.03183999999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,0.003328,0.03516799999999999,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002752,0.03791999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,0.002912,0.040831999999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,0.003008,0.04383999999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,17408.0,65536.0,0.004544,0.04838399999999998,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,544.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00288,0.05126399999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003872,0.055135999999999984,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002944,0.058079999999999986,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.002656,0.060735999999999984,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.003072,0.06380799999999999,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,0.00352,0.06732799999999999,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.00288,0.07020799999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.003616,0.07382399999999997,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002816,0.07663999999999997,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003008,0.07964799999999997,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00688,0.08652799999999997,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,0.08924799999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,0.09225599999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,0.09564799999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,0.09900799999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78308864.0,65600.0,0.082496,0.18150399999999997,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2447152.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78508288.0,65600.0,0.081216,0.26271999999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2453384.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78800768.0,65568.0,0.080928,0.34364799999999995,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2462524.0,2049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003392,0.34703999999999996,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,0.35059199999999996,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004256,0.35484799999999994,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003616,0.35846399999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,0.36143999999999993,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,0.36495999999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003584,0.3685439999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,0.37276799999999993,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,0.37622399999999995,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003136,0.3793599999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.0384,0.4177599999999999,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79026560.0,65888.0,0.081248,0.4990079999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2469580.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,0.5019839999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002944,0.5049279999999998,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006784,0.5117119999999998,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,0.5144319999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,0.5174079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00352,0.5209279999999997,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,0.5242879999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,513160448.0,403072.0,0.400864,0.9251519999999998,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16036264.0,12596.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003584,0.9287359999999998,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,508187008.0,401600.0,0.401824,1.3305599999999997,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15880844.0,12550.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003552,1.3341119999999997,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,495962368.0,65760.0,0.422304,1.7564159999999998,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15498824.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,1.7594239999999997,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002848,1.7622719999999996,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00704,1.7693119999999996,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,1.7720639999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,1.7749439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003456,1.7783999999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003328,1.7817279999999995,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79587584.0,65600.0,0.080288,1.8620159999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2487112.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79981952.0,65600.0,0.081216,1.9432319999999994,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2499436.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79242624.0,65536.0,0.083936,2.027167999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2476332.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,2.030623999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003904,2.034527999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.00416,2.038687999999999,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,2.042111999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,2.045055999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,2.048575999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,2.0520639999999988,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,2.056255999999999,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,2.059775999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,2.062815999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038368,2.101183999999999,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79192576.0,65856.0,0.080416,2.181599999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2474768.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,2.184543999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002912,2.1874559999999987,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007008,2.1944639999999986,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,2.1972159999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,2.2001279999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,2.2035199999999984,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00352,2.2070399999999983,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,512544256.0,405280.0,0.400672,2.6077119999999985,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16017008.0,12665.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003744,2.6114559999999987,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,508183168.0,401120.0,0.402016,3.013471999999999,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15880724.0,12535.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003648,3.017119999999999,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,494397312.0,65696.0,0.421088,3.438207999999999,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15449916.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003168,3.441375999999999,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,3.4442559999999993,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007104,3.4513599999999993,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,3.4540799999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,3.4570879999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,3.460479999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003488,3.463967999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78961792.0,65536.0,0.081984,3.545951999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467556.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78644480.0,65536.0,0.081408,3.627359999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457640.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79432576.0,65536.0,0.081216,3.708575999999999,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2482268.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003392,3.711967999999999,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,3.715519999999999,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004256,3.7197759999999986,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00336,3.7231359999999984,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.0032,3.7263359999999985,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,3.7298559999999985,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,3.7333439999999984,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,3.7375359999999986,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003648,3.7411839999999987,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,3.7441279999999986,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038272,3.7823999999999987,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78856576.0,65920.0,0.081312,3.8637119999999987,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464268.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003168,3.8668799999999988,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,3.869759999999999,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006944,3.876703999999999,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002624,3.8793279999999988,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,3.882207999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00352,3.885727999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,3.889119999999999,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,509410816.0,404320.0,0.402048,4.291167999999999,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15919088.0,12635.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003552,4.294719999999999,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510171392.0,402560.0,0.410688,4.705407999999999,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15942856.0,12580.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003776,4.709184,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,501395072.0,66176.0,0.420224,5.129408,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15668596.0,2068.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,5.132384,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002848,5.135232,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006784,5.142016,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,5.144704,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002976,5.14768,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003488,5.151168,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,5.15456,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80661376.0,65600.0,0.081312,5.235872,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2520668.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79306752.0,65632.0,0.082144,5.318016,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2478336.0,2051.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79905024.0,65536.0,0.080992,5.399008,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2497032.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,5.402432,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,5.405952,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,5.410144,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,5.4136,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,5.416576,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,5.42,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003616,5.423616,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004256,5.427872,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,5.431296,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,5.434336,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038432,5.472768,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79266560.0,65600.0,0.081408,5.554176,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2477080.0,2050.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003104,5.55728,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002944,5.560224000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006944,5.567168000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,5.569856000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,5.572768000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003328,5.576096000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003328,5.579424,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511151616.0,401984.0,0.401216,5.98064,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15973488.0,12562.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003552,5.984192,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,509660928.0,401152.0,0.401632,6.385824,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15926904.0,12536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003808,6.389632000000001,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,496336000.0,66080.0,0.419968,6.8096000000000005,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15510500.0,2065.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,6.812544000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,6.815424000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006976,6.822400000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,6.825152000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,6.828064000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003328,6.831392000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,6.834784000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79840768.0,65568.0,0.080512,6.9152960000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2495024.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79179008.0,65600.0,0.081568,6.996864,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2474344.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80313216.0,65536.0,0.080256,7.077120000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2509788.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,7.080704000000001,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003456,7.084160000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,7.0883840000000005,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003616,7.0920000000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002912,7.094912000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003392,7.098304000000001,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00368,7.101984000000001,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,7.1062080000000005,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00336,7.109568,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003232,7.1128,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038368,7.151168,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80045312.0,65856.0,0.08096,7.232128,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2501416.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,7.235104000000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,7.237984000000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007008,7.244992000000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,7.247744000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003104,7.250848000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003488,7.254336000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,7.257728000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510148480.0,404224.0,0.401472,7.659200000000001,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15942140.0,12632.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003488,7.662688000000001,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510889344.0,398368.0,0.400416,8.063104000000001,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15965292.0,12449.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00368,8.066784,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,495300224.0,66144.0,0.42032,8.487104,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15478132.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,8.490112,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,8.492992,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00704,8.500032,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,8.502783999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,8.505663999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003424,8.509087999999998,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003552,8.51264,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79905152.0,65728.0,0.081184,8.593824,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2497036.0,2054.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78326784.0,65600.0,0.08208,8.675904,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2447712.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79507584.0,65536.0,0.08144,8.757344,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2484612.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,8.760864,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003584,8.764448,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,8.768672,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,8.772256,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,8.775264,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003552,8.778816,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,8.782304000000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,8.786528000000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,8.790048000000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,8.793024000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038368,8.831392000000003,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,77894272.0,65728.0,0.082144,8.913536000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2434196.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003296,8.916832000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003136,8.919968000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00688,8.926848000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,8.929568000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,8.932480000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,8.935872000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,8.939264000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,512155264.0,400000.0,0.401472,9.340736000000003,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16004852.0,12500.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.00352,9.344256000000003,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,512368768.0,404704.0,0.40064,9.744896000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16011524.0,12647.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003808,9.748704000000002,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,507302016.0,66048.0,0.41872,10.167424000000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15853188.0,2064.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003168,10.170592000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,10.173472000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006784,10.180256000000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002656,10.182912000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,10.185760000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00336,10.189120000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003328,10.192448000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78023424.0,65600.0,0.082528,10.274976000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2438232.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,77960832.0,65536.0,0.081504,10.356480000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2436276.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78483456.0,65600.0,0.081312,10.437792000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2452608.0,2050.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,10.441216000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003456,10.444672000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.00416,10.448832000000005,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,10.452352000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,10.455392000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,10.458816000000006,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003616,10.462432000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004288,10.466720000000006,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003552,10.470272000000007,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,10.473312000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.038368,10.511680000000007,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78367232.0,66208.0,0.082336,10.594016000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2448976.0,2069.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003232,10.597248000000008,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002912,10.600160000000008,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007008,10.607168000000009,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,10.609856000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003072,10.612928000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00352,10.616448000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003328,10.619776000000007,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511903872.0,401664.0,0.401056,11.020832000000008,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15996996.0,12552.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003584,11.024416000000008,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511705088.0,403584.0,0.400416,11.424832000000007,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15990784.0,12612.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003776,11.428608000000008,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,505528960.0,66144.0,0.41536,11.843968000000007,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15797780.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003072,11.847040000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,11.849920000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006848,11.856768000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002848,11.859616000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,11.862560000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003424,11.865984000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00352,11.869504000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79827200.0,65568.0,0.081344,11.950848000000006,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2494600.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78862336.0,65536.0,0.081888,12.032736000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464448.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79962496.0,65568.0,0.081088,12.113824000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2498828.0,2049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,12.117312000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,12.120800000000006,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.00416,12.124960000000007,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,12.128416000000007,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,12.131392000000007,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003616,12.135008000000006,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00368,12.138688000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004256,12.142944000000005,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,12.146400000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,12.149408000000005,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,262144.0,24059904.0,0.0,0,0.0,24059904.0,24059904.0,133120.0,256.0,0.9980806142034548,196608.0,65536.0,0.0384,12.187808000000004,20365312.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79268864.0,65888.0,0.081344,12.269152000000004,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2477152.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003072,12.272224000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00304,12.275264000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006912,12.282176000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,12.284864000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,12.287712000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,12.291104000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003456,12.294560000000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,512994560.0,404896.0,0.400064,12.694624000000003,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16031080.0,12653.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003904,12.698528000000003,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511345408.0,401312.0,0.401376,13.099904000000004,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15979544.0,12541.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003488,13.103392000000005,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,495944320.0,65920.0,0.42176,13.525152000000006,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15498260.0,2060.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,13.528192000000006,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002912,13.531104000000006,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006752,13.537856000000007,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,13.540544000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,13.543456000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,13.546848000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003328,13.550176000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,3653568896.0,2763392.0,2.739104,16.289280000000005,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,114174028.0,86356.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002304,16.291584000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.002912,16.294496000000002,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00272,16.297216000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.00576,16.302976,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.0024,16.305376000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006176,16.311552000000002,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20563392.0,0.0,0.013024,16.324576000000004,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,642606.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,307716.0,0.0,615432.0,0,0.0,615432.0,615432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006336,16.330912000000005,0.0,0.0,0.0,307716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,426496.0,0.0,852992.0,0,0.0,852992.0,852992.0,31416.0,459824.0,0.06395244686914746,20571328.0,0.0,0.013408,16.344320000000003,0.0,0.0,0.0,426496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,642854.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243728.0,0.0,487456.0,0,0.0,487456.0,487456.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006304,16.350624000000003,0.0,0.0,0.0,243728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,502656.0,0.0,1005312.0,0,0.0,1005312.0,1005312.0,31416.0,462204.0,0.0636440986994044,20644608.0,0.0,0.01344,16.364064000000003,0.0,0.0,0.0,502656.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645144.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006112,16.370176000000004,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,502656.0,0.0,1005312.0,0,0.0,1005312.0,1005312.0,31416.0,462204.0,0.0636440986994044,20667584.0,128.0,0.012928,16.383104000000003,0.0,0.0,0.0,502656.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645862.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.00384,16.386944000000003,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002432,16.389376000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.00496,16.394336000000003,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002336,16.396672000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004992,16.401664000000004,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,172528.0,34552.0,0.8331466100057948,2473696.0,11040.0,0.009056,16.410720000000005,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,345.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006784,16.417504000000005,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006816,16.424320000000005,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2176.0,0.006944,16.431264000000006,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,68.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.007008,16.438272000000005,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388711.0,0.0,777422.0,0,0.0,777422.0,777422.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.007488,16.445760000000003,0.0,0.0,0.0,388711.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.00288,16.448640000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,496128.0,0.0,992256.0,0,0.0,992256.0,992256.0,168982.0,83921.0,0.6681692190286395,8272768.0,5618048.0,0.027808,16.476448000000005,0.0,0.0,0.0,496128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,258524.0,175564.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,95638.0,0.2939343826595399,8400640.0,7410688.0,0.023808,16.500256000000004,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262520.0,231584.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,98209.0,0.29243726539816567,8431488.0,5617504.0,0.023936,16.524192000000003,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263484.0,175547.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39186.0,95639.0,0.29064342666419435,8438016.0,7410304.0,0.023392,16.547584000000004,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263688.0,231572.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.008992,16.556576000000003,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.002912,16.559488,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,49568.0,0.43801727851976147,5958400.0,3841440.0,0.015104,16.574592000000003,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,186200.0,120045.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7332992.0,7292928.0,0.012416,16.587008000000004,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229156.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.06656,16.653568000000003,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.230112,16.883680000000002,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.005952,16.889632000000002,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002592,16.892224000000002,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,223104.0,0.01184,16.904064,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6972.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2560.0,0.007328,16.911392000000003,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,80.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9885000.0,20076672.0,2753168.0,0,0.0,22829840.0,22829840.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066048,16.97744,2452096.0,607744.0,8508416.0,1376584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00864,16.98608,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002752,16.988832000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008352,16.997184,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002816,17.0,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.00288,17.00288,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003584,17.006464,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.008832,17.015296000000003,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.002784,17.01808,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.00416,17.02224,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.003168,17.025408,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003584,17.028992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.005664,17.034656,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649736.0,6082560.0,1216912.0,0,0.0,7299472.0,7299472.0,0.0,14280.0,0.0,4861952.0,43520.0,0.00992,17.044576,0.0,0.0,3041280.0,608456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,1360.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2720.0,0.010112,17.054688,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,85.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,0.00336,17.058048,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.0024,17.060448,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002464,17.062912,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.002976,17.065888,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00272,17.068608,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003136,17.071744000000002,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.00352,17.075264000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002784,17.078048000000003,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002816,17.080864000000002,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,0.003648,17.084512,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,0.003168,17.08768,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,0.003104,17.090784,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,0.00272,17.093504,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,0.002816,17.09632,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,0.003008,17.099328,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,20480.0,0.0,40960.0,0,0.0,40960.0,40960.0,0.0,1536.0,0.0,50176.0,65536.0,0.005824,17.105152,0.0,0.0,0.0,20480.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1568.0,2048.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,0.00288,17.108032,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,0.003872,17.111904000000003,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,0.002848,17.114752000000003,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,0.002656,17.117408000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,0.003008,17.120416000000006,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,0.003488,17.123904000000007,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002816,17.126720000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,0.00416,17.130880000000005,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,0.002816,17.133696000000004,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002848,17.136544000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007168,17.143712000000004,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,17.146432000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,17.149440000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003552,17.152992000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,17.156384000000006,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78503424.0,65568.0,0.082176,17.238560000000007,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2453232.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79497856.0,65696.0,0.081728,17.320288000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2484308.0,2053.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78107904.0,65632.0,0.082912,17.403200000000005,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2440872.0,2051.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,17.406656000000005,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003904,17.410560000000004,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,17.414784000000004,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,17.418240000000004,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,17.421280000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,17.424864000000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,17.428384000000005,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.00416,17.432544000000004,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003648,17.436192000000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003104,17.439296000000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003008,17.442304000000004,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.0032,17.445504000000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,255712.0,24051250.0,0.0,0,0.0,24051250.0,24051250.0,133528.0,256.0,0.9980864677390421,327680.0,65536.0,0.038752,17.484256000000002,20370087.0,3169739.0,255712.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79052288.0,65888.0,0.080576,17.564832000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2470384.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,17.567808000000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,17.570688000000004,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006976,17.577664000000006,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,17.580352000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,17.583360000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003424,17.586784000000005,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003424,17.590208000000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511165440.0,402784.0,0.40192,17.992128000000005,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15973920.0,12587.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003712,17.995840000000005,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510550528.0,402304.0,0.402304,18.398144000000006,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15954704.0,12572.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,18.401664000000007,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,507381376.0,66144.0,0.420352,18.82201600000001,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15855668.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,18.82502400000001,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,18.82790400000001,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006912,18.83481600000001,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,18.83753600000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,18.84038400000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003456,18.84384000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,18.84720000000001,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78631424.0,65600.0,0.081024,18.92822400000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457232.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79947392.0,65728.0,0.081824,19.010048000000012,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2498356.0,2054.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78865664.0,65568.0,0.082272,19.09232000000001,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2464552.0,2049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,19.095840000000013,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,19.099328000000014,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004512,19.103840000000012,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,19.107424000000012,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,19.110432000000014,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003392,19.113824000000015,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,19.117376000000014,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,19.121568000000014,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,19.125024000000014,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,19.128000000000014,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.00304,19.131040000000013,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003008,19.134048000000014,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,261888.0,24067424.0,0.0,0,0.0,24067424.0,24067424.0,133129.0,256.0,0.9980807437118117,327680.0,65536.0,0.03856,19.172608000000015,20373368.0,3170280.0,261888.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,80654208.0,66016.0,0.080416,19.253024000000014,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2520444.0,2063.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003168,19.256192000000013,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,19.259072000000014,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00688,19.265952000000013,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,19.268672000000013,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,19.271552000000014,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003424,19.274976000000013,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003456,19.278432000000013,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,508765312.0,398208.0,0.40208,19.680512000000014,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15898916.0,12444.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003744,19.684256000000016,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,508543872.0,403552.0,0.401888,20.086144000000015,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15891996.0,12611.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003872,20.090016000000016,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,508422400.0,65888.0,0.420032,20.510048000000015,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15888200.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003072,20.513120000000015,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,20.516000000000016,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006944,20.522944000000017,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,20.525696000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.003008,20.52870400000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,20.53209600000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003488,20.53558400000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78585472.0,65536.0,0.08224,20.61782400000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2455796.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79101568.0,65536.0,0.080768,20.69859200000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2471924.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78426496.0,65600.0,0.081888,20.78048000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450828.0,2050.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,20.783904000000017,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,20.78739200000002,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,20.791584000000018,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,20.795008000000017,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,20.798048000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,20.801472000000015,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,20.804992000000016,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,20.809184000000016,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,20.812608000000015,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,20.815616000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003232,20.818848000000017,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003136,20.82198400000002,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,261888.0,24067424.0,0.0,0,0.0,24067424.0,24067424.0,133129.0,256.0,0.9980807437118117,327680.0,65536.0,0.038272,20.860256000000017,20373368.0,3170280.0,261888.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,79093376.0,65760.0,0.081824,20.94208000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2471668.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003072,20.945152000000018,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002848,20.948000000000018,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006944,20.95494400000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,20.95766400000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,20.96054400000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00336,20.96390400000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003648,20.96755200000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510635392.0,398912.0,0.401024,21.36857600000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15957356.0,12466.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003776,21.372352000000017,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,509359616.0,400288.0,0.400768,21.773120000000016,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15917488.0,12509.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00352,21.776640000000018,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,493780480.0,65728.0,0.418336,22.19497600000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15430640.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,22.19798400000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002976,22.20096000000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007104,22.20806400000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,22.21078400000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,22.213664000000023,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003456,22.217120000000023,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,22.220480000000023,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80388096.0,65600.0,0.080864,22.30134400000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2512128.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78729600.0,65568.0,0.080928,22.38227200000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2460300.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,81085312.0,65536.0,0.081344,22.463616000000023,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2533916.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.00352,22.467136000000025,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003712,22.470848000000025,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004416,22.475264000000024,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,22.478688000000023,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,22.48172800000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,22.485216000000023,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,22.488736000000024,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004288,22.493024000000023,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003712,22.496736000000023,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,22.499744000000025,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003072,22.502816000000024,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003104,22.505920000000025,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,261888.0,24067424.0,0.0,0,0.0,24067424.0,24067424.0,133129.0,256.0,0.9980807437118117,327680.0,65536.0,0.03856,22.544480000000025,20373368.0,3170280.0,261888.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78245376.0,65696.0,0.081536,22.626016000000025,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2445168.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,22.629056000000023,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,22.631936000000024,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006976,22.638912000000026,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,22.641600000000025,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,22.644480000000026,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00336,22.647840000000027,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003424,22.651264000000026,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510906240.0,400864.0,0.401344,23.052608000000028,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15965820.0,12527.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003648,23.056256000000026,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511263872.0,401952.0,0.401472,23.457728000000024,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15976996.0,12561.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003648,23.461376000000023,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,512556672.0,66176.0,0.420672,23.882048000000022,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16017396.0,2068.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,23.885056000000024,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002912,23.887968000000022,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006912,23.894880000000022,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002816,23.89769600000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,23.900576000000022,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003488,23.904064000000023,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00352,23.907584000000025,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79508608.0,65536.0,0.080864,23.988448000000023,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2484644.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78228992.0,65568.0,0.082848,24.07129600000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2444656.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79365888.0,65536.0,0.080512,24.15180800000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2480184.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,24.15526400000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,24.158784000000022,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,24.16297600000002,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,24.16643200000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003008,24.169440000000023,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,24.172928000000024,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00352,24.176448000000025,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,24.180640000000025,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003456,24.184096000000025,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,24.187040000000025,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.00304,24.190080000000023,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003168,24.193248000000022,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,261888.0,24067424.0,0.0,0,0.0,24067424.0,24067424.0,133129.0,256.0,0.9980807437118117,327680.0,65536.0,0.038368,24.23161600000002,20373368.0,3170280.0,261888.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78954624.0,65696.0,0.080448,24.31206400000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2467332.0,2053.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,24.31500800000002,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003104,24.31811200000002,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006912,24.32502400000002,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002752,24.32777600000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002944,24.33072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003456,24.33417600000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003616,24.33779200000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511976832.0,402752.0,0.400736,24.73852800000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15999276.0,12586.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003552,24.74208000000002,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510364544.0,402528.0,0.401248,25.143328000000018,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15948892.0,12579.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.00368,25.147008000000017,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,505039232.0,65952.0,0.417504,25.56451200000002,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15782476.0,2061.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,25.567552000000017,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003232,25.570784000000017,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007136,25.577920000000017,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,25.580640000000017,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,25.583488000000017,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00352,25.58700800000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003456,25.59046400000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,79940992.0,65536.0,0.081088,25.67155200000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2498156.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78384896.0,65568.0,0.082272,25.75382400000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2449528.0,2049.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80543744.0,65568.0,0.081536,25.83536000000002,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2516992.0,2049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,25.83894400000002,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003648,25.842592000000018,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,25.846784000000017,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003712,25.850496000000017,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003168,25.853664000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,25.857088000000015,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,25.860640000000014,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,25.864832000000014,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,25.868320000000015,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,25.871264000000014,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003168,25.874432000000013,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003136,25.877568000000014,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.038336,25.915904000000015,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78403584.0,65728.0,0.08048,25.996384000000017,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2450112.0,2054.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,25.999328000000016,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003008,26.002336000000017,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006816,26.009152000000018,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,26.011872000000018,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,26.01472000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,26.01811200000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003392,26.02150400000002,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,510791168.0,405600.0,0.402016,26.42352000000002,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15962224.0,12675.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.00352,26.427040000000023,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,513327232.0,401728.0,0.40048,26.827520000000025,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16041476.0,12554.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003552,26.831072000000024,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,492366336.0,66144.0,0.420288,27.251360000000023,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15386448.0,2067.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003104,27.254464000000024,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.003008,27.257472000000025,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006912,27.264384000000025,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,27.267104000000025,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,27.269984000000026,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00336,27.273344000000026,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,27.276704000000027,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78127104.0,65600.0,0.08336,27.360064000000026,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2441472.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78208512.0,65664.0,0.082016,27.442080000000026,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2444016.0,2052.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,77632000.0,65600.0,0.082496,27.524576000000025,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2426000.0,2050.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,27.528064000000025,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.00368,27.531744000000025,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,27.535968000000025,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,27.539456000000026,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,27.542432000000026,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003392,27.545824000000028,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,27.549376000000027,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,27.553568000000027,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003584,27.557152000000027,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,27.560128000000027,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003104,27.563232000000028,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003232,27.56646400000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.038304,27.60476800000003,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,78641024.0,65760.0,0.081792,27.68656000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2457532.0,2055.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.003104,27.68966400000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002848,27.69251200000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007008,27.699520000000028,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,27.702240000000028,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,27.70512000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.00336,27.70848000000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003488,27.71196800000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,513071616.0,405440.0,0.401888,28.11385600000003,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16033488.0,12670.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003488,28.11734400000003,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,512304640.0,403904.0,0.401248,28.51859200000003,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16009520.0,12622.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003456,28.52204800000003,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,506180096.0,65888.0,0.417408,28.93945600000003,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15818128.0,2059.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,28.942496000000027,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002976,28.945472000000027,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.006848,28.95232000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,28.95504000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002912,28.957952000000027,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,28.96134400000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00336,28.96470400000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80376192.0,65600.0,0.081696,29.04640000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2511756.0,2050.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,78246016.0,65632.0,0.081952,29.12835200000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2445188.0,2051.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,796672.0,0.5267639902676399,80191104.0,65568.0,0.081664,29.21001600000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2505972.0,2049.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003552,29.21356800000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003552,29.21712000000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004192,29.22131200000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003712,29.22502400000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002944,29.22796800000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003488,29.23145600000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,12288.0,8192.0,24576.0,0,0.0,32768.0,32768.0,0.0,512.0,0.0,32768.0,32768.0,0.003488,29.23494400000003,8192.0,0.0,0.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1024.0,1024.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,204800.0,0.0,409600.0,0,0.0,409600.0,409600.0,0.0,1024.0,0.0,65536.0,65536.0,0.004224,29.23916800000003,0.0,0.0,0.0,204800.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,49152.0,16384.0,98304.0,0,0.0,114688.0,114688.0,0.0,1536.0,0.0,98304.0,65536.0,0.003424,29.24259200000003,0.0,16384.0,0.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,2048.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,29.24563200000003,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003136,29.24876800000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,24576.0,0.0,49152.0,0,0.0,49152.0,49152.0,0.0,1280.0,0.0,131072.0,131072.0,0.003136,29.25190400000003,0.0,0.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,4096.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,262144.0,24068096.0,0.0,0,0.0,24068096.0,24068096.0,133120.0,256.0,0.9980806142034548,327680.0,65536.0,0.038304,29.29020800000003,20373504.0,3170304.0,262144.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10240.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,68288512.0,147062784.0,2359296.0,0,0.0,149422080.0,149422080.0,886784.0,794624.0,0.5274056029232643,77850368.0,65632.0,0.080672,29.37088000000003,4456448.0,8388608.0,67108864.0,1179648.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2432824.0,2051.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.002976,29.373856000000032,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.002944,29.37680000000003,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.00688,29.38368000000003,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.002688,29.38636800000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002848,29.38921600000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003456,29.39267200000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.00352,29.39619200000003,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511145856.0,402080.0,0.400192,29.79638400000003,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15973308.0,12565.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,968704.0,1849344.0,176128.0,0,0.0,2025472.0,2025472.0,0.0,1376.0,0.0,352256.0,352256.0,0.003616,29.800000000000033,88064.0,0.0,880640.0,88064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,11008.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,367050752.0,790462464.0,12681216.0,0,0.0,803143680.0,803143680.0,4766464.0,4271104.0,0.5274056029232643,511140224.0,400512.0,0.401696,30.201696000000034,23953408.0,45088768.0,360710144.0,6340608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15973132.0,12516.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,88064.0,0.0,0,0.0,88064.0,88064.0,0.0,2064.0,0.0,704512.0,352256.0,0.003616,30.205312000000035,0.0,88064.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,22016.0,11008.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,366477312.0,789315584.0,11534336.0,0,0.0,800849920.0,800849920.0,4614144.0,4235264.0,0.5214070816940523,503151360.0,65856.0,0.416256,30.621568000000035,22806528.0,45088768.0,360710144.0,5767168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15723480.0,2058.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,16384.0,32768.0,0.0,0,0.0,32768.0,32768.0,0.0,384.0,0.0,131072.0,65536.0,0.00304,30.624608000000034,0.0,0.0,16384.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,16384.0,0.0,0,0.0,16384.0,16384.0,0.0,256.0,0.0,65536.0,65536.0,0.00288,30.627488000000035,0.0,16384.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,2048.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,20868.0,4096.0,0,0.0,24964.0,24964.0,40.0,132.0,0.23255813953488372,65536.0,32.0,0.007072,30.634560000000036,20864.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2048.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,0.00272,30.637280000000036,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.00288,30.640160000000037,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,67584.0,65536.0,0.003392,30.64355200000004,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2112.0,2048.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,32768.0,16384.0,65536.0,0,0.0,81920.0,81920.0,0.0,1536.0,0.0,131072.0,65536.0,0.003424,30.646976000000038,0.0,16384.0,0.0,32768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4096.0,2048.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,2533076992.0,5455110144.0,87515136.0,0,0.0,5542625280.0,5542625280.0,32894144.0,29475584.0,0.5274056029232643,3663611008.0,2709472.0,2.734752,33.38172800000004,165306368.0,311164928.0,2489319424.0,43757568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,114487844.0,84671.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.00224,33.38396800000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.002976,33.386944000000035,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,0.002656,33.38960000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,0.005408,33.39500800000004,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,0.002368,33.39737600000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006272,33.40364800000004,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20615488.0,0.0,0.013056,33.41670400000004,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,644234.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,308028.0,0.0,616056.0,0,0.0,616056.0,616056.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.0064,33.42310400000004,0.0,0.0,0.0,308028.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,426496.0,0.0,852992.0,0,0.0,852992.0,852992.0,31416.0,459824.0,0.06395244686914746,20607232.0,0.0,0.012672,33.43577600000004,0.0,0.0,0.0,426496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,643976.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243744.0,0.0,487488.0,0,0.0,487488.0,487488.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.005952,33.44172800000004,0.0,0.0,0.0,243744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,453152.0,0.0,906304.0,0,0.0,906304.0,906304.0,31416.0,460657.0,0.06384418572041141,20737984.0,0.0,0.012576,33.45430400000004,0.0,0.0,0.0,453152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,648062.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,0.006272,33.460576000000046,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,445536.0,0.0,891072.0,0,0.0,891072.0,891072.0,31416.0,460419.0,0.0638750800573363,20655904.0,128.0,0.012928,33.47350400000005,0.0,0.0,0.0,445536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,645497.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,0.003936,33.47744000000005,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002304,33.47974400000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004864,33.48460800000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,0.002304,33.48691200000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,0.004864,33.49177600000005,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,147395.0,34560.0,0.8100629276469457,2473696.0,10112.0,0.00864,33.50041600000005,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,316.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,0.006592,33.50700800000005,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,0.006688,33.513696000000046,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,1536.0,0.00688,33.52057600000005,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,48.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,0.006912,33.52748800000005,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388706.0,0.0,777412.0,0,0.0,777412.0,777412.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,0.006848,33.534336000000046,0.0,0.0,0.0,388706.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,0.003008,33.53734400000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,489216.0,0.0,978432.0,0,0.0,978432.0,978432.0,166174.0,83275.0,0.6661642259540026,8310400.0,5575488.0,0.027424,33.56476800000005,0.0,0.0,0.0,489216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,259700.0,174234.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,185088.0,0.0,370176.0,0,0.0,370176.0,370176.0,42622.0,98577.0,0.3018576618814581,8408832.0,6324160.0,0.023296,33.58806400000005,0.0,0.0,0.0,185088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262776.0,197630.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,94810.0,0.2997784342688331,8409728.0,5623520.0,0.023616,33.61168000000005,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262804.0,175735.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39186.0,96218.0,0.28940060854923044,8392960.0,7409792.0,0.022624,33.63430400000005,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262280.0,231556.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,0.009024,33.64332800000005,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,0.002912,33.64624000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,50946.0,0.43127930341594106,5922304.0,3838400.0,0.014944,33.66118400000005,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185072.0,119950.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7331008.0,7292928.0,0.012064,33.67324800000005,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229094.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066016,33.73926400000005,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,0.228608,33.96787200000005,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,0.005504,33.97337600000005,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,0.002624,33.97600000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,218080.0,0.011872,33.987872000000046,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6815.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,6272.0,0.00672,33.99459200000005,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,196.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884997.0,20076672.0,2753162.0,0,0.0,22829834.0,22829834.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,0.066464,34.06105600000005,2452096.0,607744.0,8508416.0,1376581.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.008448,34.06950400000005,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002816,34.072320000000055,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,0.00832,34.08064000000005,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,0.002816,34.083456000000055,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,0.002784,34.08624000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003616,34.089856000000054,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,0.008512,34.09836800000006,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,0.002752,34.10112000000006,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,0.003904,34.10502400000006,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,0.002816,34.10784000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,0.003488,34.11132800000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,0.005568,34.116896000000054,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649733.0,6082560.0,1216906.0,0,0.0,7299466.0,7299466.0,0.0,14280.0,0.0,4861952.0,30208.0,0.009344,34.12624000000005,0.0,0.0,3041280.0,608453.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,944.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2752.0,0.009984,34.136224000000055,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,86.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,0.002944,34.139168000000055,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002368,34.14153600000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,0.002336,34.14387200000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.00288,34.14675200000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.002752,34.14950400000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,0.003072,34.15257600000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,0.003552,34.15612800000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,0.002784,34.15891200000005,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
