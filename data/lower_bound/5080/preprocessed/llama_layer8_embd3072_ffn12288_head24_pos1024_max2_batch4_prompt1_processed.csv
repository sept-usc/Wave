Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.856,3.904,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,2.016,5.92,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.272,8.192,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,3.04,11.232,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.232,14.463999999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,4.224,18.688,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.584,22.272,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.848,25.119999999999997,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,27.487999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,29.855999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.496,32.352,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.2,35.552,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,38.336,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.816,41.152,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.264,44.416000000000004,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,47.168000000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.816,49.98400000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.912,52.89600000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,13056.0,49152.0,4.512,57.40800000000001,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,408.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.912,60.32000000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.808,64.12800000000001,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,3.008,67.13600000000001,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.752,69.888,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.944,72.83200000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.648,76.48,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.912,79.39200000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.552,82.94400000000002,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.848,85.79200000000002,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,88.67200000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.272,94.94400000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.944,97.88800000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.976,100.86400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.488,104.35200000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.456,107.80800000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45160448.0,49472.0,48.96,156.76800000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1411264.0,1546.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43770368.0,49216.0,49.888,206.65600000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1367824.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44459904.0,49248.0,50.752,257.408,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1389372.0,1539.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.584,260.992,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.616,264.608,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,268.86400000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,272.32000000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,275.26400000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,278.65600000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.712,282.36800000000005,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,286.59200000000004,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.648,290.24000000000007,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,293.21600000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.112,331.3280000000001,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44546048.0,49280.0,48.736,380.0640000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1392064.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,382.97600000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.944,385.9200000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.496,392.41600000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,395.20000000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.008,398.208,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.296,401.504,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,404.86400000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203362816.0,220448.0,175.168,580.032,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6355088.0,6889.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.68,583.712,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203110912.0,215456.0,175.488,759.2,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6347216.0,6733.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,762.368,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,186028544.0,49344.0,183.328,945.696,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5813392.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,948.64,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,951.52,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.176,957.696,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,960.448,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,963.328,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,966.688,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.52,970.208,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43903872.0,49280.0,52.064,1022.2719999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1371996.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44305280.0,49344.0,49.152,1071.424,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1384540.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44860032.0,49376.0,49.248,1120.672,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1401876.0,1543.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,1124.064,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.584,1127.6480000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,1131.872,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,1135.328,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,1138.272,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,1141.76,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.456,1145.216,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,1149.472,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,1152.9279999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,1155.904,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.272,1194.176,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43736192.0,49216.0,49.696,1243.8719999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1366756.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,1246.9439999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,1249.8559999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.016,1255.8719999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,1258.5919999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,1261.504,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.616,1265.12,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,1268.4479999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205545600.0,219392.0,174.496,1442.944,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6423300.0,6856.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.68,1446.624,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205023744.0,217792.0,175.008,1621.632,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6406992.0,6806.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,1624.8,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176622080.0,49312.0,189.472,1814.272,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5519440.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,1817.216,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,1820.096,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.984,1826.08,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,1828.896,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,1831.744,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.328,1835.072,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.296,1838.368,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45195136.0,49376.0,48.896,1887.264,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1412348.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45006464.0,49280.0,49.376,1936.6399999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1406452.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45351296.0,49152.0,49.888,1986.5279999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1417228.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.36,1989.8879999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,1993.4079999999997,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,1997.6319999999996,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,2001.1199999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,2004.0319999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.52,2007.5519999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.552,2011.1039999999996,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,2015.3599999999997,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,2018.7839999999997,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,2021.6959999999997,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.24,2059.9359999999997,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43212416.0,49184.0,51.008,2110.9439999999995,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1350388.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,2113.8879999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,2116.7359999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.08,2122.8159999999993,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,2125.6639999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,2128.5119999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,2131.8719999999994,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,2135.2319999999995,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205702656.0,217184.0,175.296,2310.5279999999993,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6428208.0,6787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.36,2313.8879999999995,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205643776.0,216736.0,176.16,2490.0479999999993,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6426368.0,6773.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,2493.3119999999994,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,180069504.0,49376.0,182.592,2675.9039999999995,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5627172.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,2678.8479999999995,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.04,2681.8879999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.984,2687.8719999999994,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,2690.591999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,2693.4719999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.68,2697.151999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.488,2700.639999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45059584.0,49280.0,50.496,2751.135999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1408112.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43691648.0,49536.0,50.336,2801.471999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1365364.0,1548.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44996480.0,49312.0,49.536,2851.007999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1406140.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,2854.431999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,2857.951999999999,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,2862.143999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.648,2865.791999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,2868.799999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,2872.2879999999986,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,2875.8079999999986,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.128,2879.935999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,2883.3599999999988,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,2886.335999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.208,2924.543999999999,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43342976.0,49440.0,51.04,2975.583999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1354468.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,2978.527999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.072,2981.599999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.272,2987.871999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,2990.5919999999987,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,2993.471999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.328,2996.799999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,3000.159999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204475264.0,215904.0,176.064,3176.223999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6389852.0,6747.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.392,3179.6159999999986,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,201830272.0,215040.0,176.96,3356.5759999999987,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6307196.0,6720.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.36,3359.935999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,181167488.0,49280.0,185.664,3545.5999999999985,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5661484.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,3548.5759999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.072,3551.647999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.016,3557.663999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,3560.415999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.944,3563.3599999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,3566.719999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.392,3570.1119999999987,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43490432.0,49344.0,50.368,3620.4799999999987,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1359076.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44780032.0,49280.0,49.696,3670.1759999999986,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1399376.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45427584.0,49184.0,49.76,3719.935999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1419612.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,3723.3599999999988,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.488,3726.8479999999986,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,3731.0719999999988,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,3734.4959999999987,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,3737.4399999999987,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,3740.9279999999985,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.424,3744.3519999999985,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,3748.5439999999985,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,3751.9359999999983,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,3754.8799999999983,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.304,3793.1839999999984,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44002560.0,49280.0,51.712,3844.8959999999984,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1375080.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,3847.9679999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,3850.8159999999984,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.952,3856.7679999999987,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,3859.6159999999986,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,3862.4959999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.488,3865.9839999999986,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,3869.3119999999985,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203296384.0,216064.0,176.224,4045.5359999999987,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6353012.0,6752.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.52,4049.0559999999987,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202515712.0,215424.0,176.352,4225.4079999999985,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6328616.0,6732.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,4228.575999999998,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176681344.0,49152.0,187.68,4416.2559999999985,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5521292.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,4419.231999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,4422.079999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.24,4428.319999999998,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.88,4431.199999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,4434.079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,4437.471999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,4440.799999999998,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43293440.0,49376.0,52.16,4492.959999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1352920.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43632896.0,49408.0,49.92,4542.879999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1363528.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43664768.0,49472.0,50.272,4593.151999999998,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1364524.0,1546.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.552,4596.703999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.552,4600.255999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,4604.479999999998,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,4607.967999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,4610.975999999998,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,4614.431999999998,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,4617.951999999998,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,4622.207999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.52,4625.727999999999,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,4628.703999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.304,4667.007999999999,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43979520.0,49312.0,49.696,4716.703999999999,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1374360.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,4719.6799999999985,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.816,4722.495999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.984,4728.479999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,4731.231999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,4734.143999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,4737.503999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,4740.831999999999,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203793920.0,216928.0,176.128,4916.959999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6368560.0,6779.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.52,4920.48,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203333760.0,214112.0,175.552,5096.031999999999,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6354180.0,6691.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.168,5099.199999999999,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,180065792.0,49280.0,186.016,5285.2159999999985,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5627056.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,5288.159999999999,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.04,5291.199999999999,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.176,5297.375999999999,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,5300.096,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,5302.976,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.328,5306.304,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.296,5309.6,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43723008.0,49248.0,50.688,5360.2880000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1366344.0,1539.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43715200.0,49312.0,49.696,5409.984,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1366100.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,46467072.0,49216.0,49.568,5459.552000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1452096.0,1538.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.52,5463.072000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.488,5466.560000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,5470.752000000001,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,5474.144000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,5477.088000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,5480.480000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,5484.000000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,5488.256000000002,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.52,5491.776000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,5494.688000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.176,5532.864000000003,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43807360.0,49344.0,50.208,5583.072000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1368980.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,5586.0480000000025,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,5588.960000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.208,5595.168000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,5597.952000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,5600.832000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,5604.224000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,5607.584000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202063872.0,215328.0,174.848,5782.432000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6314496.0,6729.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.712,5786.144000000002,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202857472.0,215744.0,175.936,5962.080000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6339296.0,6742.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,5965.312000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,184458240.0,49280.0,183.52,6148.832000000002,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5764320.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,6151.776000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,6154.688000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.112,6160.800000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,6163.520000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,6166.400000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.424,6169.824000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.52,6173.344000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43690880.0,49344.0,50.976,6224.320000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1365340.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43144576.0,49376.0,52.384,6276.704000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1348268.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45391744.0,49408.0,49.92,6326.624000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1418492.0,1544.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.584,6330.208000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.776,6333.984000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,6338.176000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,6341.568000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,6344.512000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,6347.936000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.552,6351.488000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.288,6355.776000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,6359.200000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,6362.272000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,196608.0,18044928.0,0.0,0,0.0,18044928.0,18044928.0,99840.0,192.0,0.9980806142034548,147456.0,49152.0,38.176,6400.448000000003,15273984.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4608.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44982144.0,49344.0,49.024,6449.472000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1405692.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,6452.416000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.04,6455.456000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.176,6461.632000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,6464.352000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,6467.2320000000045,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,6470.592000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,6473.920000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205330048.0,221056.0,174.464,6648.384000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6416564.0,6908.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.712,6652.096000000005,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204469632.0,222912.0,176.544,6828.640000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6389676.0,6966.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.488,6832.128000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,180853632.0,49216.0,183.968,7016.096000000005,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5651676.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,7019.008000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,7021.856000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.08,7027.936000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,7030.784000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,7033.664000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,7037.056000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,7040.3840000000055,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,3146048000.0,6296576000.0,640000.0,0,0.0,6297216000.0,6297216000.0,9551000.0,20000.0,0.997910354194964,405476480.0,2560000.0,616.832,7657.216000000006,0.0,5120000.0,3145728000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12671140.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.304,7667.520000000006,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.336,7669.856000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,7672.768000000006,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,7675.488000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.488,7678.976000000007,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,7681.344000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.48,7685.824000000007,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.088,7690.912000000007,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,73832.0,0.0,147664.0,0,0.0,147664.0,147664.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.672,7695.584000000006,0.0,0.0,0.0,73832.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,5.216,7700.800000000007,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,64528.0,0.0,129056.0,0,0.0,129056.0,129056.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.384,7705.184000000007,0.0,0.0,0.0,64528.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,106496.0,0.0,212992.0,0,0.0,212992.0,212992.0,8448.0,34312.0,0.19756782039289056,2106624.0,0.0,5.184,7710.368000000007,0.0,0.0,0.0,106496.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.416,7714.784000000007,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,128.0,5.12,7719.904000000007,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.424,7723.328000000007,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,7725.664000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.48,7730.144000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,7732.448000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.608,7737.056000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,39524.0,8416.0,0.8244472256987901,525824.0,6240.0,6.592,7743.6480000000065,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,195.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.624,7750.272000000006,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.48,7754.752000000006,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.712,7758.464000000006,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.36,7761.824000000006,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387901.0,0.0,775802.0,0,0.0,775802.0,775802.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.672,7766.496000000006,0.0,0.0,0.0,387901.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,3.008,7769.504000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17861.0,0.6999210362729121,1706240.0,1182496.0,16.0,7785.504000000005,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53320.0,36953.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,55552.0,0.0,111104.0,0,0.0,111104.0,111104.0,15100.0,17744.0,0.4597491170381196,1687808.0,1060544.0,13.696,7799.200000000005,0.0,0.0,0.0,55552.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52744.0,33142.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17759.0,0.3775542392485367,1698304.0,1192992.0,14.496,7813.696000000005,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53072.0,37281.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,9368.0,17558.0,0.3479165119215628,1689088.0,1560576.0,15.104,7828.800000000006,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52784.0,48768.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.544,7833.3440000000055,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.88,7836.224000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9469.0,0.5272119033353305,1158272.0,822240.0,7.968,7844.1920000000055,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36196.0,25695.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1549184.0,1536000.0,4.864,7849.056000000005,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48412.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1045632.0,512000.0,18.72,7867.776000000005,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32676.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,52.096,7919.872000000005,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.616,7923.488000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.56,7926.048000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,51872.0,9.536,7935.584000000005,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1621.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.776,7939.360000000005,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1025280.0,512000.0,18.848,7958.208000000005,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32040.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.248,7987.456000000005,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.784,7990.240000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.864,8019.104000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.88,8021.984000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.88,8024.864000000004,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.584,8028.448000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.952,8038.400000000004,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.72,8041.120000000004,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.776,8044.896000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.912,8047.8080000000045,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.52,8051.328000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.352,8055.680000000005,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,5.056,8060.736000000004,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.312,8074.048000000004,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.688,8076.736000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,8079.520000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.912,8082.432000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.784,8085.216000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.912,8088.128000000004,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.464,8090.592000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.304,8092.896000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.04,8095.936000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,8098.304000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.816,8101.120000000004,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.112,8107.2320000000045,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.752,8109.984000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.688,8112.672000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,8115.744000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.52,8119.264000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.688,8121.952000000006,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.848,8124.800000000006,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.744,8128.544000000005,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,3.36,8131.904000000005,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.688,8134.592000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.688,8137.280000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.752,8140.032000000006,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.976,8143.008000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,15360.0,0.0,30720.0,0,0.0,30720.0,30720.0,0.0,1152.0,0.0,49920.0,49152.0,6.144,8149.1520000000055,0.0,0.0,0.0,15360.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1560.0,1536.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.912,8152.064000000006,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.84,8155.904000000006,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.976,8158.880000000006,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.624,8161.504000000005,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.944,8164.448000000006,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.456,8167.904000000006,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.88,8170.784000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.552,8174.336000000006,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.88,8177.216000000006,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,8180.128000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.112,8186.240000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,8189.056000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,8191.968000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,8195.360000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,8198.720000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44543744.0,49376.0,48.864,8247.584000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1391992.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44821504.0,49280.0,48.96,8296.544000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1400672.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43432320.0,49312.0,52.512,8349.056000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1357260.0,1541.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,8352.512000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,8356.032000000007,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.32,8360.352000000006,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,8363.808000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,8366.816000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,8370.304000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.584,8373.888000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,8378.112000000006,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,8381.504000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.232,8384.736000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.976,8387.712000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,8390.752000000008,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,195680.0,18048636.0,0.0,0,0.0,18048636.0,18048636.0,99903.0,192.0,0.9980818222688446,245760.0,49152.0,38.144,8428.896000000008,15279635.0,2377641.0,195680.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,42969856.0,49248.0,52.096,8480.992000000007,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1342808.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,8483.968000000008,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,8486.816000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.048,8492.864000000009,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,8495.584000000008,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,8498.432000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.328,8501.760000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.296,8505.056000000008,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205306240.0,217184.0,174.24,8679.296000000008,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6415820.0,6787.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.392,8682.688000000007,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,202476672.0,215488.0,174.944,8857.632000000007,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6327396.0,6734.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.296,8860.928000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,177900032.0,49376.0,189.088,9050.016000000007,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5559376.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.168,9053.184000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,9056.032000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.112,9062.144000000006,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,9064.864000000005,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,3.072,9067.936000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.456,9071.392000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.392,9074.784000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43163520.0,49216.0,52.768,9127.552000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1348860.0,1538.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44043264.0,49344.0,48.864,9176.416000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1376352.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43917824.0,49472.0,50.048,9226.464000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1372432.0,1546.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,9229.856000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.584,9233.440000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.32,9237.760000000006,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,9241.248000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,9244.192000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,9247.584000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.552,9251.136000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,9255.392000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,9258.784000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,9261.760000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,2.976,9264.736000000004,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,9267.776000000005,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,196064.0,18049644.0,0.0,0,0.0,18049644.0,18049644.0,99873.0,192.0,0.9980812471893269,245760.0,49152.0,38.304,9306.080000000005,15279839.0,2377677.0,196064.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43277824.0,49312.0,50.72,9356.800000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1352432.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.136,9359.936000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.816,9362.752000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.888,9368.640000000007,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.816,9371.456000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,9374.336000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.488,9377.824000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,9381.152000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205194624.0,215392.0,179.648,9560.800000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6412332.0,6731.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.296,9564.096000000005,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206015872.0,215072.0,173.92,9738.016000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6437996.0,6721.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.232,9741.248000000005,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,175067776.0,49344.0,194.496,9935.744000000004,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5470868.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.168,9938.912000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,9941.760000000004,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.176,9947.936000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,9950.656000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,9953.504000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,9956.864000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.68,9960.544000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44546560.0,49344.0,49.504,10010.048000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1392080.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43530752.0,49376.0,49.952,10060.000000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1360336.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45116800.0,49280.0,49.536,10109.536000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1409900.0,1540.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,10112.928000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.584,10116.512000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.16,10120.672000000004,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,10124.064000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,10126.976000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,10130.464000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.488,10133.952000000003,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,10138.176000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,10141.568000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,10144.576000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,10147.616000000004,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.008,10150.624000000003,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,196512.0,18050820.0,0.0,0,0.0,18050820.0,18050820.0,99843.0,192.0,0.9980806717648822,245760.0,49152.0,38.336,10188.960000000003,15280077.0,2377719.0,196512.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43734656.0,49280.0,48.576,10237.536000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1366708.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.136,10240.672000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,10243.552000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.984,10249.536000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.688,10252.224000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,10255.072000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.52,10258.592000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,10261.920000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,203567744.0,215488.0,175.328,10437.248000000001,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6361492.0,6734.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.392,10440.640000000001,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,201758592.0,215680.0,176.032,10616.672,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6304956.0,6740.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,10619.872000000001,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,178637824.0,49248.0,184.128,10804.000000000002,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5582432.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.104,10807.104000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.04,10810.144000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.016,10816.160000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.784,10818.944000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,10821.824,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,10825.216,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,10828.544,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44796032.0,49344.0,49.28,10877.824,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1399876.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45378816.0,49408.0,48.384,10926.208,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1418088.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,46887040.0,49344.0,47.584,10973.792000000001,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1465220.0,1542.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.36,10977.152000000002,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.648,10980.800000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.288,10985.088000000002,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,10988.576000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,10991.584,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.648,10995.232,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.776,10999.008,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,11003.199999999999,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.36,11006.56,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,11009.6,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.072,11012.672,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.008,11015.68,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,196512.0,18050820.0,0.0,0,0.0,18050820.0,18050820.0,99843.0,192.0,0.9980806717648822,245760.0,49152.0,38.432,11054.112000000001,15280077.0,2377719.0,196512.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43480064.0,49152.0,49.888,11104.000000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1358752.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,11106.976000000002,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.848,11109.824000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.016,11115.840000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,11118.560000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,11121.408000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,11124.800000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.296,11128.096000000001,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,206242432.0,217408.0,175.328,11303.424,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6445076.0,6794.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.488,11306.912,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204516352.0,216576.0,174.656,11481.568000000001,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6391136.0,6768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,11484.768000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,183185408.0,49248.0,180.928,11665.696000000002,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5724544.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,11668.736000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.008,11671.744000000002,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.048,11677.792000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,11680.512000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.816,11683.328000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.296,11686.624000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.264,11689.888000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44449664.0,49312.0,48.608,11738.496000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1389052.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43456000.0,49280.0,50.272,11788.768000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1358000.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45314816.0,49184.0,49.152,11837.920000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1416088.0,1537.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,11841.312000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,11844.832000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,11849.024000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,11852.448000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.976,11855.424000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.552,11858.976000000004,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.552,11862.528000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,11866.784000000003,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,11870.176000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,11873.088000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.168,11876.256000000003,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,11879.296000000004,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,196512.0,18050820.0,0.0,0,0.0,18050820.0,18050820.0,99843.0,192.0,0.9980806717648822,245760.0,49152.0,38.208,11917.504000000004,15280077.0,2377719.0,196512.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44342144.0,49216.0,49.248,11966.752000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1385692.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,11969.824000000004,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,11972.704000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.048,11978.752000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,11981.472000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,11984.320000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,11987.680000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,11991.040000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,201625344.0,214368.0,182.656,12173.696000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6300792.0,6699.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.616,12177.312000000005,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204676480.0,222016.0,176.864,12354.176000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6396140.0,6938.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,12357.376000000006,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,176688640.0,49408.0,186.08,12543.456000000006,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5521520.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.168,12546.624000000005,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.816,12549.440000000006,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.048,12555.488000000007,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.88,12558.368000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,12561.248000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,12564.608000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,12567.936000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44785024.0,49408.0,49.824,12617.760000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1399532.0,1544.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,42939904.0,49504.0,51.808,12669.568000000007,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1341872.0,1547.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44099712.0,49216.0,49.344,12718.912000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1378116.0,1538.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.456,12722.368000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.52,12725.888000000006,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,12730.144000000006,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,12733.568000000007,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,12736.608000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,12740.096000000007,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.616,12743.712000000007,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.16,12747.872000000007,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,12751.264000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.072,12754.336000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.072,12757.408000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.328,12760.736000000006,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,196512.0,18050820.0,0.0,0,0.0,18050820.0,18050820.0,99843.0,192.0,0.9980806717648822,245760.0,49152.0,38.304,12799.040000000006,15280077.0,2377719.0,196512.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44382976.0,49344.0,48.256,12847.296000000006,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1386968.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,12850.208000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.88,12853.088000000005,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.016,12859.104000000005,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,12861.824000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,12864.704000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.424,12868.128000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,12871.488000000005,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204049920.0,218976.0,175.68,13047.168000000005,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6376560.0,6843.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.264,13050.432000000004,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205625600.0,217728.0,172.928,13223.360000000004,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6425800.0,6804.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.264,13226.624000000003,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,184219392.0,49376.0,180.16,13406.784000000003,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5756856.0,1543.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,13409.728000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,13412.640000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.112,13418.752000000002,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,13421.472000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.912,13424.384000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.296,13427.680000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,13431.040000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43149440.0,49280.0,52.256,13483.296000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1348420.0,1540.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,45596160.0,49376.0,47.456,13530.752000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1424880.0,1543.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,46978048.0,49376.0,48.544,13579.296000000002,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1468064.0,1543.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.584,13582.880000000003,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.648,13586.528000000002,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.16,13590.688000000002,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.648,13594.336000000001,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,13597.248000000001,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.36,13600.608000000002,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.488,13604.096000000001,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.256,13608.352,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.488,13611.84,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.008,13614.848,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.136,13617.984,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,13621.024000000001,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,196512.0,18050820.0,0.0,0,0.0,18050820.0,18050820.0,99843.0,192.0,0.9980806717648822,245760.0,49152.0,38.208,13659.232000000002,15280077.0,2377719.0,196512.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44209152.0,49248.0,49.504,13708.736000000003,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1381536.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.136,13711.872000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.944,13714.816000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.92,13720.736000000003,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,13723.584000000003,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,13726.432000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.328,13729.760000000002,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,13733.120000000003,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205880832.0,221152.0,174.784,13907.904000000002,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6433776.0,6911.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.424,13911.328000000003,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205862656.0,217824.0,176.64,14087.968000000003,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6433208.0,6807.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.328,14091.296000000002,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,181566848.0,49440.0,182.144,14273.440000000002,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,5673964.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,14276.352000000003,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.816,14279.168000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.368,14285.536000000004,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.752,14288.288000000004,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,14291.136000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.392,14294.528000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,14297.888000000004,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43404288.0,49344.0,51.36,14349.248000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1356384.0,1542.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,43277568.0,49312.0,50.944,14400.192000000005,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1352424.0,1541.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44951168.0,49248.0,49.248,14449.440000000004,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1404724.0,1539.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.36,14452.800000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.488,14456.288000000004,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.224,14460.512000000004,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,14463.936000000005,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.04,14466.976000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.424,14470.400000000007,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,9216.0,6144.0,18432.0,0,0.0,24576.0,24576.0,0.0,384.0,0.0,24576.0,24576.0,3.616,14474.016000000007,6144.0,0.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,196608.0,0.0,393216.0,0,0.0,393216.0,393216.0,0.0,768.0,0.0,49152.0,49152.0,4.192,14478.208000000006,0.0,0.0,0.0,196608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,36864.0,12288.0,73728.0,0,0.0,86016.0,86016.0,0.0,1152.0,0.0,73728.0,49152.0,3.392,14481.600000000006,0.0,12288.0,0.0,36864.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2304.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,3.136,14484.736000000006,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.04,14487.776000000007,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,18432.0,0.0,36864.0,0,0.0,36864.0,36864.0,0.0,960.0,0.0,98304.0,98304.0,3.2,14490.976000000008,0.0,0.0,0.0,18432.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,3072.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,196608.0,18051072.0,0.0,0,0.0,18051072.0,18051072.0,99840.0,192.0,0.9980806142034548,245760.0,49152.0,38.208,14529.184000000008,15280128.0,2377728.0,196608.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,7680.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,38436864.0,82771968.0,1376256.0,0,0.0,84148224.0,84148224.0,505344.0,448512.0,0.5297906602254429,44542720.0,49312.0,48.96,14578.144000000008,2555904.0,4718592.0,37748736.0,688128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1391960.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.944,14581.088000000007,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,2.912,14584.000000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,5.952,14589.952000000007,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,14592.800000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.88,14595.680000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.36,14599.040000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.328,14602.368000000006,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,205948928.0,218080.0,174.464,14776.832000000006,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6435904.0,6815.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,540672.0,1032192.0,98304.0,0,0.0,1130496.0,1130496.0,0.0,768.0,0.0,196608.0,196608.0,3.36,14780.192000000006,49152.0,0.0,491520.0,49152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6144.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,153747456.0,331087872.0,5505024.0,0,0.0,336592896.0,336592896.0,2021376.0,1794048.0,0.5297906602254429,204531456.0,217696.0,174.464,14954.656000000006,10223616.0,18874368.0,150994944.0,2752512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6391608.0,6803.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,49152.0,0.0,0,0.0,49152.0,49152.0,0.0,1152.0,0.0,393216.0,196608.0,3.2,14957.856000000007,0.0,49152.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12288.0,6144.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,153452544.0,330498048.0,4915200.0,0,0.0,335413248.0,335413248.0,1943040.0,1775616.0,0.5225113589425857,192414592.0,49312.0,182.528,15140.384000000007,9633792.0,18874368.0,150994944.0,2457600.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,6012956.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,12288.0,24576.0,0.0,0,0.0,24576.0,24576.0,0.0,288.0,0.0,98304.0,49152.0,2.912,15143.296000000008,0.0,0.0,12288.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,192.0,0.0,49152.0,49152.0,3.072,15146.368000000008,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,16772.0,4096.0,0,0.0,20868.0,20868.0,40.0,100.0,0.2857142857142857,49152.0,32.0,6.144,15152.512000000008,16768.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.72,15155.232000000007,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,15158.080000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,50688.0,49152.0,3.456,15161.536000000007,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1584.0,1536.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,24576.0,12288.0,49152.0,0,0.0,61440.0,61440.0,0.0,1152.0,0.0,98304.0,49152.0,3.36,15164.896000000008,0.0,12288.0,0.0,24576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,3146048000.0,6296576000.0,640000.0,0,0.0,6297216000.0,6297216000.0,9551000.0,20000.0,0.997910354194964,405470656.0,2560000.0,618.208,15783.104000000008,0.0,5120000.0,3145728000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,12670958.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.624,15793.728000000008,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.4,15796.128000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.912,15799.040000000008,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,15801.760000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.616,15805.376000000007,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.368,15807.744000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,15812.096000000009,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,5.312,15817.408000000009,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,74041.0,0.0,148082.0,0,0.0,148082.0,148082.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.352,15821.76000000001,0.0,0.0,0.0,74041.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,0.0,5.248,15827.008000000009,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64526.0,0.0,129052.0,0,0.0,129052.0,129052.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.544,15831.552000000009,0.0,0.0,0.0,64526.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,8448.0,34632.0,0.19610027855153203,2106624.0,0.0,5.024,15836.576000000008,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.48,15841.056000000008,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,119808.0,0.0,239616.0,0,0.0,239616.0,239616.0,8448.0,34728.0,0.19566425792106726,2106624.0,128.0,5.248,15846.304000000007,0.0,0.0,0.0,119808.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.584,15849.888000000008,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.336,15852.224000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.8,15857.024000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,15859.328000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.544,15863.872000000007,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,30914.0,8422.0,0.7858958714663412,525824.0,6912.0,6.432,15870.304000000007,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,216.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.656,15876.960000000008,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.448,15881.408000000009,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.712,15885.120000000008,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.392,15888.512000000008,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387910.0,0.0,775820.0,0,0.0,775820.0,775820.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.704,15893.216000000008,0.0,0.0,0.0,387910.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.88,15896.096000000007,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17856.0,0.699979837354661,1704832.0,1220608.0,15.84,15911.936000000007,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53276.0,38144.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17760.0,0.3481133460578476,1692672.0,1560832.0,13.088,15925.024000000007,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52896.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17742.0,0.37777933646629724,1690112.0,1190944.0,14.944,15939.968000000006,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52816.0,37217.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,39936.0,0.0,79872.0,0,0.0,79872.0,79872.0,9368.0,17716.0,0.3458868704770344,1688064.0,1560960.0,14.912,15954.880000000006,0.0,0.0,0.0,39936.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52752.0,48780.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.672,15959.552000000007,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.944,15962.496000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9630.0,0.5230075783842687,1158144.0,817280.0,8.224,15970.720000000007,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36192.0,25540.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548960.0,1536000.0,4.96,15975.680000000006,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48405.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1009920.0,512000.0,18.56,15994.240000000005,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31560.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,51.008,16045.248000000005,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.36,16048.608000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.624,16051.232000000005,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,51488.0,9.504,16060.736000000006,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1609.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.68,16064.416000000007,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,2097989.0,4245120.0,611978.0,0,0.0,4857098.0,4857098.0,528.0,5248.0,0.09141274238227147,1020160.0,512000.0,19.04,16083.456000000007,533120.0,128000.0,1792000.0,305989.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31880.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.152,16112.608000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.752,16115.360000000008,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,29.408,16144.768000000007,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.816,16147.584000000008,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.848,16150.432000000008,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.552,16153.984000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,10.464,16164.448000000008,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.72,16167.168000000007,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.808,16170.976000000008,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.848,16173.824000000008,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.456,16177.280000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.48,16181.760000000007,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,767813.0,1280000.0,255626.0,0,0.0,1535626.0,1535626.0,0.0,3000.0,0.0,1024000.0,0.0,4.896,16186.656000000008,0.0,0.0,640000.0,127813.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,13.376,16200.032000000008,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.848,16202.880000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.784,16205.664000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,16208.512000000008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.912,16211.424000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.944,16214.368000000008,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,16216.736000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.336,16219.072000000007,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.848,16221.920000000007,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.368,16224.288000000008,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.816,16227.104000000008,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,6.176,16233.280000000008,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.816,16236.096000000009,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,16238.848000000009,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.072,16241.92000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.52,16245.44000000001,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.752,16248.19200000001,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
