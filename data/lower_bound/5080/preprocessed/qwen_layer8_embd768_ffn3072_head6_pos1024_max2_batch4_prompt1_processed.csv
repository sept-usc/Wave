Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.6,3.2960000000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",3,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.24,5.5360000000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",4,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.392,8.928,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",5,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.912,11.84,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",6,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.016,13.856,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",7,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,15.552,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",8,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.208,17.759999999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",9,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.144,19.903999999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",10,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.008,22.911999999999995,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,25.471999999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",12,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.528,27.999999999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",13,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,3.072,31.071999999999992,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,33.56799999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",15,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.528,36.09599999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",16,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.528,38.62399999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",17,3840.0,0.0,7680.0,0,0.0,7680.0,7680.0,0.0,288.0,0.0,3264.0,12288.0,4.256,42.87999999999999,0.0,0.0,0.0,3840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",18,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.816,45.69599999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",19,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.36,49.05599999999999,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",20,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.752,51.80799999999999,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",21,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.72,54.52799999999999,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",22,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.528,57.05599999999999,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",23,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.296,60.35199999999999,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",24,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.56,62.91199999999999,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",25,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.328,66.24,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",26,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.464,68.704,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",27,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,71.264,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",28,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.032,75.29599999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",29,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,77.66399999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,80.32,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",31,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,83.45599999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",32,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,86.55999999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",33,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394944.0,12288.0,8.64,95.19999999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106092.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",34,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3395968.0,12288.0,8.0,103.19999999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106124.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",35,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.384,111.58399999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",36,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,114.68799999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",37,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,117.79199999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",38,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.744,121.53599999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,124.67199999999998,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",40,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,127.26399999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",41,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,130.368,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,133.376,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",43,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,137.056,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,140.16000000000003,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",45,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,142.72000000000003,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",46,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.32,163.04000000000002,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",47,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,7.744,170.78400000000002,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,173.34400000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",49,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,176.00000000000003,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",50,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,179.84000000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",51,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,182.27200000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,184.83200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",53,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.2,188.032,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",54,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,191.104,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",55,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10735872.0,49280.0,15.328,206.43200000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335496.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",56,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.04,209.472,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",57,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10796032.0,49248.0,16.032,225.50400000000002,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337376.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",58,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.752,228.25600000000003,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",59,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13593088.0,12288.0,22.688,250.94400000000002,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424784.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",60,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,253.568,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",61,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,256.128,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",62,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,260.0,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",63,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,262.4,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,264.928,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",65,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,268.0,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",66,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,271.04,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",67,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3396224.0,12288.0,8.32,279.36,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106132.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",68,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.064,287.42400000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",69,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394944.0,12288.0,7.968,295.39200000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106092.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",70,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,298.56000000000006,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",71,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,301.56800000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",72,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.776,305.34400000000005,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,308.4800000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",74,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,311.1360000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",75,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,314.4000000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,317.4400000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",77,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,321.1200000000001,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,324.2240000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",79,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,326.8160000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",80,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.128,346.9440000000001,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",81,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3393024.0,12288.0,7.872,354.8160000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106032.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,357.5360000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",83,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,360.0960000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",84,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,364.0000000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",85,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,366.4000000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,368.9280000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",87,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,372.0000000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",88,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,375.1040000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",89,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10717056.0,49280.0,15.392,390.4960000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334908.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",90,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.04,393.5360000000001,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",91,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10735488.0,49344.0,15.84,409.3760000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335484.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",92,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.72,412.0960000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",93,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13574528.0,12288.0,23.232,435.3280000000001,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424204.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",94,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,437.8880000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",95,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.816,440.70400000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",96,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,444.54400000000004,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",97,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,446.97600000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,449.53600000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",99,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,452.54400000000004,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",100,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,455.648,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",101,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12320.0,8.512,464.16,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,385.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",102,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.0,472.16,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",103,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3396224.0,12288.0,8.128,480.288,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106132.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",104,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,483.42400000000004,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",105,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,486.528,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",106,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,490.208,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,493.312,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",108,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,495.904,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",109,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,499.04,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,502.144,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",111,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.808,505.952,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,509.152,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",113,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,511.74399999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",114,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.416,532.16,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",115,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12320.0,8.032,540.192,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,542.88,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",117,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,545.408,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",118,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.0,549.408,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",119,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,551.7760000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,554.3040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",121,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.2,557.5040000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",122,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,560.6400000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",123,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10719488.0,49344.0,15.776,576.416,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334984.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",124,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,579.3280000000001,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",125,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10561280.0,49344.0,16.704,596.032,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,330040.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",126,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.688,598.72,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",127,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13576320.0,12288.0,22.464,621.184,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424260.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",128,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,623.7439999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",129,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,626.3039999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",130,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,630.1759999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",131,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,632.6079999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,635.2639999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",133,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,638.2719999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",134,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,641.3439999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",135,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.256,649.5999999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",136,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.096,657.6959999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",137,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394816.0,12288.0,8.288,665.9839999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106088.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",138,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,669.0879999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",139,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,672.0959999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",140,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,675.7759999999998,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,678.8799999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",142,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.784,681.6639999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",143,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,684.7679999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,687.776,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",145,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.712,691.4879999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,694.688,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",147,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.816,697.504,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",148,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,717.6,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",149,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.776,725.376,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,727.968,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",151,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,730.496,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",152,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,734.3679999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",153,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,736.7679999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,739.3279999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",155,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,742.3359999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",156,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,745.4079999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",157,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10673792.0,49216.0,15.808,761.2159999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333556.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",158,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,764.1599999999999,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",159,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10609792.0,49248.0,16.352,780.5119999999998,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331556.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",160,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.656,783.1679999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",161,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13594112.0,12288.0,22.784,805.9519999999998,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424816.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",162,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,808.6719999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",163,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,811.1999999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",164,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,815.1679999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",165,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,817.5359999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,820.1919999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",167,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.104,823.2959999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",168,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.008,826.3039999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",169,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.096,834.3999999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",170,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.936,842.3359999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",171,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394688.0,12288.0,8.32,850.656,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",172,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,853.7919999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",173,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,856.8,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",174,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,860.4799999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,863.5519999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",176,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,866.1439999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",177,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,869.4079999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,2.976,872.3839999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",179,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.712,876.0959999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,879.2319999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",181,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.752,881.9839999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",182,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.064,902.0479999999998,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",183,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.192,910.2399999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,912.8959999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",185,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,915.4239999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",186,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,919.3279999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",187,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,921.7279999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,924.2879999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",189,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,927.3279999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",190,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,930.3679999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",191,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10715520.0,49216.0,15.84,946.2079999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334860.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",192,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,949.1519999999996,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",193,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10785152.0,49184.0,15.2,964.3519999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337036.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",194,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,966.9439999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",195,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13590912.0,12288.0,22.912,989.8559999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424716.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",196,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,992.4159999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",197,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,994.9759999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",198,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,998.8159999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",199,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1001.2159999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1003.7439999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",201,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.104,1006.8479999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",202,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,1009.9519999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",203,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.128,1018.0799999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",204,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.032,1026.1119999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",205,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.84,1033.9519999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",206,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1037.0879999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",207,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,1040.1279999999995,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",208,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1043.7759999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1046.8799999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",210,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,1049.5679999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",211,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1052.6719999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,1055.7759999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",213,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.616,1059.3919999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,1062.5919999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",215,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1065.1519999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",216,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1085.2479999999996,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",217,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3393280.0,12288.0,7.808,1093.0559999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106040.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,1095.6799999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",219,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,1098.2719999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",220,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.224,1102.4959999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",221,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1104.8639999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1107.4239999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",223,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,1110.4639999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",224,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,1113.5039999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",225,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10537088.0,49152.0,16.544,1130.0479999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,329284.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",226,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.008,1133.0559999999996,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",227,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10732416.0,49216.0,15.36,1148.4159999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335388.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",228,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,1151.0079999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",229,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13575680.0,12288.0,22.144,1173.1519999999996,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424240.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",230,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,1175.8079999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",231,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1178.4319999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",232,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,1182.3679999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",233,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1184.7679999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1187.3279999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",235,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,1190.3999999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",236,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,1193.5679999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",237,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.032,1201.5999999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",238,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.936,1209.5359999999991,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",239,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.84,1217.375999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",240,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,1220.607999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",241,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.136,1223.743999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",242,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,1227.423999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1230.527999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",244,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1233.087999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",245,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1236.223999999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,1239.231999999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",247,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1242.879999999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,1245.9519999999989,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",249,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.528,1248.4799999999989,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",250,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1268.5759999999989,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",251,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.904,1276.4799999999989,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1279.071999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",253,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1281.599999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",254,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,1285.567999999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",255,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1287.9679999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,1290.4959999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",257,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,1293.5039999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",258,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,1296.5439999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",259,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10657664.0,49248.0,16.416,1312.9599999999991,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333052.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",260,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,1315.8719999999992,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",261,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10590592.0,49344.0,16.064,1331.9359999999992,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,330956.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",262,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,1334.5279999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",263,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13584384.0,12288.0,23.36,1357.8879999999992,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424512.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",264,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1360.4479999999992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",265,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1363.0719999999992,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",266,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1366.8799999999992,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",267,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1369.3119999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1371.8719999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",269,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,1375.0079999999991,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",270,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.008,1378.0159999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",271,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3395456.0,12288.0,8.384,1386.3999999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106108.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",272,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.16,1394.5599999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",273,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.352,1402.9119999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",274,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1406.0159999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",275,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,2.976,1408.9919999999995,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",276,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1412.6399999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,1415.8079999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",278,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.848,1418.6559999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",279,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,1421.8239999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,2.976,1424.7999999999993,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",281,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,1428.4799999999993,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1431.5839999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",283,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1434.1759999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",284,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.32,1454.4959999999994,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",285,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.256,1462.7519999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1465.3119999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",287,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.72,1468.0319999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",288,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,1471.9039999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",289,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1474.3039999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1476.8639999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",291,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,1479.8719999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",292,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,1483.0399999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",293,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10635776.0,49184.0,15.744,1498.7839999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332368.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",294,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,1501.6959999999995,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",295,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10735104.0,49280.0,15.168,1516.8639999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335472.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",296,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,1519.4559999999994,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",297,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13571584.0,12352.0,22.592,1542.0479999999995,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424112.0,386.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",298,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1544.6399999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",299,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1547.1679999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",300,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,1551.0719999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",301,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1553.4399999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1555.9999999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",303,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,1559.0399999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",304,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,1562.2079999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",305,478902272.0,1030733824.0,24309760.0,0,0.0,1055043584.0,1055043584.0,7216960.0,5773568.0,0.5555555555555556,650122496.0,2839360.0,519.584,2081.7919999999995,38895616.0,58343424.0,466747392.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20316328.0,88730.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",306,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,2083.8399999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",307,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.464,2086.303999999999,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",308,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2088.735999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",309,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.44,2094.175999999999,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.112,2096.287999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",311,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,6.176,2102.463999999999,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",312,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20375648.0,32.0,12.48,2114.943999999999,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,636739.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",313,244952.0,0.0,489904.0,0,0.0,489904.0,489904.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.728,2120.671999999999,0.0,0.0,0.0,244952.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",314,502656.0,0.0,1005312.0,0,0.0,1005312.0,1005312.0,31416.0,462204.0,0.0636440986994044,20507040.0,0.0,12.512,2133.1839999999993,0.0,0.0,0.0,502656.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,640845.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,243744.0,0.0,487488.0,0,0.0,487488.0,487488.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.664,2138.8479999999995,0.0,0.0,0.0,243744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,487424.0,0.0,974848.0,0,0.0,974848.0,974848.0,31416.0,461728.0,0.0637055302305209,20498496.0,0.0,12.864,2151.7119999999995,0.0,0.0,0.0,487424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,640578.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.664,2157.3759999999997,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20426304.0,128.0,12.416,2169.792,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,638322.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",319,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.584,2173.3759999999997,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",320,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,2175.488,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",321,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.544,2180.0319999999997,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",322,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,2182.048,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",323,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.64,2186.6879999999996,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",324,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,148912.0,34560.0,0.8116333827505015,2473696.0,10560.0,7.808,2194.4959999999996,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,330.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",325,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.208,2200.7039999999997,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",326,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,6.496,2207.2,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",327,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,69888.0,6.368,2213.5679999999998,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,2184.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",328,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.592,2220.16,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",329,388510.0,0.0,777020.0,0,0.0,777020.0,777020.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.528,2226.6879999999996,0.0,0.0,0.0,388510.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",330,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.56,2229.2479999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",331,496128.0,0.0,992256.0,0,0.0,992256.0,992256.0,168982.0,84458.0,0.6667534722222223,8443776.0,5563232.0,28.064,2257.3119999999994,0.0,0.0,0.0,496128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263868.0,173851.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",332,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,39814.0,90085.0,0.3064996651244428,8458880.0,7410304.0,23.552,2280.8639999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,264340.0,231572.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",333,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,91155.0,0.30809518387794604,8440704.0,7410560.0,23.584,2304.4479999999994,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263772.0,231580.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",334,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,89156.0,0.312842014397361,8436352.0,5635264.0,23.552,2327.9999999999995,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263636.0,176102.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",335,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.704,2336.7039999999997,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",336,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,2339.2639999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,51533.0,0.42847161378331317,5955328.0,3842144.0,14.592,2353.8559999999998,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,186104.0,120067.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",338,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7332768.0,7292928.0,11.616,2365.4719999999998,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229149.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",339,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.888,2431.3599999999997,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",340,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,228.864,2660.2239999999997,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",341,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.12,2665.3439999999996,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",342,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.144,2667.4879999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",343,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,219552.0,10.88,2678.3679999999995,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6861.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",344,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,2304.0,6.752,2685.1199999999994,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,72.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",345,9884992.0,20076672.0,2753152.0,0,0.0,22829824.0,22829824.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.984,2751.1039999999994,2452096.0,607744.0,8508416.0,1376576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",346,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.416,2759.5199999999995,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",347,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,2761.9199999999996,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",348,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.096,2770.0159999999996,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",349,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2772.4479999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",350,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.656,2775.1039999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",351,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.36,2778.4639999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",352,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,7.84,2786.3039999999996,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",353,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.368,2788.6719999999996,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",354,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.36,2792.0319999999997,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",355,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,2794.528,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",356,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2797.7599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",357,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.152,2802.912,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",358,3649728.0,6082560.0,1216896.0,0,0.0,7299456.0,7299456.0,0.0,14280.0,0.0,4861952.0,192000.0,8.832,2811.7439999999997,0.0,0.0,3041280.0,608448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,6000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",359,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2688.0,9.696,2821.4399999999996,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,84.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",360,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.496,2823.9359999999997,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",361,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2825.9839999999995,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",362,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2828.0319999999992,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",363,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.624,2830.655999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",364,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.464,2833.119999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",365,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,2836.223999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.232,2839.4559999999988,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",367,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2841.855999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",368,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2844.2879999999986,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",369,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.296,2847.5839999999985,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",370,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,2850.5279999999984,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",371,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.528,2853.055999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",372,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.4,2855.4559999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.496,2857.9519999999984,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",374,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.464,2860.4159999999983,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",375,3840.0,0.0,7680.0,0,0.0,7680.0,7680.0,0.0,288.0,0.0,12480.0,12288.0,5.44,2865.8559999999984,0.0,0.0,0.0,3840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,390.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",376,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.944,2868.7999999999984,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",377,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.36,2872.1599999999985,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",378,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.72,2874.8799999999983,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",379,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.624,2877.503999999998,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",380,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.56,2880.063999999998,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",381,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2883.231999999998,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",382,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2885.759999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",383,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.168,2888.927999999998,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",384,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2891.455999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",385,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2893.9839999999976,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",386,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,2897.8559999999975,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",387,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2900.2879999999973,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",388,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2902.8479999999972,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",389,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,2905.855999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",390,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,2908.927999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",391,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.128,2917.0559999999973,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",392,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.352,2925.407999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",393,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.064,2933.471999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",394,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,2936.639999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",395,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,2939.647999999997,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",396,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2943.327999999997,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",397,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,2946.4639999999968,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",398,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.752,2949.2159999999967,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",399,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,2952.3199999999965,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",400,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,2955.3279999999963,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",401,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2959.007999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,2962.0799999999963,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",403,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2964.6399999999962,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",404,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.656,2967.295999999996,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",405,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,2969.855999999996,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",406,47040.0,4507228.0,0.0,0,0.0,4507228.0,4507228.0,25026.0,48.0,0.998085666427375,61440.0,12288.0,20.544,2990.399999999996,3818910.0,594238.0,47040.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",407,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,7.744,2998.143999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",408,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3000.767999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",409,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3003.2959999999957,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",410,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3007.1679999999956,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",411,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3009.5679999999957,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",412,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3012.1279999999956,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",413,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,3015.1679999999956,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,3018.3039999999955,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",415,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10621952.0,49280.0,15.808,3034.1119999999955,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331936.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",416,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.008,3037.1199999999953,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",417,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10791168.0,49248.0,15.2,3052.319999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337224.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",418,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3054.9119999999953,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13585152.0,12288.0,22.208,3077.1199999999953,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424536.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3079.743999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3082.271999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3086.143999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3088.639999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3091.231999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.264,3094.495999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,3097.663999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.968,3105.631999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",428,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.904,3113.535999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394688.0,12288.0,8.352,3121.887999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",430,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,3125.1839999999947,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",431,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,3128.2879999999946,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",432,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3131.9359999999947,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",433,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,3135.007999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",434,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3137.599999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",435,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,3140.863999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",436,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,3143.871999999995,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",437,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3147.519999999995,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3150.655999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",439,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.752,3153.407999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",440,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3156.0319999999947,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",441,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3158.623999999995,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",442,48800.0,4511844.0,0.0,0,0.0,4511844.0,4511844.0,24981.0,48.0,0.9980822246194414,61440.0,12288.0,20.352,3178.9759999999947,3819845.0,594399.0,48800.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",443,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,7.904,3186.8799999999947,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",444,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3189.4399999999946,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",445,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,3191.9999999999945,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",446,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,3195.9359999999947,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",447,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,3198.4639999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",448,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3201.0239999999944,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",449,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,3204.1599999999944,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,3207.1999999999944,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",451,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10793088.0,49280.0,15.168,3222.3679999999945,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337284.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",452,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,3225.2799999999943,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",453,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10747008.0,49184.0,15.584,3240.863999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335844.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",454,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.88,3243.7439999999942,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13579136.0,12288.0,22.848,3266.591999999994,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424348.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3269.1839999999943,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,3271.8399999999942,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,3275.615999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3278.015999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3280.6079999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,3283.615999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,3286.719999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.936,3294.655999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",464,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.256,3302.911999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.032,3310.943999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",466,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3314.175999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",467,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,3317.215999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",468,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.712,3320.927999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",469,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,3323.999999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",470,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3326.623999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",471,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3329.855999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",472,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.072,3332.927999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",473,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3336.607999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,3339.775999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",475,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.848,3342.623999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",476,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3345.215999999994,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",477,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,3347.775999999994,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",478,48896.0,4512096.0,0.0,0,0.0,4512096.0,4512096.0,24972.0,48.0,0.9980815347721822,61440.0,12288.0,20.352,3368.127999999994,3819896.0,594408.0,48896.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",479,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,7.808,3375.935999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",480,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3378.4959999999937,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",481,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,3381.087999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",482,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,3385.023999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",483,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3387.4559999999938,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",484,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3390.1119999999937,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",485,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,3393.1519999999937,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.232,3396.3839999999936,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",487,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10762752.0,49312.0,15.36,3411.743999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,336336.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",488,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,3414.6879999999937,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",489,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10643072.0,49248.0,15.776,3430.4639999999936,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332596.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",490,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.688,3433.1519999999937,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13576832.0,12320.0,22.592,3455.743999999994,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424276.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,3458.431999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,3461.0559999999937,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.096,3465.1519999999937,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3467.5519999999938,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3470.1119999999937,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,3473.1519999999937,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,3476.2559999999935,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394688.0,12288.0,8.096,3484.3519999999935,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",500,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394688.0,12288.0,8.192,3492.5439999999935,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3395456.0,12288.0,8.032,3500.5759999999937,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106108.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",502,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.392,3503.9679999999935,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",503,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,3507.0719999999933,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",504,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.808,3510.8799999999933,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",505,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,3514.175999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",506,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3516.767999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",507,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3519.903999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",508,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.2,3523.103999999993,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",509,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3526.783999999993,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3529.919999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",511,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3532.511999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",512,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3535.103999999993,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",513,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3537.695999999993,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",514,48896.0,4512096.0,0.0,0,0.0,4512096.0,4512096.0,24972.0,48.0,0.9980815347721822,61440.0,12288.0,20.288,3557.983999999993,3819896.0,594408.0,48896.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",515,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.936,3565.9199999999933,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",516,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3568.479999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",517,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3571.007999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",518,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3574.879999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",519,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3577.3119999999926,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",520,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3579.8719999999926,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",521,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.168,3583.0399999999927,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,3586.111999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",523,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10816768.0,49280.0,15.072,3601.183999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,338024.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",524,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,3604.0959999999927,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",525,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10650624.0,49312.0,15.936,3620.031999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332832.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",526,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3622.6559999999927,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13599488.0,12288.0,23.648,3646.303999999993,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3648.9279999999926,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,3651.5199999999927,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3655.3919999999925,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3657.8239999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3660.4159999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,3663.4879999999926,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.232,3666.7199999999925,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394944.0,12288.0,7.968,3674.6879999999924,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106092.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",536,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394688.0,12288.0,7.968,3682.655999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3395200.0,12288.0,8.352,3691.007999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106100.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",538,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3694.143999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",539,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,3697.183999999992,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",540,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3700.863999999992,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",541,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3704.095999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",542,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3706.687999999992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",543,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3709.7919999999917,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",544,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.072,3712.863999999992,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",545,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3716.511999999992,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,3719.775999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",547,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3722.399999999992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",548,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3724.991999999992,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",549,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.72,3727.711999999992,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",550,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.416,3748.127999999992,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",551,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3394688.0,12288.0,7.872,3755.999999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106084.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",552,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3758.6239999999916,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",553,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,3761.2479999999914,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",554,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.0,3765.2479999999914,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",555,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3767.679999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",556,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3770.239999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",557,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,3773.3119999999913,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,3776.415999999991,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",559,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10646784.0,49152.0,16.32,3792.7359999999912,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332712.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",560,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,3795.647999999991,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",561,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10612096.0,49280.0,16.224,3811.871999999991,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331628.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",562,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3814.4639999999913,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13587584.0,12288.0,22.944,3837.4079999999913,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424612.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3839.9999999999914,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,3842.5919999999915,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,3846.4639999999913,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3848.8639999999914,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3851.391999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.168,3854.5599999999913,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,3857.5999999999913,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3395072.0,12288.0,7.968,3865.567999999991,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106096.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",572,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.288,3873.855999999991,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,7.872,3881.727999999991,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",574,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3884.863999999991,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",575,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,3887.9679999999908,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",576,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3891.615999999991,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",577,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,3894.687999999991,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",578,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3897.247999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",579,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3900.3519999999908,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",580,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,3903.3599999999906,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",581,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3907.0399999999904,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,3910.2399999999902,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",583,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3912.79999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",584,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,3915.35999999999,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",585,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.624,3917.98399999999,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",586,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.416,3938.39999999999,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",587,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3396736.0,12288.0,7.936,3946.3359999999902,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106148.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",588,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3948.9279999999903,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",589,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3951.45599999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",590,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3955.26399999999,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",591,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3957.69599999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",592,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3960.25599999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",593,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.104,3963.3599999999897,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,3966.4959999999896,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",595,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10756352.0,49312.0,15.712,3982.2079999999896,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,336136.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",596,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,3985.1519999999896,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",597,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10601984.0,49216.0,16.544,4001.6959999999895,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331312.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",598,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.688,4004.3839999999896,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13578112.0,12288.0,22.496,4026.8799999999896,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424316.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,4029.5999999999894,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,4032.1599999999894,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,4035.9999999999895,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4038.3999999999896,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,4040.9919999999897,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,4043.9999999999895,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,4047.1679999999897,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394816.0,12288.0,8.096,4055.2639999999897,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106088.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",608,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.192,4063.4559999999897,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.288,4071.7439999999897,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",610,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,4074.8799999999896,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",611,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,4077.9839999999895,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",612,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.712,4081.6959999999895,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",613,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,4084.8319999999894,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",614,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4087.3919999999894,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",615,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,4090.5279999999893,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",616,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,4093.535999999989,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",617,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,4097.183999999989,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.328,4100.51199999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",619,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4103.07199999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",620,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,4105.6319999999905,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",621,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.688,4108.319999999991,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",622,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.288,4128.60799999999,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",623,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3393280.0,12288.0,8.256,4136.8639999999905,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106040.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",624,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4139.423999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",625,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,4141.951999999991,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",626,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,4145.727999999991,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",627,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,4148.095999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",628,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4150.655999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",629,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,4153.727999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,4156.767999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",631,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10636416.0,49312.0,15.872,4172.639999999992,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332388.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",632,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,4175.551999999992,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",633,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10742016.0,49280.0,15.68,4191.231999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335688.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",634,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.72,4193.951999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13595008.0,12288.0,22.72,4216.671999999993,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424844.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4219.231999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,4221.759999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,4225.631999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,4227.9999999999945,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,4230.559999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,4233.599999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,4236.639999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.064,4244.703999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",644,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394560.0,12288.0,8.256,4252.9599999999955,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106080.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29568.0,0.5523255813953488,3394816.0,12288.0,8.288,4261.247999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106088.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",646,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,4264.447999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",647,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,4267.487999999995,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",648,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,4271.135999999995,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",649,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,4274.367999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",650,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4276.927999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",651,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,4280.031999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",652,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,4283.071999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",653,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.744,4286.815999999995,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,4289.983999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",655,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,4292.671999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",656,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,4295.231999999995,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",657,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.624,4297.855999999995,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::Sm80, 1, 64, 128, 128, 1, 1>::Params)",658,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,4318.079999999995,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",659,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3394304.0,12288.0,7.936,4326.015999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106072.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",660,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,4328.5759999999955,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",661,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,4331.135999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",662,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,4335.039999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",663,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4337.439999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",664,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,4340.063999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",665,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,4343.071999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,4346.1119999999955,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",667,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10610816.0,49216.0,16.416,4362.527999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331588.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",668,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,4365.471999999996,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",669,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10639232.0,49184.0,15.488,4380.959999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332476.0,1537.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",670,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,4383.583999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13570048.0,12288.0,22.56,4406.143999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424064.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,4408.735999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,4411.295999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.0,4415.295999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,4417.695999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,4420.4159999999965,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,4423.423999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,4426.463999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,478902272.0,1030733824.0,24309760.0,0,0.0,1055043584.0,1055043584.0,7216960.0,5773568.0,0.5555555555555556,649689984.0,2830688.0,519.616,4946.079999999996,38895616.0,58343424.0,466747392.0,12154880.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20302812.0,88459.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",680,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.208,4948.287999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",681,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.464,4950.751999999996,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",682,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,4953.183999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",683,0.0,608256.0,0.0,0,0.0,608256.0,608256.0,0.0,9520.0,0.0,2430976.0,2430976.0,5.248,4958.431999999995,0.0,608256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",684,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,4960.479999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",685,851456.0,0.0,1702912.0,0,0.0,1702912.0,1702912.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.76,4966.239999999995,0.0,0.0,0.0,851456.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",686,411264.0,0.0,822528.0,0,0.0,822528.0,822528.0,31416.0,459348.0,0.06401447538939287,20467136.0,0.0,13.12,4979.359999999995,0.0,0.0,0.0,411264.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,639598.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",687,244965.0,0.0,489930.0,0,0.0,489930.0,489930.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.952,4985.311999999995,0.0,0.0,0.0,244965.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",688,502656.0,0.0,1005312.0,0,0.0,1005312.0,1005312.0,31416.0,462204.0,0.0636440986994044,20584096.0,0.0,13.024,4998.335999999996,0.0,0.0,0.0,502656.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,643253.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",689,243731.0,0.0,487462.0,0,0.0,487462.0,487462.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,5.632,5003.967999999995,0.0,0.0,0.0,243731.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",690,445536.0,0.0,891072.0,0,0.0,891072.0,891072.0,31416.0,460419.0,0.0638750800573363,20520832.0,0.0,13.12,5017.087999999995,0.0,0.0,0.0,445536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,641276.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",691,243716.0,0.0,487432.0,0,0.0,487432.0,487432.0,7616.0,26608.0,0.22253389434315102,2433664.0,121856.0,6.016,5023.103999999995,0.0,0.0,0.0,243716.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76052.0,3808.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",692,434112.0,0.0,868224.0,0,0.0,868224.0,868224.0,31416.0,460062.0,0.06392147766532785,20561888.0,128.0,13.056,5036.159999999994,0.0,0.0,0.0,434112.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,642559.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",693,1244.0,0.0,2488.0,0,0.0,2488.0,2488.0,0.0,45.0,0.0,15264.0,1920.0,3.712,5039.871999999995,0.0,0.0,0.0,1244.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,477.0,60.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",694,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,1.984,5041.855999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",695,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.96,5046.815999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",696,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,5048.895999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",697,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,39.0,0.9422222222222222,1920.0,0.0,4.704,5053.599999999995,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,60.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",698,730512.0,0.0,1461024.0,0,0.0,1461024.0,1461024.0,151249.0,34558.0,0.8140113128138337,2473696.0,10496.0,8.0,5061.599999999995,0.0,0.0,0.0,730512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,77303.0,328.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",699,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.112,5067.711999999995,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",700,1215488.0,0.0,2430976.0,0,0.0,2430976.0,2430976.0,0.0,56976.0,0.0,2441728.0,151936.0,6.464,5074.175999999995,0.0,0.0,0.0,1215488.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76304.0,4748.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",701,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,1920.0,6.464,5080.639999999995,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,60.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",702,1823744.0,0.0,3647488.0,0,0.0,3647488.0,3647488.0,0.0,18992.0,0.0,0.0,4861952.0,6.624,5087.263999999995,0.0,0.0,0.0,1823744.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,151936.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",703,388501.0,0.0,777002.0,0,0.0,777002.0,777002.0,64512.0,18992.0,0.7725617934470205,2430976.0,0.0,6.368,5093.631999999995,0.0,0.0,0.0,388501.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",704,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,5096.223999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",705,496128.0,0.0,992256.0,0,0.0,992256.0,992256.0,168982.0,83146.0,0.6702230613021957,8354560.0,5652064.0,27.456,5123.679999999995,0.0,0.0,0.0,496128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,261080.0,176627.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",706,185088.0,0.0,370176.0,0,0.0,370176.0,370176.0,42622.0,90632.0,0.3198553139117775,8437120.0,5690432.0,23.936,5147.6159999999945,0.0,0.0,0.0,185088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,263660.0,177826.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",707,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90431.0,0.30979766602300396,8415616.0,7410688.0,23.168,5170.783999999994,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262988.0,231584.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",708,181632.0,0.0,363264.0,0,0.0,363264.0,363264.0,40590.0,90796.0,0.3089370252538322,8410496.0,5631232.0,23.552,5194.335999999994,0.0,0.0,0.0,181632.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,262828.0,175976.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",709,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,18992.0,0.3312676056338028,4861952.0,0.0,8.384,5202.719999999994,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",710,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,5205.279999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",711,95722.0,0.0,191444.0,0,0.0,191444.0,191444.0,38634.0,51649.0,0.4279210925644917,5942784.0,3835680.0,14.528,5219.8079999999945,0.0,0.0,0.0,95722.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,185712.0,119865.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",712,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,75968.0,0.0,7332832.0,7292928.0,11.616,5231.4239999999945,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,229151.0,227904.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",713,9884984.0,20076672.0,2753136.0,0,0.0,22829808.0,22829808.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.76,5297.183999999995,2452096.0,607744.0,8508416.0,1376568.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",714,616448.0,3052116.0,1232896.0,0,0.0,4285012.0,4285012.0,334872.0,37984.0,0.8981268908103933,2430976.0,2430976.0,228.704,5525.8879999999945,3052116.0,0.0,0.0,616448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,75968.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",715,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,9520.0,0.0,2430976.0,607360.0,5.472,5531.359999999994,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75968.0,18980.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",716,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.112,5533.471999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",717,1823232.0,0.0,3646464.0,0,0.0,3646464.0,3646464.0,0.0,56976.0,0.0,5469696.0,220544.0,10.88,5544.351999999994,0.0,0.0,0.0,1823232.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,170928.0,6892.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",718,76032.0,0.0,152064.0,0,0.0,152064.0,152064.0,0.0,14280.0,0.0,3038720.0,5760.0,6.24,5550.591999999994,0.0,0.0,0.0,76032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,94960.0,180.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",719,9884995.0,20076672.0,2753158.0,0,0.0,22829830.0,22829830.0,528.0,19136.0,0.026851098454027666,7292928.0,2430976.0,65.856,5616.447999999994,2452096.0,607744.0,8508416.0,1376579.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,227904.0,75968.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",720,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,8.16,5624.607999999994,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",721,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,5627.007999999993,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",722,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,5987.0,4827.0,0.5536341779175143,2431296.0,2432.0,7.968,5634.975999999993,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75978.0,76.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",723,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.368,5637.343999999994,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",724,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,5639.871999999994,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",725,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,5643.103999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",726,200704.0,990796.0,401408.0,0,0.0,1392204.0,1392204.0,7692.0,4832.0,0.6141807729160013,2431392.0,2560.0,8.32,5651.423999999994,990796.0,0.0,0.0,200704.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,75981.0,80.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",727,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.496,5653.919999999994,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",728,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,5657.183999999994,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,5659.5839999999935,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",730,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.328,5662.911999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",731,2709504.0,4570112.0,2064384.0,0,0.0,6634496.0,6634496.0,0.0,18992.0,0.0,0.0,2430976.0,5.184,5668.095999999994,0.0,1215488.0,1677312.0,1032192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,75968.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",732,3649731.0,6082560.0,1216902.0,0,0.0,7299462.0,7299462.0,0.0,14280.0,0.0,4861952.0,74240.0,8.992,5677.087999999994,0.0,0.0,3041280.0,608451.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,151936.0,2320.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",733,541440.0,0.0,1082880.0,0,0.0,1082880.0,1082880.0,14092.0,4912.0,0.7415280993475057,2432256.0,2848.0,9.216,5686.303999999995,0.0,0.0,0.0,541440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,76008.0,89.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",734,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.464,5688.767999999995,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",735,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,5690.815999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",736,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,5692.863999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,5695.391999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",738,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,5697.823999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",739,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.04,5700.863999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",740,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.2,5704.063999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",741,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,5706.463999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
