Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.016,6.912,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.784,9.696,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.496,12.192,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.904,16.096,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.232,19.328,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.912,22.24,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.08,24.32,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,26.368000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,28.480000000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,2.976,31.456000000000003,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,33.952000000000005,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,36.416000000000004,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,32.0,32.0,2.944,39.36000000000001,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,41.79200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.4,44.19200000000001,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.528,46.720000000000006,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,3840.0,0.0,7680.0,0,0.0,7680.0,7680.0,0.0,288.0,0.0,3264.0,12288.0,4.096,50.816,0.0,0.0,0.0,3840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.752,53.568000000000005,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.36,56.928000000000004,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.72,59.648,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.688,62.336000000000006,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.496,64.83200000000001,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,5120.0,9216.0,2048.0,0,0.0,11264.0,11264.0,0.0,32.0,0.0,2048.0,2048.0,3.392,68.224,0.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.592,70.816,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.392,74.208,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,76.736,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,79.36,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.064,83.424,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,85.82400000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,88.44800000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,91.584,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,94.62400000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12352.0,8.48,103.10400000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,386.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,7.808,110.912,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,7.872,118.784,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,121.888,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.2,125.08800000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.744,128.83200000000002,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,131.96800000000002,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,134.68800000000002,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,137.76000000000002,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,140.86400000000003,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.776,144.64000000000004,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,147.74400000000006,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,150.33600000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.064,170.40000000000006,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.936,178.33600000000007,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,180.89600000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,183.42400000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.128,187.55200000000008,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,190.0480000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,192.67200000000008,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,195.71200000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,2.976,198.68800000000007,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10670336.0,49248.0,15.168,213.85600000000008,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333448.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,216.80000000000007,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10806784.0,49344.0,15.52,232.32000000000008,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337712.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,234.9120000000001,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13565952.0,12288.0,22.112,257.0240000000001,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,423936.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,259.6160000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,262.1760000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,266.1440000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.592,268.7360000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,271.2960000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,274.3680000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,277.50400000000013,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,8.032,285.5360000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.712,293.2480000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392896.0,12288.0,8.032,301.2800000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106028.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,304.4480000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.168,307.6160000000001,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.84,311.4560000000001,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,314.75200000000007,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,317.3760000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,320.4800000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,323.48800000000006,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.776,327.26400000000007,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,330.4960000000001,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,333.0880000000001,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,353.1840000000001,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.0,361.1840000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,363.77600000000007,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,366.3040000000001,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,370.0800000000001,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,372.4800000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,375.0400000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,378.1120000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,381.1840000000001,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10647040.0,49408.0,15.616,396.80000000000007,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332720.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.976,399.77600000000007,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10634880.0,49280.0,16.384,416.1600000000001,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332340.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,418.75200000000007,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13568640.0,12288.0,22.592,441.34400000000005,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424020.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,443.93600000000004,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,446.46400000000006,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,450.30400000000003,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,452.672,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,455.264,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,458.30400000000003,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,461.34400000000005,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392512.0,12288.0,8.128,469.47200000000004,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106016.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3393280.0,12288.0,7.968,477.44000000000005,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106040.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392128.0,12288.0,8.064,485.5040000000001,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106004.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,488.60800000000006,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,491.61600000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.872,495.48800000000006,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,498.59200000000004,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,501.184,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,504.48,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,507.52000000000004,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,511.16800000000006,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,514.432,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,516.992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.128,537.12,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,7.712,544.832,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,547.3919999999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,549.9519999999999,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,553.9199999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,556.4159999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,559.0079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.2,562.2079999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,565.3759999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10661504.0,49248.0,15.936,581.3119999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333172.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.88,584.1919999999999,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10699776.0,49312.0,16.064,600.2559999999999,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334368.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,602.8479999999998,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13568000.0,12288.0,21.92,624.7679999999998,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424000.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.848,627.6159999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.496,630.1119999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,634.0799999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,636.5119999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,639.1039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.104,642.2079999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,645.2479999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.064,653.3119999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.808,661.1199999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,8.0,669.1199999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,672.3519999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,675.3919999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.936,679.3279999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,682.6239999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,685.2799999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,688.5119999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,691.5519999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,695.1999999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,698.3679999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,700.9279999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.16,721.0879999999995,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392896.0,12320.0,7.872,728.9599999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106028.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,731.5519999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,734.0799999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,737.9519999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,740.3519999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,742.9759999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,746.1119999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,749.1519999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10720384.0,49344.0,15.744,764.8959999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335012.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.88,767.7759999999994,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10576000.0,49312.0,16.352,784.1279999999994,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,330500.0,1541.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.656,786.7839999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13591296.0,12320.0,22.464,809.2479999999994,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424728.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,811.9359999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,814.5279999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,818.3679999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,820.7999999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,823.3599999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,826.3999999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.264,829.6639999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12352.0,7.808,837.4719999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,386.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392384.0,12288.0,8.032,845.5039999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106012.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,8.0,853.5039999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,856.6399999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,859.6479999999993,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,863.2959999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,866.4959999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,869.1199999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,872.2879999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,875.3279999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,879.0079999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.264,882.2719999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,884.9919999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.16,905.1519999999994,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,7.872,913.0239999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,915.5839999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,918.1119999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.936,922.0479999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,924.5759999999993,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,927.1679999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,930.1759999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,933.2479999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10762752.0,49344.0,15.232,948.4799999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,336336.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.944,951.4239999999993,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10617984.0,49344.0,15.968,967.3919999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,331812.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,970.0159999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13578368.0,12288.0,22.368,992.3839999999993,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424324.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,994.9759999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,997.5039999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,1001.3439999999994,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1003.8079999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1006.3679999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,1009.4079999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,1012.5439999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.744,1020.2879999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,7.808,1028.0959999999993,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392896.0,12288.0,7.968,1036.0639999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106028.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1039.1679999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.168,1042.3359999999993,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,1046.0159999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,1049.2479999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1051.8399999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1054.9759999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.072,1058.0479999999993,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,1061.7279999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,1064.9599999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1067.5199999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.192,1087.7119999999993,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12320.0,8.032,1095.7439999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1098.3359999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1100.8639999999994,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,1104.7679999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1107.1999999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1109.7919999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,1112.8319999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,1115.9039999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10641280.0,49280.0,15.52,1131.4239999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332540.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.976,1134.3999999999994,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10704128.0,49408.0,15.968,1150.3679999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334504.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,1152.9599999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13603328.0,12288.0,23.456,1176.4159999999995,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,425104.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1178.9759999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,1181.5679999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.872,1185.4399999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,1187.8079999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1190.3679999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,1193.4399999999994,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,1196.4799999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,8.064,1204.5439999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.712,1212.2559999999994,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392512.0,12288.0,7.872,1220.1279999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106016.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.392,1223.5199999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,1226.5279999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,1230.2079999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1233.3439999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1235.9359999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,1239.1359999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,1242.1439999999998,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1245.7919999999997,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1248.8959999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1251.4559999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1271.5519999999997,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.84,1279.3919999999996,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,1282.1119999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.592,1284.7039999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,1288.6079999999997,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1291.0079999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1293.6319999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,1296.7039999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,1299.7439999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10624128.0,49248.0,15.936,1315.6799999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332004.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.008,1318.6879999999996,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10702080.0,49216.0,15.36,1334.0479999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334440.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,1336.6719999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13570176.0,12288.0,22.976,1359.6479999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424068.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,1362.2719999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1364.7999999999997,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.968,1368.7679999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1371.168,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.848,1374.0159999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.2,1377.216,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,1380.2879999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12320.0,7.776,1388.0639999999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,385.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.128,1396.1919999999998,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392000.0,12288.0,8.128,1404.3199999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106000.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1407.4559999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,1410.4959999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,4.032,1414.5279999999996,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1417.6319999999996,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1420.1919999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,1423.3279999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,1426.4319999999996,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,1430.0799999999995,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,1433.1839999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,1435.7439999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,49152.0,4511232.0,0.0,0,0.0,4511232.0,4511232.0,24960.0,48.0,0.9980806142034548,36864.0,12288.0,20.096,1455.8399999999995,3818496.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1152.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.904,1463.7439999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1466.3359999999996,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,1468.9599999999996,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1472.7679999999996,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1475.1679999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1477.7599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,1480.7999999999997,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.264,1484.0639999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10738304.0,49280.0,15.488,1499.5519999999997,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335572.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.104,1502.6559999999997,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10645120.0,49344.0,15.84,1518.4959999999996,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332660.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,1521.1199999999997,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13569152.0,12288.0,22.624,1543.7439999999997,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424036.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,1546.3359999999998,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,1548.8639999999998,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,1552.6719999999998,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1555.072,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,1557.7279999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.2,1560.9279999999999,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,1563.9999999999998,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,20000.0,0.9924783753290711,101337312.0,2560000.0,165.664,1729.6639999999998,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3166791.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.24,1739.9039999999998,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,1741.9519999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.56,1744.5119999999997,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,1747.0079999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.232,1750.2399999999998,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,1752.3839999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.256,1756.6399999999999,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.672,1761.312,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,64768.0,0.0,129536.0,0,0.0,129536.0,129536.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.128,1765.4399999999998,0.0,0.0,0.0,64768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,0.0,4.8,1770.2399999999998,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,64520.0,0.0,129040.0,0,0.0,129040.0,129040.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.0,1774.2399999999998,0.0,0.0,0.0,64520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,114688.0,0.0,229376.0,0,0.0,229376.0,229376.0,8448.0,34568.0,0.19639204017109912,2106624.0,0.0,4.64,1778.8799999999999,0.0,0.0,0.0,114688.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,3.936,1782.8159999999998,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,128.0,4.736,1787.552,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.072,1790.6239999999998,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1792.7039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.352,1797.0559999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.08,1799.1359999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.448,1803.5839999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,26568.0,8416.0,0.7594328836039332,525824.0,7392.0,5.824,1809.408,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,231.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.272,1815.6799999999998,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.192,1819.8719999999998,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.232,1823.1039999999998,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.104,1826.2079999999999,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387725.0,0.0,775450.0,0,0.0,775450.0,775450.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.224,1830.4319999999998,0.0,0.0,0.0,387725.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.72,1833.1519999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17820.0,0.7004034969737727,1700608.0,1246336.0,15.872,1849.024,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53144.0,38948.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17756.0,0.3481644640234949,1693056.0,1560832.0,12.64,1861.664,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52908.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17691.0,0.37845624143625056,1693696.0,1560832.0,14.336,1876.0,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52928.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17587.0,0.37984414118974574,1689472.0,1193760.0,14.368,1890.368,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52796.0,37305.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.352,1894.72,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.528,1897.248,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9486.0,0.526764779246695,1161728.0,817888.0,7.776,1905.0240000000001,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36304.0,25559.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548992.0,1536000.0,4.352,1909.3760000000002,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48406.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1002368.0,512000.0,18.784,1928.1600000000003,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31324.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,50.688,1978.8480000000004,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.072,1981.9200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.112,1984.0320000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,50272.0,9.12,1993.1520000000003,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1571.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.264,1996.4160000000002,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,2097988.0,4245120.0,611976.0,0,0.0,4857096.0,4857096.0,528.0,5248.0,0.09141274238227147,1021440.0,512000.0,18.688,2015.1040000000003,533120.0,128000.0,1792000.0,305988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31920.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.48,2043.5840000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.496,2046.0800000000004,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.48,2074.5600000000004,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2076.992,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.688,2079.6800000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2082.9440000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.568,2092.5120000000006,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.4,2094.9120000000007,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,2098.2080000000005,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.4,2100.6080000000006,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2103.8400000000006,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.096,2107.9360000000006,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,767812.0,1280000.0,255624.0,0,0.0,1535624.0,1535624.0,0.0,3000.0,0.0,1024000.0,0.0,5.024,2112.9600000000005,0.0,0.0,640000.0,127812.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.864,2125.8240000000005,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.624,2128.4480000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,2130.88,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.464,2133.344,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.528,2135.872,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,260.0,0.0,520.0,0,0.0,520.0,520.0,0.0,6.0,0.0,64.0,128.0,2.528,2138.3999999999996,0.0,0.0,0.0,260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,4.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.112,2140.5119999999997,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.176,2142.6879999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.624,2145.3119999999994,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,2147.359999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,32.0,2.528,2149.887999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.696,2155.583999999999,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,2158.1119999999987,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.4,2160.511999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.168,2163.679999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.168,2166.847999999999,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.4,2169.247999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,2171.679999999999,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,136.0,0.0,272.0,0,0.0,272.0,272.0,0.0,3.0,0.0,96.0,32.0,3.392,2175.0719999999988,0.0,0.0,0.0,136.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1152.0,0.0,2304.0,0,0.0,2304.0,2304.0,56.0,4.0,0.9333333333333333,64.0,32.0,2.944,2178.0159999999987,0.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,64.0,64.0,2.432,2180.4479999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,64.0,32.0,2.432,2182.8799999999983,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,96.0,0.0,2.528,2185.407999999998,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,64.0,32.0,2.464,2187.871999999998,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,3840.0,0.0,7680.0,0,0.0,7680.0,7680.0,0.0,288.0,0.0,12480.0,12288.0,5.28,2193.151999999998,0.0,0.0,0.0,3840.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,390.0,384.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,16.0,0.0,32.0,0,0.0,32.0,32.0,0.0,2.0,0.0,64.0,32.0,2.912,2196.063999999998,0.0,0.0,0.0,16.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,24.0,0.0,48.0,0,0.0,48.0,48.0,0.0,2.0,0.0,32.0,32.0,3.392,2199.455999999998,0.0,0.0,0.0,24.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,524.0,0.0,1048.0,0,0.0,1048.0,1048.0,0.0,2.0,0.0,32.0,32.0,2.784,2202.239999999998,0.0,0.0,0.0,524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,512.0,0.0,0,0.0,512.0,512.0,32.0,24.0,0.5714285714285714,1280.0,1024.0,2.592,2204.831999999998,0.0,512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,32.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,384.0,0.0,768.0,0,0.0,768.0,768.0,0.0,20.0,0.0,2048.0,2048.0,2.528,2207.359999999998,0.0,0.0,0.0,384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,5120.0,9232.0,2048.0,0,0.0,11280.0,11280.0,0.0,32.0,0.0,2048.0,2048.0,3.232,2210.591999999998,16.0,1024.0,4096.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.56,2213.1519999999978,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,4992.0,9216.0,1792.0,0,0.0,11008.0,11008.0,0.0,32.0,0.0,2048.0,2048.0,3.232,2216.3839999999977,0.0,1024.0,4096.0,896.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,32.0,0.0,2048.0,2048.0,2.528,2218.9119999999975,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,64.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2221.4719999999975,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,2225.3759999999975,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2227.7439999999974,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2230.3359999999975,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,2233.3439999999973,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,2236.3839999999973,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.84,2244.2239999999974,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12320.0,7.872,2252.0959999999973,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,385.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.776,2259.871999999997,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,2262.9439999999972,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,2265.951999999997,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2269.599999999997,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,2272.831999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2275.4239999999972,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,2278.623999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,2281.727999999997,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.84,2285.567999999997,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,2288.863999999997,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2291.455999999997,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,2294.047999999997,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2296.671999999997,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.352,2317.0239999999967,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.872,2324.8959999999965,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2327.4879999999966,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2330.0159999999964,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,2333.7919999999963,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2336.159999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2338.783999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.296,2342.079999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,2345.215999999996,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10644608.0,49248.0,15.776,2360.9919999999956,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332644.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.88,2363.8719999999958,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10728448.0,49216.0,15.328,2379.1999999999957,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335264.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,2381.791999999996,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13571840.0,12352.0,22.624,2404.4159999999956,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424120.0,386.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2407.0079999999957,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2409.5359999999955,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,2413.3439999999955,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2415.7439999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2418.3679999999954,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.104,2421.471999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,2424.6399999999953,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.712,2432.3519999999953,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.84,2440.1919999999955,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12320.0,8.032,2448.2239999999956,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,385.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,2451.5199999999954,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,2454.5279999999952,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.616,2458.1439999999952,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,2461.247999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2463.839999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,2466.975999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.072,2470.047999999995,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2473.6959999999954,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.296,2476.991999999995,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,2479.6799999999953,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,2482.2399999999952,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.688,2484.9279999999953,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.352,2505.279999999995,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,8.352,2513.631999999995,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2516.223999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2518.751999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,2522.655999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2525.0879999999947,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2527.6479999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,2530.719999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,2533.8239999999946,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10657408.0,49216.0,15.648,2549.4719999999948,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333044.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.976,2552.447999999995,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10706176.0,49440.0,15.36,2567.807999999995,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334568.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.784,2570.591999999995,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13593856.0,12288.0,22.752,2593.343999999995,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424808.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2595.935999999995,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2598.463999999995,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.096,2602.559999999995,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2604.959999999995,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2607.519999999995,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,2610.527999999995,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.2,2613.7279999999946,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.128,2621.8559999999948,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.776,2629.6319999999946,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.256,2637.8879999999945,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,2641.0879999999943,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,2644.1279999999942,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2647.807999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.072,2650.879999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2653.503999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,2656.639999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,2659.679999999994,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2663.327999999994,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,2666.463999999994,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2669.119999999994,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.624,2671.743999999994,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.752,2674.4959999999937,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.32,2694.815999999994,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.064,2702.8799999999937,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,2705.5039999999935,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,2708.1279999999933,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2711.9679999999935,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,2714.4319999999934,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2716.9919999999934,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,2719.999999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,2723.039999999993,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10711296.0,49344.0,15.552,2738.5919999999933,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334728.0,1542.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.848,2741.4399999999932,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10626688.0,49152.0,16.256,2757.695999999993,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332084.0,1536.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.688,2760.383999999993,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13585408.0,12288.0,21.888,2782.271999999993,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424544.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2784.927999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,2787.487999999993,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,4.064,2791.551999999993,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,2794.0799999999927,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2796.6079999999924,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,2799.6159999999923,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,2802.6879999999924,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.84,2810.5279999999925,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.128,2818.6559999999927,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392128.0,12288.0,7.904,2826.5599999999927,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106004.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.328,2829.8879999999926,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,2.976,2832.8639999999928,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,2836.511999999993,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,2839.647999999993,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,2842.303999999993,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,2845.4079999999926,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,2848.4479999999926,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,2852.1279999999924,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,2855.2319999999922,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2857.8239999999923,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,2860.3839999999923,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,2862.9759999999924,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.192,2883.1679999999924,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,8.096,2891.2639999999924,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,2893.8559999999925,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2896.3839999999923,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2900.2239999999924,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2902.6239999999925,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2905.1839999999925,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,2908.2239999999924,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.136,2911.3599999999924,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10538624.0,49216.0,16.48,2927.8399999999924,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,329332.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.232,2931.0719999999924,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10726912.0,49440.0,15.68,2946.751999999992,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335216.0,1545.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.656,2949.407999999992,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13580032.0,12288.0,22.944,2972.351999999992,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424376.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,2974.911999999992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,2977.439999999992,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,2981.279999999992,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,2983.647999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2986.207999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.136,2989.343999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,2992.383999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.808,3000.191999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,7.904,3008.095999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3394048.0,12288.0,8.128,3016.223999999992,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106064.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3019.327999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.008,3022.3359999999916,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3025.9839999999917,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3029.0879999999916,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,3031.7759999999917,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3035.0079999999916,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,2.976,3037.9839999999917,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3041.631999999992,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3044.863999999992,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3047.455999999992,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3050.047999999992,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3052.639999999992,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,3072.8639999999923,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.744,3080.6079999999924,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3083.1679999999924,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3085.695999999992,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.904,3089.599999999992,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3091.967999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3094.527999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.168,3097.695999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,3100.799999999992,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10689024.0,49248.0,15.584,3116.383999999992,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334032.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.88,3119.263999999992,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10665472.0,49216.0,15.264,3134.527999999992,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,333296.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3137.119999999992,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13582720.0,12288.0,22.336,3159.455999999992,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424460.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.624,3162.0799999999917,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.496,3164.575999999992,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.776,3168.3519999999917,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,3170.7519999999918,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3173.2799999999916,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,3176.2879999999914,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,3179.3599999999915,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392896.0,12288.0,7.968,3187.3279999999913,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106028.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.84,3195.1679999999915,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3393664.0,12288.0,7.968,3203.1359999999913,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106052.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,3206.335999999991,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,3209.439999999991,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.776,3213.215999999991,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3216.3519999999908,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3218.943999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3222.0479999999907,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.136,3225.1839999999906,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3228.831999999991,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3231.9679999999908,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,3234.655999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3237.247999999991,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,3239.807999999991,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.224,3260.031999999991,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.808,3267.839999999991,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.656,3270.495999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.624,3273.119999999991,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3276.959999999991,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3279.455999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3281.983999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.04,3285.023999999991,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.008,3288.0319999999906,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10728960.0,49280.0,15.744,3303.7759999999907,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335280.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,3.072,3306.847999999991,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10736512.0,49248.0,15.712,3322.559999999991,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,335516.0,1539.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.592,3325.151999999991,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13612288.0,12288.0,22.4,3347.551999999991,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,425384.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3350.111999999991,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.656,3352.767999999991,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3356.575999999991,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.336,3358.9119999999907,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3361.4719999999907,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,3364.543999999991,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.104,3367.6479999999906,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391744.0,12288.0,8.128,3375.7759999999907,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105992.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12320.0,7.808,3383.5839999999907,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,385.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391872.0,12288.0,8.064,3391.6479999999906,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105996.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.232,3394.8799999999906,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,3397.9199999999905,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3401.5999999999904,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3404.70399999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3407.2959999999903,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.2,3410.49599999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.072,3413.56799999999,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.68,3417.24799999999,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.136,3420.38399999999,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.592,3422.97599999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.56,3425.53599999999,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3428.12799999999,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.192,3448.31999999999,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.872,3456.19199999999,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.72,3458.91199999999,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.528,3461.4399999999896,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3465.2799999999897,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3467.6479999999897,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3470.1759999999895,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.008,3473.1839999999893,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.168,3476.3519999999894,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10563328.0,49408.0,16.032,3492.3839999999896,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,330104.0,1544.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.912,3495.2959999999894,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10802432.0,49472.0,15.2,3510.495999999989,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,337576.0,1546.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.88,3513.3759999999893,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13571072.0,12288.0,22.88,3536.2559999999894,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424096.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,3538.9439999999895,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.72,3541.6639999999893,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3545.4719999999893,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3547.8399999999892,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3550.367999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.168,3553.535999999989,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,3556.575999999989,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392000.0,12288.0,7.648,3564.2239999999892,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106000.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391488.0,12288.0,7.776,3571.999999999989,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105984.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3392896.0,12288.0,8.192,3580.191999999989,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,106028.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.168,3583.359999999989,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.04,3586.399999999989,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.616,3590.015999999989,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3593.119999999989,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3595.679999999989,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3598.7839999999887,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,2304.0,1536.0,4608.0,0,0.0,6144.0,6144.0,0.0,96.0,0.0,6144.0,6144.0,3.104,3601.8879999999886,1536.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,178176.0,0.0,356352.0,0,0.0,356352.0,356352.0,0.0,192.0,0.0,12288.0,12288.0,3.648,3605.5359999999887,0.0,0.0,0.0,178176.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,9216.0,3072.0,18432.0,0,0.0,21504.0,21504.0,0.0,288.0,0.0,18432.0,12288.0,3.104,3608.6399999999885,0.0,3072.0,0.0,9216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.688,3611.3279999999886,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.592,3613.9199999999887,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,4608.0,0.0,9216.0,0,0.0,9216.0,9216.0,0.0,240.0,0.0,24576.0,24576.0,2.688,3616.607999999989,0.0,0.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,49152.0,4512768.0,0.0,0,0.0,4512768.0,4512768.0,24960.0,48.0,0.9980806142034548,61440.0,12288.0,20.192,3636.799999999989,3820032.0,594432.0,49152.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1920.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,2420736.0,5210112.0,122880.0,0,0.0,5332992.0,5332992.0,36480.0,29184.0,0.5555555555555556,3391616.0,12288.0,7.68,3644.4799999999886,196608.0,294912.0,2359296.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,105988.0,384.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.56,3647.0399999999886,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.496,3649.5359999999887,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.808,3653.3439999999887,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3655.7759999999885,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,3658.3039999999883,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.072,3661.3759999999884,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.072,3664.4479999999885,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10715904.0,49216.0,15.712,3680.1599999999885,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,334872.0,1538.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,135168.0,258048.0,24576.0,0,0.0,282624.0,282624.0,0.0,192.0,0.0,49152.0,49152.0,2.976,3683.1359999999886,12288.0,0.0,122880.0,12288.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,9682944.0,20840448.0,491520.0,0,0.0,21331968.0,21331968.0,145920.0,116736.0,0.5555555555555556,10651520.0,49280.0,16.032,3699.1679999999888,786432.0,1179648.0,9437184.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,332860.0,1540.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,12288.0,0.0,0,0.0,12288.0,12288.0,0.0,288.0,0.0,98304.0,49152.0,2.624,3701.7919999999885,0.0,12288.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3072.0,1536.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,9609216.0,20692992.0,344064.0,0,0.0,21037056.0,21037056.0,126336.0,112128.0,0.5297906602254429,13584896.0,12320.0,22.656,3724.4479999999885,638976.0,1179648.0,9437184.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,424528.0,385.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,3072.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,72.0,0.0,24576.0,12288.0,2.528,3726.9759999999883,0.0,0.0,3072.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,0.0,3072.0,0.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,12288.0,12288.0,2.56,3729.5359999999882,0.0,3072.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,2048.0,7556.0,4096.0,0,0.0,11652.0,11652.0,40.0,28.0,0.5882352941176471,12288.0,32.0,3.84,3733.3759999999884,7552.0,4.0,0.0,2048.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.368,3735.7439999999883,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3738.3999999999883,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,12672.0,12288.0,3.168,3741.5679999999884,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,396.0,384.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,6144.0,3072.0,12288.0,0,0.0,15360.0,15360.0,0.0,288.0,0.0,24576.0,12288.0,3.04,3744.6079999999884,0.0,3072.0,0.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,384.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,20000.0,0.9924783753290711,101347296.0,2560000.0,165.888,3910.4959999999883,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3167103.0,80000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,128000.0,768000.0,256000.0,0,0.0,1024000.0,1024000.0,0.0,24000.0,0.0,2560000.0,512000.0,10.528,3921.023999999988,640000.0,128000.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80000.0,16000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3923.071999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.56,3925.631999999988,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,3928.0639999999876,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,128000.0,0.0,0,0.0,128000.0,128000.0,0.0,2000.0,0.0,512000.0,512000.0,3.232,3931.2959999999875,0.0,128000.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3933.3439999999873,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.128,3937.4719999999875,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,110592.0,0.0,221184.0,0,0.0,221184.0,221184.0,8448.0,34440.0,0.1969781757134863,2106624.0,0.0,4.832,3942.3039999999874,0.0,0.0,0.0,110592.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,64772.0,0.0,129544.0,0,0.0,129544.0,129544.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.128,3946.4319999999875,0.0,0.0,0.0,64772.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,135168.0,0.0,270336.0,0,0.0,270336.0,270336.0,8448.0,35208.0,0.19351291918636612,2106624.0,0.0,4.672,3951.1039999999875,0.0,0.0,0.0,135168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,64533.0,0.0,129066.0,0,0.0,129066.0,129066.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.096,3955.1999999999875,0.0,0.0,0.0,64533.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,116736.0,0.0,233472.0,0,0.0,233472.0,233472.0,8448.0,34632.0,0.19610027855153203,2106624.0,0.0,4.736,3959.9359999999874,0.0,0.0,0.0,116736.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,64516.0,0.0,129032.0,0,0.0,129032.0,129032.0,2048.0,6048.0,0.25296442687747034,514688.0,32768.0,4.288,3964.2239999999874,0.0,0.0,0.0,64516.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16084.0,1024.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,118784.0,0.0,237568.0,0,0.0,237568.0,237568.0,8448.0,34696.0,0.19580938253291302,2106624.0,128.0,4.704,3968.9279999999876,0.0,0.0,0.0,118784.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65832.0,4.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,640.0,0.0,1280.0,0,0.0,1280.0,1280.0,0.0,12.0,0.0,4128.0,512.0,3.104,3972.0319999999874,0.0,0.0,0.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,129.0,16.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,3974.0479999999875,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.352,3978.3999999999874,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.048,3980.447999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,17.0,0.9739663093415007,512.0,0.0,4.32,3984.7679999999873,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,161168.0,0.0,322336.0,0,0.0,322336.0,322336.0,36941.0,8424.0,0.8143061831808663,525824.0,7168.0,6.08,3990.847999999987,0.0,0.0,0.0,161168.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16432.0,224.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,512.0,0.0,1024.0,0,0.0,1024.0,1024.0,1832.0,32.0,0.9828326180257511,2560.0,0.0,6.336,3997.183999999987,0.0,0.0,0.0,512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,80.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,256000.0,0.0,512000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,520064.0,32000.0,4.032,4001.215999999987,0.0,0.0,0.0,256000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16252.0,1000.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.168,4004.3839999999873,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,4000.0,0.0,0.0,1024000.0,3.072,4007.4559999999874,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,32000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387719.0,0.0,775438.0,0,0.0,775438.0,775438.0,64512.0,4000.0,0.9416160672582905,512000.0,0.0,4.288,4011.7439999999874,0.0,0.0,0.0,387719.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.688,4014.4319999999875,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,119424.0,0.0,238848.0,0,0.0,238848.0,238848.0,41660.0,17721.0,0.7015712096461831,1703168.0,1209152.0,15.584,4030.0159999999873,0.0,0.0,0.0,119424.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53224.0,37786.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,41728.0,0.0,83456.0,0,0.0,83456.0,83456.0,9484.0,17746.0,0.34829232464193904,1696896.0,1560832.0,13.056,4043.0719999999874,0.0,0.0,0.0,41728.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,53028.0,48776.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17685.0,0.3785360368274941,1687168.0,1560576.0,14.272,4057.3439999999873,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52724.0,48768.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,43392.0,0.0,86784.0,0,0.0,86784.0,86784.0,10772.0,17538.0,0.3805015895443306,1688320.0,1193888.0,14.56,4071.9039999999873,0.0,0.0,0.0,43392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,52760.0,37309.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,4000.0,0.7016706443914081,1024000.0,0.0,4.224,4076.1279999999874,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,4078.6879999999874,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,31895.0,0.0,63790.0,0,0.0,63790.0,63790.0,10559.0,9576.0,0.5244102309411472,1158912.0,819616.0,7.904,4086.5919999999874,0.0,0.0,0.0,31895.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36216.0,25613.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,16000.0,0.0,1548960.0,1536000.0,4.352,4090.943999999987,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,48405.0,48000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,2097976.0,4245120.0,611952.0,0,0.0,4857072.0,4857072.0,528.0,5248.0,0.09141274238227147,1014400.0,512000.0,18.528,4109.471999999987,533120.0,128000.0,1792000.0,305976.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31700.0,16000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,137216.0,655488.0,274432.0,0,0.0,929920.0,929920.0,71840.0,8000.0,0.8997995991983968,512000.0,512000.0,52.064,4161.535999999987,655488.0,0.0,0.0,137216.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,16000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2000.0,0.0,512000.0,128000.0,3.008,4164.543999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4000.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,128.0,2.208,4166.751999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,4.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,384000.0,0.0,768000.0,0,0.0,768000.0,768000.0,0.0,12000.0,0.0,1152000.0,49728.0,9.248,4175.999999999986,0.0,0.0,0.0,384000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,36000.0,1554.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,16000.0,0.0,32000.0,0,0.0,32000.0,32000.0,0.0,3000.0,0.0,640000.0,0.0,3.168,4179.167999999986,0.0,0.0,0.0,16000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,2097987.0,4245120.0,611974.0,0,0.0,4857094.0,4857094.0,528.0,5248.0,0.09141274238227147,1003264.0,512000.0,18.72,4197.887999999986,533120.0,128000.0,1792000.0,305987.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,31352.0,16000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.736,4226.623999999986,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.4,4229.023999999986,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,1001.0,0.05832549388523048,512000.0,32.0,28.928,4257.951999999986,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.464,4260.415999999986,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.528,4262.943999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,4266.207999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,8192.0,147456.0,16384.0,0,0.0,163840.0,163840.0,320.0,1004.0,0.24169184290030213,512000.0,128.0,9.536,4275.743999999986,147456.0,0.0,0.0,8192.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,2.0,0.0,32.0,32.0,2.56,4278.303999999986,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.264,4281.567999999987,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4283.999999999986,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.2,4287.199999999986,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,1792000.0,2560000.0,1280000.0,0,0.0,3840000.0,3840000.0,0.0,4000.0,0.0,0.0,512000.0,4.096,4291.295999999986,0.0,256000.0,1152000.0,640000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,767811.0,1280000.0,255622.0,0,0.0,1535622.0,1535622.0,0.0,3000.0,0.0,1024000.0,0.0,4.544,4295.839999999986,0.0,0.0,640000.0,127811.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,74240.0,0.0,148480.0,0,0.0,148480.0,148480.0,640.0,1004.0,0.38929440389294406,512000.0,128.0,12.768,4308.607999999986,0.0,0.0,0.0,74240.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,4.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,4311.039999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,4313.503999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.624,4316.127999999985,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.72,4318.847999999985,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,262.0,0.0,524.0,0,0.0,524.0,524.0,0.0,6.0,0.0,96.0,160.0,2.56,4321.407999999986,0.0,0.0,0.0,262.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,5.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.08,4323.487999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4325.5359999999855,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.56,4328.095999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,1.0,0.0,0.0,32.0,2.048,4330.143999999986,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,128.0,32.0,2.496,4332.639999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,4.0,1.0
"void native::reduce_kernel<128, 4, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,5.0,0.0,32.0,32.0,5.792,4338.431999999986,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,2.528,4340.959999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.432,4343.391999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,3.0,0.0,64.0,32.0,3.104,4346.495999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,3.232,4349.727999999986,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,4352.159999999986,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
