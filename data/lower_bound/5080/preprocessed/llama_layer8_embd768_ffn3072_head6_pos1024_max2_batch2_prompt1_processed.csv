Kernel Name,index,total_fma_ops,float_flops,half_flops,double_flops,tensor_flops,total_flops,total_flops_with_tensor,shared_ops,external_memory_ops,shared_ratio,global_op_ld_lookup_miss_bytes,global_op_st_lookup_miss_bytes,kernel_duration,accumulated_time,smsp__sass_thread_inst_executed_op_fadd_pred_on.sum,smsp__sass_thread_inst_executed_op_fmul_pred_on.sum,smsp__sass_thread_inst_executed_op_ffma_pred_on.sum,smsp__sass_thread_inst_executed_op_hfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dfma_pred_on.sum,smsp__sass_thread_inst_executed_op_dmul_pred_on.sum,smsp__sass_thread_inst_executed_op_dadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hadd_pred_on.sum,smsp__sass_thread_inst_executed_op_hmul_pred_on.sum,sm__ops_path_tensor_src_fp16_dst_fp16.sum,sm__ops_path_tensor_src_fp16_dst_fp32.sum,sm__ops_path_tensor_src_bf16_dst_fp32.sum,sm__ops_path_tensor_src_fp8.sum,sm__ops_path_tensor_src_tf32_dst_fp32.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_ld_lookup_miss.sum,l1tex__t_sectors_pipe_lsu_mem_global_op_st_lookup_miss.sum
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",1,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.696,1.696,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",2,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,1.568,3.2640000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",3,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,1.0,0.0,0.0,32.0,1.632,4.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",4,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,3.0,0.0,64.0,32.0,2.08,6.976,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",5,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.688,9.664,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",6,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.56,12.224,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",7,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.84,16.064,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, 4, 4>>(T3)",8,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.36,19.424,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",9,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.912,22.336,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",10,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,24.384,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",11,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,26.432000000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void at_cuda_detail::DeviceScanInitKernel<at_cuda_detail::ScanTileState<long, 1>>(T1, int)",12,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.304,28.736,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanKernel<at_cuda_detail::DeviceScanPolicy<long, std::plus<long>>::Policy900, const long *, long *, at_cuda_detail::ScanTileState<long, 1>, std::plus<long>, at_cuda_detail::NullType, unsigned int, long, 0>(T2, T3, T4, int, T5, T6, T7)",13,128.0,0.0,256.0,0,0.0,256.0,256.0,129.0,6.0,0.9555555555555556,32.0,32.0,3.104,31.84,0.0,0.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",14,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,34.432,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",15,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,36.896,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",16,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.944,39.84,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",17,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,42.24,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",18,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.464,44.704,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",19,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,0.0,2.528,47.232,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",20,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,3264.0,6144.0,3.776,51.007999999999996,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,102.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",21,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.008,54.016,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",22,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.328,57.344,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",23,518.0,0.0,1036.0,0,0.0,1036.0,1036.0,0.0,2.0,0.0,32.0,32.0,2.816,60.160000000000004,0.0,0.0,0.0,518.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",24,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,3.104,63.264,0.0,256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",25,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,2.496,65.76,0.0,0.0,0.0,320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",26,2816.0,4608.0,1536.0,0,0.0,6144.0,6144.0,0.0,16.0,0.0,1024.0,1024.0,3.104,68.864,0.0,512.0,2048.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",27,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.592,71.456,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",28,2688.0,4608.0,1280.0,0,0.0,5888.0,5888.0,0.0,16.0,0.0,1024.0,1024.0,3.072,74.528,0.0,512.0,2048.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",29,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.528,77.05600000000001,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",30,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.656,79.71200000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",31,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,83.48800000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",32,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.848,86.33600000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",33,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,88.99200000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",34,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,92.12800000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",35,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,95.26400000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",36,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,8.224,103.48800000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",37,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.84,111.32800000000002,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",38,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.84,119.16800000000002,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",39,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.328,122.49600000000002,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",40,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,125.56800000000003,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",41,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.84,129.40800000000002,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",42,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,132.57600000000002,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",43,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,135.104,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",44,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,138.17600000000002,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",45,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,141.216,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",46,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,144.8,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",47,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,147.936,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",48,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,150.464,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",49,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.288,170.752,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",50,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876160.0,6144.0,7.552,178.304,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89880.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",51,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.752,181.056,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",52,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,183.55200000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",53,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,187.32800000000003,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",54,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,189.76000000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",55,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,192.35200000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",56,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,195.39200000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",57,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,198.43200000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",58,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10074240.0,24576.0,14.56,212.99200000000002,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314820.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",59,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.008,216.00000000000003,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",60,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9989376.0,24576.0,16.512,232.51200000000003,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312168.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",61,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,235.07200000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",62,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11502208.0,6144.0,20.608,255.68000000000004,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359444.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",63,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,258.27200000000005,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",64,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,260.83200000000005,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",65,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,264.64000000000004,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",66,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,267.07200000000006,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",67,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,269.66400000000004,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",68,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,272.672,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",69,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,275.80800000000005,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",70,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,8.0,283.80800000000005,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",71,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.776,291.58400000000006,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",72,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.712,299.29600000000005,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",73,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,302.40000000000003,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",74,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.136,305.53600000000006,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",75,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,309.1840000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",76,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,312.3200000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",77,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,314.8800000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",78,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,317.9840000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",79,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.104,321.0880000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",80,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.808,324.8960000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",81,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,328.1280000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",82,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,330.8480000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",83,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.384,351.23200000000014,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",84,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2877312.0,6144.0,7.456,358.68800000000016,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89916.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",85,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,361.2160000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",86,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,363.80800000000016,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",87,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,367.52000000000015,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",88,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.592,370.11200000000014,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",89,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,372.7040000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",90,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,375.74400000000014,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",91,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,378.81600000000014,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",92,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10024192.0,24576.0,14.944,393.76000000000016,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313256.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",93,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,396.67200000000014,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",94,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10050816.0,24576.0,15.584,412.25600000000014,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314088.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",95,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,414.91200000000015,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",96,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11501824.0,6144.0,21.664,436.57600000000014,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359432.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",97,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,439.0720000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",98,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.688,441.7600000000001,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",99,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,445.50400000000013,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",100,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,447.96800000000013,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",101,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,450.5600000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",102,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,453.5680000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",103,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.168,456.7360000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",104,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,8.224,464.9600000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",105,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,7.328,472.28800000000007,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",106,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875904.0,6144.0,7.936,480.22400000000005,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89872.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",107,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,483.32800000000003,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",108,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,486.36800000000005,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",109,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,490.0160000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",110,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,493.0880000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",111,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,495.7120000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",112,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,498.8480000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",113,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,2.976,501.8240000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",114,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,505.47200000000015,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",115,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,508.6080000000002,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",116,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,511.1680000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",117,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.192,531.3600000000001,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",118,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.776,539.1360000000001,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",119,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,541.696,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",120,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.624,544.32,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",121,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,548.0640000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",122,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,550.4960000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",123,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,553.1200000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",124,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,556.1600000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",125,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.168,559.3280000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",126,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10024832.0,24576.0,15.328,574.6560000000001,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313276.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",127,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,577.5680000000001,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",128,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10085888.0,24608.0,14.784,592.3520000000001,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315184.0,769.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",129,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,594.912,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",130,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11504640.0,6144.0,20.48,615.392,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359520.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",131,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,617.952,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",132,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,620.544,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",133,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,624.256,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",134,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,626.688,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",135,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,629.28,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",136,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,632.352,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",137,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,635.3919999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",138,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.584,642.9759999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",139,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.904,650.8799999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",140,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,8.128,659.0079999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",141,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,662.112,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",142,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.2,665.312,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",143,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,668.96,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",144,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,672.0640000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",145,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,674.5920000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",146,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,677.7920000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",147,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.264,681.0560000000002,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",148,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.68,684.7360000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",149,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,687.9360000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",150,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,690.4960000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",151,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.384,710.8800000000001,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",152,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.2,718.0800000000002,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",153,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,720.7040000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",154,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.624,723.3280000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",155,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,727.0720000000002,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",156,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.592,729.6640000000002,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",157,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,732.2560000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",158,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,735.2960000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",159,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,738.3680000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",160,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10087680.0,24576.0,14.976,753.3440000000002,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315240.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",161,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.104,756.4480000000002,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",162,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10091136.0,24576.0,14.816,771.2640000000002,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315348.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",163,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,773.8880000000003,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",164,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505152.0,6144.0,21.696,795.5840000000003,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359536.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",165,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,798.1440000000002,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",166,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,800.7040000000002,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",167,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,804.3840000000001,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",168,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,806.9120000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",169,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,809.4720000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",170,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,812.6080000000001,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",171,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,815.648,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",172,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6176.0,7.616,823.264,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,193.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",173,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.808,831.072,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",174,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876544.0,6144.0,7.648,838.72,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89892.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",175,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,841.8240000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",176,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,844.8960000000001,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",177,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.744,848.6400000000001,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",178,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,851.7760000000001,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",179,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,854.3040000000001,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",180,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,857.44,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",181,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,860.48,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",182,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,864.064,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",183,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,867.2959999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",184,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,869.824,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",185,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.288,890.112,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",186,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.584,897.6959999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",187,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,900.2239999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",188,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,902.7199999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",189,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,906.4639999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",190,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,909.0239999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",191,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,911.6159999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",192,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,914.6559999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",193,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,917.6959999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",194,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10147968.0,24576.0,14.464,932.1599999999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,317124.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",195,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,3.008,935.1679999999999,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",196,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10004224.0,24576.0,15.296,950.4639999999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312632.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",197,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,953.0559999999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",198,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11506432.0,6144.0,20.864,973.92,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359576.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",199,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,976.5759999999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",200,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,979.1039999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",201,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,982.8799999999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",202,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,985.3439999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",203,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,988.064,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",204,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,991.072,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",205,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,994.112,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",206,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.872,1001.9839999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",207,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.424,1009.4079999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",208,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,7.872,1017.2799999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",209,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,1020.3519999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",210,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,1023.4239999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",211,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1027.04,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",212,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,1030.1119999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",213,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1032.6719999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",214,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1035.7759999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",215,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1038.8159999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",216,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,1042.4639999999997,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",217,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1045.5679999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",218,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1048.1279999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",219,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.16,1068.2879999999998,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",220,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.36,1075.6479999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",221,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,1078.3679999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",222,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,1080.8639999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",223,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,1084.6079999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",224,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.336,1086.9439999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",225,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1089.5039999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",226,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,1092.5439999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",227,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1095.5839999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",228,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10078080.0,24576.0,15.104,1110.6879999999996,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314940.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",229,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.976,1113.6639999999998,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",230,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10052480.0,24576.0,15.872,1129.5359999999998,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314140.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",231,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,1132.128,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",232,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11518720.0,6144.0,21.664,1153.792,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359960.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",233,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1156.384,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",234,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,1158.912,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",235,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,1162.624,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",236,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1165.0240000000001,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",237,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1167.6480000000001,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",238,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,1170.7520000000002,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",239,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,1173.824,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",240,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.36,1181.184,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",241,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.744,1188.9279999999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",242,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.968,1196.896,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",243,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1200.032,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",244,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.136,1203.168,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",245,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,1206.8159999999998,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",246,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1209.9519999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",247,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,1212.6079999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",248,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,1215.7759999999996,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",249,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,1218.7839999999997,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",250,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1222.3999999999996,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",251,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1225.5039999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",252,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,1228.0319999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",253,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.128,1248.1599999999996,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",254,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.776,1255.9359999999997,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",255,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,1258.5919999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",256,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.624,1261.2159999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",257,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,1264.9599999999996,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",258,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.528,1267.4879999999996,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",259,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,1270.1119999999996,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",260,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,1273.1199999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",261,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.168,1276.2879999999996,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",262,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10068736.0,24608.0,15.104,1291.3919999999996,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314648.0,769.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",263,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,1294.3039999999996,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",264,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10002688.0,24576.0,16.288,1310.5919999999996,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312584.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",265,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,1313.2479999999996,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",266,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11501568.0,6144.0,22.24,1335.4879999999996,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359424.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",267,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,1338.1119999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",268,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,1340.6079999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",269,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,1344.4799999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",270,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,1346.9439999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",271,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1349.5359999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",272,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,1352.6399999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",273,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1355.6799999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",274,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.68,1363.36,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",275,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.552,1370.9119999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",276,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.52,1378.4319999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",277,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1381.5359999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",278,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,1384.5439999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",279,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,1388.1919999999998,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",280,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,1391.3599999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",281,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,1393.9519999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",282,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,1397.0559999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",283,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,1400.0959999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",284,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,1403.7119999999998,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",285,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,1406.8479999999997,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",286,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,1409.4079999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",287,24576.0,2255616.0,0.0,0,0.0,2255616.0,2255616.0,12480.0,24.0,0.9980806142034548,18432.0,6144.0,20.448,1429.8559999999998,1909248.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,576.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",288,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.776,1437.6319999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",289,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,1440.128,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",290,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.656,1442.7839999999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",291,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,1446.6239999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",292,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,1449.024,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",293,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,1451.616,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",294,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,1454.6879999999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",295,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.008,1457.696,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",296,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10051712.0,24576.0,15.072,1472.7679999999998,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314116.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",297,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.848,1475.6159999999998,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",298,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10113792.0,24576.0,15.232,1490.8479999999997,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,316056.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",299,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.656,1493.5039999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",300,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11508096.0,6144.0,21.248,1514.7519999999997,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359628.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",301,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.688,1517.4399999999998,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",302,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,1519.936,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",303,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.68,1523.616,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",304,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,1526.048,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",305,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,1528.608,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",306,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,1531.6799999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",307,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,1534.7199999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),308,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,10000.0,0.9962249905624764,99826432.0,1280000.0,164.8,1699.5199999999998,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3119576.0,40000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",309,64000.0,384000.0,128000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1280000.0,256000.0,10.048,1709.5679999999998,320000.0,64000.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,8000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",310,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.208,1711.7759999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",311,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.528,1714.3039999999999,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",312,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.432,1716.7359999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",313,0.0,64512.0,0.0,0,0.0,64512.0,64512.0,0.0,1024.0,0.0,256000.0,256000.0,2.848,1719.5839999999998,0.0,64512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",314,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.176,1721.7599999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",315,96256.0,0.0,192512.0,0,0.0,192512.0,192512.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,4.096,1725.8559999999998,0.0,0.0,0.0,96256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",316,55296.0,0.0,110592.0,0,0.0,110592.0,110592.0,4224.0,17220.0,0.1969781757134863,1054720.0,0.0,4.704,1730.5599999999997,0.0,0.0,0.0,55296.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",317,32384.0,0.0,64768.0,0,0.0,64768.0,64768.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,4.224,1734.7839999999997,0.0,0.0,0.0,32384.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",318,67584.0,0.0,135168.0,0,0.0,135168.0,135168.0,4224.0,17604.0,0.19351291918636612,1054720.0,0.0,4.832,1739.6159999999998,0.0,0.0,0.0,67584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",319,32260.0,0.0,64520.0,0,0.0,64520.0,64520.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,4.0,1743.6159999999998,0.0,0.0,0.0,32260.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",320,57344.0,0.0,114688.0,0,0.0,114688.0,114688.0,4224.0,17284.0,0.19639204017109912,1054720.0,0.0,4.896,1748.5119999999997,0.0,0.0,0.0,57344.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",321,32258.0,0.0,64516.0,0,0.0,64516.0,64516.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,3.904,1752.4159999999997,0.0,0.0,0.0,32258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",322,67584.0,0.0,135168.0,0,0.0,135168.0,135168.0,4224.0,17604.0,0.19351291918636612,1054720.0,64.0,4.864,1757.2799999999997,0.0,0.0,0.0,67584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",323,448.0,0.0,896.0,0,0.0,896.0,896.0,0.0,6.0,0.0,2080.0,256.0,3.008,1760.2879999999998,0.0,0.0,0.0,448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",324,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,1762.3039999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",325,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,256.0,0.0,4.224,1766.5279999999998,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",326,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,1768.6399999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",327,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,256.0,0.0,4.352,1772.992,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",328,80584.0,0.0,161168.0,0,0.0,161168.0,161168.0,13284.0,4208.0,0.7594328836039332,263616.0,3680.0,6.08,1779.072,0.0,0.0,0.0,80584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8238.0,115.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",329,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.272,1785.3439999999998,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",330,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,259744.0,16000.0,4.0,1789.3439999999998,0.0,0.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8117.0,500.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",331,8064.0,0.0,16128.0,0,0.0,16128.0,16128.0,0.0,1536.0,0.0,320000.0,0.0,3.936,1793.2799999999997,0.0,0.0,0.0,8064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",332,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,0.0,2000.0,0.0,0.0,512000.0,2.496,1795.7759999999998,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",333,387402.0,0.0,774804.0,0,0.0,774804.0,774804.0,64512.0,2000.0,0.9699302381525138,256000.0,0.0,4.064,1799.84,0.0,0.0,0.0,387402.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",334,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.56,1802.3999999999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",335,59520.0,0.0,119040.0,0,0.0,119040.0,119040.0,20832.0,8649.0,0.7066246056782335,829824.0,602080.0,15.104,1817.504,0.0,0.0,0.0,59520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25932.0,18815.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",336,23552.0,0.0,47104.0,0,0.0,47104.0,47104.0,5440.0,8598.0,0.38751958968514033,828800.0,780288.0,12.864,1830.368,0.0,0.0,0.0,23552.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25900.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",337,24960.0,0.0,49920.0,0,0.0,49920.0,49920.0,6792.0,8659.0,0.43958319849847904,824320.0,780672.0,13.984,1844.3519999999999,0.0,0.0,0.0,24960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25760.0,24396.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",338,24960.0,0.0,49920.0,0,0.0,49920.0,49920.0,6792.0,8559.0,0.4424467461403166,824320.0,687552.0,14.336,1858.6879999999999,0.0,0.0,0.0,24960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25760.0,21486.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",339,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,2000.0,0.8246844319775596,512000.0,0.0,3.808,1862.4959999999999,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",340,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.56,1865.0559999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",341,16524.0,0.0,33048.0,0,0.0,33048.0,33048.0,5276.0,4594.0,0.534549138804458,567296.0,440768.0,7.008,1872.0639999999999,0.0,0.0,0.0,16524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,17728.0,13774.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",342,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,0.0,8000.0,0.0,774432.0,768000.0,3.904,1875.9679999999998,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,24201.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",343,1048988.0,2122560.0,305976.0,0,0.0,2428536.0,2428536.0,264.0,2624.0,0.09141274238227147,502400.0,256000.0,18.592,1894.56,266560.0,64000.0,896000.0,152988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15700.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",344,68608.0,327744.0,137216.0,0,0.0,464960.0,464960.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,50.624,1945.184,327744.0,0.0,0.0,68608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",345,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,1024.0,0.0,256000.0,63616.0,2.72,1947.904,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",346,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.176,1950.08,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",347,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,0.0,6000.0,0.0,576000.0,24896.0,9.088,1959.168,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18000.0,778.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",348,8064.0,0.0,16128.0,0,0.0,16128.0,16128.0,0.0,1536.0,0.0,320000.0,0.0,3.968,1963.136,0.0,0.0,0.0,8064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",349,1048994.0,2122560.0,305988.0,0,0.0,2428548.0,2428548.0,264.0,2624.0,0.09141274238227147,512128.0,256000.0,18.4,1981.536,266560.0,64000.0,896000.0,152994.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16004.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",350,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,16.736,1998.2720000000002,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",351,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2000.7040000000002,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",352,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,16.352,2017.0560000000003,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",353,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,2019.4880000000003,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",354,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.624,2022.1120000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",355,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.264,2025.3760000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",356,4096.0,73600.0,8192.0,0,0.0,81792.0,81792.0,152.0,502.0,0.2324159021406728,256000.0,64.0,9.536,2034.9120000000003,73600.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",357,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.432,2037.3440000000003,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",358,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.232,2040.5760000000002,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",359,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,2043.0080000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",360,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.232,2046.2400000000002,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",361,896000.0,1280000.0,640000.0,0,0.0,1920000.0,1920000.0,0.0,2000.0,0.0,0.0,256000.0,3.072,2049.3120000000004,0.0,128000.0,576000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",362,387362.0,645120.0,129604.0,0,0.0,774724.0,774724.0,0.0,1536.0,0.0,512000.0,0.0,4.192,2053.5040000000004,0.0,0.0,322560.0,64802.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",363,37120.0,0.0,74240.0,0,0.0,74240.0,74240.0,304.0,502.0,0.3771712158808933,256000.0,64.0,12.96,2066.4640000000004,0.0,0.0,0.0,37120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",364,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,2068.896,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",365,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,2071.3920000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",366,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.464,2073.856,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",367,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,2076.3520000000003,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",368,258.0,0.0,516.0,0,0.0,516.0,516.0,0.0,6.0,0.0,64.0,64.0,2.496,2078.8480000000004,0.0,0.0,0.0,258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",369,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.016,2080.8640000000005,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",370,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,2082.9120000000003,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",371,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.688,2085.6000000000004,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",372,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,2087.648,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",373,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.528,2090.176,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",374,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,3.0,0.0,32.0,32.0,4.064,2094.24,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",375,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.528,2096.7679999999996,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",376,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,2099.1999999999994,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",377,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.04,2102.2399999999993,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",378,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.232,2105.4719999999993,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",379,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.496,2107.9679999999994,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<long>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], std::array<char *, 2>>(int, T2, T3)",380,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.464,2110.4319999999993,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::index_elementwise_kernel<128, 4, void native::gpu_index_kernel<void native::index_kernel_impl<native::OpaqueType<8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, const char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(long, T3)",381,132.0,0.0,264.0,0,0.0,264.0,264.0,0.0,3.0,0.0,64.0,32.0,3.232,2113.6639999999993,0.0,0.0,0.0,132.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::tensor_kernel_scan_innermost_dim<long, std::plus<long>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",382,1088.0,0.0,2176.0,0,0.0,2176.0,2176.0,36.0,2.0,0.9473684210526315,32.0,32.0,2.848,2116.5119999999993,0.0,0.0,0.0,1088.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",383,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.4,2118.9119999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",384,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.432,2121.343999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<2, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",385,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,0.0,2.464,2123.807999999999,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,0.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",386,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.496,2126.303999999999,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, 2, 2, (int)-2>(cuda::TensorInfo<T1, T3>, cuda::TensorInfo<const T1, T3>, cuda::TensorInfo<const T2, T3>, int, int, T3, long)",387,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,144.0,0.0,6336.0,6144.0,4.0,2130.303999999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 11)]::operator ()() const::[lambda(bool) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",388,8.0,0.0,16.0,0,0.0,16.0,16.0,0.0,2.0,0.0,32.0,32.0,2.88,2133.1839999999993,0.0,0.0,0.0,8.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::and_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",389,12.0,0.0,24.0,0,0.0,24.0,24.0,0.0,2.0,0.0,32.0,32.0,3.296,2136.479999999999,0.0,0.0,0.0,12.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 3)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>, 8, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<1>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",390,518.0,0.0,1036.0,0,0.0,1036.0,1036.0,0.0,2.0,0.0,32.0,32.0,2.752,2139.231999999999,0.0,0.0,0.0,518.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void gemmk1_kernel<int, float, 256, 5, 1, 0, 0, 0, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float, 0>(cublasGemmk1Params<T2, T9, T10, T11, T12, biasType<T11::value_type, T12>::type>)",391,0.0,256.0,0.0,0,0.0,256.0,256.0,16.0,12.0,0.5714285714285714,640.0,512.0,2.624,2141.855999999999,0.0,256.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,20.0,16.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 3, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",392,320.0,0.0,640.0,0,0.0,640.0,640.0,0.0,10.0,0.0,1024.0,1024.0,2.528,2144.3839999999987,0.0,0.0,0.0,320.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::cos_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",393,2816.0,4616.0,1536.0,0,0.0,6152.0,6152.0,0.0,16.0,0.0,1024.0,1024.0,3.008,2147.3919999999985,8.0,512.0,2048.0,768.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",394,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.496,2149.8879999999986,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::sin_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",395,2688.0,4608.0,1280.0,0,0.0,5888.0,5888.0,0.0,16.0,0.0,1024.0,1024.0,3.008,2152.8959999999984,0.0,512.0,2048.0,640.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",396,0.0,1024.0,0.0,0,0.0,1024.0,1024.0,0.0,16.0,0.0,1024.0,1024.0,2.528,2155.423999999998,0.0,1024.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32.0,32.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",397,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2157.951999999998,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",398,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.872,2161.823999999998,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",399,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2164.223999999998,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",400,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2166.815999999998,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",401,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,2169.951999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",402,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,2172.991999999998,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",403,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.616,2180.607999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",404,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.808,2188.415999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",405,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.744,2196.159999999998,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",406,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2199.295999999998,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",407,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,2202.303999999998,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",408,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,2205.919999999998,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",409,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,2209.0239999999976,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",410,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,2211.6799999999976,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",411,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2214.8159999999975,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",412,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,2217.8879999999976,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",413,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.616,2221.5039999999976,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",414,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2224.6399999999976,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",415,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,2227.1359999999977,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",416,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,2229.6959999999976,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",417,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.528,2232.2239999999974,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",418,23392.0,2253276.0,0.0,0,0.0,2253276.0,2253276.0,12511.0,24.0,0.9980853609892302,30720.0,6144.0,20.64,2252.8639999999973,1909387.0,297105.0,23392.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",419,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2878976.0,6144.0,7.616,2260.4799999999973,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89968.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",420,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2263.007999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",421,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2265.535999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",422,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.904,2269.439999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",423,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,2271.935999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",424,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2274.495999999997,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",425,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,2277.535999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",426,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,2280.575999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",427,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10099968.0,24576.0,14.4,2294.975999999997,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315624.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",428,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.944,2297.919999999997,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",429,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10103552.0,24576.0,14.976,2312.895999999997,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315736.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",430,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,2315.519999999997,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",431,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11502976.0,6144.0,20.864,2336.383999999997,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359468.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",432,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,2338.975999999997,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",433,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,2341.535999999997,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",434,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2345.279999999997,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",435,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2347.711999999997,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",436,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2350.2719999999968,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",437,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,2353.343999999997,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",438,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.008,2356.3519999999967,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",439,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875904.0,6144.0,7.424,2363.7759999999967,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89872.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",440,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.68,2371.4559999999965,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",441,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.936,2379.3919999999966,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",442,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2382.5279999999966,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",443,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,2385.5359999999964,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",444,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.584,2389.1199999999963,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",445,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,2392.1919999999964,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",446,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2394.7519999999963,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",447,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,2397.855999999996,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",448,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2400.895999999996,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",449,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,2404.5439999999962,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",450,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2407.679999999996,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",451,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2410.239999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",452,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,2412.799999999996,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",453,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.656,2415.455999999996,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",454,24000.0,2254872.0,0.0,0,0.0,2254872.0,2254872.0,12510.0,24.0,0.9980852082336046,30720.0,6144.0,20.416,2435.871999999996,1909710.0,297162.0,24000.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",455,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.392,2443.263999999996,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",456,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,2445.887999999996,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",457,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2448.4159999999956,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",458,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2452.1599999999958,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",459,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2454.5919999999956,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",460,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2457.2479999999955,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",461,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,2460.3519999999953,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",462,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,2463.4879999999953,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",463,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10048768.0,24576.0,14.72,2478.207999999995,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314024.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",464,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.976,2481.183999999995,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",465,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9981056.0,24576.0,15.872,2497.055999999995,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,311908.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",466,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,2499.615999999995,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",467,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11501696.0,6144.0,21.632,2521.247999999995,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359428.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",468,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2523.775999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",469,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2526.3039999999946,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",470,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2530.0799999999945,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",471,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2532.4799999999946,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",472,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,2535.0719999999947,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",473,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,2538.1759999999945,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",474,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,2541.3119999999944,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",475,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.36,2548.6719999999946,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",476,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.488,2556.1599999999944,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",477,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876544.0,6144.0,7.648,2563.8079999999945,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89892.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",478,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,2566.9759999999947,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",479,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,2570.0479999999948,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",480,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,2573.695999999995,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",481,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2576.831999999995,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",482,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2579.391999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",483,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2582.527999999995,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",484,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2585.5679999999948,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",485,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.712,2589.2799999999947,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",486,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,2592.5119999999947,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",487,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.496,2595.007999999995,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",488,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.688,2597.695999999995,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",489,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,2600.255999999995,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",490,24416.0,2255964.0,0.0,0,0.0,2255964.0,2255964.0,12495.0,24.0,0.9980829139707644,30720.0,6144.0,20.256,2620.5119999999947,1909931.0,297201.0,24416.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",491,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.744,2628.255999999995,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",492,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2630.7839999999946,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",493,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,2633.3119999999944,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",494,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,2637.1199999999944,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",495,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,2639.6799999999944,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",496,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,2642.3359999999943,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",497,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,2645.343999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",498,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,2648.4159999999943,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",499,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,9997824.0,24576.0,15.744,2664.1599999999944,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,312432.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",500,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,2667.0399999999945,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",501,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10100992.0,24576.0,14.976,2682.0159999999946,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315656.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",502,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,2684.6079999999947,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",503,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505408.0,6144.0,21.408,2706.0159999999946,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359544.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",504,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2708.5759999999946,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",505,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,2711.0719999999947,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",506,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,2714.815999999995,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",507,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,2717.2479999999946,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",508,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.528,2719.7759999999944,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",509,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.264,2723.0399999999945,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",510,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.104,2726.1439999999943,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",511,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.584,2733.727999999994,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",512,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.808,2741.535999999994,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",513,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.424,2748.959999999994,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",514,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2752.095999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",515,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2755.135999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",516,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,2758.783999999994,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",517,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,2761.9519999999943,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",518,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2764.479999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",519,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,2767.583999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",520,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,2770.655999999994,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",521,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,2774.303999999994,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",522,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.104,2777.407999999994,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",523,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2779.967999999994,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",524,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.752,2782.719999999994,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",525,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2785.311999999994,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",526,24480.0,2256132.0,0.0,0,0.0,2256132.0,2256132.0,12489.0,24.0,0.9980819947254855,30720.0,6144.0,20.32,2805.631999999994,1909965.0,297207.0,24480.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",527,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,7.392,2813.023999999994,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",528,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2815.5519999999938,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",529,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,2818.047999999994,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",530,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,2821.887999999994,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",531,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.56,2824.447999999994,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",532,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,2827.007999999994,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",533,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,2830.1119999999937,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",534,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,2833.183999999994,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",535,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10048640.0,24576.0,15.04,2848.223999999994,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314020.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",536,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.944,2851.1679999999938,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",537,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10069120.0,24608.0,15.104,2866.2719999999936,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314660.0,769.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",538,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.56,2868.8319999999935,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",539,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11506304.0,6144.0,21.312,2890.1439999999934,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359572.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",540,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2892.671999999993,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",541,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,2895.1679999999933,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",542,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,2898.943999999993,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",543,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.4,2901.3439999999932,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",544,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,2903.967999999993,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",545,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.136,2907.103999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",546,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.104,2910.207999999993,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",547,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.712,2917.919999999993,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",548,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.84,2925.759999999993,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",549,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.872,2933.631999999993,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",550,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,2936.799999999993,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",551,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.008,2939.8079999999927,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",552,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.68,2943.4879999999926,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",553,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.232,2946.7199999999925,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",554,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,2949.2799999999925,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",555,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2952.4159999999924,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",556,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,2955.4559999999924,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",557,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.712,2959.1679999999924,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",558,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,2962.3039999999924,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",559,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,2964.831999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",560,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.688,2967.5199999999923,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",561,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,2970.1119999999923,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",562,24480.0,2256132.0,0.0,0,0.0,2256132.0,2256132.0,12489.0,24.0,0.9980819947254855,30720.0,6144.0,20.384,2990.4959999999924,1909965.0,297207.0,24480.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",563,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.552,2998.0479999999925,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",564,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3000.5759999999923,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",565,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.592,3003.1679999999924,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",566,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,3007.0079999999925,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",567,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3009.4399999999923,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",568,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.624,3012.063999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",569,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,3015.1359999999922,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",570,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,3018.175999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",571,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10079744.0,24576.0,15.104,3033.279999999992,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314992.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",572,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,3036.159999999992,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",573,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10047616.0,24576.0,14.72,3050.879999999992,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313988.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",574,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.592,3053.471999999992,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",575,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11504000.0,6144.0,20.736,3074.207999999992,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359500.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",576,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.72,3076.9279999999917,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",577,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,3079.4879999999916,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",578,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,3083.327999999992,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",579,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.496,3085.823999999992,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",580,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.56,3088.383999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",581,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,3091.455999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",582,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,3094.591999999992,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",583,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2876160.0,6144.0,7.36,3101.951999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89880.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",584,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.648,3109.599999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",585,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875520.0,6144.0,7.424,3117.023999999992,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89860.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",586,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.168,3120.1919999999923,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",587,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,3123.2639999999924,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",588,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3126.9119999999925,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",589,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3130.0479999999925,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",590,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3132.6399999999926,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",591,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,3135.9039999999927,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",592,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3139.071999999993,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",593,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.808,3142.879999999993,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",594,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3146.015999999993,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",595,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3148.5759999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",596,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3151.1359999999927,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",597,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.848,3153.9839999999926,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",598,24480.0,2256132.0,0.0,0,0.0,2256132.0,2256132.0,12489.0,24.0,0.9980819947254855,30720.0,6144.0,20.288,3174.2719999999927,1909965.0,297207.0,24480.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",599,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875904.0,6144.0,7.424,3181.6959999999926,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89872.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",600,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.688,3184.3839999999927,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",601,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,3186.879999999993,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",602,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.712,3190.591999999993,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",603,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3193.0559999999928,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",604,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.656,3195.7119999999927,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",605,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,3198.7199999999925,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",606,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3201.7919999999926,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",607,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10048000.0,24576.0,15.328,3217.1199999999926,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314000.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",608,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,3220.0319999999924,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",609,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10062592.0,24576.0,15.008,3235.0399999999922,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314456.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",610,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3237.663999999992,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",611,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11512064.0,6144.0,21.248,3258.911999999992,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359752.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",612,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3261.503999999992,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",613,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.624,3264.127999999992,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",614,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.808,3267.935999999992,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",615,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3270.3679999999918,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",616,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3272.959999999992,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",617,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.104,3276.0639999999917,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",618,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.008,3279.0719999999915,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",619,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.776,3286.8479999999913,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",620,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.68,3294.527999999991,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",621,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875776.0,6144.0,7.584,3302.111999999991,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89868.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",622,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3305.247999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",623,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,3308.319999999991,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",624,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3311.967999999991,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",625,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3315.103999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",626,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3317.727999999991,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",627,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.072,3320.799999999991,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",628,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.072,3323.871999999991,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",629,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.648,3327.5199999999913,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",630,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.264,3330.7839999999915,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",631,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3333.3439999999914,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",632,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3335.9359999999915,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",633,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.56,3338.4959999999915,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",634,24480.0,2256132.0,0.0,0,0.0,2256132.0,2256132.0,12489.0,24.0,0.9980819947254855,30720.0,6144.0,20.224,3358.7199999999916,1909965.0,297207.0,24480.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",635,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2877440.0,6144.0,7.584,3366.3039999999914,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89920.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",636,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.528,3368.8319999999912,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",637,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,3371.391999999991,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",638,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.84,3375.2319999999913,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",639,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3377.663999999991,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",640,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.752,3380.415999999991,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",641,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.008,3383.423999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",642,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,3386.559999999991,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",643,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10063488.0,24576.0,14.816,3401.3759999999907,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,314484.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",644,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.88,3404.2559999999908,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",645,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10128128.0,24576.0,14.528,3418.7839999999906,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,316504.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",646,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3421.4079999999904,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",647,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11505664.0,6144.0,20.608,3442.0159999999905,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359552.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",648,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.56,3444.5759999999905,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",649,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.528,3447.1039999999903,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",650,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,3450.8479999999904,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",651,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3453.3119999999903,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",652,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.72,3456.03199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",653,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,3459.1039999999903,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",654,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.04,3462.1439999999902,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",655,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.584,3469.72799999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",656,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.456,3477.18399999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",657,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875648.0,6144.0,7.552,3484.7359999999903,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89864.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",658,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3487.8719999999903,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",659,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.04,3490.9119999999903,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",660,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.712,3494.6239999999902,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",661,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.136,3497.75999999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",662,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.752,3500.51199999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",663,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,3503.71199999999,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::neg_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",664,1152.0,768.0,2304.0,0,0.0,3072.0,3072.0,0.0,48.0,0.0,3072.0,3072.0,3.168,3506.87999999999,768.0,0.0,0.0,1152.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,96.0,96.0
"void native::<unnamed>::CatArrayBatchedCopy<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 64, 64>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",665,175104.0,0.0,350208.0,0,0.0,350208.0,350208.0,0.0,96.0,0.0,6144.0,6144.0,3.68,3510.55999999999,0.0,0.0,0.0,175104.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",666,4608.0,1536.0,9216.0,0,0.0,10752.0,10752.0,0.0,144.0,0.0,9216.0,6144.0,3.2,3513.7599999999898,0.0,1536.0,0.0,4608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,288.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",667,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.592,3516.35199999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",668,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.592,3518.94399999999,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<4>, unsigned int, 4, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",669,2304.0,0.0,4608.0,0,0.0,4608.0,4608.0,0.0,120.0,0.0,12288.0,12288.0,2.624,3521.5679999999898,0.0,0.0,0.0,2304.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,384.0
"fmha_cutlassF_f32_aligned_64x128_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, arch::Sm80, 1, 64, 128, 128, 1, 1>::Params)",670,24576.0,2256384.0,0.0,0,0.0,2256384.0,2256384.0,12480.0,24.0,0.9980806142034548,30720.0,6144.0,20.416,3541.98399999999,1910016.0,297216.0,24576.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,960.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",671,1241088.0,2605056.0,122880.0,0,0.0,2727936.0,2727936.0,28800.0,23808.0,0.5474452554744526,2875392.0,6144.0,7.328,3549.31199999999,98304.0,147456.0,1179648.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,89856.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",672,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.656,3551.96799999999,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",673,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.496,3554.46399999999,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",674,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.744,3558.20799999999,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",675,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.432,3560.63999999999,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",676,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3563.23199999999,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",677,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.072,3566.30399999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",678,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.072,3569.37599999999,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",679,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10085376.0,24576.0,14.784,3584.1599999999903,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,315168.0,768.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",680,67584.0,129024.0,12288.0,0,0.0,141312.0,141312.0,0.0,96.0,0.0,24576.0,24576.0,2.912,3587.07199999999,6144.0,0.0,61440.0,6144.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,768.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",681,4964352.0,10420224.0,491520.0,0,0.0,10911744.0,10911744.0,115200.0,95232.0,0.5474452554744526,10028160.0,24576.0,15.232,3602.30399999999,393216.0,589824.0,4718592.0,245760.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,313380.0,768.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",682,0.0,6144.0,0.0,0,0.0,6144.0,6144.0,0.0,144.0,0.0,49152.0,24576.0,2.624,3604.92799999999,0.0,6144.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1536.0,768.0
"void gemmSN_TN_kernel<float, 128, 16, 2, 4, 2, 2, 1, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<T9, T10, T11, T1>)",683,4890624.0,10346496.0,344064.0,0,0.0,10690560.0,10690560.0,104832.0,92928.0,0.5300970873786408,11501568.0,6144.0,21.12,3626.0479999999898,319488.0,589824.0,4718592.0,172032.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,359424.0,192.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctor_add<float>, std::array<char *, 3>>(int, T2, T3)",684,2048.0,4096.0,0.0,0,0.0,4096.0,4096.0,0.0,72.0,0.0,12288.0,6144.0,2.624,3628.6719999999896,0.0,0.0,2048.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
"void native::vectorized_elementwise_kernel<4, void native::<unnamed>::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase &, T2)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",685,128.0,1536.0,256.0,0,0.0,1792.0,1792.0,0.0,48.0,0.0,6144.0,6144.0,2.56,3631.2319999999895,0.0,1536.0,0.0,128.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,192.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>>(T3)",686,1024.0,3778.0,2048.0,0,0.0,5826.0,5826.0,20.0,14.0,0.5882352941176471,6144.0,32.0,3.776,3635.0079999999894,3776.0,2.0,0.0,1024.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,192.0,1.0
"void native::vectorized_elementwise_kernel<4, native::CUDAFunctorOnSelf_add<float>, std::array<char *, 2>>(int, T2, T3)",687,1024.0,2048.0,0.0,0,0.0,2048.0,2048.0,0.0,2.0,0.0,32.0,32.0,2.464,3637.4719999999893,0.0,0.0,1024.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::rsqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",688,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.592,3640.0639999999894,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",689,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,6336.0,6144.0,3.04,3643.1039999999894,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,198.0,192.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<float, float, float, binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",690,3072.0,1536.0,6144.0,0,0.0,7680.0,7680.0,0.0,144.0,0.0,12288.0,6144.0,3.136,3646.2399999999893,0.0,1536.0,0.0,3072.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,384.0,192.0
void cutlass::Kernel2<cutlass_80_simt_sgemm_128x32_8x5_tn_align1>(T1::Params),691,786752000.0,1577984000.0,640000.0,0,0.0,1578624000.0,1578624000.0,2639000.0,10000.0,0.9962249905624764,99824864.0,1280000.0,163.68,3809.919999999989,0.0,5120000.0,786432000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3119527.0,40000.0
"void cublasLt::splitKreduce_kernel<32, 16, int, float, float, float, float, 0, float, float, float, 1, 0, 0>(cublasLt::cublasSplitKParams<T6>, const T4 *, const T10 *, T9 *, T5 *, const T6 *, const T6 *, const T11 *, const T4 *, T11 *, void *, long, T6 *, int *, T6 *, T6 *, const T6 *, const T6 *, const T6 *, const T6 *, const T6 *)",692,64000.0,384000.0,128000.0,0,0.0,512000.0,512000.0,0.0,12000.0,0.0,1280000.0,256000.0,9.984,3819.903999999989,320000.0,64000.0,0.0,64000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40000.0,8000.0
"void native::vectorized_elementwise_kernel<2, native::FillFunctor<long>, std::array<char *, 1>>(int, T2, T3)",693,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.144,3822.047999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",694,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.56,3824.607999999989,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnSelf_add<long>, std::array<char *, 2>>(int, T2, T3)",695,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.496,3827.103999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BUnaryFunctor<float, float, float, binary_internal::MulFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",696,0.0,64512.0,0.0,0,0.0,64512.0,64512.0,0.0,1024.0,0.0,256000.0,256000.0,2.976,3830.079999999989,0.0,64512.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,8000.0
"void mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)",697,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,32.0,2.048,3832.127999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",698,96256.0,0.0,192512.0,0,0.0,192512.0,192512.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,4.064,3836.1919999999886,0.0,0.0,0.0,96256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",699,55296.0,0.0,110592.0,0,0.0,110592.0,110592.0,4224.0,17220.0,0.1969781757134863,1054720.0,0.0,4.736,3840.9279999999885,0.0,0.0,0.0,55296.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",700,32378.0,0.0,64756.0,0,0.0,64756.0,64756.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,3.936,3844.8639999999887,0.0,0.0,0.0,32378.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",701,67584.0,0.0,135168.0,0,0.0,135168.0,135168.0,4224.0,17604.0,0.19351291918636612,1054720.0,0.0,4.608,3849.471999999989,0.0,0.0,0.0,67584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",702,32267.0,0.0,64534.0,0,0.0,64534.0,64534.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,4.064,3853.5359999999887,0.0,0.0,0.0,32267.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",703,59392.0,0.0,118784.0,0,0.0,118784.0,118784.0,4224.0,17348.0,0.19580938253291302,1054720.0,0.0,4.8,3858.335999999989,0.0,0.0,0.0,59392.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,0.0
"void mbtopk::radixFindKthValues<float, unsigned int, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, unsigned int, unsigned int *, unsigned int, T2, int, int, unsigned int, T3, T3 *, short *)",704,32258.0,0.0,64516.0,0,0.0,64516.0,64516.0,1024.0,3024.0,0.25296442687747034,258048.0,16384.0,3.936,3862.271999999989,0.0,0.0,0.0,32258.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8064.0,512.0
"void mbtopk::computeBlockwiseWithinKCounts<unsigned int, float>(T1 *, short *, unsigned int *, unsigned int, int, bool, unsigned int *, T2 *, unsigned int *, T1 *, unsigned int)",705,61440.0,0.0,122880.0,0,0.0,122880.0,122880.0,4224.0,17412.0,0.19523017193566278,1054720.0,64.0,4.64,3866.911999999989,0.0,0.0,0.0,61440.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,32960.0,2.0
"void mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsigned int, unsigned int *)",706,448.0,0.0,896.0,0,0.0,896.0,896.0,0.0,6.0,0.0,2080.0,256.0,3.136,3870.047999999989,0.0,0.0,0.0,448.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,65.0,8.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",707,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.016,3872.063999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",708,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,256.0,0.0,4.448,3876.511999999989,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,0.0
"void at_cuda_detail::DeviceScanByKeyInitKernel<at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>>(T1, T2, std::iterator_traits<T2>::value_type *, unsigned int, int)",709,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,0.0,544.0,2.112,3878.623999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,17.0
"void at_cuda_detail::DeviceScanByKeyKernel<at_cuda_detail::DeviceScanByKeyPolicy<at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int, unsigned int, __4::plus<void>>::Policy900, at_cuda_detail::TransformInputIterator<unsigned int, mbtopk::BlockIdxToKey, at_cuda_detail::CountingInputIterator<unsigned int, unsigned int>, long>, unsigned int *, unsigned int *, at_cuda_detail::ReduceByKeyScanTileState<unsigned int, int, 1>, __4::equal_to<void>, __4::plus<void>, at_cuda_detail::NullType, int, unsigned int, unsigned int>(T2, T11 *, T3, T4, T5, int, T6, T7, T8, T9)",710,576.0,0.0,1152.0,0,0.0,1152.0,1152.0,636.0,13.0,0.9799691833590138,256.0,0.0,4.48,3883.103999999989,0.0,0.0,0.0,576.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8.0,0.0
"void mbtopk::gatherTopK<float, unsigned int, 2>(cuda::TensorInfo<const T1, T2>, T2, T2, bool, unsigned int, T2, cuda::TensorInfo<T1, T2>, T2, cuda::TensorInfo<long, T2>, T2, unsigned int, unsigned int, T1 *, unsigned int *, unsigned int *, unsigned int)",711,80584.0,0.0,161168.0,0,0.0,161168.0,161168.0,17548.0,4212.0,0.8064338235294117,263616.0,3648.0,6.112,3889.215999999989,0.0,0.0,0.0,80584.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8238.0,114.0
"void native::radixSortKVInPlace<2, (int)-1, 32, 4, float, long, unsigned int>(cuda::TensorInfo<T5, T7>, T7, T7, T7, cuda::TensorInfo<T6, T7>, T7, bool)",712,256.0,0.0,512.0,0,0.0,512.0,512.0,916.0,16.0,0.9828326180257511,1280.0,0.0,6.24,3895.4559999999888,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,40.0,0.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::<unnamed>::CompareFunctor<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",713,128000.0,0.0,256000.0,0,0.0,256000.0,256000.0,0.0,6000.0,0.0,259744.0,16000.0,4.224,3899.679999999989,0.0,0.0,0.0,128000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8117.0,500.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",714,8064.0,0.0,16128.0,0,0.0,16128.0,16128.0,0.0,1536.0,0.0,320000.0,0.0,3.712,3903.391999999989,0.0,0.0,0.0,8064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10000.0,0.0
"native::<unnamed>::fill_index_and_segment_kernel(int2 *, int, cuda::IntDivider<unsigned int>)",715,192512.0,0.0,385024.0,0,0.0,385024.0,385024.0,0.0,2000.0,0.0,0.0,512000.0,2.528,3905.9199999999887,0.0,0.0,0.0,192512.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,16000.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",716,387397.0,0.0,774794.0,0,0.0,774794.0,774794.0,64512.0,2000.0,0.9699302381525138,256000.0,0.0,3.936,3909.855999999989,0.0,0.0,0.0,387397.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, unsigned long long>(T2 *)",717,0.0,0.0,0.0,0,0.0,0.0,0.0,128.0,64.0,0.6666666666666666,8192.0,0.0,2.592,3912.447999999989,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,256.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",718,59520.0,0.0,119040.0,0,0.0,119040.0,119040.0,20832.0,8694.0,0.705547652916074,833024.0,604800.0,15.04,3927.487999999989,0.0,0.0,0.0,59520.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,26032.0,18900.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",719,23552.0,0.0,47104.0,0,0.0,47104.0,47104.0,5440.0,8641.0,0.3863361977132306,829440.0,780288.0,13.088,3940.575999999989,0.0,0.0,0.0,23552.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25920.0,24384.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",720,24960.0,0.0,49920.0,0,0.0,49920.0,49920.0,6792.0,8621.0,0.4406669694413807,825088.0,780416.0,14.016,3954.591999999989,0.0,0.0,0.0,24960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25784.0,24388.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<float, cuda::OpaqueType<8>, unsigned long long>::Policy900, 0, float, cuda::OpaqueType<8>, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",721,24960.0,0.0,49920.0,0,0.0,49920.0,49920.0,6792.0,8645.0,0.4399818617607048,824576.0,690176.0,13.92,3968.5119999999893,0.0,0.0,0.0,24960.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,25768.0,21568.0
"void at_cuda_detail::DeviceRadixSortHistogramKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, unsigned long long, at_cuda_detail::identity_decomposer_t>(T4 *, const T3 *, T4, int, int, T5)",722,301056.0,0.0,602112.0,0,0.0,602112.0,602112.0,9408.0,2000.0,0.8246844319775596,512000.0,0.0,3.808,3972.3199999999892,0.0,0.0,0.0,301056.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void at_cuda_detail::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, unsigned long long>(T2 *)",723,0.0,0.0,0.0,0,0.0,0.0,0.0,32.0,16.0,0.6666666666666666,2048.0,0.0,2.592,3974.9119999999893,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,64.0,0.0
"void at_cuda_detail::DeviceRadixSortOnesweepKernel<at_cuda_detail::DeviceRadixSortPolicy<long, at_cuda_detail::NullType, unsigned long long>::Policy900, 0, long, at_cuda_detail::NullType, unsigned long long, int, int, at_cuda_detail::identity_decomposer_t>(T7 *, T7 *, T5 *, const T5 *, T3 *, const T3 *, T4 *, const T4 *, T6, int, int, T8)",724,16524.0,0.0,33048.0,0,0.0,33048.0,33048.0,5276.0,4596.0,0.5344408427876823,567296.0,440032.0,7.04,3981.9519999999893,0.0,0.0,0.0,16524.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,17728.0,13751.0
"void native::<unnamed>::sort_postprocess_kernel<float>(const T1 *, T1 *, long *, const int2 *, int, int)",725,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,0.0,8000.0,0.0,774464.0,768000.0,3.616,3985.5679999999893,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,24202.0,24000.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",726,1048988.0,2122560.0,305976.0,0,0.0,2428536.0,2428536.0,264.0,2624.0,0.09141274238227147,509568.0,256000.0,18.304,4003.8719999999894,266560.0,64000.0,896000.0,152988.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,15924.0,8000.0
"void native::tensor_kernel_scan_innermost_dim<float, std::plus<float>>(T1 *, const T1 *, unsigned int, unsigned int, unsigned int, T1, T2)",727,68608.0,327744.0,137216.0,0,0.0,464960.0,464960.0,35920.0,4000.0,0.8997995991983968,256000.0,256000.0,50.496,4054.3679999999895,327744.0,0.0,0.0,68608.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,8000.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",728,256.0,0.0,512.0,0,0.0,512.0,512.0,0.0,1024.0,0.0,256000.0,63616.0,2.784,4057.1519999999896,0.0,0.0,0.0,256.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1988.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::FillFunctor<bool>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",729,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,64.0,2.144,4059.2959999999894,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,2.0
"void native::_scatter_gather_elementwise_kernel<128, 8, void native::_cuda_scatter_gather_internal_kernel<1, native::OpaqueType<1>>::operator ()<native::TensorAssign>(at::TensorIterator &, long, long, long, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",730,192000.0,0.0,384000.0,0,0.0,384000.0,384000.0,0.0,6000.0,0.0,576000.0,24288.0,9.152,4068.4479999999894,0.0,0.0,0.0,192000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,18000.0,759.0
"void native::vectorized_elementwise_kernel<4, native::<unnamed>::masked_fill_kernel(at::TensorIterator &, const c10::Scalar &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float, bool) (instance 1)], std::array<char *, 3>>(int, T2, T3)",731,8064.0,0.0,16128.0,0,0.0,16128.0,16128.0,0.0,1536.0,0.0,320000.0,0.0,3.968,4072.4159999999893,0.0,0.0,0.0,8064.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,10000.0,0.0
"void native::<unnamed>::cunn_SoftMaxForward<4, float, float, float, native::<unnamed>::SoftMaxForwardEpilogue>(T4 *, const T2 *, int)",732,1048994.0,2122560.0,305988.0,0,0.0,2428548.0,2428548.0,264.0,2624.0,0.09141274238227147,519040.0,256000.0,18.944,4091.359999999989,266560.0,64000.0,896000.0,152994.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16220.0,8000.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MinNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",733,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,16.064,4107.423999999989,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",734,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,4109.855999999989,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::MaxNanFunctor<float>>, unsigned int, float, 4, 4>>(T3)",735,1536.0,0.0,3072.0,0,0.0,3072.0,3072.0,62.0,501.0,0.11012433392539965,256000.0,32.0,16.352,4126.207999999989,0.0,0.0,0.0,1536.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,1.0
"void native::vectorized_elementwise_kernel<4, void native::compare_scalar_kernel<float>(at::TensorIteratorBase &, native::<unnamed>::OpType, T1)::[lambda(float) (instance 1)], std::array<char *, 2>>(int, T2, T3)",736,129.0,0.0,258.0,0,0.0,258.0,258.0,0.0,2.0,0.0,32.0,32.0,2.432,4128.6399999999885,0.0,0.0,0.0,129.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseAndFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",737,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,3.0,0.0,64.0,32.0,2.496,4131.135999999989,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",738,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,4134.303999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::func_wrapper_t<float, native::sum_functor<float, float, float>::operator ()(at::TensorIterator &)::[lambda(float, float) (instance 1)]>, unsigned int, float, 4, 4>>(T3)",739,4096.0,73600.0,8192.0,0,0.0,81792.0,81792.0,152.0,502.0,0.2324159021406728,256000.0,64.0,9.76,4144.0639999999885,73600.0,0.0,0.0,4096.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<float, float, bool, native::<unnamed>::CompareEqFunctor<float>>, std::array<char *, 2>>(int, T2, T3)",740,130.0,0.0,260.0,0,0.0,260.0,260.0,0.0,2.0,0.0,32.0,32.0,2.432,4146.495999999988,0.0,0.0,0.0,130.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",741,6.0,0.0,12.0,0,0.0,12.0,12.0,0.0,2.0,0.0,32.0,32.0,3.264,4149.759999999988,0.0,0.0,0.0,6.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",742,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,2.0,0.0,32.0,32.0,2.432,4152.191999999988,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::_assert_async_cuda_kernel<bool>(const T1 *, native::Msg)",743,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,1.0,0.0,32.0,0.0,3.168,4155.359999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,0.0
"void native::<unnamed>::distribution_elementwise_grid_stride_kernel<float, 4, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void native::<unnamed>::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl *, void templates::uniform_and_transform<float, float, at::CUDAGeneratorImpl *, void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T3, T4)::[lambda(curandStatePhilox4_32_10 *) (instance 2)], void templates::exponential_kernel<at::CUDAGeneratorImpl *>(at::TensorIteratorBase &, double, T1)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, T4, const T5 &, T6)::[lambda(int, float) (instance 1)]>(long, at::PhiloxCudaState, T3, T4)",744,896000.0,1280000.0,640000.0,0,0.0,1920000.0,1920000.0,0.0,2000.0,0.0,0.0,256000.0,3.136,4158.495999999988,0.0,128000.0,576000.0,320000.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,8000.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<float, float, float, binary_internal::DivFunctor<float>>, std::array<char *, 3>>(int, T2, T3)",745,387362.0,645120.0,129604.0,0,0.0,774724.0,774724.0,0.0,1536.0,0.0,512000.0,0.0,3.968,4162.463999999988,0.0,0.0,322560.0,64802.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,16000.0,0.0
"void native::reduce_kernel<512, 1, native::ReduceOp<float, native::ArgMaxOps<float>, unsigned int, long, 4, 4>>(T3)",746,37120.0,0.0,74240.0,0,0.0,74240.0,74240.0,304.0,502.0,0.3771712158808933,256000.0,64.0,12.864,4175.327999999988,0.0,0.0,0.0,37120.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,8000.0,2.0
"void native::vectorized_elementwise_kernel<2, native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>, std::array<char *, 3>>(int, T2, T3)",747,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.432,4177.7599999999875,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctorOnOther_add<long>, std::array<char *, 2>>(int, T2, T3)",748,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,2.0,0.0,32.0,32.0,2.464,4180.223999999987,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::elementwise_kernel<128, 2, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, long, binary_internal::MulFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",749,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.496,4182.7199999999875,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<2, native::CUDAFunctor_add<long>, std::array<char *, 3>>(int, T2, T3)",750,0.0,0.0,0.0,0,0.0,0.0,0.0,0.0,3.0,0.0,64.0,32.0,2.496,4185.215999999988,0.0,0.0,0.0,0.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::<unnamed>::CatArrayBatchedCopy_aligned16_contig<native::<unnamed>::OpaqueType<8>, unsigned int, 2, 128, 1>(T1 *, native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, native::<unnamed>::TensorSizeStride<T2, 4>, int, T2)",751,259.0,0.0,518.0,0,0.0,518.0,518.0,0.0,6.0,0.0,64.0,64.0,2.528,4187.743999999988,0.0,0.0,0.0,259.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,2.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",752,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.08,4189.823999999988,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",753,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.016,4191.839999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",754,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.624,4194.463999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::FillFunctor<bool>, std::array<char *, 1>>(int, T2, T3)",755,2.0,0.0,4.0,0,0.0,4.0,4.0,0.0,1.0,0.0,0.0,32.0,2.048,4196.511999999987,0.0,0.0,0.0,2.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,0.0,1.0
"void native::elementwise_kernel<128, 4, void native::gpu_kernel_impl_nocast<native::BinaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)",756,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,96.0,32.0,2.528,4199.039999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,3.0,1.0
"void native::reduce_kernel<256, 2, native::ReduceOp<bool, native::func_wrapper_t<bool, native::or_kernel_cuda(at::TensorIterator &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 12)]::operator ()() const::[lambda(bool, bool) (instance 1)]>, unsigned int, bool, 4, 4>>(T3)",757,5.0,0.0,10.0,0,0.0,10.0,10.0,0.0,3.0,0.0,32.0,32.0,4.16,4203.199999999987,0.0,0.0,0.0,5.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::BinaryFunctor<bool, bool, bool, native::BitwiseOrFunctor<bool>>, std::array<char *, 3>>(int, T2, T3)",758,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,2.624,4205.823999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::vectorized_elementwise_kernel<4, native::bitwise_not_kernel_cuda(at::TensorIteratorBase &)::[lambda(bool) (instance 1)], std::array<char *, 2>>(int, T2, T3)",759,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,2.56,4208.383999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::unrolled_elementwise_kernel<native::BinaryFunctor<long, long, long, native::BitwiseAndFunctor<long>>, std::array<char *, 3>, 8, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, memory::LoadWithCast<2>, memory::StoreWithCast<1>>(int, T1, T2, T4, T5, T6, T7)",760,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,3.0,0.0,64.0,32.0,3.072,4211.455999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,2.0,1.0
"void native::reduce_kernel<512, 1, native::ReduceOp<long, native::func_wrapper_t<long, native::MaxNanFunctor<long>>, unsigned int, long, 4, 4>>(T3)",761,4.0,0.0,8.0,0,0.0,8.0,8.0,0.0,2.0,0.0,32.0,32.0,3.232,4214.687999999987,0.0,0.0,0.0,4.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
"void native::vectorized_elementwise_kernel<4, native::AUnaryFunctor<long, long, bool, native::<unnamed>::CompareEqFunctor<long>>, std::array<char *, 2>>(int, T2, T3)",762,1.0,0.0,2.0,0,0.0,2.0,2.0,0.0,2.0,0.0,32.0,32.0,2.432,4217.119999999987,0.0,0.0,0.0,1.0,0,0,0,0,0,0.0,0.0,0.0,0,0.0,1.0,1.0
